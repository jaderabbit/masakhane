{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "herman_en-af_masakhane2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Igc5itf-xMGj"
      },
      "source": [
        "# Masakhane - Machine Translation for African Languages (Using JoeyNMT)\n",
        "\n",
        "Languages: English-Afrikaans\n",
        "\n",
        "Author: Herman Kamper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "l929HimrxS0a"
      },
      "source": [
        "## Retrieve data and make a parallel corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oGRmDELn7Az0",
        "outputId": "ebcf8f37-aa36-4900-85c8-1a315db48536",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Cn3tgQLzUxwn",
        "colab": {}
      },
      "source": [
        "# TODO: Set your source and target languages. Keep in mind, these traditionally use language codes as found here:\n",
        "# These will also become the suffix's of all vocab and corpus files used throughout\n",
        "import os\n",
        "source_language = \"en\"\n",
        "target_language = \"af\"\n",
        "tag = \"baseline\" # Give a unique name to your folder - this is to ensure you don't rewrite any models you've already submitted\n",
        "\n",
        "os.environ[\"src\"] = source_language # Sets them in bash as well, since we often use bash scripts\n",
        "os.environ[\"tgt\"] = target_language\n",
        "os.environ[\"tag\"] = tag\n",
        "\n",
        "# This will save it to a folder in our gdrive instead!\n",
        "!mkdir -p \"/content/drive/My Drive/colab/masakhane/$src-$tgt-$tag\"\n",
        "os.environ[\"gdrive_path\"] = \"/content/drive/My Drive/colab/masakhane/%s-%s-%s\" % (source_language, target_language, tag)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kBSgJHEw7Nvx",
        "outputId": "c65e5114-6a08-41ef-854a-b3fbb70141f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!echo $gdrive_path"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/colab/masakhane/en-af-baseline\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xq-tDZVks7ZD",
        "outputId": "fbd92ed9-3de7-48ef-c5a4-16e528a53022",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 794
        }
      },
      "source": [
        "# Download the corpus\n",
        "! wget \"https://www.kamperh.com/data/siyavula_en_af.noweb.3.zip\"\n",
        "! unzip siyavula_en_af.noweb.3.zip\n",
        "! ls -lah\n",
        "! head -3 train.en\n",
        "! head -3 train.af\n",
        "! cat train.en | wc -l\n",
        "! cat train.af | wc -l"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-12 12:42:13--  https://www.kamperh.com/data/siyavula_en_af.noweb.3.zip\n",
            "Resolving www.kamperh.com (www.kamperh.com)... 185.199.110.153, 185.199.108.153, 185.199.109.153, ...\n",
            "Connecting to www.kamperh.com (www.kamperh.com)|185.199.110.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 303093 (296K) [application/zip]\n",
            "Saving to: ‘siyavula_en_af.noweb.3.zip’\n",
            "\n",
            "\r          siyavula_   0%[                    ]       0  --.-KB/s               \rsiyavula_en_af.nowe 100%[===================>] 295.99K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2019-10-12 12:42:13 (5.63 MB/s) - ‘siyavula_en_af.noweb.3.zip’ saved [303093/303093]\n",
            "\n",
            "Archive:  siyavula_en_af.noweb.3.zip\n",
            "  inflating: dev.af                  \n",
            "  inflating: dev.en                  \n",
            "  inflating: readme.md               \n",
            "  inflating: test.af                 \n",
            "  inflating: test.en                 \n",
            "  inflating: train.af                \n",
            "  inflating: train.en                \n",
            "total 1.4M\n",
            "drwxr-xr-x 1 root root 4.0K Oct 12 12:42 .\n",
            "drwxr-xr-x 1 root root 4.0K Oct 12 12:27 ..\n",
            "drwxr-xr-x 1 root root 4.0K Oct  8 20:06 .config\n",
            "-rw-rw-r-- 1 root root  29K Oct 11 11:50 dev.af\n",
            "-rw-rw-r-- 1 root root  28K Oct 11 11:50 dev.en\n",
            "drwx------ 3 root root 4.0K Oct 12 12:39 drive\n",
            "-rw-rw-r-- 1 root root  310 Oct 11 11:46 readme.md\n",
            "drwxr-xr-x 1 root root 4.0K Aug 27 16:17 sample_data\n",
            "-rw-r--r-- 1 root root 296K Oct 11 09:52 siyavula_en_af.noweb.3.zip\n",
            "-rw-rw-r-- 1 root root  33K Oct 11 11:50 test.af\n",
            "-rw-rw-r-- 1 root root  32K Oct 11 11:50 test.en\n",
            "-rw-rw-r-- 1 root root 461K Oct 11 11:50 train.af\n",
            "-rw-rw-r-- 1 root root 446K Oct 11 11:50 train.en\n",
            "how to introduce this topic\n",
            "remind them of the lessons in the last term of gr. 4 when they learnt about the earth sun moon and planets .\n",
            "use figure 1 to start them thinking about what is on the surface of the earth and under the surface of the earth .\n",
            "hoe om hierdie onderwerp bekend te stel\n",
            "herinner die leerders aan die lesse in die laaste kwartaal van graad 4 toe hulle van die aarde son maan en planete geleer het .\n",
            "gebruik figuur 1 om hulle aan die dink te kry oor wat op die oppervlakte van die aarde en onder die oppervlakte van die aarde is .\n",
            "6585\n",
            "6585\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "epeCydmCyS8X"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Installation of JoeyNMT\n",
        "\n",
        "JoeyNMT is a simple, minimalist NMT package which is useful for learning and teaching. Check out the documentation for JoeyNMT [here](https://joeynmt.readthedocs.io)  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iBRMm4kMxZ8L",
        "outputId": "ddb987bc-2117-4d9c-8b79-a64de0fdf942",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Install JoeyNMT\n",
        "! git clone https://github.com/joeynmt/joeynmt.git\n",
        "! cd joeynmt; pip3 install ."
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'joeynmt'...\n",
            "remote: Enumerating objects: 45, done.\u001b[K\n",
            "remote: Counting objects: 100% (45/45), done.\u001b[K\n",
            "remote: Compressing objects: 100% (35/35), done.\u001b[K\n",
            "remote: Total 2051 (delta 25), reused 22 (delta 10), pack-reused 2006\u001b[K\n",
            "Receiving objects: 100% (2051/2051), 2.39 MiB | 2.59 MiB/s, done.\n",
            "Resolving deltas: 100% (1414/1414), done.\n",
            "Processing /content/joeynmt\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from joeynmt==0.0.1) (0.16.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from joeynmt==0.0.1) (4.3.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from joeynmt==0.0.1) (1.16.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from joeynmt==0.0.1) (41.2.0)\n",
            "Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.6/dist-packages (from joeynmt==0.0.1) (1.2.0)\n",
            "Requirement already satisfied: tensorflow>=1.14 in /usr/local/lib/python3.6/dist-packages (from joeynmt==0.0.1) (1.15.0rc3)\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.6/dist-packages (from joeynmt==0.0.1) (0.3.1)\n",
            "Collecting sacrebleu>=1.3.6 (from joeynmt==0.0.1)\n",
            "  Downloading https://files.pythonhosted.org/packages/0e/e5/93d252182f7cbd4b59bb3ec5797e2ce33cfd6f5aadaf327db170cf4b7887/sacrebleu-1.4.2-py3-none-any.whl\n",
            "Collecting subword-nmt (from joeynmt==0.0.1)\n",
            "  Downloading https://files.pythonhosted.org/packages/26/08/58267cb3ac00f5f895457777ed9e0d106dbb5e6388fa7923d8663b04b849/subword_nmt-0.3.6-py2.py3-none-any.whl\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from joeynmt==0.0.1) (3.0.3)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (from joeynmt==0.0.1) (0.9.0)\n",
            "Collecting pyyaml>=5.1 (from joeynmt==0.0.1)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/e8/b3212641ee2718d556df0f23f78de8303f068fe29cdaa7a91018849582fe/PyYAML-5.1.2.tar.gz (265kB)\n",
            "\u001b[K     |████████████████████████████████| 266kB 7.4MB/s \n",
            "\u001b[?25hCollecting pylint (from joeynmt==0.0.1)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ef/ed/1cb8e7b85a31807aa0bff8b3e60935370bed7e141df8b530aac6352bddff/pylint-2.4.2-py3-none-any.whl (302kB)\n",
            "\u001b[K     |████████████████████████████████| 307kB 42.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.12 in /usr/local/lib/python3.6/dist-packages (from joeynmt==0.0.1) (1.12.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->joeynmt==0.0.1) (0.46)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (0.33.6)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (1.0.8)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (1.1.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (0.2.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (0.1.7)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (1.15.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (3.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (3.7.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (0.8.0)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (1.15.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (1.11.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (0.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext->joeynmt==0.0.1) (2.21.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext->joeynmt==0.0.1) (4.28.1)\n",
            "Collecting portalocker (from sacrebleu>=1.3.6->joeynmt==0.0.1)\n",
            "  Downloading https://files.pythonhosted.org/packages/60/ec/836a494dbaa72541f691ec4e66f29fdc8db9bcc7f49e1c2d457ba13ced42/portalocker-1.5.1-py2.py3-none-any.whl\n",
            "Collecting typing (from sacrebleu>=1.3.6->joeynmt==0.0.1)\n",
            "  Downloading https://files.pythonhosted.org/packages/fe/2e/b480ee1b75e6d17d2993738670e75c1feeb9ff7f64452153cf018051cc92/typing-3.7.4.1-py3-none-any.whl\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->joeynmt==0.0.1) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->joeynmt==0.0.1) (2.5.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->joeynmt==0.0.1) (2.4.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->joeynmt==0.0.1) (0.10.0)\n",
            "Requirement already satisfied: pandas>=0.15.2 in /usr/local/lib/python3.6/dist-packages (from seaborn->joeynmt==0.0.1) (0.24.2)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from seaborn->joeynmt==0.0.1) (1.3.1)\n",
            "Collecting mccabe<0.7,>=0.6 (from pylint->joeynmt==0.0.1)\n",
            "  Downloading https://files.pythonhosted.org/packages/87/89/479dc97e18549e21354893e4ee4ef36db1d237534982482c3681ee6e7b57/mccabe-0.6.1-py2.py3-none-any.whl\n",
            "Collecting isort<5,>=4.2.5 (from pylint->joeynmt==0.0.1)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/b0/c121fd1fa3419ea9bfd55c7f9c4fedfec5143208d8c7ad3ce3db6c623c21/isort-4.3.21-py2.py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 22.8MB/s \n",
            "\u001b[?25hCollecting astroid<2.4,>=2.3.0 (from pylint->joeynmt==0.0.1)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/e1/74a63c85c501c29c52da5be604c025e368f4dd77daf1fa13c878a33e5a36/astroid-2.3.1-py3-none-any.whl (205kB)\n",
            "\u001b[K     |████████████████████████████████| 215kB 42.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow>=1.14->joeynmt==0.0.1) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow>=1.14->joeynmt==0.0.1) (0.16.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow>=1.14->joeynmt==0.0.1) (2.8.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext->joeynmt==0.0.1) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext->joeynmt==0.0.1) (2019.9.11)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext->joeynmt==0.0.1) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext->joeynmt==0.0.1) (3.0.4)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.15.2->seaborn->joeynmt==0.0.1) (2018.9)\n",
            "Collecting lazy-object-proxy==1.4.* (from astroid<2.4,>=2.3.0->pylint->joeynmt==0.0.1)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/26/534a6d32572a9dbca11619321535c0a7ab34688545d9d67c2c204b9e3a3d/lazy_object_proxy-1.4.2-cp36-cp36m-manylinux1_x86_64.whl (49kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 20.3MB/s \n",
            "\u001b[?25hCollecting typed-ast<1.5,>=1.4.0; implementation_name == \"cpython\" and python_version < \"3.8\" (from astroid<2.4,>=2.3.0->pylint->joeynmt==0.0.1)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/31/d3/9d1802c161626d0278bafb1ffb32f76b9d01e123881bbf9d91e8ccf28e18/typed_ast-1.4.0-cp36-cp36m-manylinux1_x86_64.whl (736kB)\n",
            "\u001b[K     |████████████████████████████████| 737kB 45.2MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: joeynmt, pyyaml\n",
            "  Building wheel for joeynmt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for joeynmt: filename=joeynmt-0.0.1-cp36-none-any.whl size=69430 sha256=8d07db0faf1d452bfa082d8ca02b50dd3d5b248cbdf4bf074a183b7473caaa2f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-xn4bfu9r/wheels/db/01/db/751cc9f3e7f6faec127c43644ba250a3ea7ad200594aeda70a\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyyaml: filename=PyYAML-5.1.2-cp36-cp36m-linux_x86_64.whl size=44104 sha256=d0a98fb6158849b49a76a339873eb11f7a23a19aab8583ed0f1dea1e87b12193\n",
            "  Stored in directory: /root/.cache/pip/wheels/d9/45/dd/65f0b38450c47cf7e5312883deb97d065e030c5cca0a365030\n",
            "Successfully built joeynmt pyyaml\n",
            "Installing collected packages: portalocker, typing, sacrebleu, subword-nmt, pyyaml, mccabe, isort, lazy-object-proxy, typed-ast, astroid, pylint, joeynmt\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed astroid-2.3.1 isort-4.3.21 joeynmt-0.0.1 lazy-object-proxy-1.4.2 mccabe-0.6.1 portalocker-1.5.1 pylint-2.4.2 pyyaml-5.1.2 sacrebleu-1.4.2 subword-nmt-0.3.6 typed-ast-1.4.0 typing-3.7.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AaE77Tcppex9"
      },
      "source": [
        "# Preprocessing the Data into Subword BPE Tokens\n",
        "\n",
        "- One of the most powerful improvements for agglutinative languages (a feature of most Bantu languages) is using BPE tokenization [ (Sennrich, 2015) ](https://arxiv.org/abs/1508.07909).\n",
        "\n",
        "- It was also shown that by optimizing the umber of BPE codes we significantly improve results for low-resourced languages [(Sennrich, 2019)](https://www.aclweb.org/anthology/P19-1021) [(Martinus, 2019)](https://arxiv.org/abs/1906.05685)\n",
        "\n",
        "- Below we have the scripts for doing BPE tokenization of our data. We use 4000 tokens as recommended by [(Sennrich, 2019)](https://www.aclweb.org/anthology/P19-1021). You do not need to change anything. Simply running the below will be suitable. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H-TyjtmXB1mL",
        "outputId": "fb62d111-bc7c-46dc-9694-0b32c41ff270",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        }
      },
      "source": [
        "# One of the huge boosts in NMT performance was to use a different method of tokenizing. \n",
        "# Usually, NMT would tokenize by words. However, using a method called BPE gave amazing boosts to performance\n",
        "\n",
        "# Do subword NMT\n",
        "from os import path\n",
        "\n",
        "os.environ[\"data_path\"] = path.join(\"joeynmt\", \"data\", source_language + target_language) # Herman! \n",
        "! subword-nmt learn-joint-bpe-and-vocab --input train.$src train.$tgt -s 4000 -o bpe.codes.4000 --write-vocabulary vocab.$src vocab.$tgt\n",
        "\n",
        "! subword-nmt apply-bpe -c bpe.codes.4000 --vocabulary vocab.$src < train.$src > train.bpe.$src\n",
        "! subword-nmt apply-bpe -c bpe.codes.4000 --vocabulary vocab.$tgt < train.$tgt > train.bpe.$tgt\n",
        "\n",
        "! subword-nmt apply-bpe -c bpe.codes.4000 --vocabulary vocab.$src < dev.$src > dev.bpe.$src\n",
        "! subword-nmt apply-bpe -c bpe.codes.4000 --vocabulary vocab.$tgt < dev.$tgt > dev.bpe.$tgt\n",
        "! subword-nmt apply-bpe -c bpe.codes.4000 --vocabulary vocab.$src < test.$src > test.bpe.$src\n",
        "! subword-nmt apply-bpe -c bpe.codes.4000 --vocabulary vocab.$tgt < test.$tgt > test.bpe.$tgt\n",
        "\n",
        "# Create directory, move everyone we care about to the correct location\n",
        "! mkdir -p $data_path\n",
        "! cp train.* $data_path\n",
        "! cp test.* $data_path\n",
        "! cp dev.* $data_path\n",
        "! cp bpe.codes.4000 $data_path\n",
        "! ls $data_path\n",
        "\n",
        "# Also move everything we care about to a mounted location in google drive (relevant if running in colab) at gdrive_path\n",
        "! cp train.* \"$gdrive_path\"\n",
        "! cp test.* \"$gdrive_path\"\n",
        "! cp dev.* \"$gdrive_path\"\n",
        "! cp bpe.codes.4000 \"$gdrive_path\"\n",
        "! ls \"$gdrive_path\"\n",
        "\n",
        "# Create that vocab using build_vocab\n",
        "! sudo chmod 777 joeynmt/scripts/build_vocab.py\n",
        "! joeynmt/scripts/build_vocab.py joeynmt/data/$src$tgt/train.bpe.$src joeynmt/data/$src$tgt/train.bpe.$tgt --output_path joeynmt/data/$src$tgt/vocab.txt\n",
        "\n",
        "# Some output\n",
        "! echo \"BPE Afrikaans Sentences\"\n",
        "! tail -n 5 test.bpe.$tgt\n",
        "! echo \"Combined BPE Vocab\"\n",
        "! tail -n 10 joeynmt/data/$src$tgt/vocab.txt  # Herman"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bpe.codes.4000\tdev.bpe.en  test.bpe.af  train.af      train.en\n",
            "dev.af\t\tdev.en\t    test.bpe.en  train.bpe.af  vocab.txt\n",
            "dev.bpe.af\ttest.af     test.en\t train.bpe.en\n",
            "bpe.codes.4000\tdev.bpe.en  test.bpe.af  train.af      train.en\n",
            "dev.af\t\tdev.en\t    test.bpe.en  train.bpe.af\n",
            "dev.bpe.af\ttest.af     test.en\t train.bpe.en\n",
            "BPE Afrikaans Sentences\n",
            "wat is 'n on@@ we@@ t@@ tige elektriese skak@@ el@@ ings ?\n",
            "hoe dink jy kan die plaas@@ like re@@ ger@@ ing dit keer of die hoeveelheid on@@ we@@ t@@ tige skak@@ el@@ ings ver@@ minder .\n",
            "'n on@@ we@@ t@@ tige skak@@ eling is wanneer ie@@ mand toe@@ gan@@ g kry tot elektrisiteit deur 'n kra@@ gl@@ yn te sny en 'n ander l@@ yn daaraan te verbind sonder om daar@@ voor te be@@ taal .\n",
            "die plaas@@ like re@@ ger@@ ing kan dit probeer stop deur eer@@ st@@ ens te probeer om die ar@@ mer geb@@ ie@@ de met genoeg elektriese toe@@ g@@ ang@@ sp@@ unte te voorsien rond te gaan en te kyk of daar ge@@ vaar@@ like skak@@ el@@ ings is be@@ w@@ us@@ theid oor die gev@@ are van on@@ we@@ t@@ tige skak@@ el@@ ings te verbeter deur ad@@ ver@@ ten@@ sie@@ bor@@ de radi@@ o die ko@@ er@@ ant ens .\n",
            "asses@@ seer enige ander rele@@ van@@ te antwoorde wat die leerder mag h&#234; .\n",
            "Combined BPE Vocab\n",
            "sour@@\n",
            "oorspron@@\n",
            "desc@@\n",
            "unti@@\n",
            "lay@@\n",
            "ft\n",
            "prob@@\n",
            "ingsge@@\n",
            "werp@@\n",
            "youn@@\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IlMitUHR8Qy-",
        "outputId": "e6c74ff9-6545-4779-e02d-ca624a4e929d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# Also move everything we care about to a mounted location in google drive (relevant if running in colab) at gdrive_path\n",
        "! cp train.* \"$gdrive_path\"\n",
        "! cp test.* \"$gdrive_path\"\n",
        "! cp dev.* \"$gdrive_path\"\n",
        "! cp bpe.codes.4000 \"$gdrive_path\"\n",
        "! ls \"$gdrive_path\""
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bpe.codes.4000\tdev.bpe.en  test.bpe.af  train.af      train.en\n",
            "dev.af\t\tdev.en\t    test.bpe.en  train.bpe.af\n",
            "dev.bpe.af\ttest.af     test.en\t train.bpe.en\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ixmzi60WsUZ8"
      },
      "source": [
        "# Creating the JoeyNMT Config\n",
        "\n",
        "JoeyNMT requires a yaml config. We provide a template below. We've also set a number of defaults with it, that you may play with!\n",
        "\n",
        "- We used Transformer architecture \n",
        "- We set our dropout to reasonably high: 0.3 (recommended in  [(Sennrich, 2019)](https://www.aclweb.org/anthology/P19-1021))\n",
        "\n",
        "Things worth playing with:\n",
        "- The batch size (also recommended to change for low-resourced languages)\n",
        "- The number of epochs (we've set it at 30 just so it runs in about an hour, for testing purposes)\n",
        "- The decoder options (beam_size, alpha)\n",
        "- Evaluation metrics (BLEU versus Crhf4)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PIs1lY2hxMsl",
        "colab": {}
      },
      "source": [
        "# This creates the config file for our JoeyNMT system. It might seem overwhelming so we've provided a couple of useful parameters you'll need to update\n",
        "# (You can of course play with all the parameters if you'd like!)\n",
        "\n",
        "name = '%s%s' % (source_language, target_language)\n",
        "gdrive_path = os.environ[\"gdrive_path\"]\n",
        "\n",
        "# Create the config\n",
        "config = \"\"\"\n",
        "name: \"{name}_transformer\"\n",
        "\n",
        "data:\n",
        "    src: \"{source_language}\"\n",
        "    trg: \"{target_language}\"\n",
        "    train: \"data/{name}/train.bpe\"\n",
        "    dev:   \"data/{name}/dev.bpe\"\n",
        "    test:  \"data/{name}/test.bpe\"\n",
        "    level: \"bpe\"\n",
        "    lowercase: False\n",
        "    max_sent_length: 100\n",
        "    src_vocab: \"data/{name}/vocab.txt\"\n",
        "    trg_vocab: \"data/{name}/vocab.txt\"\n",
        "\n",
        "testing:\n",
        "    beam_size: 5\n",
        "    alpha: 1.0\n",
        "\n",
        "training:\n",
        "    #load_model: \"{gdrive_path}/models/{name}_transformer/1.ckpt\" # if uncommented, load a pre-trained model from this checkpoint\n",
        "    random_seed: 42\n",
        "    optimizer: \"adam\"\n",
        "    normalization: \"tokens\"\n",
        "    adam_betas: [0.9, 0.999] \n",
        "    scheduling: \"noam\"            # Try switching from plateau to Noam scheduling\n",
        "    learning_rate_factor: 0.5       # factor for Noam scheduler (used with Transformer)\n",
        "    learning_rate_warmup: 1000      # warmup steps for Noam scheduler (used with Transformer)\n",
        "    patience: 8\n",
        "    decrease_factor: 0.7\n",
        "    loss: \"crossentropy\"\n",
        "    learning_rate: 0.0002\n",
        "    learning_rate_min: 0.00000001\n",
        "    weight_decay: 0.0\n",
        "    label_smoothing: 0.1\n",
        "    batch_size: 8192 # 4096  # Herman\n",
        "    batch_type: \"token\"\n",
        "    eval_batch_size: 1000 # 3600  # Herman\n",
        "    eval_batch_type: \"token\"\n",
        "    batch_multiplier: 1\n",
        "    early_stopping_metric: \"eval_metric\"  # \"ppl\"  # Herman\n",
        "    epochs: 30 # TODO: Decrease for when playing around and checking of working. Around 30 is sufficient to check if its working at all\n",
        "    validation_freq: 500 # 4000 # Decrease this for testing  # Herman\n",
        "    logging_freq: 50 # 100  # Herman\n",
        "    eval_metric: \"bleu\"\n",
        "    model_dir: \"models/{name}_transformer\"\n",
        "    overwrite: True\n",
        "    shuffle: True\n",
        "    use_cuda: True\n",
        "    max_output_length: 100\n",
        "    print_valid_sents: [0, 1, 2, 3]\n",
        "    keep_last_ckpts: 3\n",
        "\n",
        "model:\n",
        "    initializer: \"xavier\"\n",
        "    bias_initializer: \"zeros\"\n",
        "    init_gain: 1.0\n",
        "    embed_initializer: \"xavier\"\n",
        "    embed_init_gain: 1.0\n",
        "    tied_embeddings: True\n",
        "    tied_softmax: True\n",
        "    encoder:\n",
        "        type: \"transformer\"\n",
        "        num_layers: 6\n",
        "        num_heads: 8\n",
        "        embeddings:\n",
        "            embedding_dim: 512\n",
        "            scale: True\n",
        "            dropout: 0.\n",
        "        # typically ff_size = 4 x hidden_size\n",
        "        hidden_size: 512\n",
        "        ff_size: 2048\n",
        "        dropout: 0.3\n",
        "    decoder:\n",
        "        type: \"transformer\"\n",
        "        num_layers: 6\n",
        "        num_heads: 8\n",
        "        embeddings:\n",
        "            embedding_dim: 512\n",
        "            scale: True\n",
        "            dropout: 0.\n",
        "        # typically ff_size = 4 x hidden_size\n",
        "        hidden_size: 512\n",
        "        ff_size: 2048\n",
        "        dropout: 0.3\n",
        "\"\"\".format(name=name, gdrive_path=os.environ[\"gdrive_path\"], source_language=source_language, target_language=target_language)\n",
        "with open(\"joeynmt/configs/transformer_{name}.yaml\".format(name=name),'w') as f:\n",
        "    f.write(config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pIifxE3Qzuvs"
      },
      "source": [
        "# Train the Model\n",
        "\n",
        "This single line of joeynmt runs the training using the config we made above"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6ZBPFwT94WpI",
        "outputId": "82f650a5-184e-444a-a338-400e50f8dab5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Train the model\n",
        "# You can press Ctrl-C to stop. And then run the next cell to save your checkpoints! \n",
        "!cd joeynmt; python3 -m joeynmt train configs/transformer_$src$tgt.yaml"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-10-12 13:04:21,400 Hello! This is Joey-NMT.\n",
            "2019-10-12 13:04:22,974 Total params: 46140416\n",
            "2019-10-12 13:04:22,976 Trainable parameters: ['decoder.layer_norm.bias', 'decoder.layer_norm.weight', 'decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'decoder.layers.1.dec_layer_norm.bias', 'decoder.layers.1.dec_layer_norm.weight', 'decoder.layers.1.feed_forward.layer_norm.bias', 'decoder.layers.1.feed_forward.layer_norm.weight', 'decoder.layers.1.feed_forward.pwff_layer.0.bias', 'decoder.layers.1.feed_forward.pwff_layer.0.weight', 'decoder.layers.1.feed_forward.pwff_layer.3.bias', 'decoder.layers.1.feed_forward.pwff_layer.3.weight', 'decoder.layers.1.src_trg_att.k_layer.bias', 'decoder.layers.1.src_trg_att.k_layer.weight', 'decoder.layers.1.src_trg_att.output_layer.bias', 'decoder.layers.1.src_trg_att.output_layer.weight', 'decoder.layers.1.src_trg_att.q_layer.bias', 'decoder.layers.1.src_trg_att.q_layer.weight', 'decoder.layers.1.src_trg_att.v_layer.bias', 'decoder.layers.1.src_trg_att.v_layer.weight', 'decoder.layers.1.trg_trg_att.k_layer.bias', 'decoder.layers.1.trg_trg_att.k_layer.weight', 'decoder.layers.1.trg_trg_att.output_layer.bias', 'decoder.layers.1.trg_trg_att.output_layer.weight', 'decoder.layers.1.trg_trg_att.q_layer.bias', 'decoder.layers.1.trg_trg_att.q_layer.weight', 'decoder.layers.1.trg_trg_att.v_layer.bias', 'decoder.layers.1.trg_trg_att.v_layer.weight', 'decoder.layers.1.x_layer_norm.bias', 'decoder.layers.1.x_layer_norm.weight', 'decoder.layers.2.dec_layer_norm.bias', 'decoder.layers.2.dec_layer_norm.weight', 'decoder.layers.2.feed_forward.layer_norm.bias', 'decoder.layers.2.feed_forward.layer_norm.weight', 'decoder.layers.2.feed_forward.pwff_layer.0.bias', 'decoder.layers.2.feed_forward.pwff_layer.0.weight', 'decoder.layers.2.feed_forward.pwff_layer.3.bias', 'decoder.layers.2.feed_forward.pwff_layer.3.weight', 'decoder.layers.2.src_trg_att.k_layer.bias', 'decoder.layers.2.src_trg_att.k_layer.weight', 'decoder.layers.2.src_trg_att.output_layer.bias', 'decoder.layers.2.src_trg_att.output_layer.weight', 'decoder.layers.2.src_trg_att.q_layer.bias', 'decoder.layers.2.src_trg_att.q_layer.weight', 'decoder.layers.2.src_trg_att.v_layer.bias', 'decoder.layers.2.src_trg_att.v_layer.weight', 'decoder.layers.2.trg_trg_att.k_layer.bias', 'decoder.layers.2.trg_trg_att.k_layer.weight', 'decoder.layers.2.trg_trg_att.output_layer.bias', 'decoder.layers.2.trg_trg_att.output_layer.weight', 'decoder.layers.2.trg_trg_att.q_layer.bias', 'decoder.layers.2.trg_trg_att.q_layer.weight', 'decoder.layers.2.trg_trg_att.v_layer.bias', 'decoder.layers.2.trg_trg_att.v_layer.weight', 'decoder.layers.2.x_layer_norm.bias', 'decoder.layers.2.x_layer_norm.weight', 'decoder.layers.3.dec_layer_norm.bias', 'decoder.layers.3.dec_layer_norm.weight', 'decoder.layers.3.feed_forward.layer_norm.bias', 'decoder.layers.3.feed_forward.layer_norm.weight', 'decoder.layers.3.feed_forward.pwff_layer.0.bias', 'decoder.layers.3.feed_forward.pwff_layer.0.weight', 'decoder.layers.3.feed_forward.pwff_layer.3.bias', 'decoder.layers.3.feed_forward.pwff_layer.3.weight', 'decoder.layers.3.src_trg_att.k_layer.bias', 'decoder.layers.3.src_trg_att.k_layer.weight', 'decoder.layers.3.src_trg_att.output_layer.bias', 'decoder.layers.3.src_trg_att.output_layer.weight', 'decoder.layers.3.src_trg_att.q_layer.bias', 'decoder.layers.3.src_trg_att.q_layer.weight', 'decoder.layers.3.src_trg_att.v_layer.bias', 'decoder.layers.3.src_trg_att.v_layer.weight', 'decoder.layers.3.trg_trg_att.k_layer.bias', 'decoder.layers.3.trg_trg_att.k_layer.weight', 'decoder.layers.3.trg_trg_att.output_layer.bias', 'decoder.layers.3.trg_trg_att.output_layer.weight', 'decoder.layers.3.trg_trg_att.q_layer.bias', 'decoder.layers.3.trg_trg_att.q_layer.weight', 'decoder.layers.3.trg_trg_att.v_layer.bias', 'decoder.layers.3.trg_trg_att.v_layer.weight', 'decoder.layers.3.x_layer_norm.bias', 'decoder.layers.3.x_layer_norm.weight', 'decoder.layers.4.dec_layer_norm.bias', 'decoder.layers.4.dec_layer_norm.weight', 'decoder.layers.4.feed_forward.layer_norm.bias', 'decoder.layers.4.feed_forward.layer_norm.weight', 'decoder.layers.4.feed_forward.pwff_layer.0.bias', 'decoder.layers.4.feed_forward.pwff_layer.0.weight', 'decoder.layers.4.feed_forward.pwff_layer.3.bias', 'decoder.layers.4.feed_forward.pwff_layer.3.weight', 'decoder.layers.4.src_trg_att.k_layer.bias', 'decoder.layers.4.src_trg_att.k_layer.weight', 'decoder.layers.4.src_trg_att.output_layer.bias', 'decoder.layers.4.src_trg_att.output_layer.weight', 'decoder.layers.4.src_trg_att.q_layer.bias', 'decoder.layers.4.src_trg_att.q_layer.weight', 'decoder.layers.4.src_trg_att.v_layer.bias', 'decoder.layers.4.src_trg_att.v_layer.weight', 'decoder.layers.4.trg_trg_att.k_layer.bias', 'decoder.layers.4.trg_trg_att.k_layer.weight', 'decoder.layers.4.trg_trg_att.output_layer.bias', 'decoder.layers.4.trg_trg_att.output_layer.weight', 'decoder.layers.4.trg_trg_att.q_layer.bias', 'decoder.layers.4.trg_trg_att.q_layer.weight', 'decoder.layers.4.trg_trg_att.v_layer.bias', 'decoder.layers.4.trg_trg_att.v_layer.weight', 'decoder.layers.4.x_layer_norm.bias', 'decoder.layers.4.x_layer_norm.weight', 'decoder.layers.5.dec_layer_norm.bias', 'decoder.layers.5.dec_layer_norm.weight', 'decoder.layers.5.feed_forward.layer_norm.bias', 'decoder.layers.5.feed_forward.layer_norm.weight', 'decoder.layers.5.feed_forward.pwff_layer.0.bias', 'decoder.layers.5.feed_forward.pwff_layer.0.weight', 'decoder.layers.5.feed_forward.pwff_layer.3.bias', 'decoder.layers.5.feed_forward.pwff_layer.3.weight', 'decoder.layers.5.src_trg_att.k_layer.bias', 'decoder.layers.5.src_trg_att.k_layer.weight', 'decoder.layers.5.src_trg_att.output_layer.bias', 'decoder.layers.5.src_trg_att.output_layer.weight', 'decoder.layers.5.src_trg_att.q_layer.bias', 'decoder.layers.5.src_trg_att.q_layer.weight', 'decoder.layers.5.src_trg_att.v_layer.bias', 'decoder.layers.5.src_trg_att.v_layer.weight', 'decoder.layers.5.trg_trg_att.k_layer.bias', 'decoder.layers.5.trg_trg_att.k_layer.weight', 'decoder.layers.5.trg_trg_att.output_layer.bias', 'decoder.layers.5.trg_trg_att.output_layer.weight', 'decoder.layers.5.trg_trg_att.q_layer.bias', 'decoder.layers.5.trg_trg_att.q_layer.weight', 'decoder.layers.5.trg_trg_att.v_layer.bias', 'decoder.layers.5.trg_trg_att.v_layer.weight', 'decoder.layers.5.x_layer_norm.bias', 'decoder.layers.5.x_layer_norm.weight', 'encoder.layer_norm.bias', 'encoder.layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'encoder.layers.3.feed_forward.layer_norm.bias', 'encoder.layers.3.feed_forward.layer_norm.weight', 'encoder.layers.3.feed_forward.pwff_layer.0.bias', 'encoder.layers.3.feed_forward.pwff_layer.0.weight', 'encoder.layers.3.feed_forward.pwff_layer.3.bias', 'encoder.layers.3.feed_forward.pwff_layer.3.weight', 'encoder.layers.3.layer_norm.bias', 'encoder.layers.3.layer_norm.weight', 'encoder.layers.3.src_src_att.k_layer.bias', 'encoder.layers.3.src_src_att.k_layer.weight', 'encoder.layers.3.src_src_att.output_layer.bias', 'encoder.layers.3.src_src_att.output_layer.weight', 'encoder.layers.3.src_src_att.q_layer.bias', 'encoder.layers.3.src_src_att.q_layer.weight', 'encoder.layers.3.src_src_att.v_layer.bias', 'encoder.layers.3.src_src_att.v_layer.weight', 'encoder.layers.4.feed_forward.layer_norm.bias', 'encoder.layers.4.feed_forward.layer_norm.weight', 'encoder.layers.4.feed_forward.pwff_layer.0.bias', 'encoder.layers.4.feed_forward.pwff_layer.0.weight', 'encoder.layers.4.feed_forward.pwff_layer.3.bias', 'encoder.layers.4.feed_forward.pwff_layer.3.weight', 'encoder.layers.4.layer_norm.bias', 'encoder.layers.4.layer_norm.weight', 'encoder.layers.4.src_src_att.k_layer.bias', 'encoder.layers.4.src_src_att.k_layer.weight', 'encoder.layers.4.src_src_att.output_layer.bias', 'encoder.layers.4.src_src_att.output_layer.weight', 'encoder.layers.4.src_src_att.q_layer.bias', 'encoder.layers.4.src_src_att.q_layer.weight', 'encoder.layers.4.src_src_att.v_layer.bias', 'encoder.layers.4.src_src_att.v_layer.weight', 'encoder.layers.5.feed_forward.layer_norm.bias', 'encoder.layers.5.feed_forward.layer_norm.weight', 'encoder.layers.5.feed_forward.pwff_layer.0.bias', 'encoder.layers.5.feed_forward.pwff_layer.0.weight', 'encoder.layers.5.feed_forward.pwff_layer.3.bias', 'encoder.layers.5.feed_forward.pwff_layer.3.weight', 'encoder.layers.5.layer_norm.bias', 'encoder.layers.5.layer_norm.weight', 'encoder.layers.5.src_src_att.k_layer.bias', 'encoder.layers.5.src_src_att.k_layer.weight', 'encoder.layers.5.src_src_att.output_layer.bias', 'encoder.layers.5.src_src_att.output_layer.weight', 'encoder.layers.5.src_src_att.q_layer.bias', 'encoder.layers.5.src_src_att.q_layer.weight', 'encoder.layers.5.src_src_att.v_layer.bias', 'encoder.layers.5.src_src_att.v_layer.weight', 'src_embed.lut.weight']\n",
            "2019-10-12 13:04:28,432 cfg.name                           : enaf_transformer\n",
            "2019-10-12 13:04:28,432 cfg.data.src                       : en\n",
            "2019-10-12 13:04:28,432 cfg.data.trg                       : af\n",
            "2019-10-12 13:04:28,433 cfg.data.train                     : data/enaf/train.bpe\n",
            "2019-10-12 13:04:28,433 cfg.data.dev                       : data/enaf/dev.bpe\n",
            "2019-10-12 13:04:28,433 cfg.data.test                      : data/enaf/test.bpe\n",
            "2019-10-12 13:04:28,433 cfg.data.level                     : bpe\n",
            "2019-10-12 13:04:28,433 cfg.data.lowercase                 : False\n",
            "2019-10-12 13:04:28,433 cfg.data.max_sent_length           : 100\n",
            "2019-10-12 13:04:28,433 cfg.data.src_vocab                 : data/enaf/vocab.txt\n",
            "2019-10-12 13:04:28,433 cfg.data.trg_vocab                 : data/enaf/vocab.txt\n",
            "2019-10-12 13:04:28,433 cfg.testing.beam_size              : 5\n",
            "2019-10-12 13:04:28,433 cfg.testing.alpha                  : 1.0\n",
            "2019-10-12 13:04:28,434 cfg.training.random_seed           : 42\n",
            "2019-10-12 13:04:28,434 cfg.training.optimizer             : adam\n",
            "2019-10-12 13:04:28,434 cfg.training.normalization         : tokens\n",
            "2019-10-12 13:04:28,434 cfg.training.adam_betas            : [0.9, 0.999]\n",
            "2019-10-12 13:04:28,434 cfg.training.scheduling            : noam\n",
            "2019-10-12 13:04:28,434 cfg.training.learning_rate_factor  : 0.5\n",
            "2019-10-12 13:04:28,434 cfg.training.learning_rate_warmup  : 1000\n",
            "2019-10-12 13:04:28,434 cfg.training.patience              : 8\n",
            "2019-10-12 13:04:28,434 cfg.training.decrease_factor       : 0.7\n",
            "2019-10-12 13:04:28,434 cfg.training.loss                  : crossentropy\n",
            "2019-10-12 13:04:28,434 cfg.training.learning_rate         : 0.0002\n",
            "2019-10-12 13:04:28,434 cfg.training.learning_rate_min     : 1e-08\n",
            "2019-10-12 13:04:28,435 cfg.training.weight_decay          : 0.0\n",
            "2019-10-12 13:04:28,435 cfg.training.label_smoothing       : 0.1\n",
            "2019-10-12 13:04:28,435 cfg.training.batch_size            : 8192\n",
            "2019-10-12 13:04:28,435 cfg.training.batch_type            : token\n",
            "2019-10-12 13:04:28,435 cfg.training.eval_batch_size       : 1000\n",
            "2019-10-12 13:04:28,435 cfg.training.eval_batch_type       : token\n",
            "2019-10-12 13:04:28,435 cfg.training.batch_multiplier      : 1\n",
            "2019-10-12 13:04:28,435 cfg.training.early_stopping_metric : eval_metric\n",
            "2019-10-12 13:04:28,435 cfg.training.epochs                : 30\n",
            "2019-10-12 13:04:28,435 cfg.training.validation_freq       : 500\n",
            "2019-10-12 13:04:28,435 cfg.training.logging_freq          : 50\n",
            "2019-10-12 13:04:28,435 cfg.training.eval_metric           : bleu\n",
            "2019-10-12 13:04:28,436 cfg.training.model_dir             : models/enaf_transformer\n",
            "2019-10-12 13:04:28,436 cfg.training.overwrite             : True\n",
            "2019-10-12 13:04:28,436 cfg.training.shuffle               : True\n",
            "2019-10-12 13:04:28,436 cfg.training.use_cuda              : True\n",
            "2019-10-12 13:04:28,436 cfg.training.max_output_length     : 100\n",
            "2019-10-12 13:04:28,436 cfg.training.print_valid_sents     : [0, 1, 2, 3]\n",
            "2019-10-12 13:04:28,436 cfg.training.keep_last_ckpts       : 3\n",
            "2019-10-12 13:04:28,436 cfg.model.initializer              : xavier\n",
            "2019-10-12 13:04:28,436 cfg.model.bias_initializer         : zeros\n",
            "2019-10-12 13:04:28,436 cfg.model.init_gain                : 1.0\n",
            "2019-10-12 13:04:28,436 cfg.model.embed_initializer        : xavier\n",
            "2019-10-12 13:04:28,436 cfg.model.embed_init_gain          : 1.0\n",
            "2019-10-12 13:04:28,436 cfg.model.tied_embeddings          : True\n",
            "2019-10-12 13:04:28,437 cfg.model.tied_softmax             : True\n",
            "2019-10-12 13:04:28,437 cfg.model.encoder.type             : transformer\n",
            "2019-10-12 13:04:28,437 cfg.model.encoder.num_layers       : 6\n",
            "2019-10-12 13:04:28,437 cfg.model.encoder.num_heads        : 8\n",
            "2019-10-12 13:04:28,437 cfg.model.encoder.embeddings.embedding_dim : 512\n",
            "2019-10-12 13:04:28,437 cfg.model.encoder.embeddings.scale : True\n",
            "2019-10-12 13:04:28,437 cfg.model.encoder.embeddings.dropout : 0.0\n",
            "2019-10-12 13:04:28,437 cfg.model.encoder.hidden_size      : 512\n",
            "2019-10-12 13:04:28,437 cfg.model.encoder.ff_size          : 2048\n",
            "2019-10-12 13:04:28,437 cfg.model.encoder.dropout          : 0.3\n",
            "2019-10-12 13:04:28,437 cfg.model.decoder.type             : transformer\n",
            "2019-10-12 13:04:28,438 cfg.model.decoder.num_layers       : 6\n",
            "2019-10-12 13:04:28,438 cfg.model.decoder.num_heads        : 8\n",
            "2019-10-12 13:04:28,438 cfg.model.decoder.embeddings.embedding_dim : 512\n",
            "2019-10-12 13:04:28,438 cfg.model.decoder.embeddings.scale : True\n",
            "2019-10-12 13:04:28,438 cfg.model.decoder.embeddings.dropout : 0.0\n",
            "2019-10-12 13:04:28,438 cfg.model.decoder.hidden_size      : 512\n",
            "2019-10-12 13:04:28,438 cfg.model.decoder.ff_size          : 2048\n",
            "2019-10-12 13:04:28,438 cfg.model.decoder.dropout          : 0.3\n",
            "2019-10-12 13:04:28,438 Data set sizes: \n",
            "\ttrain 6582,\n",
            "\tvalid 400,\n",
            "\ttest 400\n",
            "2019-10-12 13:04:28,438 First training example:\n",
            "\t[SRC] how to introduce this topic\n",
            "\t[TRG] hoe om hierdie onderwerp bekend te stel\n",
            "2019-10-12 13:04:28,438 First 10 words (src): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) . (5) die (6) the (7) is (8) in (9) of\n",
            "2019-10-12 13:04:28,439 First 10 words (trg): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) . (5) die (6) the (7) is (8) in (9) of\n",
            "2019-10-12 13:04:28,439 Number of Src words (types): 3906\n",
            "2019-10-12 13:04:28,440 Number of Trg words (types): 3906\n",
            "2019-10-12 13:04:28,440 Model(\n",
            "\tencoder=TransformerEncoder(num_layers=6, num_heads=8),\n",
            "\tdecoder=TransformerDecoder(num_layers=6, num_heads=8),\n",
            "\tsrc_embed=Embeddings(embedding_dim=512, vocab_size=3906),\n",
            "\ttrg_embed=Embeddings(embedding_dim=512, vocab_size=3906))\n",
            "2019-10-12 13:04:28,443 EPOCH 1\n",
            "2019-10-12 13:05:09,344 Epoch   1: total training loss 243.81\n",
            "2019-10-12 13:05:09,344 EPOCH 2\n",
            "2019-10-12 13:05:21,860 Epoch   2 Step:       50 Batch Loss:     6.284245 Tokens per Sec:     3020, Lr: 0.000035\n",
            "2019-10-12 13:05:50,410 Epoch   2: total training loss 224.23\n",
            "2019-10-12 13:05:50,411 EPOCH 3\n",
            "2019-10-12 13:06:15,647 Epoch   3 Step:      100 Batch Loss:     5.503494 Tokens per Sec:     2560, Lr: 0.000070\n",
            "2019-10-12 13:06:32,548 Epoch   3: total training loss 211.34\n",
            "2019-10-12 13:06:32,548 EPOCH 4\n",
            "2019-10-12 13:07:11,389 Epoch   4 Step:      150 Batch Loss:     5.099205 Tokens per Sec:     2733, Lr: 0.000105\n",
            "2019-10-12 13:07:13,682 Epoch   4: total training loss 190.40\n",
            "2019-10-12 13:07:13,682 EPOCH 5\n",
            "2019-10-12 13:07:55,476 Epoch   5: total training loss 192.08\n",
            "2019-10-12 13:07:55,477 EPOCH 6\n",
            "2019-10-12 13:08:06,255 Epoch   6 Step:      200 Batch Loss:     4.973370 Tokens per Sec:     2620, Lr: 0.000140\n",
            "2019-10-12 13:08:36,606 Epoch   6: total training loss 181.75\n",
            "2019-10-12 13:08:36,606 EPOCH 7\n",
            "2019-10-12 13:09:00,902 Epoch   7 Step:      250 Batch Loss:     4.832087 Tokens per Sec:     2470, Lr: 0.000175\n",
            "2019-10-12 13:09:18,425 Epoch   7: total training loss 183.76\n",
            "2019-10-12 13:09:18,426 EPOCH 8\n",
            "2019-10-12 13:09:57,008 Epoch   8 Step:      300 Batch Loss:     4.528731 Tokens per Sec:     2705, Lr: 0.000210\n",
            "2019-10-12 13:10:00,325 Epoch   8: total training loss 178.99\n",
            "2019-10-12 13:10:00,325 EPOCH 9\n",
            "2019-10-12 13:10:42,220 Epoch   9: total training loss 171.56\n",
            "2019-10-12 13:10:42,220 EPOCH 10\n",
            "2019-10-12 13:10:52,039 Epoch  10 Step:      350 Batch Loss:     3.306069 Tokens per Sec:     2599, Lr: 0.000245\n",
            "2019-10-12 13:11:23,637 Epoch  10: total training loss 165.06\n",
            "2019-10-12 13:11:23,637 EPOCH 11\n",
            "2019-10-12 13:11:45,746 Epoch  11 Step:      400 Batch Loss:     4.233754 Tokens per Sec:     2572, Lr: 0.000280\n",
            "2019-10-12 13:12:06,033 Epoch  11: total training loss 163.78\n",
            "2019-10-12 13:12:06,033 EPOCH 12\n",
            "2019-10-12 13:12:40,947 Epoch  12 Step:      450 Batch Loss:     3.916130 Tokens per Sec:     2685, Lr: 0.000314\n",
            "2019-10-12 13:12:47,833 Epoch  12: total training loss 153.07\n",
            "2019-10-12 13:12:47,834 EPOCH 13\n",
            "2019-10-12 13:13:29,419 Epoch  13: total training loss 147.70\n",
            "2019-10-12 13:13:29,419 EPOCH 14\n",
            "2019-10-12 13:13:36,170 Epoch  14 Step:      500 Batch Loss:     4.652871 Tokens per Sec:     2262, Lr: 0.000349\n",
            "2019-10-12 13:15:13,672 Hooray! New best validation result [eval_metric]!\n",
            "2019-10-12 13:15:13,672 Saving new checkpoint.\n",
            "2019-10-12 13:15:15,342 Example #0\n",
            "2019-10-12 13:15:15,342 \tSource:     resources about water\n",
            "2019-10-12 13:15:15,342 \tReference:  hulpbronne oor water\n",
            "2019-10-12 13:15:15,343 \tHypothesis: materiale\n",
            "2019-10-12 13:15:15,343 Example #1\n",
            "2019-10-12 13:15:15,343 \tSource:     what does it mean to purify water ?\n",
            "2019-10-12 13:15:15,343 \tReference:  wat beteken dit om water te suiwer ?\n",
            "2019-10-12 13:15:15,343 \tHypothesis: wat het dit ?\n",
            "2019-10-12 13:15:15,344 Example #2\n",
            "2019-10-12 13:15:15,344 \tSource:     it means to clean water; to remove pollutants from the water .\n",
            "2019-10-12 13:15:15,344 \tReference:  om water te suiwer beteken om besoedeling uit water te verwyder .\n",
            "2019-10-12 13:15:15,344 \tHypothesis: dit is baie baie baie baie baie baie baie baie energie .\n",
            "2019-10-12 13:15:15,344 Example #3\n",
            "2019-10-12 13:15:15,345 \tSource:     what is clean water ?\n",
            "2019-10-12 13:15:15,345 \tReference:  wat is skoon water ?\n",
            "2019-10-12 13:15:15,345 \tHypothesis: wat is 'n mengsel ?\n",
            "2019-10-12 13:15:15,345 Validation result at epoch  14, step      500: bleu:   0.74, loss: 28996.0254, ppl:  65.3205, duration: 99.1749s\n",
            "2019-10-12 13:15:50,181 Epoch  14: total training loss 143.06\n",
            "2019-10-12 13:15:50,181 EPOCH 15\n",
            "2019-10-12 13:16:09,182 Epoch  15 Step:      550 Batch Loss:     3.723561 Tokens per Sec:     2468, Lr: 0.000384\n",
            "2019-10-12 13:16:31,882 Epoch  15: total training loss 139.90\n",
            "2019-10-12 13:16:31,883 EPOCH 16\n",
            "2019-10-12 13:17:05,565 Epoch  16 Step:      600 Batch Loss:     2.977489 Tokens per Sec:     2681, Lr: 0.000419\n",
            "2019-10-12 13:17:13,934 Epoch  16: total training loss 130.22\n",
            "2019-10-12 13:17:13,934 EPOCH 17\n",
            "2019-10-12 13:17:55,492 Epoch  17: total training loss 123.59\n",
            "2019-10-12 13:17:55,492 EPOCH 18\n",
            "2019-10-12 13:18:00,199 Epoch  18 Step:      650 Batch Loss:     2.841545 Tokens per Sec:     2733, Lr: 0.000454\n",
            "2019-10-12 13:18:37,541 Epoch  18: total training loss 119.31\n",
            "2019-10-12 13:18:37,541 EPOCH 19\n",
            "2019-10-12 13:18:55,769 Epoch  19 Step:      700 Batch Loss:     3.136394 Tokens per Sec:     2867, Lr: 0.000489\n",
            "2019-10-12 13:19:18,842 Epoch  19: total training loss 110.25\n",
            "2019-10-12 13:19:18,842 EPOCH 20\n",
            "2019-10-12 13:19:51,506 Epoch  20 Step:      750 Batch Loss:     2.843098 Tokens per Sec:     2687, Lr: 0.000524\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MBoDS09JM807",
        "colab": {}
      },
      "source": [
        "# Copy the created models from the notebook storage to google drive for persistant storage \n",
        "!cp -r joeynmt/models/${src}${tgt}_transformer/* \"$gdrive_path/models/${src}${tgt}_transformer/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n94wlrCjVc17",
        "outputId": "1c9a7514-2b4e-4a9d-87c3-11b73103385f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Output our validation accuracy\n",
        "! cat \"$gdrive_path/models/${src}${tgt}_transformer/validations.txt\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Steps: 2\tLoss: 220568.71875\tPPL: 1101.96460\tbleu: 0.00000\tLR: 0.00000070\t*\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "66WhRE9lIhoD",
        "outputId": "2d34e7cb-5462-468d-c57b-54bcdcc69b82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Test our model\n",
        "! cd joeynmt; python3 -m joeynmt test \"$gdrive_path/models/${src}${tgt}_transformer/config.yaml\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-10-05 14:18:07,761 -  dev bleu:   0.00 [Beam search decoding with beam size = 5 and alpha = 1.0]\n",
            "2019-10-05 14:18:14,912 - test bleu:   0.00 [Beam search decoding with beam size = 5 and alpha = 1.0]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}