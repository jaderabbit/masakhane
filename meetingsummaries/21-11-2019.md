# Masakhane Meeting Notes: 21/11/2019

- Time: 18:30
- Number of Attendees: 6
- Notes taken by Jade Abbott

--------------------

## General

Attendees of the meeting decided to continue the meetings, through December, except between Christmas and New Years

--------------------
## Data

### Fuzzywuzzy

- Daniel has added in fuzzywuzzy and the training set size decreased by 3-4%

Action Items:
- Worth rerunning ones training with fuzzy wuzzy - but perhaps wait until we've run it on test sets too

### Raw data

- Data got the raw JW300 data. http://statmt.org/heafield/jw/. The files are meant to be the same. content.json.zip is the original but dealing with zip files > 4 GB is often broken. He has attempted to extract it then gzip which is content.json.gz
- So far no one has looked at the data. 

### Zindi Dataset Challenge

Zindi is running this challenge and they so far have no submissions. Jade encourage's anyone who has discovered an open source dataset (or built their own) to submit it - as you can win some money - they're giving away $500 per month. Jade thought that Olabiyi should definitely submit his dataset. 

Here is the link: https://zindi.africa/competitions/ai4d-african-language-dataset-challenge

Action Items:
    - Ping Olabiyi about his dataset and review his dataset.


### Test sets


- Jade poses the question: Can/Should we add unique patterns if we can verify they aren't in all the other datasets?
    - Team says that there should be quite a process to make sure the added data does not occur within the rest of the dataset. Would like to chat to Julia to find out more! 
    - Ari suggested that it shouldn't be a problem to add more as long as we're ALSO storing the source of the pattern with it. That would allow us to filter out later. 
- Daniel noticed that he was getting test scores that are better than dev scores, which made him consider that the test set was much easier - perhaps because we have not used fuzzywuzzy on it. If the test sets are too simple, we might need to consider augmenting it


Action Items:

- We need to rework the test sets to store source.
- We need to run fuzzywuzzy on test sets and (a) See how many patterns this affects (b) See if we can filter out
- If the test sets are (a) too small or (b) too easy we will need to think about how to augment them safely so we don't leak data. 
- We need to define a process for adding to the test sets. 

### Vukosi still needing preprocessing help? Who can help? 

- Ari has offered to help, if needed.

### Crowd-sourcing Platform Update

Action Items: 
- Ping Brian Muhia for updates. 

### Updates from Daniel about SIL data:

- Daniel is trying to loop in people from SIL Senegal who apparently have radio transcripts. They need to just clear the copyright issues. 
- Daniel also managed to extract Bambara data from a terrible website but managed to get lots of it. Ismael is going to find someone from Mali who can help it

### Abdullah on Arabic:
- Abdullah has found data and a corpus with more than 12 diaects for arabic. 
- It has around 12K parallel sentences for standard Arabic. 
- And approximately 6k for each other sentence. 
- Jade recommends that it is enough to get a baseline.
- Daniel recommends OpenSubtitles. It's going to be noisy, but it's 31 million for Arabic. Daniel has trained statistical word alignment model to filter out bad translations. Daniel will send a link to it. 

Action Items:
- Daniel to send Abdullah a link to the translations nad the statistical word alignment model

--------------------
## Compute Update

Action Items:
- Ping Espoir Murhbazi that everything is setup
- Jade to ask anyone if they need compute

--------------------
## Techniques

### Transfer Learning

- Team to ask Alp if he has a notebook for his transfer learning. Which approach was used? Can he submit a PR? 
- Jade to setup a notebook for Zoph et al and/or [Ranzanto et al](https://github.com/facebookresearch/XLM)  using JoeyNMT .

Daniel recommends the following approaches due to their simplicity:
- [Transfer learning for low resource languages (Zoph)](https://github.com/isi-nlp/Zoph_RNN)
- [Rapid adaptation methods (Neubig)](https://github.com/neubig/rapid-adaptation)
- [Technique from The Place Effect talk (Ranzanto)](https://youtu.be/5A6MlGfZni0)
--------------------
## Paper Milestones

Jade reports that Vukosi has a vision for a few papers. The one's she remembers are:
- A TACL/ACL/EMNLP paper on the baselines and transfer learning. 
- A Development journal paper telling the story of Masakhane.io. Where we found all the data etc etc

Action Items:
- Find out from Vukosi what the other paper ideas were
- Spend some time in the up-coming meeting doing paper planning to focus our efforts. 
--------------------
## Mentors for Newbies

Jade reports that Kathleen raised that some people dropped off the project because they hit errors with the notebook early on. As a result, she has recommended that we identify mentors and then reach out to everyone and offer a mentor.

So far, our mentors who've offered their assistance are:
- Daniel
- Ari

Action Items:
- Anyone who would like to be a mentor, please let Jade know or add yourself to this note via a PR. 
--------------------
## Questions & Ideas

- Ari has trained a couple of models and consistently get decent training score, and much lower test score. For example, for Tswane - dev score of 36 and test of 17. Daniel notes that it depends on the size of training data. Jade comments that the test BLEU has always been significantly lower than the training BLEU. 
- Jade recommended he share some graphs so that we could have more information. 
- Daniel recommended to run the model training much longer and plot that too. 
- Daniel highlighted that this could be because the BLEU score is just terrible with African languages and that it could be another place where we make a contribution research-wise. Could be a contribution: a statement about trying out the metrics and which one is helpful and correlates best with human evaluation. 

--------------------