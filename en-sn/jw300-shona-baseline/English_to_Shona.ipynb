{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of starter_notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Igc5itf-xMGj"
      },
      "source": [
        "# Masakhane - Machine Translation for African Languages (Using JoeyNMT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "x4fXCKCf36IK"
      },
      "source": [
        "## Note before beginning:\n",
        "### - The idea is that you should be able to make minimal changes to this in order to get SOME result for your own translation corpus. \n",
        "\n",
        "### - The tl;dr: Go to the **\"TODO\"** comments which will tell you what to update to get up and running\n",
        "\n",
        "### - If you actually want to have a clue what you're doing, read the text and peek at the links\n",
        "\n",
        "### - With 100 epochs, it should take around 7 hours to run in Google Colab\n",
        "\n",
        "### - Once you've gotten a result for your language, please attach and email your notebook that generated it to masakhanetranslation@gmail.com\n",
        "\n",
        "### - If you care enough and get a chance, doing a brief background on your language would be amazing. See examples in  [(Martinus, 2019)](https://arxiv.org/abs/1906.05685)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "l929HimrxS0a"
      },
      "source": [
        "## Retrieve your data & make a parallel corpus\n",
        "\n",
        "If you are wanting to use the JW300 data referenced on the Masakhane website or in our GitHub repo, you can use `opus-tools` to convert the data into a convenient format. `opus_read` from that package provides a convenient tool for reading the native aligned XML files and to convert them to TMX format. The tool can also be used to fetch relevant files from OPUS on the fly and to filter the data as necessary. [Read the documentation](https://pypi.org/project/opustools-pkg/) for more details.\n",
        "\n",
        "Once you have your corpus files in TMX format (an xml structure which will include the sentences in your target language and your source language in a single file), we recommend reading them into a pandas dataframe. Thankfully, Jade wrote a silly `tmx2dataframe` package which converts your tmx file to a pandas dataframe. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oGRmDELn7Az0",
        "outputId": "49cb35fb-9cb4-4eae-bc5e-1e001fa4deb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Cn3tgQLzUxwn",
        "colab": {}
      },
      "source": [
        "# TODO: Set your source and target languages. Keep in mind, these traditionally use language codes as found here:\n",
        "# These will also become the suffix's of all vocab and corpus files used throughout\n",
        "import os\n",
        "source_language = \"en\"\n",
        "target_language = \"sn\"\n",
        "tag = \"baseline\" # Give a unique name to your folder - this is to ensure you don't rewrite any models you've already submitted\n",
        "\n",
        "os.environ[\"src\"] = source_language # Sets them in bash as well, since we often use bash scripts\n",
        "os.environ[\"tgt\"] = target_language\n",
        "os.environ[\"tag\"] = tag\n",
        "\n",
        "# This will save it to a folder in our gdrive instead!\n",
        "!mkdir -p \"/content/drive/My Drive/masakhane/$src-$tgt-$tag\"\n",
        "os.environ[\"gdrive_path\"] = \"/content/drive/My Drive/masakhane/%s-%s-%s\" % (source_language, target_language, tag)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kBSgJHEw7Nvx",
        "outputId": "723d40cf-b2c5-4818-c6c8-70bd4b1e3030",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!echo $gdrive_path"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/masakhane/en-sn-baseline\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gA75Fs9ys8Y9",
        "outputId": "a538c4b6-d8d1-4a46-91f9-4c637af7ce1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# Install opus-tools\n",
        "! pip install opustools-pkg"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting opustools-pkg\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/2f/3a10a39e7d93786e775b5a56896a28e90443a31f167344d857ffb67b36d1/opustools_pkg-0.0.49-py3-none-any.whl (44kB)\n",
            "\r\u001b[K     |███████▍                        | 10kB 15.4MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 20kB 2.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 30kB 3.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 40kB 2.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 2.5MB/s \n",
            "\u001b[?25hInstalling collected packages: opustools-pkg\n",
            "Successfully installed opustools-pkg-0.0.49\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xq-tDZVks7ZD",
        "outputId": "78181f00-ffaf-4fde-f45e-b882a9934750",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Downloading our corpus\n",
        "! opus_read -d JW300 -s $src -t $tgt -wm moses -w jw300.$src jw300.$tgt -q\n",
        "\n",
        "# extract the corpus file\n",
        "! gunzip JW300_latest_xml_$src-$tgt.xml.gz"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Alignment file /proj/nlpl/data/OPUS/JW300/latest/xml/en-sn.xml.gz not found. The following files are available for downloading:\n",
            "\n",
            "   6 MB https://object.pouta.csc.fi/OPUS-JW300/v1/xml/en-sn.xml.gz\n",
            " 263 MB https://object.pouta.csc.fi/OPUS-JW300/v1/xml/en.zip\n",
            "  69 MB https://object.pouta.csc.fi/OPUS-JW300/v1/xml/sn.zip\n",
            "\n",
            " 339 MB Total size\n",
            "./JW300_latest_xml_en-sn.xml.gz ... 100% of 6 MB\n",
            "./JW300_latest_xml_en.zip ... 100% of 263 MB\n",
            "./JW300_latest_xml_sn.zip ... 100% of 69 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3CNdwLBCfSIl",
        "outputId": "90c4c2d0-767f-45f0-864a-a180b23af1e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# TMX file to dataframe\n",
        "source_file = 'jw300.' + source_language\n",
        "target_file = 'jw300.' + target_language\n",
        "\n",
        "source = []\n",
        "target = []\n",
        "with open(source_file) as f:\n",
        "  for _, line in enumerate(f):\n",
        "    source.append(line)\n",
        "with open(target_file) as f:\n",
        "  for _, line in enumerate(f):\n",
        "    target.append(line)\n",
        "\n",
        "df = pd.DataFrame(zip(source, target), columns=['source_sentence', 'target_sentence'])\n",
        "df.head(20)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source_sentence</th>\n",
              "      <th>target_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Young People Ask . . .\\n</td>\n",
              "      <td>Vechiduku Vanobvunza Kuti . . .\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Why Do I Lose My Temper ?\\n</td>\n",
              "      <td>Neiko Ndichitsamwa ?\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>“ When I’m angry , I’m furious , and you would...</td>\n",
              "      <td>“ Apo ndinoshatirwa , ndinotyisa , uye haungad...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I turn red in the face . . .\\n</td>\n",
              "      <td>Ndinotsvuka kumeso . . . .\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sometimes I just yell . ” ​ — 11 - year - old ...</td>\n",
              "      <td>Pane dzimwe nguva ndinozhamba . ” — Evan wamak...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>YOUR sister ruins your favorite blouse .\\n</td>\n",
              "      <td>MUKOMA wako anokanganisa bhurauzi raunodisa zv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Your teacher gives you an unfair mark on a tes...</td>\n",
              "      <td>Mudzidzisi wako anokupa mamakisi asina kunaka ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Just when you need it the most , your hair dry...</td>\n",
              "      <td>Apo unorida zvikurusa , muchina wokuomesa vhud...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>For many youths , any such intrusions , injust...</td>\n",
              "      <td>Nokuda kwepwere dzakawanda , pindiro ipi neipi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>An article in Health magazine by Dr .\\n</td>\n",
              "      <td>Nyaya iri mumagazini inonzi Health yakanyorwa ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Georgia Witkin - Lanoil explains : “ As the br...</td>\n",
              "      <td>Georgia Witkin - Lanoil inotsanangura kuti : “...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Adrenaline , released from the adrenal glands ...</td>\n",
              "      <td>Adrenaline , inobudiswa mumaburi eadrenal , in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>With what results ?\\n</td>\n",
              "      <td>Nomuuyoi ?\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>“ Actions we take under the influence of our o...</td>\n",
              "      <td>“ Zviito zvatinoita pasi pepesvedzero yaadrena...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Witkin - Lanoil , “ are often overreactions .\\n</td>\n",
              "      <td>Witkin - Lanoil , “ kazhinji kazhinji kunyanyi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>We scream , hurl hateful semi - truths , hit ,...</td>\n",
              "      <td>Tinozhambatata tichitaura mashoko asiri echokw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>An article in ’ Teen magazine similarly observ...</td>\n",
              "      <td>Nyaya iri mumagazini ye’Teen nenzira yakafanan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Did you ever lose your temper ?\\n</td>\n",
              "      <td>Wakambotsamwa here ?\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>If so , you are not alone .\\n</td>\n",
              "      <td>Kana zvakadaro , hausati uriwe woga .\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Like most of us , you no doubt felt quite fool...</td>\n",
              "      <td>Kufanana navazhinji vedu , iwe pasina panikiro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      source_sentence                                    target_sentence\n",
              "0                            Young People Ask . . .\\n                  Vechiduku Vanobvunza Kuti . . .\\n\n",
              "1                         Why Do I Lose My Temper ?\\n                             Neiko Ndichitsamwa ?\\n\n",
              "2   “ When I’m angry , I’m furious , and you would...  “ Apo ndinoshatirwa , ndinotyisa , uye haungad...\n",
              "3                      I turn red in the face . . .\\n                       Ndinotsvuka kumeso . . . .\\n\n",
              "4   Sometimes I just yell . ” ​ — 11 - year - old ...  Pane dzimwe nguva ndinozhamba . ” — Evan wamak...\n",
              "5          YOUR sister ruins your favorite blouse .\\n  MUKOMA wako anokanganisa bhurauzi raunodisa zv...\n",
              "6   Your teacher gives you an unfair mark on a tes...  Mudzidzisi wako anokupa mamakisi asina kunaka ...\n",
              "7   Just when you need it the most , your hair dry...  Apo unorida zvikurusa , muchina wokuomesa vhud...\n",
              "8   For many youths , any such intrusions , injust...  Nokuda kwepwere dzakawanda , pindiro ipi neipi...\n",
              "9             An article in Health magazine by Dr .\\n  Nyaya iri mumagazini inonzi Health yakanyorwa ...\n",
              "10  Georgia Witkin - Lanoil explains : “ As the br...  Georgia Witkin - Lanoil inotsanangura kuti : “...\n",
              "11  Adrenaline , released from the adrenal glands ...  Adrenaline , inobudiswa mumaburi eadrenal , in...\n",
              "12                              With what results ?\\n                                       Nomuuyoi ?\\n\n",
              "13  “ Actions we take under the influence of our o...  “ Zviito zvatinoita pasi pepesvedzero yaadrena...\n",
              "14    Witkin - Lanoil , “ are often overreactions .\\n  Witkin - Lanoil , “ kazhinji kazhinji kunyanyi...\n",
              "15  We scream , hurl hateful semi - truths , hit ,...  Tinozhambatata tichitaura mashoko asiri echokw...\n",
              "16  An article in ’ Teen magazine similarly observ...  Nyaya iri mumagazini ye’Teen nenzira yakafanan...\n",
              "17                  Did you ever lose your temper ?\\n                             Wakambotsamwa here ?\\n\n",
              "18                      If so , you are not alone .\\n            Kana zvakadaro , hausati uriwe woga .\\n\n",
              "19  Like most of us , you no doubt felt quite fool...  Kufanana navazhinji vedu , iwe pasina panikiro..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YkuK3B4p2AkN"
      },
      "source": [
        "## Pre-processing and export\n",
        "\n",
        "It is generally a good idea to remove duplicate translations and conflicting translations from the corpus. In practice, these public corpora include some number of these that need to be cleaned.\n",
        "\n",
        "In addition we will split our data into dev/test/train and export to the filesystem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "M_2ouEOH1_1q",
        "outputId": "bf75364e-b832-44c1-8ba8-6ad0e5e93dcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# drop duplicate translations\n",
        "df_pp = df.drop_duplicates()\n",
        "\n",
        "# drop conflicting translations\n",
        "df_pp.drop_duplicates(subset='source_sentence', inplace=True)\n",
        "df_pp.drop_duplicates(subset='target_sentence', inplace=True)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hxxBOCA-xXhy",
        "outputId": "e00b5d9d-58d3-48b1-ec6e-9c53a86f163e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "# This section does the split between train/test/dev for the parallel corpora then saves them as separate files\n",
        "# We use 1000 dev test and 1000 test set. In practice, it's useful to use an external test set\n",
        "\n",
        "# Do the split between dev/test/train and create parallel corpora\n",
        "num_dev_patterns = 1000\n",
        "num_test_patterns = 1000\n",
        "\n",
        "# Lower case the corpora\n",
        "df_pp[\"source_sentence\"] = df_pp[\"source_sentence\"].str.lower()\n",
        "df_pp[\"target_sentence\"] = df_pp[\"target_sentence\"].str.lower()\n",
        "\n",
        "devtest = df_pp.tail(num_dev_patterns + num_test_patterns)\n",
        "test = devtest.tail(num_test_patterns) # Herman\n",
        "dev = devtest.head(num_dev_patterns)  # Herman: Error in original\n",
        "stripped = df_pp.drop(df_pp.tail(num_dev_patterns + num_test_patterns).index)\n",
        "\n",
        "stripped[[\"source_sentence\"]].to_csv(\"train.en\", index=False)\n",
        "stripped[[\"target_sentence\"]].to_csv(\"train.sn\", index=False)\n",
        "\n",
        "dev[[\"source_sentence\"]].to_csv(\"dev.en\", index=False)\n",
        "dev[[\"target_sentence\"]].to_csv(\"dev.sn\", index=False)\n",
        "\n",
        "test[[\"source_sentence\"]].to_csv(\"test.en\", index=False)\n",
        "test[[\"target_sentence\"]].to_csv(\"test.sn\", index=False)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "epeCydmCyS8X"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Installation of JoeyNMT\n",
        "\n",
        "JoeyNMT is a simple, minimalist NMT package which is useful for learning and teaching. Check out the documentation for JoeyNMT [here](https://joeynmt.readthedocs.io)  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iBRMm4kMxZ8L",
        "outputId": "035c51e7-aefa-4c33-f48e-00e9fb7999e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Install JoeyNMT\n",
        "! git clone https://github.com/joeynmt/joeynmt.git\n",
        "! cd joeynmt; pip3 install ."
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'joeynmt'...\n",
            "remote: Enumerating objects: 52, done.\u001b[K\n",
            "remote: Counting objects:   1% (1/52)\u001b[K\rremote: Counting objects:   3% (2/52)\u001b[K\rremote: Counting objects:   5% (3/52)\u001b[K\rremote: Counting objects:   7% (4/52)\u001b[K\rremote: Counting objects:   9% (5/52)\u001b[K\rremote: Counting objects:  11% (6/52)\u001b[K\rremote: Counting objects:  13% (7/52)\u001b[K\rremote: Counting objects:  15% (8/52)\u001b[K\rremote: Counting objects:  17% (9/52)\u001b[K\rremote: Counting objects:  19% (10/52)\u001b[K\rremote: Counting objects:  21% (11/52)\u001b[K\rremote: Counting objects:  23% (12/52)\u001b[K\rremote: Counting objects:  25% (13/52)\u001b[K\rremote: Counting objects:  26% (14/52)\u001b[K\rremote: Counting objects:  28% (15/52)\u001b[K\rremote: Counting objects:  30% (16/52)\u001b[K\rremote: Counting objects:  32% (17/52)\u001b[K\rremote: Counting objects:  34% (18/52)\u001b[K\rremote: Counting objects:  36% (19/52)\u001b[K\rremote: Counting objects:  38% (20/52)\u001b[K\rremote: Counting objects:  40% (21/52)\u001b[K\rremote: Counting objects:  42% (22/52)\u001b[K\rremote: Counting objects:  44% (23/52)\u001b[K\rremote: Counting objects:  46% (24/52)\u001b[K\rremote: Counting objects:  48% (25/52)\u001b[K\rremote: Counting objects:  50% (26/52)\u001b[K\rremote: Counting objects:  51% (27/52)\u001b[K\rremote: Counting objects:  53% (28/52)\u001b[K\rremote: Counting objects:  55% (29/52)\u001b[K\rremote: Counting objects:  57% (30/52)\u001b[K\rremote: Counting objects:  59% (31/52)\u001b[K\rremote: Counting objects:  61% (32/52)\u001b[K\rremote: Counting objects:  63% (33/52)\u001b[K\rremote: Counting objects:  65% (34/52)\u001b[K\rremote: Counting objects:  67% (35/52)\u001b[K\rremote: Counting objects:  69% (36/52)\u001b[K\rremote: Counting objects:  71% (37/52)\u001b[K\rremote: Counting objects:  73% (38/52)\u001b[K\rremote: Counting objects:  75% (39/52)\u001b[K\rremote: Counting objects:  76% (40/52)\u001b[K\rremote: Counting objects:  78% (41/52)\u001b[K\rremote: Counting objects:  80% (42/52)\u001b[K\rremote: Counting objects:  82% (43/52)\u001b[K\rremote: Counting objects:  84% (44/52)\u001b[K\rremote: Counting objects:  86% (45/52)\u001b[K\rremote: Counting objects:  88% (46/52)\u001b[K\rremote: Counting objects:  90% (47/52)\u001b[K\rremote: Counting objects:  92% (48/52)\u001b[K\rremote: Counting objects:  94% (49/52)\u001b[K\rremote: Counting objects:  96% (50/52)\u001b[K\rremote: Counting objects:  98% (51/52)\u001b[K\rremote: Counting objects: 100% (52/52)\u001b[K\rremote: Counting objects: 100% (52/52), done.\u001b[K\n",
            "remote: Compressing objects: 100% (40/40), done.\u001b[K\n",
            "remote: Total 2058 (delta 29), reused 24 (delta 12), pack-reused 2006\u001b[K\n",
            "Receiving objects: 100% (2058/2058), 2.40 MiB | 16.57 MiB/s, done.\n",
            "Resolving deltas: 100% (1418/1418), done.\n",
            "Processing /content/joeynmt\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from joeynmt==0.0.1) (0.16.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from joeynmt==0.0.1) (4.3.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from joeynmt==0.0.1) (1.16.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from joeynmt==0.0.1) (41.2.0)\n",
            "Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.6/dist-packages (from joeynmt==0.0.1) (1.2.0)\n",
            "Requirement already satisfied: tensorflow>=1.14 in /usr/local/lib/python3.6/dist-packages (from joeynmt==0.0.1) (1.15.0rc3)\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.6/dist-packages (from joeynmt==0.0.1) (0.3.1)\n",
            "Collecting sacrebleu>=1.3.6 (from joeynmt==0.0.1)\n",
            "  Downloading https://files.pythonhosted.org/packages/0e/e5/93d252182f7cbd4b59bb3ec5797e2ce33cfd6f5aadaf327db170cf4b7887/sacrebleu-1.4.2-py3-none-any.whl\n",
            "Collecting subword-nmt (from joeynmt==0.0.1)\n",
            "  Downloading https://files.pythonhosted.org/packages/26/08/58267cb3ac00f5f895457777ed9e0d106dbb5e6388fa7923d8663b04b849/subword_nmt-0.3.6-py2.py3-none-any.whl\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from joeynmt==0.0.1) (3.0.3)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (from joeynmt==0.0.1) (0.9.0)\n",
            "Collecting pyyaml>=5.1 (from joeynmt==0.0.1)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/e8/b3212641ee2718d556df0f23f78de8303f068fe29cdaa7a91018849582fe/PyYAML-5.1.2.tar.gz (265kB)\n",
            "\u001b[K     |████████████████████████████████| 266kB 9.6MB/s \n",
            "\u001b[?25hCollecting pylint (from joeynmt==0.0.1)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ef/ed/1cb8e7b85a31807aa0bff8b3e60935370bed7e141df8b530aac6352bddff/pylint-2.4.2-py3-none-any.whl (302kB)\n",
            "\u001b[K     |████████████████████████████████| 307kB 40.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.12 in /usr/local/lib/python3.6/dist-packages (from joeynmt==0.0.1) (1.12.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->joeynmt==0.0.1) (0.46)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (0.2.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (0.1.7)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (0.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (1.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (3.1.0)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (1.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (1.11.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (3.7.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (1.15.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (0.8.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (0.33.6)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (1.0.8)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext->joeynmt==0.0.1) (4.28.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext->joeynmt==0.0.1) (2.21.0)\n",
            "Collecting portalocker (from sacrebleu>=1.3.6->joeynmt==0.0.1)\n",
            "  Downloading https://files.pythonhosted.org/packages/60/ec/836a494dbaa72541f691ec4e66f29fdc8db9bcc7f49e1c2d457ba13ced42/portalocker-1.5.1-py2.py3-none-any.whl\n",
            "Collecting typing (from sacrebleu>=1.3.6->joeynmt==0.0.1)\n",
            "  Downloading https://files.pythonhosted.org/packages/fe/2e/b480ee1b75e6d17d2993738670e75c1feeb9ff7f64452153cf018051cc92/typing-3.7.4.1-py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->joeynmt==0.0.1) (2.5.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->joeynmt==0.0.1) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->joeynmt==0.0.1) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->joeynmt==0.0.1) (2.4.2)\n",
            "Requirement already satisfied: pandas>=0.15.2 in /usr/local/lib/python3.6/dist-packages (from seaborn->joeynmt==0.0.1) (0.24.2)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from seaborn->joeynmt==0.0.1) (1.3.1)\n",
            "Collecting isort<5,>=4.2.5 (from pylint->joeynmt==0.0.1)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/b0/c121fd1fa3419ea9bfd55c7f9c4fedfec5143208d8c7ad3ce3db6c623c21/isort-4.3.21-py2.py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 21.7MB/s \n",
            "\u001b[?25hCollecting mccabe<0.7,>=0.6 (from pylint->joeynmt==0.0.1)\n",
            "  Downloading https://files.pythonhosted.org/packages/87/89/479dc97e18549e21354893e4ee4ef36db1d237534982482c3681ee6e7b57/mccabe-0.6.1-py2.py3-none-any.whl\n",
            "Collecting astroid<2.4,>=2.3.0 (from pylint->joeynmt==0.0.1)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/e1/74a63c85c501c29c52da5be604c025e368f4dd77daf1fa13c878a33e5a36/astroid-2.3.1-py3-none-any.whl (205kB)\n",
            "\u001b[K     |████████████████████████████████| 215kB 39.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow>=1.14->joeynmt==0.0.1) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow>=1.14->joeynmt==0.0.1) (0.16.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow>=1.14->joeynmt==0.0.1) (2.8.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext->joeynmt==0.0.1) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext->joeynmt==0.0.1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext->joeynmt==0.0.1) (2019.9.11)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext->joeynmt==0.0.1) (2.8)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.15.2->seaborn->joeynmt==0.0.1) (2018.9)\n",
            "Collecting lazy-object-proxy==1.4.* (from astroid<2.4,>=2.3.0->pylint->joeynmt==0.0.1)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/26/534a6d32572a9dbca11619321535c0a7ab34688545d9d67c2c204b9e3a3d/lazy_object_proxy-1.4.2-cp36-cp36m-manylinux1_x86_64.whl (49kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 20.5MB/s \n",
            "\u001b[?25hCollecting typed-ast<1.5,>=1.4.0; implementation_name == \"cpython\" and python_version < \"3.8\" (from astroid<2.4,>=2.3.0->pylint->joeynmt==0.0.1)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/31/d3/9d1802c161626d0278bafb1ffb32f76b9d01e123881bbf9d91e8ccf28e18/typed_ast-1.4.0-cp36-cp36m-manylinux1_x86_64.whl (736kB)\n",
            "\u001b[K     |████████████████████████████████| 737kB 39.4MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: joeynmt, pyyaml\n",
            "  Building wheel for joeynmt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for joeynmt: filename=joeynmt-0.0.1-cp36-none-any.whl size=69430 sha256=671ff7e8d9903d7be22daed23125f54c3edaa39be47a70e126aad34b0fa0f26d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-j9ns8cw4/wheels/db/01/db/751cc9f3e7f6faec127c43644ba250a3ea7ad200594aeda70a\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyyaml: filename=PyYAML-5.1.2-cp36-cp36m-linux_x86_64.whl size=44104 sha256=9226f59010e0e4fae37b29e372b5ddaec24db48592d016a85179428b29d5f8c7\n",
            "  Stored in directory: /root/.cache/pip/wheels/d9/45/dd/65f0b38450c47cf7e5312883deb97d065e030c5cca0a365030\n",
            "Successfully built joeynmt pyyaml\n",
            "Installing collected packages: portalocker, typing, sacrebleu, subword-nmt, pyyaml, isort, mccabe, lazy-object-proxy, typed-ast, astroid, pylint, joeynmt\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed astroid-2.3.1 isort-4.3.21 joeynmt-0.0.1 lazy-object-proxy-1.4.2 mccabe-0.6.1 portalocker-1.5.1 pylint-2.4.2 pyyaml-5.1.2 sacrebleu-1.4.2 subword-nmt-0.3.6 typed-ast-1.4.0 typing-3.7.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AaE77Tcppex9"
      },
      "source": [
        "# Preprocessing the Data into Subword BPE Tokens\n",
        "\n",
        "- One of the most powerful improvements for agglutinative languages (a feature of most Bantu languages) is using BPE tokenization [ (Sennrich, 2015) ](https://arxiv.org/abs/1508.07909).\n",
        "\n",
        "- It was also shown that by optimizing the umber of BPE codes we significantly improve results for low-resourced languages [(Sennrich, 2019)](https://www.aclweb.org/anthology/P19-1021) [(Martinus, 2019)](https://arxiv.org/abs/1906.05685)\n",
        "\n",
        "- Below we have the scripts for doing BPE tokenization of our data. We use 4000 tokens as recommended by [(Sennrich, 2019)](https://www.aclweb.org/anthology/P19-1021). You do not need to change anything. Simply running the below will be suitable. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H-TyjtmXB1mL",
        "outputId": "eda16eca-2cbf-40f4-88ba-833ed7d9b563",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "# One of the huge boosts in NMT performance was to use a different method of tokenizing. \n",
        "# Usually, NMT would tokenize by words. However, using a method called BPE gave amazing boosts to performance\n",
        "\n",
        "# Do subword NMT\n",
        "from os import path\n",
        "\n",
        "os.environ[\"data_path\"] = path.join(\"joeynmt\", \"data\", source_language + target_language) # Herman! \n",
        "! subword-nmt learn-joint-bpe-and-vocab --input train.$src train.$tgt -s 4000 -o bpe.codes.4000 --write-vocabulary vocab.$src vocab.$tgt\n",
        "\n",
        "! subword-nmt apply-bpe -c bpe.codes.4000 --vocabulary vocab.$src < train.$src > train.bpe.$src\n",
        "! subword-nmt apply-bpe -c bpe.codes.4000 --vocabulary vocab.$tgt < train.$tgt > train.bpe.$tgt\n",
        "\n",
        "! subword-nmt apply-bpe -c bpe.codes.4000 --vocabulary vocab.$src < dev.$src > dev.bpe.$src\n",
        "! subword-nmt apply-bpe -c bpe.codes.4000 --vocabulary vocab.$tgt < dev.$tgt > dev.bpe.$tgt\n",
        "! subword-nmt apply-bpe -c bpe.codes.4000 --vocabulary vocab.$src < test.$src > test.bpe.$src\n",
        "! subword-nmt apply-bpe -c bpe.codes.4000 --vocabulary vocab.$tgt < test.$tgt > test.bpe.$tgt\n",
        "\n",
        "# Create directory, move everyone we care about to the correct location\n",
        "! mkdir -p $data_path\n",
        "! cp train.* $data_path\n",
        "! cp test.* $data_path\n",
        "! cp dev.* $data_path\n",
        "! cp bpe.codes.4000 $data_path\n",
        "! ls $data_path\n",
        "\n",
        "# Also move everything we care about to a mounted location in google drive (relevant if running in colab) at gdrive_path\n",
        "! cp train.* \"$gdrive_path\"\n",
        "! cp test.* \"$gdrive_path\"\n",
        "! cp dev.* \"$gdrive_path\"\n",
        "! cp bpe.codes.4000 \"$gdrive_path\"\n",
        "! ls \"$gdrive_path\"\n",
        "\n",
        "# Create that vocab using build_vocab\n",
        "! sudo chmod 777 joeynmt/scripts/build_vocab.py\n",
        "! joeynmt/scripts/build_vocab.py joeynmt/data/$src$tgt/train.bpe.$src joeynmt/data/$src$tgt/train.bpe.$tgt --output_path joeynmt/data/$src$tgt/vocab.txt\n",
        "\n",
        "# Some output\n",
        "! echo \"BPE Shona Sentences\"\n",
        "! tail -n 5 test.bpe.$tgt\n",
        "! echo \"Combined BPE Vocab\"\n",
        "! tail -n 10 joeynmt/data/ensn/vocab.txt"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bpe.codes.4000\tdev.en\t     test.bpe.sn  train.bpe.en\ttrain.sn\n",
            "dev.bpe.en\tdev.sn\t     test.en\t  train.bpe.sn\n",
            "dev.bpe.sn\ttest.bpe.en  test.sn\t  train.en\n",
            "bpe.codes.4000\tdev.en\t     test.bpe.sn  train.bpe.en\ttrain.sn\n",
            "dev.bpe.en\tdev.sn\t     test.en\t  train.bpe.sn\n",
            "dev.bpe.sn\ttest.bpe.en  test.sn\t  train.en\n",
            "BPE Shona Sentences\n",
            "\"\n",
            "\"pane cha@@ unogona kushandisa muushumiri here ?\n",
            "\"\n",
            "\"kana uk@@ aita izvi ucha@@ yeuka pfungwa dzino@@ kosha uye vamwe vach@@ ab@@ ats@@ irwa ne@@ kudzidza kwa@@ un@@ enge uchi@@ ita .\n",
            "\"\n",
            "Combined BPE Vocab\n",
            "☒\n",
            "›\n",
            "̆\n",
            "evhang@@\n",
            ";@@\n",
            "×\n",
            "ḥ\n",
            "̀@@\n",
            "❍\n",
            "ι\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IlMitUHR8Qy-",
        "outputId": "db98e73f-5196-49d5-9f3b-12c451b558eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Also move everything we care about to a mounted location in google drive (relevant if running in colab) at gdrive_path\n",
        "! cp train.* \"$gdrive_path\"\n",
        "! cp test.* \"$gdrive_path\"\n",
        "! cp dev.* \"$gdrive_path\"\n",
        "! cp bpe.codes.4000 \"$gdrive_path\"\n",
        "! ls \"$gdrive_path\""
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bpe.codes.4000\tdev.en\t     test.bpe.sn  train.bpe.en\ttrain.sn\n",
            "dev.bpe.en\tdev.sn\t     test.en\t  train.bpe.sn\n",
            "dev.bpe.sn\ttest.bpe.en  test.sn\t  train.en\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ixmzi60WsUZ8"
      },
      "source": [
        "# Creating the JoeyNMT Config\n",
        "\n",
        "JoeyNMT requires a yaml config. We provide a template below. We've also set a number of defaults with it, that you may play with!\n",
        "\n",
        "- We used Transformer architecture \n",
        "- We set our dropout to reasonably high: 0.3 (recommended in  [(Sennrich, 2019)](https://www.aclweb.org/anthology/P19-1021))\n",
        "\n",
        "Things worth playing with:\n",
        "- The batch size (also recommended to change for low-resourced languages)\n",
        "- The number of epochs (we've set it at 30 just so it runs in about an hour, for testing purposes)\n",
        "- The decoder options (beam_size, alpha)\n",
        "- Evaluation metrics (BLEU versus Crhf4)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PIs1lY2hxMsl",
        "colab": {}
      },
      "source": [
        "# This creates the config file for our JoeyNMT system. It might seem overwhelming so we've provided a couple of useful parameters you'll need to update\n",
        "# (You can of course play with all the parameters if you'd like!)\n",
        "\n",
        "name = '%s%s' % (source_language, target_language)\n",
        "gdrive_path = os.environ[\"gdrive_path\"]\n",
        "\n",
        "# Create the config\n",
        "config = \"\"\"\n",
        "name: \"{name}_transformer\"\n",
        "\n",
        "data:\n",
        "    src: \"{source_language}\"\n",
        "    trg: \"{target_language}\"\n",
        "    train: \"data/{name}/train.bpe\"\n",
        "    dev:   \"data/{name}/dev.bpe\"\n",
        "    test:  \"data/{name}/test.bpe\"\n",
        "    level: \"bpe\"\n",
        "    lowercase: False\n",
        "    max_sent_length: 100\n",
        "    src_vocab: \"data/{name}/vocab.txt\"\n",
        "    trg_vocab: \"data/{name}/vocab.txt\"\n",
        "\n",
        "testing:\n",
        "    beam_size: 5\n",
        "    alpha: 1.0\n",
        "\n",
        "training:\n",
        "    load_model: \"{gdrive_path}/models/{name}_transformer/16000.ckpt\" # if uncommented, load a pre-trained model from this checkpoint\n",
        "    random_seed: 42\n",
        "    optimizer: \"adam\"\n",
        "    normalization: \"tokens\"\n",
        "    adam_betas: [0.9, 0.999] \n",
        "    scheduling: \"noam\"            # Try switching from plateau to Noam scheduling\n",
        "    learning_rate_factor: 0.5       # factor for Noam scheduler (used with Transformer)\n",
        "    learning_rate_warmup: 1000      # warmup steps for Noam scheduler (used with Transformer)\n",
        "    patience: 8\n",
        "    decrease_factor: 0.7\n",
        "    loss: \"crossentropy\"\n",
        "    learning_rate: 0.0002\n",
        "    learning_rate_min: 0.00000001\n",
        "    weight_decay: 0.0\n",
        "    label_smoothing: 0.1\n",
        "    batch_size: 4096\n",
        "    batch_type: \"token\"\n",
        "    eval_batch_size: 3600\n",
        "    eval_batch_type: \"token\"\n",
        "    batch_multiplier: 1\n",
        "    early_stopping_metric: \"ppl\"\n",
        "    epochs: 30 # TODO: Decrease for when playing around and checking of working. Around 30 is sufficient to check if its working at all\n",
        "    validation_freq: 4000 # Decrease this for testing\n",
        "    logging_freq: 100\n",
        "    eval_metric: \"bleu\"\n",
        "    model_dir: \"models/{name}_transformer\"\n",
        "    overwrite: True\n",
        "    shuffle: True\n",
        "    use_cuda: True\n",
        "    max_output_length: 100\n",
        "    print_valid_sents: [0, 1, 2, 3]\n",
        "    keep_last_ckpts: 3\n",
        "\n",
        "model:\n",
        "    initializer: \"xavier\"\n",
        "    bias_initializer: \"zeros\"\n",
        "    init_gain: 1.0\n",
        "    embed_initializer: \"xavier\"\n",
        "    embed_init_gain: 1.0\n",
        "    tied_embeddings: True\n",
        "    tied_softmax: True\n",
        "    encoder:\n",
        "        type: \"transformer\"\n",
        "        num_layers: 6\n",
        "        num_heads: 8\n",
        "        embeddings:\n",
        "            embedding_dim: 512\n",
        "            scale: True\n",
        "            dropout: 0.\n",
        "        # typically ff_size = 4 x hidden_size\n",
        "        hidden_size: 512\n",
        "        ff_size: 2048\n",
        "        dropout: 0.3\n",
        "    decoder:\n",
        "        type: \"transformer\"\n",
        "        num_layers: 6\n",
        "        num_heads: 8\n",
        "        embeddings:\n",
        "            embedding_dim: 512\n",
        "            scale: True\n",
        "            dropout: 0.\n",
        "        # typically ff_size = 4 x hidden_size\n",
        "        hidden_size: 512\n",
        "        ff_size: 2048\n",
        "        dropout: 0.3\n",
        "\"\"\".format(name=name, gdrive_path=os.environ[\"gdrive_path\"], source_language=source_language, target_language=target_language)\n",
        "with open(\"joeynmt/configs/transformer_{name}.yaml\".format(name=name),'w') as f:\n",
        "    f.write(config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pIifxE3Qzuvs"
      },
      "source": [
        "# Train the Model\n",
        "\n",
        "This single line of joeynmt runs the training using the config we made above"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6ZBPFwT94WpI",
        "outputId": "7bb3e905-35af-4227-94da-5f54385e341a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Train the model\n",
        "# You can press Ctrl-C to stop. And then run the next cell to save your checkpoints! \n",
        "!cd joeynmt; python3 -m joeynmt train configs/transformer_$src$tgt.yaml"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-10-15 15:15:49,057 Hello! This is Joey-NMT.\n",
            "2019-10-15 15:15:50,703 Total params: 46364672\n",
            "2019-10-15 15:15:50,705 Trainable parameters: ['decoder.layer_norm.bias', 'decoder.layer_norm.weight', 'decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'decoder.layers.1.dec_layer_norm.bias', 'decoder.layers.1.dec_layer_norm.weight', 'decoder.layers.1.feed_forward.layer_norm.bias', 'decoder.layers.1.feed_forward.layer_norm.weight', 'decoder.layers.1.feed_forward.pwff_layer.0.bias', 'decoder.layers.1.feed_forward.pwff_layer.0.weight', 'decoder.layers.1.feed_forward.pwff_layer.3.bias', 'decoder.layers.1.feed_forward.pwff_layer.3.weight', 'decoder.layers.1.src_trg_att.k_layer.bias', 'decoder.layers.1.src_trg_att.k_layer.weight', 'decoder.layers.1.src_trg_att.output_layer.bias', 'decoder.layers.1.src_trg_att.output_layer.weight', 'decoder.layers.1.src_trg_att.q_layer.bias', 'decoder.layers.1.src_trg_att.q_layer.weight', 'decoder.layers.1.src_trg_att.v_layer.bias', 'decoder.layers.1.src_trg_att.v_layer.weight', 'decoder.layers.1.trg_trg_att.k_layer.bias', 'decoder.layers.1.trg_trg_att.k_layer.weight', 'decoder.layers.1.trg_trg_att.output_layer.bias', 'decoder.layers.1.trg_trg_att.output_layer.weight', 'decoder.layers.1.trg_trg_att.q_layer.bias', 'decoder.layers.1.trg_trg_att.q_layer.weight', 'decoder.layers.1.trg_trg_att.v_layer.bias', 'decoder.layers.1.trg_trg_att.v_layer.weight', 'decoder.layers.1.x_layer_norm.bias', 'decoder.layers.1.x_layer_norm.weight', 'decoder.layers.2.dec_layer_norm.bias', 'decoder.layers.2.dec_layer_norm.weight', 'decoder.layers.2.feed_forward.layer_norm.bias', 'decoder.layers.2.feed_forward.layer_norm.weight', 'decoder.layers.2.feed_forward.pwff_layer.0.bias', 'decoder.layers.2.feed_forward.pwff_layer.0.weight', 'decoder.layers.2.feed_forward.pwff_layer.3.bias', 'decoder.layers.2.feed_forward.pwff_layer.3.weight', 'decoder.layers.2.src_trg_att.k_layer.bias', 'decoder.layers.2.src_trg_att.k_layer.weight', 'decoder.layers.2.src_trg_att.output_layer.bias', 'decoder.layers.2.src_trg_att.output_layer.weight', 'decoder.layers.2.src_trg_att.q_layer.bias', 'decoder.layers.2.src_trg_att.q_layer.weight', 'decoder.layers.2.src_trg_att.v_layer.bias', 'decoder.layers.2.src_trg_att.v_layer.weight', 'decoder.layers.2.trg_trg_att.k_layer.bias', 'decoder.layers.2.trg_trg_att.k_layer.weight', 'decoder.layers.2.trg_trg_att.output_layer.bias', 'decoder.layers.2.trg_trg_att.output_layer.weight', 'decoder.layers.2.trg_trg_att.q_layer.bias', 'decoder.layers.2.trg_trg_att.q_layer.weight', 'decoder.layers.2.trg_trg_att.v_layer.bias', 'decoder.layers.2.trg_trg_att.v_layer.weight', 'decoder.layers.2.x_layer_norm.bias', 'decoder.layers.2.x_layer_norm.weight', 'decoder.layers.3.dec_layer_norm.bias', 'decoder.layers.3.dec_layer_norm.weight', 'decoder.layers.3.feed_forward.layer_norm.bias', 'decoder.layers.3.feed_forward.layer_norm.weight', 'decoder.layers.3.feed_forward.pwff_layer.0.bias', 'decoder.layers.3.feed_forward.pwff_layer.0.weight', 'decoder.layers.3.feed_forward.pwff_layer.3.bias', 'decoder.layers.3.feed_forward.pwff_layer.3.weight', 'decoder.layers.3.src_trg_att.k_layer.bias', 'decoder.layers.3.src_trg_att.k_layer.weight', 'decoder.layers.3.src_trg_att.output_layer.bias', 'decoder.layers.3.src_trg_att.output_layer.weight', 'decoder.layers.3.src_trg_att.q_layer.bias', 'decoder.layers.3.src_trg_att.q_layer.weight', 'decoder.layers.3.src_trg_att.v_layer.bias', 'decoder.layers.3.src_trg_att.v_layer.weight', 'decoder.layers.3.trg_trg_att.k_layer.bias', 'decoder.layers.3.trg_trg_att.k_layer.weight', 'decoder.layers.3.trg_trg_att.output_layer.bias', 'decoder.layers.3.trg_trg_att.output_layer.weight', 'decoder.layers.3.trg_trg_att.q_layer.bias', 'decoder.layers.3.trg_trg_att.q_layer.weight', 'decoder.layers.3.trg_trg_att.v_layer.bias', 'decoder.layers.3.trg_trg_att.v_layer.weight', 'decoder.layers.3.x_layer_norm.bias', 'decoder.layers.3.x_layer_norm.weight', 'decoder.layers.4.dec_layer_norm.bias', 'decoder.layers.4.dec_layer_norm.weight', 'decoder.layers.4.feed_forward.layer_norm.bias', 'decoder.layers.4.feed_forward.layer_norm.weight', 'decoder.layers.4.feed_forward.pwff_layer.0.bias', 'decoder.layers.4.feed_forward.pwff_layer.0.weight', 'decoder.layers.4.feed_forward.pwff_layer.3.bias', 'decoder.layers.4.feed_forward.pwff_layer.3.weight', 'decoder.layers.4.src_trg_att.k_layer.bias', 'decoder.layers.4.src_trg_att.k_layer.weight', 'decoder.layers.4.src_trg_att.output_layer.bias', 'decoder.layers.4.src_trg_att.output_layer.weight', 'decoder.layers.4.src_trg_att.q_layer.bias', 'decoder.layers.4.src_trg_att.q_layer.weight', 'decoder.layers.4.src_trg_att.v_layer.bias', 'decoder.layers.4.src_trg_att.v_layer.weight', 'decoder.layers.4.trg_trg_att.k_layer.bias', 'decoder.layers.4.trg_trg_att.k_layer.weight', 'decoder.layers.4.trg_trg_att.output_layer.bias', 'decoder.layers.4.trg_trg_att.output_layer.weight', 'decoder.layers.4.trg_trg_att.q_layer.bias', 'decoder.layers.4.trg_trg_att.q_layer.weight', 'decoder.layers.4.trg_trg_att.v_layer.bias', 'decoder.layers.4.trg_trg_att.v_layer.weight', 'decoder.layers.4.x_layer_norm.bias', 'decoder.layers.4.x_layer_norm.weight', 'decoder.layers.5.dec_layer_norm.bias', 'decoder.layers.5.dec_layer_norm.weight', 'decoder.layers.5.feed_forward.layer_norm.bias', 'decoder.layers.5.feed_forward.layer_norm.weight', 'decoder.layers.5.feed_forward.pwff_layer.0.bias', 'decoder.layers.5.feed_forward.pwff_layer.0.weight', 'decoder.layers.5.feed_forward.pwff_layer.3.bias', 'decoder.layers.5.feed_forward.pwff_layer.3.weight', 'decoder.layers.5.src_trg_att.k_layer.bias', 'decoder.layers.5.src_trg_att.k_layer.weight', 'decoder.layers.5.src_trg_att.output_layer.bias', 'decoder.layers.5.src_trg_att.output_layer.weight', 'decoder.layers.5.src_trg_att.q_layer.bias', 'decoder.layers.5.src_trg_att.q_layer.weight', 'decoder.layers.5.src_trg_att.v_layer.bias', 'decoder.layers.5.src_trg_att.v_layer.weight', 'decoder.layers.5.trg_trg_att.k_layer.bias', 'decoder.layers.5.trg_trg_att.k_layer.weight', 'decoder.layers.5.trg_trg_att.output_layer.bias', 'decoder.layers.5.trg_trg_att.output_layer.weight', 'decoder.layers.5.trg_trg_att.q_layer.bias', 'decoder.layers.5.trg_trg_att.q_layer.weight', 'decoder.layers.5.trg_trg_att.v_layer.bias', 'decoder.layers.5.trg_trg_att.v_layer.weight', 'decoder.layers.5.x_layer_norm.bias', 'decoder.layers.5.x_layer_norm.weight', 'encoder.layer_norm.bias', 'encoder.layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'encoder.layers.3.feed_forward.layer_norm.bias', 'encoder.layers.3.feed_forward.layer_norm.weight', 'encoder.layers.3.feed_forward.pwff_layer.0.bias', 'encoder.layers.3.feed_forward.pwff_layer.0.weight', 'encoder.layers.3.feed_forward.pwff_layer.3.bias', 'encoder.layers.3.feed_forward.pwff_layer.3.weight', 'encoder.layers.3.layer_norm.bias', 'encoder.layers.3.layer_norm.weight', 'encoder.layers.3.src_src_att.k_layer.bias', 'encoder.layers.3.src_src_att.k_layer.weight', 'encoder.layers.3.src_src_att.output_layer.bias', 'encoder.layers.3.src_src_att.output_layer.weight', 'encoder.layers.3.src_src_att.q_layer.bias', 'encoder.layers.3.src_src_att.q_layer.weight', 'encoder.layers.3.src_src_att.v_layer.bias', 'encoder.layers.3.src_src_att.v_layer.weight', 'encoder.layers.4.feed_forward.layer_norm.bias', 'encoder.layers.4.feed_forward.layer_norm.weight', 'encoder.layers.4.feed_forward.pwff_layer.0.bias', 'encoder.layers.4.feed_forward.pwff_layer.0.weight', 'encoder.layers.4.feed_forward.pwff_layer.3.bias', 'encoder.layers.4.feed_forward.pwff_layer.3.weight', 'encoder.layers.4.layer_norm.bias', 'encoder.layers.4.layer_norm.weight', 'encoder.layers.4.src_src_att.k_layer.bias', 'encoder.layers.4.src_src_att.k_layer.weight', 'encoder.layers.4.src_src_att.output_layer.bias', 'encoder.layers.4.src_src_att.output_layer.weight', 'encoder.layers.4.src_src_att.q_layer.bias', 'encoder.layers.4.src_src_att.q_layer.weight', 'encoder.layers.4.src_src_att.v_layer.bias', 'encoder.layers.4.src_src_att.v_layer.weight', 'encoder.layers.5.feed_forward.layer_norm.bias', 'encoder.layers.5.feed_forward.layer_norm.weight', 'encoder.layers.5.feed_forward.pwff_layer.0.bias', 'encoder.layers.5.feed_forward.pwff_layer.0.weight', 'encoder.layers.5.feed_forward.pwff_layer.3.bias', 'encoder.layers.5.feed_forward.pwff_layer.3.weight', 'encoder.layers.5.layer_norm.bias', 'encoder.layers.5.layer_norm.weight', 'encoder.layers.5.src_src_att.k_layer.bias', 'encoder.layers.5.src_src_att.k_layer.weight', 'encoder.layers.5.src_src_att.output_layer.bias', 'encoder.layers.5.src_src_att.output_layer.weight', 'encoder.layers.5.src_src_att.q_layer.bias', 'encoder.layers.5.src_src_att.q_layer.weight', 'encoder.layers.5.src_src_att.v_layer.bias', 'encoder.layers.5.src_src_att.v_layer.weight', 'src_embed.lut.weight']\n",
            "2019-10-15 15:15:53,635 Loading model from /content/drive/My Drive/masakhane/en-sn-baseline/models/ensn_transformer/16000.ckpt\n",
            "2019-10-15 15:15:55,246 cfg.name                           : ensn_transformer\n",
            "2019-10-15 15:15:55,246 cfg.data.src                       : en\n",
            "2019-10-15 15:15:55,247 cfg.data.trg                       : sn\n",
            "2019-10-15 15:15:55,247 cfg.data.train                     : data/ensn/train.bpe\n",
            "2019-10-15 15:15:55,247 cfg.data.dev                       : data/ensn/dev.bpe\n",
            "2019-10-15 15:15:55,247 cfg.data.test                      : data/ensn/test.bpe\n",
            "2019-10-15 15:15:55,247 cfg.data.level                     : bpe\n",
            "2019-10-15 15:15:55,247 cfg.data.lowercase                 : False\n",
            "2019-10-15 15:15:55,248 cfg.data.max_sent_length           : 100\n",
            "2019-10-15 15:15:55,248 cfg.data.src_vocab                 : data/ensn/vocab.txt\n",
            "2019-10-15 15:15:55,248 cfg.data.trg_vocab                 : data/ensn/vocab.txt\n",
            "2019-10-15 15:15:55,248 cfg.testing.beam_size              : 5\n",
            "2019-10-15 15:15:55,248 cfg.testing.alpha                  : 1.0\n",
            "2019-10-15 15:15:55,248 cfg.training.load_model            : /content/drive/My Drive/masakhane/en-sn-baseline/models/ensn_transformer/16000.ckpt\n",
            "2019-10-15 15:15:55,248 cfg.training.random_seed           : 42\n",
            "2019-10-15 15:15:55,248 cfg.training.optimizer             : adam\n",
            "2019-10-15 15:15:55,249 cfg.training.normalization         : tokens\n",
            "2019-10-15 15:15:55,249 cfg.training.adam_betas            : [0.9, 0.999]\n",
            "2019-10-15 15:15:55,249 cfg.training.scheduling            : noam\n",
            "2019-10-15 15:15:55,249 cfg.training.learning_rate_factor  : 0.5\n",
            "2019-10-15 15:15:55,249 cfg.training.learning_rate_warmup  : 1000\n",
            "2019-10-15 15:15:55,249 cfg.training.patience              : 8\n",
            "2019-10-15 15:15:55,249 cfg.training.decrease_factor       : 0.7\n",
            "2019-10-15 15:15:55,249 cfg.training.loss                  : crossentropy\n",
            "2019-10-15 15:15:55,249 cfg.training.learning_rate         : 0.0002\n",
            "2019-10-15 15:15:55,249 cfg.training.learning_rate_min     : 1e-08\n",
            "2019-10-15 15:15:55,249 cfg.training.weight_decay          : 0.0\n",
            "2019-10-15 15:15:55,249 cfg.training.label_smoothing       : 0.1\n",
            "2019-10-15 15:15:55,250 cfg.training.batch_size            : 4096\n",
            "2019-10-15 15:15:55,250 cfg.training.batch_type            : token\n",
            "2019-10-15 15:15:55,250 cfg.training.eval_batch_size       : 3600\n",
            "2019-10-15 15:15:55,250 cfg.training.eval_batch_type       : token\n",
            "2019-10-15 15:15:55,250 cfg.training.batch_multiplier      : 1\n",
            "2019-10-15 15:15:55,250 cfg.training.early_stopping_metric : ppl\n",
            "2019-10-15 15:15:55,250 cfg.training.epochs                : 30\n",
            "2019-10-15 15:15:55,250 cfg.training.validation_freq       : 4000\n",
            "2019-10-15 15:15:55,250 cfg.training.logging_freq          : 100\n",
            "2019-10-15 15:15:55,250 cfg.training.eval_metric           : bleu\n",
            "2019-10-15 15:15:55,250 cfg.training.model_dir             : models/ensn_transformer\n",
            "2019-10-15 15:15:55,250 cfg.training.overwrite             : True\n",
            "2019-10-15 15:15:55,250 cfg.training.shuffle               : True\n",
            "2019-10-15 15:15:55,250 cfg.training.use_cuda              : True\n",
            "2019-10-15 15:15:55,251 cfg.training.max_output_length     : 100\n",
            "2019-10-15 15:15:55,251 cfg.training.print_valid_sents     : [0, 1, 2, 3]\n",
            "2019-10-15 15:15:55,251 cfg.training.keep_last_ckpts       : 3\n",
            "2019-10-15 15:15:55,251 cfg.model.initializer              : xavier\n",
            "2019-10-15 15:15:55,251 cfg.model.bias_initializer         : zeros\n",
            "2019-10-15 15:15:55,251 cfg.model.init_gain                : 1.0\n",
            "2019-10-15 15:15:55,251 cfg.model.embed_initializer        : xavier\n",
            "2019-10-15 15:15:55,251 cfg.model.embed_init_gain          : 1.0\n",
            "2019-10-15 15:15:55,251 cfg.model.tied_embeddings          : True\n",
            "2019-10-15 15:15:55,251 cfg.model.tied_softmax             : True\n",
            "2019-10-15 15:15:55,251 cfg.model.encoder.type             : transformer\n",
            "2019-10-15 15:15:55,251 cfg.model.encoder.num_layers       : 6\n",
            "2019-10-15 15:15:55,252 cfg.model.encoder.num_heads        : 8\n",
            "2019-10-15 15:15:55,252 cfg.model.encoder.embeddings.embedding_dim : 512\n",
            "2019-10-15 15:15:55,252 cfg.model.encoder.embeddings.scale : True\n",
            "2019-10-15 15:15:55,252 cfg.model.encoder.embeddings.dropout : 0.0\n",
            "2019-10-15 15:15:55,252 cfg.model.encoder.hidden_size      : 512\n",
            "2019-10-15 15:15:55,252 cfg.model.encoder.ff_size          : 2048\n",
            "2019-10-15 15:15:55,252 cfg.model.encoder.dropout          : 0.3\n",
            "2019-10-15 15:15:55,252 cfg.model.decoder.type             : transformer\n",
            "2019-10-15 15:15:55,252 cfg.model.decoder.num_layers       : 6\n",
            "2019-10-15 15:15:55,252 cfg.model.decoder.num_heads        : 8\n",
            "2019-10-15 15:15:55,252 cfg.model.decoder.embeddings.embedding_dim : 512\n",
            "2019-10-15 15:15:55,253 cfg.model.decoder.embeddings.scale : True\n",
            "2019-10-15 15:15:55,253 cfg.model.decoder.embeddings.dropout : 0.0\n",
            "2019-10-15 15:15:55,253 cfg.model.decoder.hidden_size      : 512\n",
            "2019-10-15 15:15:55,253 cfg.model.decoder.ff_size          : 2048\n",
            "2019-10-15 15:15:55,253 cfg.model.decoder.dropout          : 0.3\n",
            "2019-10-15 15:15:55,253 Data set sizes: \n",
            "\ttrain 1430611,\n",
            "\tvalid 2001,\n",
            "\ttest 2001\n",
            "2019-10-15 15:15:55,253 First training example:\n",
            "\t[SRC] sour@@ ce@@ _@@ s@@ ent@@ ence\n",
            "\t[TRG] tar@@ get@@ _@@ s@@ ent@@ ence\n",
            "2019-10-15 15:15:55,253 First 10 words (src): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) \" (5) . (6) , (7) the (8) \"@@ (9) to\n",
            "2019-10-15 15:15:55,253 First 10 words (trg): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) \" (5) . (6) , (7) the (8) \"@@ (9) to\n",
            "2019-10-15 15:15:55,254 Number of Src words (types): 4344\n",
            "2019-10-15 15:15:55,254 Number of Trg words (types): 4344\n",
            "2019-10-15 15:15:55,254 Model(\n",
            "\tencoder=TransformerEncoder(num_layers=6, num_heads=8),\n",
            "\tdecoder=TransformerDecoder(num_layers=6, num_heads=8),\n",
            "\tsrc_embed=Embeddings(embedding_dim=512, vocab_size=4344),\n",
            "\ttrg_embed=Embeddings(embedding_dim=512, vocab_size=4344))\n",
            "2019-10-15 15:15:55,261 EPOCH 1\n",
            "2019-10-15 15:17:15,300 Epoch   1 Step:    16100 Batch Loss:     1.460289 Tokens per Sec:     3208, Lr: 0.000070\n",
            "2019-10-15 15:18:30,330 Epoch   1 Step:    16200 Batch Loss:     0.009776 Tokens per Sec:     6734, Lr: 0.000140\n",
            "2019-10-15 15:19:45,044 Epoch   1 Step:    16300 Batch Loss:     1.437217 Tokens per Sec:    10159, Lr: 0.000210\n",
            "2019-10-15 15:21:00,824 Epoch   1 Step:    16400 Batch Loss:     1.420363 Tokens per Sec:    13392, Lr: 0.000280\n",
            "2019-10-15 15:22:16,002 Epoch   1 Step:    16500 Batch Loss:     1.586247 Tokens per Sec:    16869, Lr: 0.000349\n",
            "2019-10-15 15:23:30,193 Epoch   1 Step:    16600 Batch Loss:     1.590392 Tokens per Sec:    20418, Lr: 0.000419\n",
            "2019-10-15 15:24:44,389 Epoch   1 Step:    16700 Batch Loss:     0.009941 Tokens per Sec:    23827, Lr: 0.000489\n",
            "2019-10-15 15:26:00,150 Epoch   1 Step:    16800 Batch Loss:     1.669741 Tokens per Sec:    26745, Lr: 0.000559\n",
            "2019-10-15 15:27:15,171 Epoch   1 Step:    16900 Batch Loss:     1.853290 Tokens per Sec:    30359, Lr: 0.000629\n",
            "2019-10-15 15:28:30,552 Epoch   1 Step:    17000 Batch Loss:     1.645039 Tokens per Sec:    33533, Lr: 0.000699\n",
            "2019-10-15 15:29:46,492 Epoch   1 Step:    17100 Batch Loss:     1.582425 Tokens per Sec:    36674, Lr: 0.000666\n",
            "2019-10-15 15:31:00,717 Epoch   1 Step:    17200 Batch Loss:     1.533166 Tokens per Sec:    40885, Lr: 0.000638\n",
            "2019-10-15 15:32:15,725 Epoch   1 Step:    17300 Batch Loss:     1.719004 Tokens per Sec:    43838, Lr: 0.000613\n",
            "2019-10-15 15:33:30,906 Epoch   1 Step:    17400 Batch Loss:     1.390711 Tokens per Sec:    47120, Lr: 0.000591\n",
            "2019-10-15 15:34:45,123 Epoch   1 Step:    17500 Batch Loss:     1.619379 Tokens per Sec:    51099, Lr: 0.000571\n",
            "2019-10-15 15:35:59,792 Epoch   1 Step:    17600 Batch Loss:     1.401520 Tokens per Sec:    54122, Lr: 0.000552\n",
            "2019-10-15 15:37:15,111 Epoch   1 Step:    17700 Batch Loss:     1.322451 Tokens per Sec:    57010, Lr: 0.000536\n",
            "2019-10-15 15:38:31,188 Epoch   1 Step:    17800 Batch Loss:     1.330870 Tokens per Sec:    59800, Lr: 0.000521\n",
            "2019-10-15 15:39:45,724 Epoch   1 Step:    17900 Batch Loss:     1.693164 Tokens per Sec:    64410, Lr: 0.000507\n",
            "2019-10-15 15:41:00,109 Epoch   1 Step:    18000 Batch Loss:     1.229509 Tokens per Sec:    67880, Lr: 0.000494\n",
            "2019-10-15 15:42:14,296 Epoch   1 Step:    18100 Batch Loss:     1.183759 Tokens per Sec:    71387, Lr: 0.000482\n",
            "2019-10-15 15:43:29,571 Epoch   1 Step:    18200 Batch Loss:     0.006842 Tokens per Sec:    73736, Lr: 0.000471\n",
            "2019-10-15 15:44:45,121 Epoch   1 Step:    18300 Batch Loss:     1.488011 Tokens per Sec:    76867, Lr: 0.000461\n",
            "2019-10-15 15:45:59,833 Epoch   1 Step:    18400 Batch Loss:     1.779157 Tokens per Sec:    81089, Lr: 0.000451\n",
            "2019-10-15 15:47:14,328 Epoch   1 Step:    18500 Batch Loss:     1.469925 Tokens per Sec:    84709, Lr: 0.000442\n",
            "2019-10-15 15:48:28,436 Epoch   1 Step:    18600 Batch Loss:     1.419660 Tokens per Sec:    88482, Lr: 0.000433\n",
            "2019-10-15 15:49:43,495 Epoch   1 Step:    18700 Batch Loss:     1.082317 Tokens per Sec:    90759, Lr: 0.000425\n",
            "2019-10-15 15:50:58,355 Epoch   1 Step:    18800 Batch Loss:     1.606799 Tokens per Sec:    94314, Lr: 0.000418\n",
            "2019-10-15 15:52:13,310 Epoch   1 Step:    18900 Batch Loss:     1.341790 Tokens per Sec:    97512, Lr: 0.000410\n",
            "2019-10-15 15:53:28,691 Epoch   1 Step:    19000 Batch Loss:     1.356992 Tokens per Sec:   100358, Lr: 0.000403\n",
            "2019-10-15 15:54:43,463 Epoch   1 Step:    19100 Batch Loss:     1.440918 Tokens per Sec:   104560, Lr: 0.000397\n",
            "2019-10-15 15:55:58,012 Epoch   1 Step:    19200 Batch Loss:     1.372611 Tokens per Sec:   108183, Lr: 0.000391\n",
            "2019-10-15 15:57:12,814 Epoch   1 Step:    19300 Batch Loss:     1.383592 Tokens per Sec:   111161, Lr: 0.000385\n",
            "2019-10-15 15:58:29,401 Epoch   1 Step:    19400 Batch Loss:     1.379824 Tokens per Sec:   111933, Lr: 0.000379\n",
            "2019-10-15 15:59:44,178 Epoch   1 Step:    19500 Batch Loss:     1.482053 Tokens per Sec:   118029, Lr: 0.000374\n",
            "2019-10-15 16:00:59,216 Epoch   1 Step:    19600 Batch Loss:     1.449984 Tokens per Sec:   120979, Lr: 0.000368\n",
            "2019-10-15 16:02:13,969 Epoch   1 Step:    19700 Batch Loss:     0.005362 Tokens per Sec:   124765, Lr: 0.000363\n",
            "2019-10-15 16:03:28,599 Epoch   1 Step:    19800 Batch Loss:     1.524287 Tokens per Sec:   128344, Lr: 0.000358\n",
            "2019-10-15 16:04:44,008 Epoch   1 Step:    19900 Batch Loss:     1.342243 Tokens per Sec:   130377, Lr: 0.000354\n",
            "2019-10-15 16:05:59,599 Epoch   1 Step:    20000 Batch Loss:     1.723251 Tokens per Sec:   133438, Lr: 0.000349\n",
            "2019-10-15 16:13:47,318 Hooray! New best validation result [ppl]!\n",
            "2019-10-15 16:13:47,318 Saving new checkpoint.\n",
            "2019-10-15 16:13:49,100 Example #0\n",
            "2019-10-15 16:13:49,102 \tSource:     source_sentence\n",
            "2019-10-15 16:13:49,102 \tReference:  target_sentence\n",
            "2019-10-15 16:13:49,102 \tHypothesis: \"manyuko emazino\n",
            "2019-10-15 16:13:49,102 Example #1\n",
            "2019-10-15 16:13:49,103 \tSource:     \"why can human governments not bring about the changes mankind needs most ?\n",
            "2019-10-15 16:13:49,103 \tReference:  \"nei hurumende dzevanhu dzisingakwanisi kugadzirisa zvinhu kuti vanhu vanyatsofambirwa zvakanaka neupenyu ?\n",
            "2019-10-15 16:13:49,103 \tHypothesis: \"nei hurumende dzevanhu dzisingagoni kuunza chinjo dzorudzi rwomunhu ?\n",
            "2019-10-15 16:13:49,103 Example #2\n",
            "2019-10-15 16:13:49,103 \tSource:     \"\n",
            "2019-10-15 16:13:49,103 \tReference:  \"\n",
            "2019-10-15 16:13:49,103 \tHypothesis: \"\n",
            "2019-10-15 16:13:49,103 Example #3\n",
            "2019-10-15 16:13:49,104 \tSource:     \"a significant number of angels joined satan’s rebellion .\n",
            "2019-10-15 16:13:49,104 \tReference:  \"ngirozi dzakati kuti dzakatsigira kupanduka kwakaita satani .\n",
            "2019-10-15 16:13:49,104 \tHypothesis: \"vakawanda vengirozi vakabatana nokupanduka kwasatani .\n",
            "2019-10-15 16:13:49,104 Validation result at epoch   1, step    20000: bleu:  20.00, loss: 37864.9297, ppl:   4.4388, duration: 469.5044s\n",
            "2019-10-15 16:15:03,750 Epoch   1 Step:    20100 Batch Loss:     1.828316 Tokens per Sec:   138494, Lr: 0.000345\n",
            "2019-10-15 16:16:19,005 Epoch   1 Step:    20200 Batch Loss:     1.588263 Tokens per Sec:   140743, Lr: 0.000341\n",
            "2019-10-15 16:17:32,697 Epoch   1 Step:    20300 Batch Loss:     1.680921 Tokens per Sec:   147085, Lr: 0.000337\n",
            "2019-10-15 16:18:48,271 Epoch   1 Step:    20400 Batch Loss:     1.210815 Tokens per Sec:   146768, Lr: 0.000333\n",
            "2019-10-15 16:20:03,267 Epoch   1 Step:    20500 Batch Loss:     1.621727 Tokens per Sec:   151254, Lr: 0.000329\n",
            "2019-10-15 16:21:16,784 Epoch   1 Step:    20600 Batch Loss:     0.005258 Tokens per Sec:   157667, Lr: 0.000326\n",
            "2019-10-15 16:22:30,269 Epoch   1 Step:    20700 Batch Loss:     1.530110 Tokens per Sec:   161073, Lr: 0.000322\n",
            "2019-10-15 16:23:44,778 Epoch   1 Step:    20800 Batch Loss:     1.491510 Tokens per Sec:   162195, Lr: 0.000319\n",
            "2019-10-15 16:24:59,479 Epoch   1 Step:    20900 Batch Loss:     1.528231 Tokens per Sec:   165137, Lr: 0.000316\n",
            "2019-10-15 16:26:14,853 Epoch   1 Step:    21000 Batch Loss:     1.576401 Tokens per Sec:   167053, Lr: 0.000313\n",
            "2019-10-15 16:27:30,012 Epoch   1 Step:    21100 Batch Loss:     1.454916 Tokens per Sec:   170925, Lr: 0.000309\n",
            "2019-10-15 16:28:45,143 Epoch   1 Step:    21200 Batch Loss:     0.005718 Tokens per Sec:   174342, Lr: 0.000306\n",
            "2019-10-15 16:29:59,961 Epoch   1 Step:    21300 Batch Loss:     1.589777 Tokens per Sec:   178472, Lr: 0.000304\n",
            "2019-10-15 16:31:15,308 Epoch   1 Step:    21400 Batch Loss:     0.014106 Tokens per Sec:   180527, Lr: 0.000301\n",
            "2019-10-15 16:32:30,321 Epoch   1 Step:    21500 Batch Loss:     1.715825 Tokens per Sec:   184721, Lr: 0.000298\n",
            "2019-10-15 16:33:44,594 Epoch   1 Step:    21600 Batch Loss:     1.542007 Tokens per Sec:   189922, Lr: 0.000295\n",
            "2019-10-15 16:34:59,423 Epoch   1 Step:    21700 Batch Loss:     1.623759 Tokens per Sec:   191880, Lr: 0.000293\n",
            "2019-10-15 16:36:15,520 Epoch   1 Step:    21800 Batch Loss:     1.649916 Tokens per Sec:   192089, Lr: 0.000290\n",
            "2019-10-15 16:37:29,559 Epoch   1 Step:    21900 Batch Loss:     1.561793 Tokens per Sec:   200780, Lr: 0.000288\n",
            "2019-10-15 16:38:45,144 Epoch   1 Step:    22000 Batch Loss:     2.098029 Tokens per Sec:   200065, Lr: 0.000285\n",
            "2019-10-15 16:40:00,274 Epoch   1 Step:    22100 Batch Loss:     1.358303 Tokens per Sec:   204634, Lr: 0.000283\n",
            "2019-10-15 16:41:15,622 Epoch   1 Step:    22200 Batch Loss:     1.516303 Tokens per Sec:   207397, Lr: 0.000281\n",
            "2019-10-15 16:42:30,384 Epoch   1 Step:    22300 Batch Loss:     1.493052 Tokens per Sec:   212350, Lr: 0.000278\n",
            "2019-10-15 16:43:45,018 Epoch   1 Step:    22400 Batch Loss:     1.704814 Tokens per Sec:   216073, Lr: 0.000276\n",
            "2019-10-15 16:44:59,441 Epoch   1 Step:    22500 Batch Loss:     0.006319 Tokens per Sec:   220018, Lr: 0.000274\n",
            "2019-10-15 16:46:14,989 Epoch   1 Step:    22600 Batch Loss:     1.367968 Tokens per Sec:   220096, Lr: 0.000272\n",
            "2019-10-15 16:47:30,157 Epoch   1 Step:    22700 Batch Loss:     1.785887 Tokens per Sec:   224580, Lr: 0.000270\n",
            "2019-10-15 16:48:43,935 Epoch   1 Step:    22800 Batch Loss:     1.754336 Tokens per Sec:   232145, Lr: 0.000268\n",
            "2019-10-15 16:49:58,451 Epoch   1 Step:    22900 Batch Loss:     1.471962 Tokens per Sec:   233205, Lr: 0.000266\n",
            "2019-10-15 16:51:12,759 Epoch   1 Step:    23000 Batch Loss:     1.481439 Tokens per Sec:   237173, Lr: 0.000264\n",
            "2019-10-15 16:52:26,234 Epoch   1 Step:    23100 Batch Loss:     1.435644 Tokens per Sec:   243198, Lr: 0.000262\n",
            "2019-10-15 16:53:41,588 Epoch   1 Step:    23200 Batch Loss:     1.793061 Tokens per Sec:   240493, Lr: 0.000260\n",
            "2019-10-15 16:54:55,811 Epoch   1 Step:    23300 Batch Loss:     0.004700 Tokens per Sec:   247505, Lr: 0.000259\n",
            "2019-10-15 16:56:10,476 Epoch   1 Step:    23400 Batch Loss:     1.476343 Tokens per Sec:   249411, Lr: 0.000257\n",
            "2019-10-15 16:57:25,219 Epoch   1 Step:    23500 Batch Loss:     1.072426 Tokens per Sec:   252540, Lr: 0.000255\n",
            "2019-10-15 16:58:39,833 Epoch   1 Step:    23600 Batch Loss:     1.591359 Tokens per Sec:   256345, Lr: 0.000253\n",
            "2019-10-15 16:59:55,070 Epoch   1 Step:    23700 Batch Loss:     0.004519 Tokens per Sec:   257559, Lr: 0.000252\n",
            "2019-10-15 17:01:09,248 Epoch   1 Step:    23800 Batch Loss:     1.514610 Tokens per Sec:   264584, Lr: 0.000250\n",
            "2019-10-15 17:02:24,906 Epoch   1 Step:    23900 Batch Loss:     1.485971 Tokens per Sec:   262740, Lr: 0.000249\n",
            "2019-10-15 17:03:40,832 Epoch   1 Step:    24000 Batch Loss:     1.663965 Tokens per Sec:   265187, Lr: 0.000247\n",
            "2019-10-15 17:11:28,816 Hooray! New best validation result [ppl]!\n",
            "2019-10-15 17:11:28,816 Saving new checkpoint.\n",
            "2019-10-15 17:11:30,578 Example #0\n",
            "2019-10-15 17:11:30,579 \tSource:     source_sentence\n",
            "2019-10-15 17:11:30,579 \tReference:  target_sentence\n",
            "2019-10-15 17:11:30,579 \tHypothesis: \"manyuko\n",
            "2019-10-15 17:11:30,579 Example #1\n",
            "2019-10-15 17:11:30,579 \tSource:     \"why can human governments not bring about the changes mankind needs most ?\n",
            "2019-10-15 17:11:30,579 \tReference:  \"nei hurumende dzevanhu dzisingakwanisi kugadzirisa zvinhu kuti vanhu vanyatsofambirwa zvakanaka neupenyu ?\n",
            "2019-10-15 17:11:30,580 \tHypothesis: \"nei hurumende dzevanhu dzisingagoni kuunza chinjo dzorudzi rwomunhu dzinoda zvikurusa ?\n",
            "2019-10-15 17:11:30,580 Example #2\n",
            "2019-10-15 17:11:30,580 \tSource:     \"\n",
            "2019-10-15 17:11:30,580 \tReference:  \"\n",
            "2019-10-15 17:11:30,580 \tHypothesis: \"\n",
            "2019-10-15 17:11:30,581 Example #3\n",
            "2019-10-15 17:11:30,581 \tSource:     \"a significant number of angels joined satan’s rebellion .\n",
            "2019-10-15 17:11:30,581 \tReference:  \"ngirozi dzakati kuti dzakatsigira kupanduka kwakaita satani .\n",
            "2019-10-15 17:11:30,581 \tHypothesis: \"nhamba inokosha yengirozi yakabatana nokupanduka kwasatani .\n",
            "2019-10-15 17:11:30,582 Validation result at epoch   1, step    24000: bleu:  20.74, loss: 35488.8398, ppl:   4.0425, duration: 469.7487s\n",
            "2019-10-15 17:12:23,253 Epoch   1: total training loss 10986.79\n",
            "2019-10-15 17:12:23,254 EPOCH 2\n",
            "2019-10-15 17:12:48,734 Epoch   2 Step:    24100 Batch Loss:     1.339781 Tokens per Sec:     2905, Lr: 0.000246\n",
            "2019-10-15 17:14:04,450 Epoch   2 Step:    24200 Batch Loss:     1.618610 Tokens per Sec:     4296, Lr: 0.000244\n",
            "2019-10-15 17:15:19,938 Epoch   2 Step:    24300 Batch Loss:     1.343185 Tokens per Sec:     7714, Lr: 0.000243\n",
            "2019-10-15 17:16:35,191 Epoch   2 Step:    24400 Batch Loss:     1.348158 Tokens per Sec:    11054, Lr: 0.000241\n",
            "2019-10-15 17:17:48,833 Epoch   2 Step:    24500 Batch Loss:     1.365933 Tokens per Sec:    14679, Lr: 0.000240\n",
            "2019-10-15 17:19:03,690 Epoch   2 Step:    24600 Batch Loss:     1.427360 Tokens per Sec:    17826, Lr: 0.000238\n",
            "2019-10-15 17:20:18,956 Epoch   2 Step:    24700 Batch Loss:     1.263329 Tokens per Sec:    21099, Lr: 0.000237\n",
            "2019-10-15 17:21:34,355 Epoch   2 Step:    24800 Batch Loss:     1.217077 Tokens per Sec:    24433, Lr: 0.000236\n",
            "2019-10-15 17:22:50,323 Epoch   2 Step:    24900 Batch Loss:     1.367933 Tokens per Sec:    27649, Lr: 0.000234\n",
            "2019-10-15 17:24:05,364 Epoch   2 Step:    25000 Batch Loss:     1.365834 Tokens per Sec:    31332, Lr: 0.000233\n",
            "2019-10-15 17:25:21,024 Epoch   2 Step:    25100 Batch Loss:     1.225544 Tokens per Sec:    34460, Lr: 0.000232\n",
            "2019-10-15 17:26:34,345 Epoch   2 Step:    25200 Batch Loss:     1.514102 Tokens per Sec:    38900, Lr: 0.000230\n",
            "2019-10-15 17:27:48,686 Epoch   2 Step:    25300 Batch Loss:     1.688054 Tokens per Sec:    41767, Lr: 0.000229\n",
            "2019-10-15 17:29:03,170 Epoch   2 Step:    25400 Batch Loss:     1.629476 Tokens per Sec:    45050, Lr: 0.000228\n",
            "2019-10-15 17:30:19,381 Epoch   2 Step:    25500 Batch Loss:     1.340773 Tokens per Sec:    47417, Lr: 0.000227\n",
            "2019-10-15 17:31:33,880 Epoch   2 Step:    25600 Batch Loss:     1.278056 Tokens per Sec:    51851, Lr: 0.000226\n",
            "2019-10-15 17:32:49,428 Epoch   2 Step:    25700 Batch Loss:     1.442006 Tokens per Sec:    54537, Lr: 0.000224\n",
            "2019-10-15 17:34:03,630 Epoch   2 Step:    25800 Batch Loss:     1.233860 Tokens per Sec:    58894, Lr: 0.000223\n",
            "2019-10-15 17:35:17,451 Epoch   2 Step:    25900 Batch Loss:     1.465982 Tokens per Sec:    62563, Lr: 0.000222\n",
            "2019-10-15 17:36:31,621 Epoch   2 Step:    26000 Batch Loss:     1.359163 Tokens per Sec:    65613, Lr: 0.000221\n",
            "2019-10-15 17:37:46,150 Epoch   2 Step:    26100 Batch Loss:     1.432393 Tokens per Sec:    68642, Lr: 0.000220\n",
            "2019-10-15 17:38:59,977 Epoch   2 Step:    26200 Batch Loss:     1.264515 Tokens per Sec:    72636, Lr: 0.000219\n",
            "2019-10-15 17:40:15,423 Epoch   2 Step:    26300 Batch Loss:     1.650066 Tokens per Sec:    74421, Lr: 0.000218\n",
            "2019-10-15 17:41:30,979 Epoch   2 Step:    26400 Batch Loss:     1.386254 Tokens per Sec:    77698, Lr: 0.000217\n",
            "2019-10-15 17:42:45,417 Epoch   2 Step:    26500 Batch Loss:     1.419338 Tokens per Sec:    82198, Lr: 0.000216\n",
            "2019-10-15 17:44:00,893 Epoch   2 Step:    26600 Batch Loss:     1.351118 Tokens per Sec:    84420, Lr: 0.000215\n",
            "2019-10-15 17:45:16,003 Epoch   2 Step:    26700 Batch Loss:     1.266173 Tokens per Sec:    88185, Lr: 0.000214\n",
            "2019-10-15 17:46:28,642 Epoch   2 Step:    26800 Batch Loss:     1.309332 Tokens per Sec:    94563, Lr: 0.000213\n",
            "2019-10-15 17:47:44,913 Epoch   2 Step:    26900 Batch Loss:     1.530792 Tokens per Sec:    93432, Lr: 0.000212\n",
            "2019-10-15 17:49:00,868 Epoch   2 Step:    27000 Batch Loss:     1.271389 Tokens per Sec:    97200, Lr: 0.000211\n",
            "2019-10-15 17:50:16,523 Epoch   2 Step:    27100 Batch Loss:     1.405401 Tokens per Sec:   100957, Lr: 0.000210\n",
            "2019-10-15 17:51:32,187 Epoch   2 Step:    27200 Batch Loss:     1.138275 Tokens per Sec:   104317, Lr: 0.000209\n",
            "2019-10-15 17:52:47,289 Epoch   2 Step:    27300 Batch Loss:     1.049415 Tokens per Sec:   108466, Lr: 0.000208\n",
            "2019-10-15 17:54:01,335 Epoch   2 Step:    27400 Batch Loss:     1.253214 Tokens per Sec:   113414, Lr: 0.000207\n",
            "2019-10-15 17:55:15,678 Epoch   2 Step:    27500 Batch Loss:     1.291708 Tokens per Sec:   116305, Lr: 0.000206\n",
            "2019-10-15 17:56:29,066 Epoch   2 Step:    27600 Batch Loss:     1.763638 Tokens per Sec:   121149, Lr: 0.000205\n",
            "2019-10-15 17:57:44,943 Epoch   2 Step:    27700 Batch Loss:     1.323687 Tokens per Sec:   120524, Lr: 0.000204\n",
            "2019-10-15 17:59:00,480 Epoch   2 Step:    27800 Batch Loss:     0.939045 Tokens per Sec:   124387, Lr: 0.000203\n",
            "2019-10-15 18:00:16,582 Epoch   2 Step:    27900 Batch Loss:     1.118151 Tokens per Sec:   126852, Lr: 0.000203\n",
            "2019-10-15 18:01:31,891 Epoch   2 Step:    28000 Batch Loss:     1.498376 Tokens per Sec:   131549, Lr: 0.000202\n",
            "2019-10-15 18:09:19,881 Hooray! New best validation result [ppl]!\n",
            "2019-10-15 18:09:19,882 Saving new checkpoint.\n",
            "2019-10-15 18:09:21,771 Example #0\n",
            "2019-10-15 18:09:21,774 \tSource:     source_sentence\n",
            "2019-10-15 18:09:21,774 \tReference:  target_sentence\n",
            "2019-10-15 18:09:21,775 \tHypothesis: \"mutongo\n",
            "2019-10-15 18:09:21,776 Example #1\n",
            "2019-10-15 18:09:21,777 \tSource:     \"why can human governments not bring about the changes mankind needs most ?\n",
            "2019-10-15 18:09:21,777 \tReference:  \"nei hurumende dzevanhu dzisingakwanisi kugadzirisa zvinhu kuti vanhu vanyatsofambirwa zvakanaka neupenyu ?\n",
            "2019-10-15 18:09:21,777 \tHypothesis: \"nei hurumende dzevanhu dzisingagoni kuunza chinjo dzorudzi rwomunhu dzichida zvikurusa ?\n",
            "2019-10-15 18:09:21,777 Example #2\n",
            "2019-10-15 18:09:21,779 \tSource:     \"\n",
            "2019-10-15 18:09:21,780 \tReference:  \"\n",
            "2019-10-15 18:09:21,780 \tHypothesis: \"\n",
            "2019-10-15 18:09:21,780 Example #3\n",
            "2019-10-15 18:09:21,781 \tSource:     \"a significant number of angels joined satan’s rebellion .\n",
            "2019-10-15 18:09:21,784 \tReference:  \"ngirozi dzakati kuti dzakatsigira kupanduka kwakaita satani .\n",
            "2019-10-15 18:09:21,784 \tHypothesis: \"nhamba inokosha yengirozi yakabatana nokupanduka kwasatani .\n",
            "2019-10-15 18:09:21,784 Validation result at epoch   2, step    28000: bleu:  21.33, loss: 34181.2148, ppl:   3.8397, duration: 469.8933s\n",
            "2019-10-15 18:10:37,827 Epoch   2 Step:    28100 Batch Loss:     1.364835 Tokens per Sec:   133664, Lr: 0.000201\n",
            "2019-10-15 18:11:51,816 Epoch   2 Step:    28200 Batch Loss:     1.159007 Tokens per Sec:   140758, Lr: 0.000200\n",
            "2019-10-15 18:13:07,322 Epoch   2 Step:    28300 Batch Loss:     1.222442 Tokens per Sec:   141289, Lr: 0.000199\n",
            "2019-10-15 18:14:21,585 Epoch   2 Step:    28400 Batch Loss:     1.415774 Tokens per Sec:   147008, Lr: 0.000198\n",
            "2019-10-15 18:15:36,294 Epoch   2 Step:    28500 Batch Loss:     1.459556 Tokens per Sec:   149496, Lr: 0.000198\n",
            "2019-10-15 18:16:51,226 Epoch   2 Step:    28600 Batch Loss:     0.003912 Tokens per Sec:   152451, Lr: 0.000197\n",
            "2019-10-15 18:18:03,959 Epoch   2 Step:    28700 Batch Loss:     1.659441 Tokens per Sec:   160395, Lr: 0.000196\n",
            "2019-10-15 18:19:18,594 Epoch   2 Step:    28800 Batch Loss:     1.392671 Tokens per Sec:   159697, Lr: 0.000195\n",
            "2019-10-15 18:20:34,365 Epoch   2 Step:    28900 Batch Loss:     0.003962 Tokens per Sec:   160699, Lr: 0.000195\n",
            "2019-10-15 18:21:47,744 Epoch   2 Step:    29000 Batch Loss:     1.017727 Tokens per Sec:   169279, Lr: 0.000194\n",
            "2019-10-15 18:23:02,486 Epoch   2 Step:    29100 Batch Loss:     1.321869 Tokens per Sec:   169514, Lr: 0.000193\n",
            "2019-10-15 18:24:17,628 Epoch   2 Step:    29200 Batch Loss:     1.169079 Tokens per Sec:   171990, Lr: 0.000192\n",
            "2019-10-15 18:25:32,126 Epoch   2 Step:    29300 Batch Loss:     1.474514 Tokens per Sec:   176855, Lr: 0.000192\n",
            "2019-10-15 18:26:47,764 Epoch   2 Step:    29400 Batch Loss:     1.306491 Tokens per Sec:   177582, Lr: 0.000191\n",
            "2019-10-15 18:28:06,307 Epoch   2 Step:    29500 Batch Loss:     1.403441 Tokens per Sec:   174280, Lr: 0.000190\n",
            "2019-10-15 18:29:20,356 Epoch   2 Step:    29600 Batch Loss:     1.439412 Tokens per Sec:   188249, Lr: 0.000189\n",
            "2019-10-15 18:30:34,607 Epoch   2 Step:    29700 Batch Loss:     1.279647 Tokens per Sec:   191101, Lr: 0.000189\n",
            "2019-10-15 18:31:50,161 Epoch   2 Step:    29800 Batch Loss:     1.279837 Tokens per Sec:   191200, Lr: 0.000188\n",
            "2019-10-15 18:33:03,382 Epoch   2 Step:    29900 Batch Loss:     1.473108 Tokens per Sec:   200605, Lr: 0.000187\n",
            "2019-10-15 18:34:18,532 Epoch   2 Step:    30000 Batch Loss:     0.004305 Tokens per Sec:   198850, Lr: 0.000187\n",
            "2019-10-15 18:35:34,281 Epoch   2 Step:    30100 Batch Loss:     1.266031 Tokens per Sec:   200632, Lr: 0.000186\n",
            "2019-10-15 18:36:49,189 Epoch   2 Step:    30200 Batch Loss:     1.399594 Tokens per Sec:   206274, Lr: 0.000185\n",
            "2019-10-15 18:38:03,707 Epoch   2 Step:    30300 Batch Loss:     1.416856 Tokens per Sec:   210753, Lr: 0.000185\n",
            "2019-10-15 18:39:18,666 Epoch   2 Step:    30400 Batch Loss:     1.012994 Tokens per Sec:   212885, Lr: 0.000184\n",
            "2019-10-15 18:40:33,298 Epoch   2 Step:    30500 Batch Loss:     1.209943 Tokens per Sec:   217199, Lr: 0.000184\n",
            "2019-10-15 18:41:48,320 Epoch   2 Step:    30600 Batch Loss:     1.403959 Tokens per Sec:   219453, Lr: 0.000183\n",
            "2019-10-15 18:43:02,937 Epoch   2 Step:    30700 Batch Loss:     1.176726 Tokens per Sec:   223995, Lr: 0.000182\n",
            "2019-10-15 18:44:17,055 Epoch   2 Step:    30800 Batch Loss:     1.342930 Tokens per Sec:   228850, Lr: 0.000182\n",
            "2019-10-15 18:45:31,494 Epoch   2 Step:    30900 Batch Loss:     1.281399 Tokens per Sec:   231207, Lr: 0.000181\n",
            "2019-10-15 18:46:45,168 Epoch   2 Step:    31000 Batch Loss:     1.470716 Tokens per Sec:   236960, Lr: 0.000180\n",
            "2019-10-15 18:47:59,654 Epoch   2 Step:    31100 Batch Loss:     1.455566 Tokens per Sec:   237716, Lr: 0.000180\n",
            "2019-10-15 18:49:15,270 Epoch   2 Step:    31200 Batch Loss:     0.016091 Tokens per Sec:   237491, Lr: 0.000179\n",
            "2019-10-15 18:50:29,630 Epoch   2 Step:    31300 Batch Loss:     0.915530 Tokens per Sec:   244868, Lr: 0.000179\n",
            "2019-10-15 18:51:44,875 Epoch   2 Step:    31400 Batch Loss:     1.401765 Tokens per Sec:   245309, Lr: 0.000178\n",
            "2019-10-15 18:53:00,205 Epoch   2 Step:    31500 Batch Loss:     1.326988 Tokens per Sec:   248384, Lr: 0.000177\n",
            "2019-10-15 18:54:15,459 Epoch   2 Step:    31600 Batch Loss:     1.370676 Tokens per Sec:   252010, Lr: 0.000177\n",
            "2019-10-15 18:55:31,203 Epoch   2 Step:    31700 Batch Loss:     1.179766 Tokens per Sec:   253693, Lr: 0.000176\n",
            "2019-10-15 18:56:47,424 Epoch   2 Step:    31800 Batch Loss:     1.238122 Tokens per Sec:   255480, Lr: 0.000176\n",
            "2019-10-15 18:58:02,750 Epoch   2 Step:    31900 Batch Loss:     0.004429 Tokens per Sec:   261825, Lr: 0.000175\n",
            "2019-10-15 18:59:18,219 Epoch   2 Step:    32000 Batch Loss:     1.210855 Tokens per Sec:   264651, Lr: 0.000175\n",
            "2019-10-15 19:07:08,066 Hooray! New best validation result [ppl]!\n",
            "2019-10-15 19:07:08,066 Saving new checkpoint.\n",
            "2019-10-15 19:07:09,735 Example #0\n",
            "2019-10-15 19:07:09,736 \tSource:     source_sentence\n",
            "2019-10-15 19:07:09,736 \tReference:  target_sentence\n",
            "2019-10-15 19:07:09,736 \tHypothesis: \"tsaona\n",
            "2019-10-15 19:07:09,736 Example #1\n",
            "2019-10-15 19:07:09,736 \tSource:     \"why can human governments not bring about the changes mankind needs most ?\n",
            "2019-10-15 19:07:09,736 \tReference:  \"nei hurumende dzevanhu dzisingakwanisi kugadzirisa zvinhu kuti vanhu vanyatsofambirwa zvakanaka neupenyu ?\n",
            "2019-10-15 19:07:09,736 \tHypothesis: \"nei hurumende dzevanhu dzisingagoni kuchinja zvinhu zvinoda vanhu vakawanda ?\n",
            "2019-10-15 19:07:09,736 Example #2\n",
            "2019-10-15 19:07:09,737 \tSource:     \"\n",
            "2019-10-15 19:07:09,737 \tReference:  \"\n",
            "2019-10-15 19:07:09,737 \tHypothesis: \"\n",
            "2019-10-15 19:07:09,737 Example #3\n",
            "2019-10-15 19:07:09,737 \tSource:     \"a significant number of angels joined satan’s rebellion .\n",
            "2019-10-15 19:07:09,737 \tReference:  \"ngirozi dzakati kuti dzakatsigira kupanduka kwakaita satani .\n",
            "2019-10-15 19:07:09,737 \tHypothesis: \"vakawanda vengirozi vakabatana nokupanduka kwasatani .\n",
            "2019-10-15 19:07:09,737 Validation result at epoch   2, step    32000: bleu:  21.52, loss: 32990.1523, ppl:   3.6639, duration: 471.5178s\n",
            "2019-10-15 19:08:24,186 Epoch   2 Step:    32100 Batch Loss:     1.407795 Tokens per Sec:   271633, Lr: 0.000174\n",
            "2019-10-15 19:08:51,105 Epoch   2: total training loss 9869.44\n",
            "2019-10-15 19:08:51,105 EPOCH 3\n",
            "2019-10-15 19:09:43,011 Epoch   3 Step:    32200 Batch Loss:     1.191358 Tokens per Sec:     3117, Lr: 0.000174\n",
            "2019-10-15 19:10:57,237 Epoch   3 Step:    32300 Batch Loss:     1.302974 Tokens per Sec:     5534, Lr: 0.000173\n",
            "2019-10-15 19:12:11,196 Epoch   3 Step:    32400 Batch Loss:     1.683488 Tokens per Sec:     8922, Lr: 0.000173\n",
            "2019-10-15 19:13:27,227 Epoch   3 Step:    32500 Batch Loss:     1.215507 Tokens per Sec:    12056, Lr: 0.000172\n",
            "2019-10-15 19:14:41,588 Epoch   3 Step:    32600 Batch Loss:     1.283269 Tokens per Sec:    15652, Lr: 0.000172\n",
            "2019-10-15 19:15:57,114 Epoch   3 Step:    32700 Batch Loss:     1.129952 Tokens per Sec:    18795, Lr: 0.000171\n",
            "2019-10-15 19:17:12,289 Epoch   3 Step:    32800 Batch Loss:     1.213387 Tokens per Sec:    22262, Lr: 0.000170\n",
            "2019-10-15 19:18:27,529 Epoch   3 Step:    32900 Batch Loss:     1.038143 Tokens per Sec:    25572, Lr: 0.000170\n",
            "2019-10-15 19:19:42,117 Epoch   3 Step:    33000 Batch Loss:     1.531750 Tokens per Sec:    29161, Lr: 0.000169\n",
            "2019-10-15 19:20:58,274 Epoch   3 Step:    33100 Batch Loss:     1.329953 Tokens per Sec:    31854, Lr: 0.000169\n",
            "2019-10-15 19:22:13,125 Epoch   3 Step:    33200 Batch Loss:     1.287340 Tokens per Sec:    35730, Lr: 0.000168\n",
            "2019-10-15 19:23:28,078 Epoch   3 Step:    33300 Batch Loss:     1.438840 Tokens per Sec:    38981, Lr: 0.000168\n",
            "2019-10-15 19:24:44,249 Epoch   3 Step:    33400 Batch Loss:     0.003812 Tokens per Sec:    41739, Lr: 0.000168\n",
            "2019-10-15 19:25:58,616 Epoch   3 Step:    33500 Batch Loss:     1.154465 Tokens per Sec:    46053, Lr: 0.000167\n",
            "2019-10-15 19:27:13,853 Epoch   3 Step:    33600 Batch Loss:     1.274548 Tokens per Sec:    48912, Lr: 0.000167\n",
            "2019-10-15 19:28:29,199 Epoch   3 Step:    33700 Batch Loss:     1.418830 Tokens per Sec:    52173, Lr: 0.000166\n",
            "2019-10-15 19:29:44,782 Epoch   3 Step:    33800 Batch Loss:     1.276319 Tokens per Sec:    55343, Lr: 0.000166\n",
            "2019-10-15 19:31:00,521 Epoch   3 Step:    33900 Batch Loss:     1.134931 Tokens per Sec:    58583, Lr: 0.000165\n",
            "2019-10-15 19:32:14,771 Epoch   3 Step:    34000 Batch Loss:     1.324899 Tokens per Sec:    63037, Lr: 0.000165\n",
            "2019-10-15 19:33:28,794 Epoch   3 Step:    34100 Batch Loss:     0.957842 Tokens per Sec:    66584, Lr: 0.000164\n",
            "2019-10-15 19:34:44,128 Epoch   3 Step:    34200 Batch Loss:     1.229382 Tokens per Sec:    68742, Lr: 0.000164\n",
            "2019-10-15 19:35:59,782 Epoch   3 Step:    34300 Batch Loss:     1.219395 Tokens per Sec:    71780, Lr: 0.000163\n",
            "2019-10-15 19:37:14,873 Epoch   3 Step:    34400 Batch Loss:     0.003645 Tokens per Sec:    75662, Lr: 0.000163\n",
            "2019-10-15 19:38:29,998 Epoch   3 Step:    34500 Batch Loss:     1.372310 Tokens per Sec:    78988, Lr: 0.000162\n",
            "2019-10-15 19:39:44,971 Epoch   3 Step:    34600 Batch Loss:     1.070162 Tokens per Sec:    82495, Lr: 0.000162\n",
            "2019-10-15 19:41:00,219 Epoch   3 Step:    34700 Batch Loss:     1.449655 Tokens per Sec:    85552, Lr: 0.000162\n",
            "2019-10-15 19:42:16,842 Epoch   3 Step:    34800 Batch Loss:     1.306828 Tokens per Sec:    87357, Lr: 0.000161\n",
            "2019-10-15 19:43:32,850 Epoch   3 Step:    34900 Batch Loss:     1.092631 Tokens per Sec:    91421, Lr: 0.000161\n",
            "2019-10-15 19:44:47,100 Epoch   3 Step:    35000 Batch Loss:     0.003698 Tokens per Sec:    96946, Lr: 0.000160\n",
            "2019-10-15 19:46:01,488 Epoch   3 Step:    35100 Batch Loss:     1.037698 Tokens per Sec:   100095, Lr: 0.000160\n",
            "2019-10-15 19:47:17,918 Epoch   3 Step:    35200 Batch Loss:     1.290678 Tokens per Sec:   100775, Lr: 0.000159\n",
            "2019-10-15 19:48:32,207 Epoch   3 Step:    35300 Batch Loss:     1.402145 Tokens per Sec:   107016, Lr: 0.000159\n",
            "2019-10-15 19:49:46,388 Epoch   3 Step:    35400 Batch Loss:     1.216086 Tokens per Sec:   110461, Lr: 0.000159\n",
            "2019-10-15 19:51:01,850 Epoch   3 Step:    35500 Batch Loss:     1.552273 Tokens per Sec:   111935, Lr: 0.000158\n",
            "2019-10-15 19:52:17,726 Epoch   3 Step:    35600 Batch Loss:     1.308008 Tokens per Sec:   114682, Lr: 0.000158\n",
            "2019-10-15 19:53:33,282 Epoch   3 Step:    35700 Batch Loss:     1.252122 Tokens per Sec:   118510, Lr: 0.000157\n",
            "2019-10-15 19:54:48,688 Epoch   3 Step:    35800 Batch Loss:     1.317388 Tokens per Sec:   122115, Lr: 0.000157\n",
            "2019-10-15 19:56:04,571 Epoch   3 Step:    35900 Batch Loss:     1.337682 Tokens per Sec:   124656, Lr: 0.000157\n",
            "2019-10-15 19:57:18,626 Epoch   3 Step:    36000 Batch Loss:     0.004458 Tokens per Sec:   131054, Lr: 0.000156\n",
            "2019-10-15 20:05:08,603 Hooray! New best validation result [ppl]!\n",
            "2019-10-15 20:05:08,603 Saving new checkpoint.\n",
            "2019-10-15 20:05:10,457 Example #0\n",
            "2019-10-15 20:05:10,458 \tSource:     source_sentence\n",
            "2019-10-15 20:05:10,458 \tReference:  target_sentence\n",
            "2019-10-15 20:05:10,458 \tHypothesis: \"mutongo\n",
            "2019-10-15 20:05:10,458 Example #1\n",
            "2019-10-15 20:05:10,459 \tSource:     \"why can human governments not bring about the changes mankind needs most ?\n",
            "2019-10-15 20:05:10,459 \tReference:  \"nei hurumende dzevanhu dzisingakwanisi kugadzirisa zvinhu kuti vanhu vanyatsofambirwa zvakanaka neupenyu ?\n",
            "2019-10-15 20:05:10,459 \tHypothesis: \"nei hurumende dzevanhu dzisingagoni kuunza chinjo dzorudzi rwomunhu dzichida zvikurusa ?\n",
            "2019-10-15 20:05:10,459 Example #2\n",
            "2019-10-15 20:05:10,459 \tSource:     \"\n",
            "2019-10-15 20:05:10,459 \tReference:  \"\n",
            "2019-10-15 20:05:10,460 \tHypothesis: \"\n",
            "2019-10-15 20:05:10,460 Example #3\n",
            "2019-10-15 20:05:10,460 \tSource:     \"a significant number of angels joined satan’s rebellion .\n",
            "2019-10-15 20:05:10,460 \tReference:  \"ngirozi dzakati kuti dzakatsigira kupanduka kwakaita satani .\n",
            "2019-10-15 20:05:10,460 \tHypothesis: \"nhamba inokosha yengirozi yakakumbanira kupanduka kwasatani .\n",
            "2019-10-15 20:05:10,460 Validation result at epoch   3, step    36000: bleu:  22.05, loss: 32825.8008, ppl:   3.6402, duration: 471.8337s\n",
            "2019-10-15 20:06:24,544 Epoch   3 Step:    36100 Batch Loss:     1.211278 Tokens per Sec:   134345, Lr: 0.000156\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/joeynmt/joeynmt/__main__.py\", line 41, in <module>\n",
            "    main()\n",
            "  File \"/content/joeynmt/joeynmt/__main__.py\", line 29, in main\n",
            "    train(cfg_file=args.config_path)\n",
            "  File \"/content/joeynmt/joeynmt/training.py\", line 560, in train\n",
            "    trainer.train_and_validate(train_data=train_data, valid_data=dev_data)\n",
            "  File \"/content/joeynmt/joeynmt/training.py\", line 264, in train_and_validate\n",
            "    batch_loss = self._train_batch(batch, update=update)\n",
            "  File \"/content/joeynmt/joeynmt/training.py\", line 415, in _train_batch\n",
            "    norm_batch_multiply.backward()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/tensor.py\", line 118, in backward\n",
            "    torch.autograd.backward(self, gradient, retain_graph, create_graph)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\", line 93, in backward\n",
            "    allow_unreachable=True)  # allow_unreachable flag\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MBoDS09JM807",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5d426568-264b-40dd-f5fe-ef9b02a863ef"
      },
      "source": [
        "# Copy the created models from the notebook storage to google drive for persistant storage \n",
        "!cp -r joeynmt/models/${src}${tgt}_transformer/* \"$gdrive_path/models/${src}${tgt}_transformer/\""
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cp: cannot create symbolic link '/content/drive/My Drive/masakhane/en-sn-baseline/models/ensn_transformer/best.ckpt': Function not implemented\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n94wlrCjVc17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "e9634672-5496-4b0f-b2c1-8c540fe62cc3"
      },
      "source": [
        "# Output our validation accuracy\n",
        "! cat \"$gdrive_path/models/${src}${tgt}_transformer/validations.txt\""
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Steps: 20000\tLoss: 37864.92969\tPPL: 4.43884\tbleu: 20.00275\tLR: 0.00034939\t*\n",
            "Steps: 24000\tLoss: 35488.83984\tPPL: 4.04252\tbleu: 20.74494\tLR: 0.00024705\t*\n",
            "Steps: 28000\tLoss: 34181.21484\tPPL: 3.83972\tbleu: 21.33443\tLR: 0.00020172\t*\n",
            "Steps: 32000\tLoss: 32990.15234\tPPL: 3.66386\tbleu: 21.52222\tLR: 0.00017469\t*\n",
            "Steps: 36000\tLoss: 32825.80078\tPPL: 3.64024\tbleu: 22.04874\tLR: 0.00015625\t*\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "66WhRE9lIhoD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "632cfec4-89e0-4a43-8868-27f542e52f1b"
      },
      "source": [
        "# Test our model\n",
        "! cd joeynmt; python3 -m joeynmt test \"$gdrive_path/models/${src}${tgt}_transformer/config.yaml\""
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-10-15 20:11:50,343 -  dev bleu:  20.83 [Beam search decoding with beam size = 5 and alpha = 1.0]\n",
            "2019-10-15 20:13:53,035 - test bleu:  17.60 [Beam search decoding with beam size = 5 and alpha = 1.0]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}