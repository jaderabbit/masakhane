2021-10-14 23:14:38,022 - INFO - root - Hello! This is Joey-NMT (version 1.3).
2021-10-14 23:14:38,023 - INFO - joeynmt.data - Building vocabulary...
2021-10-14 23:14:38,330 - INFO - joeynmt.data - Loading dev data...
2021-10-14 23:14:38,347 - INFO - joeynmt.data - Loading test data...
2021-10-14 23:14:38,410 - INFO - joeynmt.data - Data loaded.
2021-10-14 23:14:38,443 - INFO - joeynmt.prediction - Process device: cuda, n_gpu: 1, batch_size per device: 3600
2021-10-14 23:14:38,443 - INFO - joeynmt.prediction - Loading model from models/nsoen_reverse_transformer/latest.ckpt
2021-10-14 23:14:40,996 - INFO - joeynmt.model - Building an encoder-decoder model...
2021-10-14 23:14:41,253 - INFO - joeynmt.model - Enc-dec model built.
2021-10-14 23:14:41,332 - INFO - joeynmt.prediction - Decoding on dev set (data/nsoen/dev.bpe.en)...
2021-10-14 23:16:02,114 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-10-14 23:16:02,114 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-10-14 23:16:02,114 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-10-14 23:16:02,120 - INFO - joeynmt.prediction -  dev bleu[13a]:  34.65 [Beam search decoding with beam size = 5 and alpha = 1.0]
2021-10-14 23:16:02,120 - INFO - joeynmt.prediction - Decoding on test set (data/nsoen/test.bpe.en)...
2021-10-14 23:18:03,573 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')
2021-10-14 23:18:03,574 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.
2021-10-14 23:18:03,574 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.
2021-10-14 23:18:03,586 - INFO - joeynmt.prediction - test bleu[13a]:  39.57 [Beam search decoding with beam size = 5 and alpha = 1.0]
