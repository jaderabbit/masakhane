{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Igc5itf-xMGj"
   },
   "source": [
    "# Masakhane - Reverse Machine Translation for African Languages (Using JoeyNMT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KmkY5eucWsJF"
   },
   "source": [
    "> ## NB\n",
    ">### - The purpose of this Notebook is to build models that translate African languages(target language) *into* English(source language). This will allow us to in future be able to make translations from one African language to the other. If you'd like to translate *from* English, please use [this](https://github.com/masakhane-io/masakhane-mt/blob/master/starter_notebook.ipynb) starter notebook instead.\n",
    "\n",
    ">### - We call this reverse training because normally we build models that make translations from the source language(English) to the target language. But in this case we are doing the reverse; building models that make translations from the target language to the source(English)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x4fXCKCf36IK"
   },
   "source": [
    "## Note before beginning:\n",
    "- The idea is that you should be able to make minimal changes to this in order to get SOME result for your own translation corpus. \n",
    "\n",
    "- The tl;dr: Go to the **\"TODO\"** comments which will tell you what to update to get up and running\n",
    "\n",
    "- If you actually want to have a clue what you're doing, read the text and peek at the links\n",
    "\n",
    "- With 100 epochs, it should take around 7 hours to run in Google Colab\n",
    "\n",
    "- Once you've gotten a result for your language, please attach and email your notebook that generated it to masakhanetranslation@gmail.com\n",
    "\n",
    "- If you care enough and get a chance, doing a brief background on your language would be amazing. See examples in  [(Martinus, 2019)](https://arxiv.org/abs/1906.05685)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes:\n",
    "\n",
    "This is a notebook for training a ve - en translation model using the JW300 dataset.\n",
    "\n",
    "We train on two configurations, one 'small' one, which uses the default config, and a 'large' one, which uses the suggestions and increases some of the parameters. Both of these models were trained for 30 epochs.\n",
    "\n",
    "We found that the larger model performed better, with the following results:\n",
    "> dev bleu[13a]:  40.20 [Beam search decoding with beam size = 5 and alpha = 1.0]\n",
    "\n",
    "> test bleu[13a]:  46.82 [Beam search decoding with beam size = 5 and alpha = 1.0]\n",
    "\n",
    "\n",
    "## Nonstandard Changes\n",
    "\n",
    "While most of this notebook is the same as the original template notebook, we made a few differences, mainly with regards to the joeynmt installation, as we has some problems with that.\n",
    "\n",
    "Instead of `git clone ... && cd ... && pip install .`, we do the following:\n",
    "\n",
    "```\n",
    "! pip install joeynmt\n",
    "! pip install torch==1.9.0\n",
    "! pip install --upgrade sacrebleu==1.5.1\n",
    "\n",
    "\n",
    "# make the directories since we didn't clone\n",
    "!mkdir -p joeynmt/configs\n",
    "!mkdir -p joeynmt/data\n",
    "!mkdir -p joeynmt/scripts\n",
    "\n",
    "# get the build_vocab.py script\n",
    "\n",
    "!cd joeynmt/scripts && wget https://raw.githubusercontent.com/joeynmt/joeynmt/master/scripts/build_vocab.py\n",
    "```\n",
    "\n",
    "------\n",
    "\n",
    "\n",
    "We also do not use google colab, and as such the google drive specific code (e.g. mounting the drive) is commented out. This can be uncommented as needed\n",
    "\n",
    "\n",
    "\n",
    "Since we trained two models, and the second one was the best performing one, when using this notebook, feel free to comment out the first training cycle, as it makes the whole process take longer. We just leave it here as a log though."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l929HimrxS0a"
   },
   "source": [
    "## Retrieve your data & make a parallel corpus\n",
    "\n",
    "If you are wanting to use the JW300 data referenced on the Masakhane website or in our GitHub repo, you can use `opus-tools` to convert the data into a convenient format. `opus_read` from that package provides a convenient tool for reading the native aligned XML files and to convert them to TMX format. The tool can also be used to fetch relevant files from OPUS on the fly and to filter the data as necessary. [Read the documentation](https://pypi.org/project/opustools-pkg/) for more details.\n",
    "\n",
    "Once you have your corpus files in TMX format (an xml structure which will include the sentences in your target language and your source language in a single file), we recommend reading them into a pandas dataframe. Thankfully, Jade wrote a silly `tmx2dataframe` package which converts your tmx file to a pandas dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Cn3tgQLzUxwn"
   },
   "outputs": [],
   "source": [
    "# TODO: Set your source and target languages. Keep in mind, these traditionally use language codes as found here:\n",
    "# These will also become the suffix's of all vocab and corpus files used throughout\n",
    "import os\n",
    "source_language = \"en\"\n",
    "target_language = \"ve\" \n",
    "lc = False  # If True, lowercase the data.\n",
    "seed = 42  # Random seed for shuffling.\n",
    "tag = \"run_v3\" # Give a unique name to your folder - this is to ensure you don't rewrite any models you've already submitted\n",
    "\n",
    "os.environ[\"src\"] = source_language # Sets them in bash as well, since we often use bash scripts\n",
    "os.environ[\"tgt\"] = target_language\n",
    "os.environ[\"tag\"] = tag\n",
    "\n",
    "# This will save it to a folder in our gdrive instead!\n",
    "!mkdir -p \"nlp_things/masakhane/$tgt-$src-$tag\"\n",
    "os.environ[\"gdrive_path\"] = \"nlp_things/masakhane/%s-%s-%s\" % (target_language, source_language, tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kBSgJHEw7Nvx",
    "outputId": "479297fa-fd5b-4059-cd2e-d45a1ee77eb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nlp_things/masakhane/ve-en-run_v3\n"
     ]
    }
   ],
   "source": [
    "!echo $gdrive_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gA75Fs9ys8Y9",
    "outputId": "6b6c9e4c-e9ef-4762-d761-32b49ea47dd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opustools-pkg in /home-mscluster/mbeukman/anaconda3/envs/nlp_q2/lib/python3.7/site-packages (0.0.52)\n"
     ]
    }
   ],
   "source": [
    "# Install opus-tools\n",
    "! pip install opustools-pkg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xq-tDZVks7ZD",
    "outputId": "e438ed40-34a0-4436-8aa9-6399abfaf457"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Alignment file /proj/nlpl/data/OPUS/JW300/latest/xml/en-ve.xml.gz not found. The following files are available for downloading:\n",
      "\n",
      "^C\n",
      "gzip: JW300_latest_xml_en-ve.xml.gz: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# Downloading our corpus\n",
    "! opus_read -d JW300 -s $src -t $tgt -wm moses -w jw300.$src jw300.$tgt -q\n",
    "    \n",
    "# extract the corpus file\n",
    "! gunzip JW300_latest_xml_$src-$tgt.xml.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n48GDRnP8y2G",
    "outputId": "70fb6cb7-d42b-4c0b-961c-14699ad5211a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-10-09 18:17:33--  https://raw.githubusercontent.com/juliakreutzer/masakhane/master/jw300_utils/test/test.en-any.en\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 277791 (271K) [text/plain]\n",
      "Saving to: ‘test.en-any.en’\n",
      "\n",
      "test.en-any.en      100%[===================>] 271.28K  --.-KB/s    in 0.005s  \n",
      "\n",
      "2021-10-09 18:17:34 (48.3 MB/s) - ‘test.en-any.en’ saved [277791/277791]\n",
      "\n",
      "--2021-10-09 18:17:34--  https://raw.githubusercontent.com/juliakreutzer/masakhane/master/jw300_utils/test/test.en-ve.en\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 206464 (202K) [text/plain]\n",
      "Saving to: ‘test.en-ve.en’\n",
      "\n",
      "test.en-ve.en       100%[===================>] 201.62K  --.-KB/s    in 0.004s  \n",
      "\n",
      "2021-10-09 18:17:34 (48.8 MB/s) - ‘test.en-ve.en’ saved [206464/206464]\n",
      "\n",
      "--2021-10-09 18:17:34--  https://raw.githubusercontent.com/juliakreutzer/masakhane/master/jw300_utils/test/test.en-ve.ve\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 245271 (240K) [text/plain]\n",
      "Saving to: ‘test.en-ve.ve’\n",
      "\n",
      "test.en-ve.ve       100%[===================>] 239.52K  --.-KB/s    in 0.005s  \n",
      "\n",
      "2021-10-09 18:17:35 (43.9 MB/s) - ‘test.en-ve.ve’ saved [245271/245271]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download the global test set.\n",
    "! wget https://raw.githubusercontent.com/juliakreutzer/masakhane/master/jw300_utils/test/test.en-any.en\n",
    "\n",
    "# And the specific test set for this language pair.\n",
    "os.environ[\"trg\"] = target_language \n",
    "os.environ[\"src\"] = source_language \n",
    "\n",
    "! wget https://raw.githubusercontent.com/juliakreutzer/masakhane/master/jw300_utils/test/test.en-$trg.en \n",
    "! mv test.en-$trg.en test.en\n",
    "! wget https://raw.githubusercontent.com/juliakreutzer/masakhane/master/jw300_utils/test/test.en-$trg.$trg \n",
    "! mv test.en-$trg.$trg test.$trg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NqDG-CI28y2L",
    "outputId": "8da9efa0-f777-4b99-f367-a005cd81592b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3571 global test sentences to filter from the training/dev data.\n"
     ]
    }
   ],
   "source": [
    "# Read the test data to filter from train and dev splits.\n",
    "# Store english portion in set for quick filtering checks.\n",
    "en_test_sents = set()\n",
    "filter_test_sents = \"test.en-any.en\"\n",
    "j = 0\n",
    "with open(filter_test_sents) as f:\n",
    "    for line in f:\n",
    "        en_test_sents.add(line.strip())\n",
    "        j += 1\n",
    "print('Loaded {} global test sentences to filter from the training/dev data.'.format(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "id": "3CNdwLBCfSIl",
    "outputId": "af89e4f6-bfed-4bc1-9437-2562631a602e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data and skipped 3835/229306 lines since contained in test set.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_sentence</th>\n",
       "      <th>target_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>‘ God , Why Did You Allow This ? ’</td>\n",
       "      <td>‘ Mudzimu , Ndi Ngani Wo Tendela Zwenezwi Zwit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RICARDO still remembers sitting with his wife ...</td>\n",
       "      <td>RICARDO u kha ḓi humbula o dzula na musadzi w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Then , Ricardo opened the envelope , and they ...</td>\n",
       "      <td>Nga zwenezwo , Ricardo a vula fulobo , nahone ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     source_sentence  \\\n",
       "0                 ‘ God , Why Did You Allow This ? ’   \n",
       "1  RICARDO still remembers sitting with his wife ...   \n",
       "2  Then , Ricardo opened the envelope , and they ...   \n",
       "\n",
       "                                     target_sentence  \n",
       "0  ‘ Mudzimu , Ndi Ngani Wo Tendela Zwenezwi Zwit...  \n",
       "1  RICARDO u kha ḓi humbula o dzula na musadzi w...  \n",
       "2  Nga zwenezwo , Ricardo a vula fulobo , nahone ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# TMX file to dataframe\n",
    "source_file = 'jw300.' + source_language\n",
    "target_file = 'jw300.' + target_language\n",
    "\n",
    "source = []\n",
    "target = []\n",
    "skip_lines = []  # Collect the line numbers of the source portion to skip the same lines for the target portion.\n",
    "with open(source_file) as f:\n",
    "    for i, line in enumerate(f):\n",
    "        # Skip sentences that are contained in the test set.\n",
    "        if line.strip() not in en_test_sents:\n",
    "            source.append(line.strip())\n",
    "        else:\n",
    "            skip_lines.append(i)             \n",
    "with open(target_file) as f:\n",
    "    for j, line in enumerate(f):\n",
    "        # Only add to corpus if corresponding source was not skipped.\n",
    "        if j not in skip_lines:\n",
    "            target.append(line.strip())\n",
    "    \n",
    "print('Loaded data and skipped {}/{} lines since contained in test set.'.format(len(skip_lines), i))\n",
    "    \n",
    "df = pd.DataFrame(zip(source, target), columns=['source_sentence', 'target_sentence'])\n",
    "# if you get TypeError: data argument can't be an iterator is because of your zip version run this below\n",
    "#df = pd.DataFrame(list(zip(source, target)), columns=['source_sentence', 'target_sentence'])\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YkuK3B4p2AkN"
   },
   "source": [
    "## Pre-processing and export\n",
    "\n",
    "It is generally a good idea to remove duplicate translations and conflicting translations from the corpus. In practice, these public corpora include some number of these that need to be cleaned.\n",
    "\n",
    "In addition we will split our data into dev/test/train and export to the filesystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M_2ouEOH1_1q",
    "outputId": "6b70c61f-6322-4473-a90e-76ed060c889c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home-mscluster/mbeukman/anaconda3/envs/nlp_q2/lib/python3.7/site-packages/pandas/util/_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# drop duplicate translations\n",
    "df_pp = df.drop_duplicates()\n",
    "\n",
    "# drop conflicting translations\n",
    "# (this is optional and something that you might want to comment out \n",
    "# depending on the size of your corpus)\n",
    "df_pp.drop_duplicates(subset='source_sentence', inplace=True)\n",
    "df_pp.drop_duplicates(subset='target_sentence', inplace=True)\n",
    "\n",
    "# Shuffle the data to remove bias in dev set selection.\n",
    "df_pp = df_pp.sample(frac=1, random_state=seed).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z_1BwAApEtMk",
    "outputId": "53d0065c-3bd9-406a-c43b-0ab2ccf74bca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fuzzywuzzy in /home-mscluster/mbeukman/anaconda3/envs/nlp_q2/lib/python3.7/site-packages (0.18.0)\n",
      "Requirement already satisfied: python-Levenshtein in /home-mscluster/mbeukman/anaconda3/envs/nlp_q2/lib/python3.7/site-packages (0.12.2)\n",
      "Requirement already satisfied: setuptools in /home-mscluster/mbeukman/anaconda3/envs/nlp_q2/lib/python3.7/site-packages (from python-Levenshtein) (58.0.4)\n"
     ]
    }
   ],
   "source": [
    "# Install fuzzy wuzzy to remove \"almost duplicate\" sentences in the\n",
    "# test and training sets.\n",
    "! pip install fuzzywuzzy\n",
    "! pip install python-Levenshtein\n",
    "import time\n",
    "from fuzzywuzzy import process\n",
    "import numpy as np\n",
    "from os import cpu_count\n",
    "from functools import partial\n",
    "from multiprocessing import Pool\n",
    "\n",
    "\n",
    "# reset the index of the training set after previous filtering\n",
    "df_pp.reset_index(drop=False, inplace=True)\n",
    "\n",
    "# Remove samples from the training data set if they \"almost overlap\" with the\n",
    "# samples in the test set.\n",
    "\n",
    "# Filtering function. Adjust pad to narrow down the candidate matches to\n",
    "# within a certain length of characters of the given sample.\n",
    "def fuzzfilter(sample, candidates, pad):\n",
    "    candidates = [x for x in candidates if len(x) <= len(sample)+pad and len(x) >= len(sample)-pad] \n",
    "    if len(candidates) > 0:\n",
    "        return process.extractOne(sample, candidates)[1]\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "92EsgTaY3B4H"
   },
   "outputs": [],
   "source": [
    "# start_time = time.time()\n",
    "# ### iterating over pandas dataframe rows is not recomended, let use multi processing to apply the function\n",
    "\n",
    "# with Pool(cpu_count()-1) as pool:\n",
    "#     scores = pool.map(partial(fuzzfilter, candidates=list(en_test_sents), pad=5), df_pp['source_sentence'])\n",
    "# hours, rem = divmod(time.time() - start_time, 3600)\n",
    "# minutes, seconds = divmod(rem, 60)\n",
    "# print(\"done in {}h:{}min:{}seconds\".format(hours, minutes, seconds))\n",
    "\n",
    "# # Filter out \"almost overlapping samples\"\n",
    "# df_pp = df_pp.assign(scores=scores)\n",
    "# df_pp = df_pp[df_pp['scores'] < 95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hxxBOCA-xXhy",
    "outputId": "57c82223-7c12-45a5-db96-2b8bdcda6580"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> train.en <==\n",
      "Because God ’ s organization has grown , “ the faithful steward ” has also appointed qualified men of Jesus ’ “ other sheep ” as overseers. — Luke 12 : 42-44 ; John 10 : 16 .\n",
      "How can we maintain wholehearted love for God ’ s Kingdom ?\n",
      "These gave encouraging talks , accompanied us in the house-to-house ministry , and showed a kind interest in children .\n",
      "3 : 8-12 .\n",
      "Milane says : “ Before I go to school , my mommy and I always pray to Jehovah . ”\n",
      "We will not criticize them or doubt their motives .\n",
      "How can we be sure that these decisions are in harmony with God ’ s will ?\n",
      "What Is God ’ s View of Alcohol ?\n",
      "7 Peter , present that night , understood that Christlike love and related qualities are to be manifest among genuine disciples of Christ .\n",
      "Similarly , people who live near a busy train station may no longer notice the noise , and those who live near a garbage dump may no longer notice the smell .\n",
      "\n",
      "==> train.ve <==\n",
      "Nga ṅwambo wa uri ndangulo ya Mudzimu i khou aluwa , “ mukoma a fulufhedzeaho ” o vhea vhanna vha faneleaho vha “ dziṅwe nngu ” dza Yesu sa vhalavhelesi . — Luka 12 : 42 - 44 ; Yohane 10 : 16 .\n",
      "Ri nga dzula hani ri tshi funa Muvhuso wa Mudzimu nga mbilu yoṱhe ?\n",
      "Vhenevha vho vha vha tshi ṋekedza nyambo dzi ṱuṱuwedzaho , vha ṱuwa na riṋe vhuḓinḓani ha nnḓu nga nnḓu , nahone vha na dzangalelo kha vhana .\n",
      "3 : 8 - 12 .\n",
      "Milane o ri : “ Musi ndi sa athu ya tshikoloni , nṋe na mme anga ri a rabela Yehova tshifhinga tshoṱhe . ”\n",
      "A ri nga vha sasaladzi kana u timatima zwiṱuṱuwedzi zwavho .\n",
      "Ri nga vha hani na vhungoho ha uri phetho dzenedzi dzi a tendelana na zwine Mudzimu a zwi funa ?\n",
      "Mudzimu U Dzhia Hani Halwa ?\n",
      "7 Petro , we a vha e hone nga eneo madekwana , o pfesesa uri lufuno lwa Vhukriste na pfaneleo dzi tshimbilelanaho nalwo zwi fanela u sumbedzwa nga vhafunziwa vha Kristo vha vhukuma .\n",
      "Nga hu fanaho , vhathu vhane vha dzula tsini na tshiṱitshi tsha tshidimela , vha nga vha vha si tsha pfa phosho , na vhathu vhane vha dzula tsini na fhethu hune ha laṱwa hone mashika , vha nga vha vha si tsha pfa munukho wao .\n",
      "==> dev.en <==\n",
      "Yes , the voice of “ the man we are inside ” may fail us .\n",
      "• How can we benefit from the training Jesus gave his disciples ?\n",
      "To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "You benefit yourself , and you delight Jehovah and your fellow Christians ! — Ps . 110 : 3 .\n",
      "At midday , the priest came straight to our shop .\n",
      "It says : “ Where jealousy and contentiousness are , there disorder and every vile thing are .\n",
      "MANIFEST A RESPECTFUL SPIRIT IN THE CONGREGATION\n",
      "“ It is the foolishness of an earthling man that distorts his way , and so his heart becomes enraged against Jehovah himself . ” — PROV .\n",
      "How good it is to correct any slipups we may make in this area with healing words of sincere apology !\n",
      "\n",
      "==> dev.ve <==\n",
      "Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "• Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "Ni a vhuyelwa , nahone ni takadza Yehova na Vhakriste nga inwi . — Ps . 110 : 3 .\n",
      "Nga masiari tshivhangalala , mufunzi a ḓa nga u ṱavhanya vhengeleni ḽa hashu .\n",
      "I ri : “ Ngauri hu re na vhuhali na dzikhani , afho ndi u dzinginyea fhedzi na zwiito zwivhi .\n",
      "SUMBEDZANI ṰHONIFHO TSHIVHIDZONI\n",
      "Muthu u tshinyadza nḓila yawe nga vhutsilu hawe ; mbilu yawe ya vhó ṅalela Yehova . ’ — MIR .\n",
      "Zwi takadza lungafhani u khakhulula vhukhakhi kha ḽeneḽi sia nga maipfi a fhodzaho a u humbela pfarelo hu bvaho mbiluni !\n"
     ]
    }
   ],
   "source": [
    "# This section does the split between train/dev for the parallel corpora then saves them as separate files\n",
    "# We use 1000 dev test and the given test set.\n",
    "import csv\n",
    "\n",
    "# Do the split between dev/train and create parallel corpora\n",
    "num_dev_patterns = 1000\n",
    "\n",
    "# Optional: lower case the corpora - this will make it easier to generalize, but without proper casing.\n",
    "if lc:  # Julia: making lowercasing optional\n",
    "    df_pp[\"source_sentence\"] = df_pp[\"source_sentence\"].str.lower()\n",
    "    df_pp[\"target_sentence\"] = df_pp[\"target_sentence\"].str.lower()\n",
    "\n",
    "# Julia: test sets are already generated\n",
    "dev = df_pp.tail(num_dev_patterns) # Herman: Error in original\n",
    "stripped = df_pp.drop(df_pp.tail(num_dev_patterns).index)\n",
    "\n",
    "with open(\"train.\"+source_language, \"w\") as src_file, open(\"train.\"+target_language, \"w\") as trg_file:\n",
    "    for index, row in stripped.iterrows():\n",
    "        src_file.write(row[\"source_sentence\"]+\"\\n\")\n",
    "        trg_file.write(row[\"target_sentence\"]+\"\\n\")\n",
    "\n",
    "with open(\"dev.\"+source_language, \"w\") as src_file, open(\"dev.\"+target_language, \"w\") as trg_file:\n",
    "    for index, row in dev.iterrows():\n",
    "        src_file.write(row[\"source_sentence\"]+\"\\n\")\n",
    "        trg_file.write(row[\"target_sentence\"]+\"\\n\")\n",
    "\n",
    "#stripped[[\"source_sentence\"]].to_csv(\"train.\"+source_language, header=False, index=False)  # Herman: Added `header=False` everywhere\n",
    "#stripped[[\"target_sentence\"]].to_csv(\"train.\"+target_language, header=False, index=False)  # Julia: Problematic handling of quotation marks.\n",
    "\n",
    "#dev[[\"source_sentence\"]].to_csv(\"dev.\"+source_language, header=False, index=False)\n",
    "#dev[[\"target_sentence\"]].to_csv(\"dev.\"+target_language, header=False, index=False)\n",
    "\n",
    "# Doublecheck the format below. There should be no extra quotation marks or weird characters.\n",
    "! head train.*\n",
    "! head dev.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "epeCydmCyS8X"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Installation of JoeyNMT\n",
    "\n",
    "JoeyNMT is a simple, minimalist NMT package which is useful for learning and teaching. Check out the documentation for JoeyNMT [here](https://joeynmt.readthedocs.io)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iBRMm4kMxZ8L",
    "outputId": "457290b0-8070-41eb-e182-5c264ee70138"
   },
   "outputs": [],
   "source": [
    "# Install JoeyNMT\n",
    "# ! pip install joeynmt\n",
    "# ! git clone https://github.com/joeynmt/joeynmt.git\n",
    "# ! cd joeynmt; pip3 install .\n",
    "# Install Pytorch with GPU support v1.9.0.\n",
    "# ! pip install torch==1.9.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-10-09 18:18:07--  https://raw.githubusercontent.com/joeynmt/joeynmt/master/scripts/build_vocab.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2034 (2.0K) [text/plain]\n",
      "Saving to: ‘build_vocab.py.1’\n",
      "\n",
      "build_vocab.py.1    100%[===================>]   1.99K  --.-KB/s    in 0s      \n",
      "\n",
      "2021-10-09 18:18:07 (41.4 MB/s) - ‘build_vocab.py.1’ saved [2034/2034]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# I had trouble with joey git installation, so I just installed it through here, and made the requisite directories.\n",
    "\n",
    "# Install using pip\n",
    "! pip install joeynmt\n",
    "! pip install torch==1.9.0\n",
    "! pip install --upgrade sacrebleu==1.5.1\n",
    "\n",
    "\n",
    "!mkdir -p joeynmt/configs\n",
    "!mkdir -p joeynmt/data\n",
    "!mkdir -p joeynmt/scripts\n",
    "\n",
    "!cd joeynmt/scripts && wget https://raw.githubusercontent.com/joeynmt/joeynmt/master/scripts/build_vocab.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AaE77Tcppex9"
   },
   "source": [
    "# Preprocessing the Data into Subword BPE Tokens\n",
    "\n",
    "- One of the most powerful improvements for agglutinative languages (a feature of most Bantu languages) is using BPE tokenization [ (Sennrich, 2015) ](https://arxiv.org/abs/1508.07909).\n",
    "\n",
    "- It was also shown that by optimizing the umber of BPE codes we significantly improve results for low-resourced languages [(Sennrich, 2019)](https://www.aclweb.org/anthology/P19-1021) [(Martinus, 2019)](https://arxiv.org/abs/1906.05685)\n",
    "\n",
    "- Below we have the scripts for doing BPE tokenization of our data. We use 4000 tokens as recommended by [(Sennrich, 2019)](https://www.aclweb.org/anthology/P19-1021). You do not need to change anything. Simply running the below will be suitable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H-TyjtmXB1mL",
    "outputId": "4ebbb8e3-e036-46f8-9cab-bb703daf07c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bpe.codes.4000\tdev.en\t     test.bpe.ve     test.ve\t   train.en\n",
      "dev.bpe.en\tdev.ve\t     test.en\t     train.bpe.en  train.ve\n",
      "dev.bpe.ve\ttest.bpe.en  test.en-any.en  train.bpe.ve  vocab.txt\n",
      "bpe.codes.4000\tdev.en\ttest.bpe.en  test.en-any.en  train.bpe.ve\n",
      "dev.bpe.en\tdev.ve\ttest.bpe.ve  test.ve\t     train.en\n",
      "dev.bpe.ve\tmodels\ttest.en      train.bpe.en    train.ve\n",
      "BPE NR Sentences\n",
      "Nga zwenezwo , ndo vha ndi tshi ḓivh@@ elwa u sa fulufhedzea .\n",
      "Musi ndi tshi guda ngoho , ndo la@@ ṱa d@@ anda na ṋ@@ o@@ wa naho mushumo wo vha u tshi hol@@ ela vhukuma .\n",
      "Ndi tsumbo yavhuḓi kha vhar@@ wa vhanga vhavhili nahone ndi a fan@@ elea u vha na ndugelo tshivhidzoni .\n",
      "Zwino vha@@ ṱ@@ ol@@ i vha mi@@ th@@ elo na vhaṅwe vhane nda ita navho zwa ma@@ b@@ ind@@ u vha n@@ ḓivha sa muthu a fulufhedzeaho . ”\n",
      "Ru@@ the o pfulu@@ tshela Isiraele he a kona u gwadamela Mudzimu wa ngoho .\n",
      "Combined BPE Vocab\n",
      "Ç@@\n",
      "Ṱ\n",
      ":@@\n",
      "especi@@\n",
      "epher@@\n",
      "tshivhi@@\n",
      "ˈ\n",
      "abolo\n",
      "Scriptu@@\n",
      "‵\n"
     ]
    }
   ],
   "source": [
    "# One of the huge boosts in NMT performance was to use a different method of tokenizing. \n",
    "# Usually, NMT would tokenize by words. However, using a method called BPE gave amazing boosts to performance\n",
    "\n",
    "# Do subword NMT\n",
    "from os import path\n",
    "os.environ[\"src\"] = source_language # Sets them in bash as well, since we often use bash scripts\n",
    "os.environ[\"tgt\"] = target_language\n",
    "\n",
    "# Learn BPEs on the training data.\n",
    "os.environ[\"data_path\"] = path.join(\"joeynmt\", \"data\",target_language + source_language ) # Herman! \n",
    "! subword-nmt learn-joint-bpe-and-vocab --input train.$src train.$tgt -s 4000 -o bpe.codes.4000 --write-vocabulary vocab.$src vocab.$tgt\n",
    "\n",
    "# Apply BPE splits to the development and test data.\n",
    "! subword-nmt apply-bpe -c bpe.codes.4000 --vocabulary vocab.$src < train.$src > train.bpe.$src\n",
    "! subword-nmt apply-bpe -c bpe.codes.4000 --vocabulary vocab.$tgt < train.$tgt > train.bpe.$tgt\n",
    "\n",
    "! subword-nmt apply-bpe -c bpe.codes.4000 --vocabulary vocab.$src < dev.$src > dev.bpe.$src\n",
    "! subword-nmt apply-bpe -c bpe.codes.4000 --vocabulary vocab.$tgt < dev.$tgt > dev.bpe.$tgt\n",
    "! subword-nmt apply-bpe -c bpe.codes.4000 --vocabulary vocab.$src < test.$src > test.bpe.$src\n",
    "! subword-nmt apply-bpe -c bpe.codes.4000 --vocabulary vocab.$tgt < test.$tgt > test.bpe.$tgt\n",
    "\n",
    "# Create directory, move everyone we care about to the correct location\n",
    "! mkdir -p $data_path\n",
    "! cp train.* $data_path\n",
    "! cp test.* $data_path\n",
    "! cp dev.* $data_path\n",
    "! cp bpe.codes.4000 $data_path\n",
    "! ls $data_path\n",
    "\n",
    "# Also move everything we care about to a mounted location in google drive (relevant if running in colab) at gdrive_path\n",
    "! cp train.* \"$gdrive_path\"\n",
    "! cp test.* \"$gdrive_path\"\n",
    "! cp dev.* \"$gdrive_path\"\n",
    "! cp bpe.codes.4000 \"$gdrive_path\"\n",
    "! ls \"$gdrive_path\"\n",
    "\n",
    "# Create that vocab using build_vocab\n",
    "! chmod 777 joeynmt/scripts/build_vocab.py\n",
    "! joeynmt/scripts/build_vocab.py joeynmt/data/$tgt$src/train.bpe.$src joeynmt/data/$tgt$src/train.bpe.$tgt --output_path joeynmt/data/$tgt$src/vocab.txt\n",
    "\n",
    "# Some output\n",
    "! echo \"BPE NR Sentences\"\n",
    "! tail -n 5 test.bpe.$tgt\n",
    "! echo \"Combined BPE Vocab\"\n",
    "! tail -n 10 joeynmt/data/$tgt$src/vocab.txt  # Herman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IlMitUHR8Qy-",
    "outputId": "4d3be082-c6a3-4acc-97fb-de3598c50c90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bpe.codes.4000\tdev.en\ttest.bpe.en  test.en-any.en  train.bpe.ve\n",
      "dev.bpe.en\tdev.ve\ttest.bpe.ve  test.ve\t     train.en\n",
      "dev.bpe.ve\tmodels\ttest.en      train.bpe.en    train.ve\n"
     ]
    }
   ],
   "source": [
    "# Also move everything we care about to a mounted location in google drive (relevant if running in colab) at gdrive_path\n",
    "! cp train.* \"$gdrive_path\"\n",
    "! cp test.* \"$gdrive_path\"\n",
    "! cp dev.* \"$gdrive_path\"\n",
    "! cp bpe.codes.4000 \"$gdrive_path\"\n",
    "! ls \"$gdrive_path\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ixmzi60WsUZ8"
   },
   "source": [
    "# Creating the JoeyNMT Config\n",
    "\n",
    "JoeyNMT requires a yaml config. We provide a template below. We've also set a number of defaults with it, that you may play with!\n",
    "\n",
    "- We used Transformer architecture \n",
    "- We set our dropout to reasonably high: 0.3 (recommended in  [(Sennrich, 2019)](https://www.aclweb.org/anthology/P19-1021))\n",
    "\n",
    "Things worth playing with:\n",
    "- The batch size (also recommended to change for low-resourced languages)\n",
    "- The number of epochs (we've set it at 30 just so it runs in about an hour, for testing purposes)\n",
    "- The decoder options (beam_size, alpha)\n",
    "- Evaluation metrics (BLEU versus Crhf4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "h8TMgv1p3L1z"
   },
   "outputs": [],
   "source": [
    "# This creates the config file for our JoeyNMT system. It might seem overwhelming so we've provided a couple of useful parameters you'll need to update\n",
    "# (You can of course play with all the parameters if you'd like!)\n",
    "\n",
    "name = '%s%s' % (target_language, source_language)\n",
    "# gdrive_path = os.environ[\"gdrive_path\"]\n",
    "\n",
    "# Create the config\n",
    "config = \"\"\"\n",
    "name: \"{target_language}{source_language}_reverse_transformer\"\n",
    "\n",
    "data:\n",
    "    src: \"{target_language}\"\n",
    "    trg: \"{source_language}\"\n",
    "    train: \"data/{name}/train.bpe\"\n",
    "    dev:   \"data/{name}/dev.bpe\"\n",
    "    test:  \"data/{name}/test.bpe\"\n",
    "    level: \"bpe\"\n",
    "    lowercase: False\n",
    "    max_sent_length: 100\n",
    "    src_vocab: \"data/{name}/vocab.txt\"\n",
    "    trg_vocab: \"data/{name}/vocab.txt\"\n",
    "\n",
    "testing:\n",
    "    beam_size: 5\n",
    "    alpha: 1.0\n",
    "\n",
    "training:\n",
    "    #load_model: \"none\"\n",
    "    random_seed: 42\n",
    "    optimizer: \"adam\"\n",
    "    normalization: \"tokens\"\n",
    "    adam_betas: [0.9, 0.999] \n",
    "    scheduling: \"noam\"              # TODO: try switching from plateau to Noam scheduling\n",
    "    patience: 5                     # For plateau: decrease learning rate by decrease_factor if validation score has not improved for this many validation rounds.\n",
    "    learning_rate_factor: 0.5       # factor for Noam scheduler (used with Transformer)\n",
    "    learning_rate_warmup: 1000      # warmup steps for Noam scheduler (used with Transformer)\n",
    "    decrease_factor: 0.7\n",
    "    loss: \"crossentropy\"\n",
    "    learning_rate: 0.0003\n",
    "    learning_rate_min: 0.00000001\n",
    "    weight_decay: 0.0\n",
    "    label_smoothing: 0.1\n",
    "    batch_size: 8192\n",
    "    batch_type: \"token\"\n",
    "    eval_batch_size: 3600\n",
    "    eval_batch_type: \"token\"\n",
    "    batch_multiplier: 1\n",
    "    early_stopping_metric: \"ppl\"\n",
    "    epochs: 30                  # TODO: Decrease for when playing around and checking of working. Around 30 is sufficient to check if its working at all\n",
    "    validation_freq: 500          # TODO: Set to at least once per epoch.\n",
    "    logging_freq: 100\n",
    "    eval_metric: \"bleu\"\n",
    "    model_dir: \"models/{name}_reverse_transformer_first\"\n",
    "    overwrite: True              # TODO: Set to True if you want to overwrite possibly existing models. \n",
    "    shuffle: True\n",
    "    use_cuda: True\n",
    "    max_output_length: 100\n",
    "    print_valid_sents: [0, 1, 2, 3]\n",
    "    keep_last_ckpts: 3\n",
    "\n",
    "model:\n",
    "    initializer: \"xavier\"\n",
    "    bias_initializer: \"zeros\"\n",
    "    init_gain: 1.0\n",
    "    embed_initializer: \"xavier\"\n",
    "    embed_init_gain: 1.0\n",
    "    tied_embeddings: True\n",
    "    tied_softmax: True\n",
    "    encoder:\n",
    "        type: \"transformer\"\n",
    "        num_layers: 6\n",
    "        num_heads: 4             # TODO: Increase to 8 for larger data.\n",
    "        embeddings:\n",
    "            embedding_dim: 256   # TODO: Increase to 512 for larger data.\n",
    "            scale: True\n",
    "            dropout: 0.2\n",
    "        # typically ff_size = 4 x hidden_size\n",
    "        hidden_size: 256         # TODO: Increase to 512 for larger data.\n",
    "        ff_size: 1024            # TODO: Increase to 2048 for larger data.\n",
    "        dropout: 0.3\n",
    "    decoder:\n",
    "        type: \"transformer\"\n",
    "        num_layers: 6\n",
    "        num_heads: 4              # TODO: Increase to 8 for larger data.\n",
    "        embeddings:\n",
    "            embedding_dim: 256    # TODO: Increase to 512 for larger data.\n",
    "            scale: True\n",
    "            dropout: 0.2\n",
    "        # typically ff_size = 4 x hidden_size\n",
    "        hidden_size: 256         # TODO: Increase to 512 for larger data.\n",
    "        ff_size: 1024            # TODO: Increase to 2048 for larger data.\n",
    "        dropout: 0.3\n",
    "\"\"\".format(name=name, gdrive_path=os.environ[\"gdrive_path\"], source_language=source_language, target_language=target_language)\n",
    "with open(\"joeynmt/configs/transformer_reverse_{name}.yaml\".format(name=name),'w') as f:\n",
    "    f.write(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer_reverse_veen.yaml\n"
     ]
    }
   ],
   "source": [
    "!ls joeynmt/configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oEzoJtV2MIpt"
   },
   "source": [
    "# Train the Model\n",
    "\n",
    "This single line of joeynmt runs the training using the config we made above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WzbNYNdjLgNb",
    "outputId": "fddbfee2-c6d2-4377-e682-8b1c78d49cc5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-09 18:19:42,260 - INFO - root - Hello! This is Joey-NMT (version 1.3).\n",
      "2021-10-09 18:19:42,319 - INFO - joeynmt.data - Loading training data...\n",
      "2021-10-09 18:19:46,579 - INFO - joeynmt.data - Building vocabulary...\n",
      "2021-10-09 18:19:46,866 - INFO - joeynmt.data - Loading dev data...\n",
      "2021-10-09 18:19:46,890 - INFO - joeynmt.data - Loading test data...\n",
      "2021-10-09 18:19:46,937 - INFO - joeynmt.data - Data loaded.\n",
      "2021-10-09 18:19:46,937 - INFO - joeynmt.model - Building an encoder-decoder model...\n",
      "2021-10-09 18:19:47,396 - INFO - joeynmt.model - Enc-dec model built.\n",
      "2021-10-09 18:19:47,409 - INFO - joeynmt.training - Total params: 12152576\n",
      "2021-10-09 18:19:56,007 - INFO - joeynmt.helpers - cfg.name                           : veen_reverse_transformer\n",
      "2021-10-09 18:19:56,007 - INFO - joeynmt.helpers - cfg.data.src                       : ve\n",
      "2021-10-09 18:19:56,008 - INFO - joeynmt.helpers - cfg.data.trg                       : en\n",
      "2021-10-09 18:19:56,008 - INFO - joeynmt.helpers - cfg.data.train                     : data/veen/train.bpe\n",
      "2021-10-09 18:19:56,008 - INFO - joeynmt.helpers - cfg.data.dev                       : data/veen/dev.bpe\n",
      "2021-10-09 18:19:56,008 - INFO - joeynmt.helpers - cfg.data.test                      : data/veen/test.bpe\n",
      "2021-10-09 18:19:56,008 - INFO - joeynmt.helpers - cfg.data.level                     : bpe\n",
      "2021-10-09 18:19:56,008 - INFO - joeynmt.helpers - cfg.data.lowercase                 : False\n",
      "2021-10-09 18:19:56,008 - INFO - joeynmt.helpers - cfg.data.max_sent_length           : 100\n",
      "2021-10-09 18:19:56,008 - INFO - joeynmt.helpers - cfg.data.src_vocab                 : data/veen/vocab.txt\n",
      "2021-10-09 18:19:56,008 - INFO - joeynmt.helpers - cfg.data.trg_vocab                 : data/veen/vocab.txt\n",
      "2021-10-09 18:19:56,008 - INFO - joeynmt.helpers - cfg.testing.beam_size              : 5\n",
      "2021-10-09 18:19:56,008 - INFO - joeynmt.helpers - cfg.testing.alpha                  : 1.0\n",
      "2021-10-09 18:19:56,009 - INFO - joeynmt.helpers - cfg.training.random_seed           : 42\n",
      "2021-10-09 18:19:56,009 - INFO - joeynmt.helpers - cfg.training.optimizer             : adam\n",
      "2021-10-09 18:19:56,009 - INFO - joeynmt.helpers - cfg.training.normalization         : tokens\n",
      "2021-10-09 18:19:56,009 - INFO - joeynmt.helpers - cfg.training.adam_betas            : [0.9, 0.999]\n",
      "2021-10-09 18:19:56,009 - INFO - joeynmt.helpers - cfg.training.scheduling            : noam\n",
      "2021-10-09 18:19:56,009 - INFO - joeynmt.helpers - cfg.training.patience              : 5\n",
      "2021-10-09 18:19:56,009 - INFO - joeynmt.helpers - cfg.training.learning_rate_factor  : 0.5\n",
      "2021-10-09 18:19:56,009 - INFO - joeynmt.helpers - cfg.training.learning_rate_warmup  : 1000\n",
      "2021-10-09 18:19:56,009 - INFO - joeynmt.helpers - cfg.training.decrease_factor       : 0.7\n",
      "2021-10-09 18:19:56,009 - INFO - joeynmt.helpers - cfg.training.loss                  : crossentropy\n",
      "2021-10-09 18:19:56,009 - INFO - joeynmt.helpers - cfg.training.learning_rate         : 0.0003\n",
      "2021-10-09 18:19:56,010 - INFO - joeynmt.helpers - cfg.training.learning_rate_min     : 1e-08\n",
      "2021-10-09 18:19:56,010 - INFO - joeynmt.helpers - cfg.training.weight_decay          : 0.0\n",
      "2021-10-09 18:19:56,010 - INFO - joeynmt.helpers - cfg.training.label_smoothing       : 0.1\n",
      "2021-10-09 18:19:56,010 - INFO - joeynmt.helpers - cfg.training.batch_size            : 8192\n",
      "2021-10-09 18:19:56,010 - INFO - joeynmt.helpers - cfg.training.batch_type            : token\n",
      "2021-10-09 18:19:56,010 - INFO - joeynmt.helpers - cfg.training.eval_batch_size       : 3600\n",
      "2021-10-09 18:19:56,010 - INFO - joeynmt.helpers - cfg.training.eval_batch_type       : token\n",
      "2021-10-09 18:19:56,010 - INFO - joeynmt.helpers - cfg.training.batch_multiplier      : 1\n",
      "2021-10-09 18:19:56,010 - INFO - joeynmt.helpers - cfg.training.early_stopping_metric : ppl\n",
      "2021-10-09 18:19:56,010 - INFO - joeynmt.helpers - cfg.training.epochs                : 30\n",
      "2021-10-09 18:19:56,010 - INFO - joeynmt.helpers - cfg.training.validation_freq       : 500\n",
      "2021-10-09 18:19:56,010 - INFO - joeynmt.helpers - cfg.training.logging_freq          : 100\n",
      "2021-10-09 18:19:56,011 - INFO - joeynmt.helpers - cfg.training.eval_metric           : bleu\n",
      "2021-10-09 18:19:56,011 - INFO - joeynmt.helpers - cfg.training.model_dir             : models/veen_reverse_transformer_first\n",
      "2021-10-09 18:19:56,011 - INFO - joeynmt.helpers - cfg.training.overwrite             : True\n",
      "2021-10-09 18:19:56,011 - INFO - joeynmt.helpers - cfg.training.shuffle               : True\n",
      "2021-10-09 18:19:56,011 - INFO - joeynmt.helpers - cfg.training.use_cuda              : True\n",
      "2021-10-09 18:19:56,011 - INFO - joeynmt.helpers - cfg.training.max_output_length     : 100\n",
      "2021-10-09 18:19:56,011 - INFO - joeynmt.helpers - cfg.training.print_valid_sents     : [0, 1, 2, 3]\n",
      "2021-10-09 18:19:56,011 - INFO - joeynmt.helpers - cfg.training.keep_last_ckpts       : 3\n",
      "2021-10-09 18:19:56,011 - INFO - joeynmt.helpers - cfg.model.initializer              : xavier\n",
      "2021-10-09 18:19:56,011 - INFO - joeynmt.helpers - cfg.model.bias_initializer         : zeros\n",
      "2021-10-09 18:19:56,011 - INFO - joeynmt.helpers - cfg.model.init_gain                : 1.0\n",
      "2021-10-09 18:19:56,011 - INFO - joeynmt.helpers - cfg.model.embed_initializer        : xavier\n",
      "2021-10-09 18:19:56,012 - INFO - joeynmt.helpers - cfg.model.embed_init_gain          : 1.0\n",
      "2021-10-09 18:19:56,012 - INFO - joeynmt.helpers - cfg.model.tied_embeddings          : True\n",
      "2021-10-09 18:19:56,012 - INFO - joeynmt.helpers - cfg.model.tied_softmax             : True\n",
      "2021-10-09 18:19:56,012 - INFO - joeynmt.helpers - cfg.model.encoder.type             : transformer\n",
      "2021-10-09 18:19:56,012 - INFO - joeynmt.helpers - cfg.model.encoder.num_layers       : 6\n",
      "2021-10-09 18:19:56,012 - INFO - joeynmt.helpers - cfg.model.encoder.num_heads        : 4\n",
      "2021-10-09 18:19:56,012 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.embedding_dim : 256\n",
      "2021-10-09 18:19:56,012 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.scale : True\n",
      "2021-10-09 18:19:56,012 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.dropout : 0.2\n",
      "2021-10-09 18:19:56,012 - INFO - joeynmt.helpers - cfg.model.encoder.hidden_size      : 256\n",
      "2021-10-09 18:19:56,012 - INFO - joeynmt.helpers - cfg.model.encoder.ff_size          : 1024\n",
      "2021-10-09 18:19:56,013 - INFO - joeynmt.helpers - cfg.model.encoder.dropout          : 0.3\n",
      "2021-10-09 18:19:56,013 - INFO - joeynmt.helpers - cfg.model.decoder.type             : transformer\n",
      "2021-10-09 18:19:56,013 - INFO - joeynmt.helpers - cfg.model.decoder.num_layers       : 6\n",
      "2021-10-09 18:19:56,013 - INFO - joeynmt.helpers - cfg.model.decoder.num_heads        : 4\n",
      "2021-10-09 18:19:56,013 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.embedding_dim : 256\n",
      "2021-10-09 18:19:56,013 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.scale : True\n",
      "2021-10-09 18:19:56,013 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.dropout : 0.2\n",
      "2021-10-09 18:19:56,013 - INFO - joeynmt.helpers - cfg.model.decoder.hidden_size      : 256\n",
      "2021-10-09 18:19:56,013 - INFO - joeynmt.helpers - cfg.model.decoder.ff_size          : 1024\n",
      "2021-10-09 18:19:56,013 - INFO - joeynmt.helpers - cfg.model.decoder.dropout          : 0.3\n",
      "2021-10-09 18:19:56,013 - INFO - joeynmt.helpers - Data set sizes: \n",
      "\ttrain 201103,\n",
      "\tvalid 1000,\n",
      "\ttest 2719\n",
      "2021-10-09 18:19:56,014 - INFO - joeynmt.helpers - First training example:\n",
      "\t[SRC] Nga ṅwambo wa uri ndangulo ya Mudzimu i khou aluwa , “ mukoma a fulufhedzeaho ” o vhea vhanna vha fan@@ eleaho vha “ dziṅwe nngu ” dza Yesu sa vhal@@ a@@ vhelesi . — Luka 12 : 42 - 44 ; Yohane 10 : 16 .\n",
      "\t[TRG] Because God ’ s organization has gro@@ wn , “ the faithful ste@@ ward ” has also appointed qu@@ ali@@ fied men of Jesus ’ “ other sheep ” as overse@@ er@@ s. — Luke 12 : 4@@ 2-@@ 44 ; John 10 : 16 .\n",
      "2021-10-09 18:19:56,014 - INFO - joeynmt.helpers - First 10 words (src): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) . (5) , (6) a (7) u (8) vha (9) the\n",
      "2021-10-09 18:19:56,014 - INFO - joeynmt.helpers - First 10 words (trg): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) . (5) , (6) a (7) u (8) vha (9) the\n",
      "2021-10-09 18:19:56,014 - INFO - joeynmt.helpers - Number of Src words (types): 4267\n",
      "2021-10-09 18:19:56,014 - INFO - joeynmt.helpers - Number of Trg words (types): 4267\n",
      "2021-10-09 18:19:56,014 - INFO - joeynmt.training - Model(\n",
      "\tencoder=TransformerEncoder(num_layers=6, num_heads=4),\n",
      "\tdecoder=TransformerDecoder(num_layers=6, num_heads=4),\n",
      "\tsrc_embed=Embeddings(embedding_dim=256, vocab_size=4267),\n",
      "\ttrg_embed=Embeddings(embedding_dim=256, vocab_size=4267))\n",
      "2021-10-09 18:19:56,023 - INFO - joeynmt.training - Train stats:\n",
      "\tdevice: cuda\n",
      "\tn_gpu: 2\n",
      "\t16-bits training: False\n",
      "\tgradient accumulation: 1\n",
      "\tbatch size per device: 4096\n",
      "\ttotal batch size (w. parallel & accumulation): 8192\n",
      "2021-10-09 18:19:56,023 - INFO - joeynmt.training - EPOCH 1\n",
      "/home-mscluster/mbeukman/anaconda3/envs/nlp_q2/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "2021-10-09 18:20:26,126 - INFO - joeynmt.training - Epoch   1, Step:      100, Batch Loss:     3.011669, Tokens per Sec:    15097, Lr: 0.000099\n",
      "2021-10-09 18:20:52,873 - INFO - joeynmt.training - Epoch   1, Step:      200, Batch Loss:     2.797342, Tokens per Sec:    16628, Lr: 0.000198\n",
      "2021-10-09 18:21:19,063 - INFO - joeynmt.training - Epoch   1, Step:      300, Batch Loss:     2.712589, Tokens per Sec:    17257, Lr: 0.000296\n",
      "2021-10-09 18:21:44,765 - INFO - joeynmt.training - Epoch   1, Step:      400, Batch Loss:     2.620348, Tokens per Sec:    17292, Lr: 0.000395\n",
      "2021-10-09 18:22:10,650 - INFO - joeynmt.training - Epoch   1, Step:      500, Batch Loss:     2.286631, Tokens per Sec:    17255, Lr: 0.000494\n",
      "2021-10-09 18:24:06,087 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 18:24:06,095 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 18:24:06,096 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 18:24:06,583 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 18:24:06,583 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 18:24:09,233 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 18:24:09,233 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 18:24:09,233 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 18:24:09,233 - INFO - joeynmt.training - \tHypothesis: ( 1 : 1 ) What have the be be be be be be be be be be be be be be be be be be be be be be be be be be be be be .\n",
      "2021-10-09 18:24:09,233 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 18:24:09,234 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 18:24:09,234 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 18:24:09,234 - INFO - joeynmt.training - \tHypothesis: What can we we we we be the be be the be the be the be the be the be the be the be the be the be the be the be the be the be the be the be the be the be the be the be be be be be ?\n",
      "2021-10-09 18:24:09,234 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 18:24:09,234 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 18:24:09,234 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 18:24:09,234 - INFO - joeynmt.training - \tHypothesis: ( 1 : 1 : 1 ) The have the Bible , the be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be be\n",
      "2021-10-09 18:24:09,235 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 18:24:09,235 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 18:24:09,235 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 18:24:09,235 - INFO - joeynmt.training - \tHypothesis: The Sried the Rried , the Rried the Rried the Rried the Rried the Rried the Rried .\n",
      "2021-10-09 18:24:09,235 - INFO - joeynmt.training - Validation result (greedy) at epoch   1, step      500: bleu:   0.04, loss: 65836.4141, ppl:  10.2728, duration: 118.5838s\n",
      "2021-10-09 18:24:35,429 - INFO - joeynmt.training - Epoch   1, Step:      600, Batch Loss:     2.020033, Tokens per Sec:    17385, Lr: 0.000593\n",
      "2021-10-09 18:25:01,582 - INFO - joeynmt.training - Epoch   1, Step:      700, Batch Loss:     2.137472, Tokens per Sec:    17538, Lr: 0.000692\n",
      "2021-10-09 18:25:28,734 - INFO - joeynmt.training - Epoch   1, Step:      800, Batch Loss:     2.112843, Tokens per Sec:    17030, Lr: 0.000791\n",
      "2021-10-09 18:25:54,925 - INFO - joeynmt.training - Epoch   1, Step:      900, Batch Loss:     2.003887, Tokens per Sec:    17427, Lr: 0.000889\n",
      "2021-10-09 18:26:20,415 - INFO - joeynmt.training - Epoch   1, Step:     1000, Batch Loss:     1.904698, Tokens per Sec:    17711, Lr: 0.000988\n",
      "2021-10-09 18:28:14,285 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 18:28:14,286 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 18:28:14,286 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 18:28:14,720 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 18:28:14,720 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 18:28:16,395 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 18:28:16,395 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 18:28:16,395 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 18:28:16,395 - INFO - joeynmt.training - \tHypothesis: So we are “ the good news of the good news of the things ” and “ the good news of the good .\n",
      "2021-10-09 18:28:16,395 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 18:28:16,396 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 18:28:16,396 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 18:28:16,396 - INFO - joeynmt.training - \tHypothesis: • How can we learn from Jesus ’ s servants of his disciples ?\n",
      "2021-10-09 18:28:16,396 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 18:28:16,396 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 18:28:16,396 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 18:28:16,396 - INFO - joeynmt.training - \tHypothesis: It will be a person and help us to be a good news of the good news of the Bible and the Kingdom . — Psalm 1 : 1 .\n",
      "2021-10-09 18:28:16,396 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 18:28:16,397 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 18:28:16,397 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 18:28:16,397 - INFO - joeynmt.training - \tHypothesis: I had been been been been to the Bible , I had been been been been been been been been been been been to the Bible .\n",
      "2021-10-09 18:28:16,397 - INFO - joeynmt.training - Validation result (greedy) at epoch   1, step     1000: bleu:   3.35, loss: 52995.4297, ppl:   6.5218, duration: 115.9808s\n",
      "2021-10-09 18:28:43,115 - INFO - joeynmt.training - Epoch   1, Step:     1100, Batch Loss:     1.987045, Tokens per Sec:    16658, Lr: 0.000942\n",
      "2021-10-09 18:29:08,443 - INFO - joeynmt.training - Epoch   1, Step:     1200, Batch Loss:     1.820419, Tokens per Sec:    17655, Lr: 0.000902\n",
      "2021-10-09 18:29:15,588 - INFO - joeynmt.training - Epoch   1: total training loss 2867.43\n",
      "2021-10-09 18:29:15,588 - INFO - joeynmt.training - EPOCH 2\n",
      "2021-10-09 18:29:34,843 - INFO - joeynmt.training - Epoch   2, Step:     1300, Batch Loss:     1.768850, Tokens per Sec:    17224, Lr: 0.000867\n",
      "2021-10-09 18:30:01,361 - INFO - joeynmt.training - Epoch   2, Step:     1400, Batch Loss:     1.495095, Tokens per Sec:    17328, Lr: 0.000835\n",
      "2021-10-09 18:30:26,747 - INFO - joeynmt.training - Epoch   2, Step:     1500, Batch Loss:     1.700388, Tokens per Sec:    17778, Lr: 0.000807\n",
      "2021-10-09 18:31:38,342 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 18:31:38,342 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 18:31:38,342 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 18:31:38,767 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 18:31:38,767 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 18:31:40,471 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 18:31:40,471 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 18:31:40,471 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 18:31:40,471 - INFO - joeynmt.training - \tHypothesis: Of course , the conscience “ the good news ” is not not to be a person .\n",
      "2021-10-09 18:31:40,471 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 18:31:40,472 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 18:31:40,472 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 18:31:40,472 - INFO - joeynmt.training - \tHypothesis: • How can we learn from Jesus ’ counsel ?\n",
      "2021-10-09 18:31:40,472 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 18:31:40,472 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 18:31:40,472 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 18:31:40,472 - INFO - joeynmt.training - \tHypothesis: This will be sure that we are not not to be a person who is not to be a person who is a great tribulation and to be a great tribulation . — Heb . 5 : 14 ; 5 : 14 ; 5 : 14 .\n",
      "2021-10-09 18:31:40,473 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 18:31:40,473 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 18:31:40,473 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 18:31:40,473 - INFO - joeynmt.training - \tHypothesis: After the church , I was a pioneer , I was a few of the brothers , I was a pioneer .\n",
      "2021-10-09 18:31:40,473 - INFO - joeynmt.training - Validation result (greedy) at epoch   2, step     1500: bleu:  12.15, loss: 43618.9180, ppl:   4.6804, duration: 73.7196s\n",
      "2021-10-09 18:32:06,405 - INFO - joeynmt.training - Epoch   2, Step:     1600, Batch Loss:     1.671982, Tokens per Sec:    17038, Lr: 0.000781\n",
      "2021-10-09 18:32:32,387 - INFO - joeynmt.training - Epoch   2, Step:     1700, Batch Loss:     1.516704, Tokens per Sec:    17276, Lr: 0.000758\n",
      "2021-10-09 18:32:59,075 - INFO - joeynmt.training - Epoch   2, Step:     1800, Batch Loss:     1.525007, Tokens per Sec:    16945, Lr: 0.000737\n",
      "2021-10-09 18:33:25,145 - INFO - joeynmt.training - Epoch   2, Step:     1900, Batch Loss:     1.498624, Tokens per Sec:    17084, Lr: 0.000717\n",
      "2021-10-09 18:33:52,019 - INFO - joeynmt.training - Epoch   2, Step:     2000, Batch Loss:     1.427896, Tokens per Sec:    17006, Lr: 0.000699\n",
      "2021-10-09 18:35:11,146 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 18:35:11,147 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 18:35:11,147 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 18:35:11,571 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 18:35:11,571 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 18:35:13,465 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 18:35:13,465 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 18:35:13,465 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 18:35:13,465 - INFO - joeynmt.training - \tHypothesis: Yes , the conscience “ the man ” may be a person ’ s heart .\n",
      "2021-10-09 18:35:13,465 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 18:35:13,466 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 18:35:13,466 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 18:35:13,466 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from Jesus ’ disciples to give his disciples ?\n",
      "2021-10-09 18:35:13,466 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 18:35:13,466 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 18:35:13,466 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 18:35:13,466 - INFO - joeynmt.training - \tHypothesis: That will be sure that we are not to be a person who is not a person who is not not a brich and to be a brich of the bace. — Heb . 5 : 14 ; Heb . 5 : 14 ; Heb . 5 : 14 .\n",
      "2021-10-09 18:35:13,466 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 18:35:13,467 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 18:35:13,467 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 18:35:13,467 - INFO - joeynmt.training - \tHypothesis: After the Promised Body , I was in 1945 , and I was a few of our children .\n",
      "2021-10-09 18:35:13,467 - INFO - joeynmt.training - Validation result (greedy) at epoch   2, step     2000: bleu:  14.60, loss: 39516.8945, ppl:   4.0480, duration: 81.4475s\n",
      "2021-10-09 18:35:39,585 - INFO - joeynmt.training - Epoch   2, Step:     2100, Batch Loss:     1.307958, Tokens per Sec:    17725, Lr: 0.000682\n",
      "2021-10-09 18:36:05,380 - INFO - joeynmt.training - Epoch   2, Step:     2200, Batch Loss:     1.140593, Tokens per Sec:    16647, Lr: 0.000666\n",
      "2021-10-09 18:36:31,648 - INFO - joeynmt.training - Epoch   2, Step:     2300, Batch Loss:     1.367100, Tokens per Sec:    17616, Lr: 0.000652\n",
      "2021-10-09 18:36:58,197 - INFO - joeynmt.training - Epoch   2, Step:     2400, Batch Loss:     1.428929, Tokens per Sec:    16592, Lr: 0.000638\n",
      "2021-10-09 18:37:13,424 - INFO - joeynmt.training - Epoch   2: total training loss 1885.10\n",
      "2021-10-09 18:37:13,425 - INFO - joeynmt.training - EPOCH 3\n",
      "2021-10-09 18:37:24,721 - INFO - joeynmt.training - Epoch   3, Step:     2500, Batch Loss:     1.332878, Tokens per Sec:    16652, Lr: 0.000625\n",
      "2021-10-09 18:38:52,077 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 18:38:52,078 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 18:38:52,078 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 18:38:52,516 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 18:38:52,516 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 18:38:54,297 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 18:38:54,297 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 18:38:54,297 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 18:38:54,297 - INFO - joeynmt.training - \tHypothesis: Of course , the conscience “ the man ” may be “ a man . ”\n",
      "2021-10-09 18:38:54,297 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 18:38:54,298 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 18:38:54,298 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 18:38:54,298 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from Jesus ’ disciples to give his disciples ?\n",
      "2021-10-09 18:38:54,298 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 18:38:54,298 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 18:38:54,298 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 18:38:54,298 - INFO - joeynmt.training - \tHypothesis: That will help us to know that the battle is the righteous and bad and bad and that we know that we are not to know the wisdom and discreet . — Heb . 5 : 14 ; Heb . 5 : 14 .\n",
      "2021-10-09 18:38:54,298 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 18:38:54,299 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 18:38:54,299 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 18:38:54,299 - INFO - joeynmt.training - \tHypothesis: After the Bron , I was in 1945 , I was baptized in the brothers and sisters in Praya .\n",
      "2021-10-09 18:38:54,299 - INFO - joeynmt.training - Validation result (greedy) at epoch   3, step     2500: bleu:  16.52, loss: 37229.3672, ppl:   3.7333, duration: 89.5773s\n",
      "2021-10-09 18:39:20,137 - INFO - joeynmt.training - Epoch   3, Step:     2600, Batch Loss:     1.556645, Tokens per Sec:    17209, Lr: 0.000613\n",
      "2021-10-09 18:39:46,890 - INFO - joeynmt.training - Epoch   3, Step:     2700, Batch Loss:     1.161260, Tokens per Sec:    16600, Lr: 0.000601\n",
      "2021-10-09 18:40:12,945 - INFO - joeynmt.training - Epoch   3, Step:     2800, Batch Loss:     1.523307, Tokens per Sec:    17392, Lr: 0.000591\n",
      "2021-10-09 18:40:39,680 - INFO - joeynmt.training - Epoch   3, Step:     2900, Batch Loss:     1.381653, Tokens per Sec:    16873, Lr: 0.000580\n",
      "2021-10-09 18:41:06,609 - INFO - joeynmt.training - Epoch   3, Step:     3000, Batch Loss:     1.435701, Tokens per Sec:    16990, Lr: 0.000571\n",
      "2021-10-09 18:42:24,625 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 18:42:24,626 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 18:42:24,626 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 18:42:25,043 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 18:42:25,043 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 18:42:27,609 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 18:42:27,609 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 18:42:27,610 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 18:42:27,610 - INFO - joeynmt.training - \tHypothesis: Yes , the conscience “ a man ” may be a person who may be able to be guided .\n",
      "2021-10-09 18:42:27,610 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 18:42:27,610 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 18:42:27,610 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 18:42:27,610 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from Jesus ’ teachings ?\n",
      "2021-10-09 18:42:27,610 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 18:42:27,610 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 18:42:27,611 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 18:42:27,611 - INFO - joeynmt.training - \tHypothesis: That will do to know that we are like the righteous and bad and not know the righteous one . — Heb . 5 : 14 ; Heb . 5 : 14 .\n",
      "2021-10-09 18:42:27,611 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 18:42:27,611 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 18:42:27,611 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 18:42:27,611 - INFO - joeynmt.training - \tHypothesis: After the Frominy of Frominy , I was in 1945 , I was a young brothers in Rian .\n",
      "2021-10-09 18:42:27,611 - INFO - joeynmt.training - Validation result (greedy) at epoch   3, step     3000: bleu:  19.82, loss: 35082.8672, ppl:   3.4603, duration: 81.0020s\n",
      "2021-10-09 18:42:53,539 - INFO - joeynmt.training - Epoch   3, Step:     3100, Batch Loss:     1.469594, Tokens per Sec:    17103, Lr: 0.000561\n",
      "2021-10-09 18:43:19,763 - INFO - joeynmt.training - Epoch   3, Step:     3200, Batch Loss:     1.342928, Tokens per Sec:    17388, Lr: 0.000552\n",
      "2021-10-09 18:43:46,110 - INFO - joeynmt.training - Epoch   3, Step:     3300, Batch Loss:     1.104658, Tokens per Sec:    17350, Lr: 0.000544\n",
      "2021-10-09 18:44:12,408 - INFO - joeynmt.training - Epoch   3, Step:     3400, Batch Loss:     1.365934, Tokens per Sec:    17380, Lr: 0.000536\n",
      "2021-10-09 18:44:38,450 - INFO - joeynmt.training - Epoch   3, Step:     3500, Batch Loss:     1.037510, Tokens per Sec:    17453, Lr: 0.000528\n",
      "2021-10-09 18:46:06,076 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 18:46:06,077 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 18:46:06,077 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 18:46:06,502 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 18:46:06,502 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 18:46:08,210 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 18:46:08,211 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 18:46:08,211 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 18:46:08,211 - INFO - joeynmt.training - \tHypothesis: Indeed , the conscience “ the man ” may be able to be a person .\n",
      "2021-10-09 18:46:08,211 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 18:46:08,211 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 18:46:08,211 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 18:46:08,211 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from Jesus ’ teachings provide disciples ?\n",
      "2021-10-09 18:46:08,211 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 18:46:08,212 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 18:46:08,212 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 18:46:08,212 - INFO - joeynmt.training - \tHypothesis: That will do so to know the righteous and righteousness and not know the righteous and the righteous one another and the wisdom of the wisdom of the wisdom and wisdom . — Heb . 5 : 14 ; Heb . 5 : 15 .\n",
      "2021-10-09 18:46:08,212 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 18:46:08,212 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 18:46:08,212 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 18:46:08,212 - INFO - joeynmt.training - \tHypothesis: After France in French 1945 , I was still still in Pererererermany .\n",
      "2021-10-09 18:46:08,212 - INFO - joeynmt.training - Validation result (greedy) at epoch   3, step     3500: bleu:  20.98, loss: 33461.7500, ppl:   3.2674, duration: 89.7619s\n",
      "2021-10-09 18:46:34,715 - INFO - joeynmt.training - Epoch   3, Step:     3600, Batch Loss:     1.474808, Tokens per Sec:    17374, Lr: 0.000521\n",
      "2021-10-09 18:46:56,437 - INFO - joeynmt.training - Epoch   3: total training loss 1611.74\n",
      "2021-10-09 18:46:56,437 - INFO - joeynmt.training - EPOCH 4\n",
      "2021-10-09 18:47:00,692 - INFO - joeynmt.training - Epoch   4, Step:     3700, Batch Loss:     1.382232, Tokens per Sec:    18133, Lr: 0.000514\n",
      "2021-10-09 18:47:26,805 - INFO - joeynmt.training - Epoch   4, Step:     3800, Batch Loss:     1.263656, Tokens per Sec:    17573, Lr: 0.000507\n",
      "2021-10-09 18:47:52,778 - INFO - joeynmt.training - Epoch   4, Step:     3900, Batch Loss:     1.269580, Tokens per Sec:    17220, Lr: 0.000500\n",
      "2021-10-09 18:48:18,742 - INFO - joeynmt.training - Epoch   4, Step:     4000, Batch Loss:     1.157800, Tokens per Sec:    17310, Lr: 0.000494\n",
      "2021-10-09 18:49:30,906 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 18:49:30,907 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 18:49:30,907 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 18:49:31,324 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 18:49:31,324 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 18:49:33,076 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 18:49:33,076 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 18:49:33,076 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 18:49:33,076 - INFO - joeynmt.training - \tHypothesis: Yes , the conscience “ a person who is in the heart ” may be able to reject us .\n",
      "2021-10-09 18:49:33,076 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 18:49:33,077 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 18:49:33,077 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 18:49:33,077 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from Jesus ’ teachings give his disciples ?\n",
      "2021-10-09 18:49:33,077 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 18:49:33,077 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 18:49:33,077 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 18:49:33,077 - INFO - joeynmt.training - \tHypothesis: That will make us aware of the difference between the righteous and righteousness and not know the wisdom of the wisdom and wisdom and wisdom . — Eph . 5 : 14 ; Heb . 5 : 15 .\n",
      "2021-10-09 18:49:33,077 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 18:49:33,078 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 18:49:33,078 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 18:49:33,078 - INFO - joeynmt.training - \tHypothesis: Later , the February in in 1945 , I had experienced children in Perererermany .\n",
      "2021-10-09 18:49:33,078 - INFO - joeynmt.training - Validation result (greedy) at epoch   4, step     4000: bleu:  23.04, loss: 32055.1973, ppl:   3.1087, duration: 74.3349s\n",
      "2021-10-09 18:49:59,190 - INFO - joeynmt.training - Epoch   4, Step:     4100, Batch Loss:     1.307843, Tokens per Sec:    17692, Lr: 0.000488\n",
      "2021-10-09 18:50:25,802 - INFO - joeynmt.training - Epoch   4, Step:     4200, Batch Loss:     1.195261, Tokens per Sec:    16804, Lr: 0.000482\n",
      "2021-10-09 18:50:52,471 - INFO - joeynmt.training - Epoch   4, Step:     4300, Batch Loss:     1.220147, Tokens per Sec:    17262, Lr: 0.000477\n",
      "2021-10-09 18:51:18,459 - INFO - joeynmt.training - Epoch   4, Step:     4400, Batch Loss:     1.175039, Tokens per Sec:    17300, Lr: 0.000471\n",
      "2021-10-09 18:51:44,135 - INFO - joeynmt.training - Epoch   4, Step:     4500, Batch Loss:     1.187667, Tokens per Sec:    17543, Lr: 0.000466\n",
      "2021-10-09 18:53:05,668 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 18:53:05,669 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 18:53:05,669 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 18:53:06,081 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 18:53:06,081 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 18:53:07,777 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 18:53:07,778 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 18:53:07,778 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 18:53:07,778 - INFO - joeynmt.training - \tHypothesis: Yes , the conscience “ a person of the one ” may be able to remove us .\n",
      "2021-10-09 18:53:07,778 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 18:53:07,778 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 18:53:07,778 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 18:53:07,778 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from Jesus ’ teachings to his disciples ?\n",
      "2021-10-09 18:53:07,779 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 18:53:07,779 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 18:53:07,779 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 18:53:07,779 - INFO - joeynmt.training - \tHypothesis: That will do so to know the difference between righteousness and righteousness and righteousness also know the wisdom between the wisdom and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 18:53:07,779 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 18:53:07,779 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 18:53:07,779 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 18:53:07,779 - INFO - joeynmt.training - \tHypothesis: After February February 1945 , I had experienced children in Pericica .\n",
      "2021-10-09 18:53:07,780 - INFO - joeynmt.training - Validation result (greedy) at epoch   4, step     4500: bleu:  23.88, loss: 31113.9180, ppl:   3.0069, duration: 83.6441s\n",
      "2021-10-09 18:53:33,689 - INFO - joeynmt.training - Epoch   4, Step:     4600, Batch Loss:     1.240791, Tokens per Sec:    17560, Lr: 0.000461\n",
      "2021-10-09 18:54:00,075 - INFO - joeynmt.training - Epoch   4, Step:     4700, Batch Loss:     1.228335, Tokens per Sec:    16766, Lr: 0.000456\n",
      "2021-10-09 18:54:26,154 - INFO - joeynmt.training - Epoch   4, Step:     4800, Batch Loss:     1.235061, Tokens per Sec:    17680, Lr: 0.000451\n",
      "2021-10-09 18:54:52,946 - INFO - joeynmt.training - Epoch   4, Step:     4900, Batch Loss:     1.194645, Tokens per Sec:    17033, Lr: 0.000446\n",
      "2021-10-09 18:54:54,859 - INFO - joeynmt.training - Epoch   4: total training loss 1468.91\n",
      "2021-10-09 18:54:54,859 - INFO - joeynmt.training - EPOCH 5\n",
      "2021-10-09 18:55:18,120 - INFO - joeynmt.training - Epoch   5, Step:     5000, Batch Loss:     1.309910, Tokens per Sec:    18230, Lr: 0.000442\n",
      "2021-10-09 18:56:34,715 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 18:56:34,715 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 18:56:34,715 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 18:56:35,133 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 18:56:35,133 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 18:56:36,903 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 18:56:36,903 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 18:56:36,903 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 18:56:36,903 - INFO - joeynmt.training - \tHypothesis: Of course , the conscience “ the man of the one ” may be able to remove us .\n",
      "2021-10-09 18:56:36,903 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 18:56:36,903 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 18:56:36,904 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 18:56:36,904 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the teachings that Jesus gave his disciples ?\n",
      "2021-10-09 18:56:36,904 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 18:56:36,904 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 18:56:36,904 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 18:56:36,904 - INFO - joeynmt.training - \tHypothesis: That will cause us to know the difference between righteousness and righteousness and also know the wise and discreet . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 18:56:36,904 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 18:56:36,904 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 18:56:36,905 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 18:56:36,905 - INFO - joeynmt.training - \tHypothesis: After February February 1945 , I faced children in Perico .\n",
      "2021-10-09 18:56:36,905 - INFO - joeynmt.training - Validation result (greedy) at epoch   5, step     5000: bleu:  25.37, loss: 30167.1836, ppl:   2.9078, duration: 78.7842s\n",
      "2021-10-09 18:57:01,642 - INFO - joeynmt.training - Epoch   5, Step:     5100, Batch Loss:     1.067294, Tokens per Sec:    18319, Lr: 0.000438\n",
      "2021-10-09 18:57:27,478 - INFO - joeynmt.training - Epoch   5, Step:     5200, Batch Loss:     1.138207, Tokens per Sec:    17338, Lr: 0.000433\n",
      "2021-10-09 18:57:53,182 - INFO - joeynmt.training - Epoch   5, Step:     5300, Batch Loss:     1.087117, Tokens per Sec:    17862, Lr: 0.000429\n",
      "2021-10-09 18:58:19,940 - INFO - joeynmt.training - Epoch   5, Step:     5400, Batch Loss:     1.132374, Tokens per Sec:    17088, Lr: 0.000425\n",
      "2021-10-09 18:58:46,183 - INFO - joeynmt.training - Epoch   5, Step:     5500, Batch Loss:     1.112204, Tokens per Sec:    17218, Lr: 0.000421\n",
      "2021-10-09 19:00:03,039 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 19:00:03,040 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 19:00:03,040 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 19:00:03,457 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 19:00:03,458 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 19:00:05,272 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 19:00:05,272 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 19:00:05,272 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 19:00:05,272 - INFO - joeynmt.training - \tHypothesis: Yes , the conscience “ a man ” may be a repeatedly .\n",
      "2021-10-09 19:00:05,272 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 19:00:05,273 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 19:00:05,273 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 19:00:05,273 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the teachings that Jesus gave his disciples ?\n",
      "2021-10-09 19:00:05,273 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 19:00:05,273 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 19:00:05,273 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 19:00:05,273 - INFO - joeynmt.training - \tHypothesis: That will lead us to know the differences between righteousness and righteousness and not knowing the same difference between the wise and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 19:00:05,273 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 19:00:05,274 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 19:00:05,274 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 19:00:05,274 - INFO - joeynmt.training - \tHypothesis: After February February 1945 , I met a children in Perico .\n",
      "2021-10-09 19:00:05,274 - INFO - joeynmt.training - Validation result (greedy) at epoch   5, step     5500: bleu:  25.68, loss: 29528.3164, ppl:   2.8428, duration: 79.0895s\n",
      "2021-10-09 19:00:31,313 - INFO - joeynmt.training - Epoch   5, Step:     5600, Batch Loss:     1.312895, Tokens per Sec:    16960, Lr: 0.000418\n",
      "2021-10-09 19:00:58,180 - INFO - joeynmt.training - Epoch   5, Step:     5700, Batch Loss:     1.101795, Tokens per Sec:    17091, Lr: 0.000414\n",
      "2021-10-09 19:01:24,090 - INFO - joeynmt.training - Epoch   5, Step:     5800, Batch Loss:     0.963485, Tokens per Sec:    17763, Lr: 0.000410\n",
      "2021-10-09 19:01:50,867 - INFO - joeynmt.training - Epoch   5, Step:     5900, Batch Loss:     0.960778, Tokens per Sec:    16825, Lr: 0.000407\n",
      "2021-10-09 19:02:16,909 - INFO - joeynmt.training - Epoch   5, Step:     6000, Batch Loss:     1.189771, Tokens per Sec:    17418, Lr: 0.000403\n",
      "2021-10-09 19:03:25,823 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 19:03:25,823 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 19:03:25,823 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 19:03:26,240 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 19:03:26,240 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 19:03:27,994 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 19:03:27,994 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 19:03:27,994 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 19:03:27,994 - INFO - joeynmt.training - \tHypothesis: Indeed , the conscience of “ a man who is a person ” may be rejected .\n",
      "2021-10-09 19:03:27,994 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 19:03:27,994 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 19:03:27,995 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 19:03:27,995 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the teacher that Jesus gave his disciples ?\n",
      "2021-10-09 19:03:27,995 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 19:03:27,995 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 19:03:27,995 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 19:03:27,995 - INFO - joeynmt.training - \tHypothesis: That will make us know the difference between righteousness and wrong and wrong and imperfect knowledge between the wisdom and wise and wise and wise . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 19:03:27,995 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 19:03:27,995 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 19:03:27,996 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 19:03:27,996 - INFO - joeynmt.training - \tHypothesis: After February February 1945 , I met children in Public Rico .\n",
      "2021-10-09 19:03:27,996 - INFO - joeynmt.training - Validation result (greedy) at epoch   5, step     6000: bleu:  26.88, loss: 28828.9141, ppl:   2.7734, duration: 71.0858s\n",
      "2021-10-09 19:03:53,129 - INFO - joeynmt.training - Epoch   5, Step:     6100, Batch Loss:     1.162272, Tokens per Sec:    17356, Lr: 0.000400\n",
      "2021-10-09 19:04:02,057 - INFO - joeynmt.training - Epoch   5: total training loss 1385.61\n",
      "2021-10-09 19:04:02,058 - INFO - joeynmt.training - EPOCH 6\n",
      "2021-10-09 19:04:18,998 - INFO - joeynmt.training - Epoch   6, Step:     6200, Batch Loss:     1.148167, Tokens per Sec:    17330, Lr: 0.000397\n",
      "2021-10-09 19:04:45,107 - INFO - joeynmt.training - Epoch   6, Step:     6300, Batch Loss:     1.060240, Tokens per Sec:    17783, Lr: 0.000394\n",
      "2021-10-09 19:05:11,857 - INFO - joeynmt.training - Epoch   6, Step:     6400, Batch Loss:     1.085674, Tokens per Sec:    17246, Lr: 0.000391\n",
      "2021-10-09 19:05:38,229 - INFO - joeynmt.training - Epoch   6, Step:     6500, Batch Loss:     1.191644, Tokens per Sec:    17804, Lr: 0.000388\n",
      "2021-10-09 19:06:54,167 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 19:06:54,168 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 19:06:54,168 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 19:06:54,585 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 19:06:54,585 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 19:06:56,373 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 19:06:56,374 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 19:06:56,374 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 19:06:56,374 - INFO - joeynmt.training - \tHypothesis: Indeed , the conscience of “ a man who is not a person ” may be rejected .\n",
      "2021-10-09 19:06:56,374 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 19:06:56,374 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 19:06:56,374 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 19:06:56,374 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the teachings that Jesus gave his disciples ?\n",
      "2021-10-09 19:06:56,374 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 19:06:56,375 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 19:06:56,375 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 19:06:56,375 - INFO - joeynmt.training - \tHypothesis: That will cause us to know the difference between righteousness and wrong and not to know the same difference between the wise and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 19:06:56,375 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 19:06:56,375 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 19:06:56,375 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 19:06:56,375 - INFO - joeynmt.training - \tHypothesis: After February in February 1945 , I met the children in Publius .\n",
      "2021-10-09 19:06:56,376 - INFO - joeynmt.training - Validation result (greedy) at epoch   6, step     6500: bleu:  27.51, loss: 28289.8457, ppl:   2.7210, duration: 78.1459s\n",
      "2021-10-09 19:07:22,248 - INFO - joeynmt.training - Epoch   6, Step:     6600, Batch Loss:     1.029907, Tokens per Sec:    17407, Lr: 0.000385\n",
      "2021-10-09 19:07:48,142 - INFO - joeynmt.training - Epoch   6, Step:     6700, Batch Loss:     1.075859, Tokens per Sec:    17332, Lr: 0.000382\n",
      "2021-10-09 19:08:14,828 - INFO - joeynmt.training - Epoch   6, Step:     6800, Batch Loss:     1.085346, Tokens per Sec:    16622, Lr: 0.000379\n",
      "2021-10-09 19:08:41,430 - INFO - joeynmt.training - Epoch   6, Step:     6900, Batch Loss:     1.102227, Tokens per Sec:    16771, Lr: 0.000376\n",
      "2021-10-09 19:09:07,431 - INFO - joeynmt.training - Epoch   6, Step:     7000, Batch Loss:     1.059070, Tokens per Sec:    17495, Lr: 0.000374\n",
      "2021-10-09 19:10:24,534 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 19:10:24,535 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 19:10:24,535 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 19:10:24,954 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 19:10:24,955 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 19:10:26,753 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 19:10:26,753 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 19:10:26,753 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 19:10:26,753 - INFO - joeynmt.training - \tHypothesis: Indeed , the conscience “ is a man of one ” may be rejected .\n",
      "2021-10-09 19:10:26,753 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 19:10:26,753 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 19:10:26,754 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 19:10:26,754 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the student Jesus gave his disciples ?\n",
      "2021-10-09 19:10:26,754 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 19:10:26,754 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 19:10:26,754 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 19:10:26,754 - INFO - joeynmt.training - \tHypothesis: That will make us know the differences between righteous and righteous and to know the same difference between the wisdom and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 19:10:26,754 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 19:10:26,754 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 19:10:26,755 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 19:10:26,755 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met the children in Puernica .\n",
      "2021-10-09 19:10:26,755 - INFO - joeynmt.training - Validation result (greedy) at epoch   6, step     7000: bleu:  28.30, loss: 27854.0371, ppl:   2.6793, duration: 79.3190s\n",
      "2021-10-09 19:10:52,815 - INFO - joeynmt.training - Epoch   6, Step:     7100, Batch Loss:     1.023699, Tokens per Sec:    17333, Lr: 0.000371\n",
      "2021-10-09 19:11:18,896 - INFO - joeynmt.training - Epoch   6, Step:     7200, Batch Loss:     1.208425, Tokens per Sec:    17377, Lr: 0.000368\n",
      "2021-10-09 19:11:45,536 - INFO - joeynmt.training - Epoch   6, Step:     7300, Batch Loss:     1.005467, Tokens per Sec:    16735, Lr: 0.000366\n",
      "2021-10-09 19:12:00,430 - INFO - joeynmt.training - Epoch   6: total training loss 1318.36\n",
      "2021-10-09 19:12:00,430 - INFO - joeynmt.training - EPOCH 7\n",
      "2021-10-09 19:12:11,902 - INFO - joeynmt.training - Epoch   7, Step:     7400, Batch Loss:     0.988546, Tokens per Sec:    17346, Lr: 0.000363\n",
      "2021-10-09 19:12:38,046 - INFO - joeynmt.training - Epoch   7, Step:     7500, Batch Loss:     1.054475, Tokens per Sec:    17543, Lr: 0.000361\n",
      "2021-10-09 19:13:52,497 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 19:13:52,497 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 19:13:52,497 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 19:13:52,919 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 19:13:52,919 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 19:13:56,254 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 19:13:56,254 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 19:13:56,255 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 19:13:56,255 - INFO - joeynmt.training - \tHypothesis: Indeed , the conscience of “ a man of man ” may be rejected .\n",
      "2021-10-09 19:13:56,255 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 19:13:56,255 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 19:13:56,255 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 19:13:56,255 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the teachings that Jesus gave his disciples ?\n",
      "2021-10-09 19:13:56,255 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 19:13:56,255 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 19:13:56,256 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 19:13:56,256 - INFO - joeynmt.training - \tHypothesis: That will make us aware of the difference between righteousness and wrong and unrighteous and also know the difference between the wisdom and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 19:13:56,256 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 19:13:56,256 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 19:13:56,256 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 19:13:56,256 - INFO - joeynmt.training - \tHypothesis: After February February 1945 , I met children in Puernica .\n",
      "2021-10-09 19:13:56,256 - INFO - joeynmt.training - Validation result (greedy) at epoch   7, step     7500: bleu:  28.46, loss: 27349.5723, ppl:   2.6319, duration: 78.2091s\n",
      "2021-10-09 19:14:22,453 - INFO - joeynmt.training - Epoch   7, Step:     7600, Batch Loss:     1.029961, Tokens per Sec:    17415, Lr: 0.000358\n",
      "2021-10-09 19:14:48,518 - INFO - joeynmt.training - Epoch   7, Step:     7700, Batch Loss:     1.009040, Tokens per Sec:    17374, Lr: 0.000356\n",
      "2021-10-09 19:15:14,854 - INFO - joeynmt.training - Epoch   7, Step:     7800, Batch Loss:     1.068348, Tokens per Sec:    17608, Lr: 0.000354\n",
      "2021-10-09 19:15:41,169 - INFO - joeynmt.training - Epoch   7, Step:     7900, Batch Loss:     1.106251, Tokens per Sec:    16837, Lr: 0.000352\n",
      "2021-10-09 19:16:07,370 - INFO - joeynmt.training - Epoch   7, Step:     8000, Batch Loss:     1.020647, Tokens per Sec:    17199, Lr: 0.000349\n",
      "2021-10-09 19:17:22,804 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 19:17:22,810 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 19:17:22,811 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 19:17:23,234 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 19:17:23,234 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 19:17:27,488 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 19:17:27,489 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 19:17:27,489 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 19:17:27,489 - INFO - joeynmt.training - \tHypothesis: Indeed , the conscience of “ a man of man ” may be rejected .\n",
      "2021-10-09 19:17:27,489 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 19:17:27,489 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 19:17:27,489 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 19:17:27,489 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the teachings that Jesus gave his disciples ?\n",
      "2021-10-09 19:17:27,490 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 19:17:27,490 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 19:17:27,490 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 19:17:27,490 - INFO - joeynmt.training - \tHypothesis: That will make us to know the difference between righteousness and wrong and to know the difference between the wise and wisdom and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 19:17:27,490 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 19:17:27,490 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 19:17:27,490 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 19:17:27,490 - INFO - joeynmt.training - \tHypothesis: After February February 1945 , I met children in Puernia Rico .\n",
      "2021-10-09 19:17:27,491 - INFO - joeynmt.training - Validation result (greedy) at epoch   7, step     8000: bleu:  28.76, loss: 27033.0820, ppl:   2.6026, duration: 80.1199s\n",
      "2021-10-09 19:17:54,063 - INFO - joeynmt.training - Epoch   7, Step:     8100, Batch Loss:     1.037385, Tokens per Sec:    17109, Lr: 0.000347\n",
      "2021-10-09 19:18:20,195 - INFO - joeynmt.training - Epoch   7, Step:     8200, Batch Loss:     1.027095, Tokens per Sec:    17533, Lr: 0.000345\n",
      "2021-10-09 19:18:46,064 - INFO - joeynmt.training - Epoch   7, Step:     8300, Batch Loss:     1.073596, Tokens per Sec:    17099, Lr: 0.000343\n",
      "2021-10-09 19:19:12,074 - INFO - joeynmt.training - Epoch   7, Step:     8400, Batch Loss:     0.970448, Tokens per Sec:    17040, Lr: 0.000341\n",
      "2021-10-09 19:19:38,756 - INFO - joeynmt.training - Epoch   7, Step:     8500, Batch Loss:     0.951397, Tokens per Sec:    17027, Lr: 0.000339\n",
      "2021-10-09 19:20:49,730 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 19:20:49,731 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 19:20:49,731 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 19:20:50,145 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 19:20:50,145 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 19:20:51,930 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 19:20:51,930 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 19:20:51,930 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 19:20:51,930 - INFO - joeynmt.training - \tHypothesis: Of course , the conscience “ is like a person ” may be rejected .\n",
      "2021-10-09 19:20:51,931 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 19:20:51,931 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 19:20:51,931 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 19:20:51,931 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the teachings Jesus gave his disciples ?\n",
      "2021-10-09 19:20:51,931 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 19:20:51,931 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 19:20:51,931 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 19:20:51,931 - INFO - joeynmt.training - \tHypothesis: That will make us know the difference between the righteous and unrighteous and also know the differences between the wisdom and wisdom and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 19:20:51,932 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 19:20:51,932 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 19:20:51,932 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 19:20:51,932 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met children in Puerto Rico .\n",
      "2021-10-09 19:20:51,932 - INFO - joeynmt.training - Validation result (greedy) at epoch   7, step     8500: bleu:  29.15, loss: 26791.6562, ppl:   2.5805, duration: 73.1752s\n",
      "2021-10-09 19:21:13,696 - INFO - joeynmt.training - Epoch   7: total training loss 1275.60\n",
      "2021-10-09 19:21:13,697 - INFO - joeynmt.training - EPOCH 8\n",
      "2021-10-09 19:21:18,973 - INFO - joeynmt.training - Epoch   8, Step:     8600, Batch Loss:     1.047231, Tokens per Sec:    16115, Lr: 0.000337\n",
      "2021-10-09 19:21:45,047 - INFO - joeynmt.training - Epoch   8, Step:     8700, Batch Loss:     1.036293, Tokens per Sec:    17564, Lr: 0.000335\n",
      "2021-10-09 19:22:11,614 - INFO - joeynmt.training - Epoch   8, Step:     8800, Batch Loss:     1.059170, Tokens per Sec:    17021, Lr: 0.000333\n",
      "2021-10-09 19:22:37,766 - INFO - joeynmt.training - Epoch   8, Step:     8900, Batch Loss:     0.902406, Tokens per Sec:    17071, Lr: 0.000331\n",
      "2021-10-09 19:23:03,939 - INFO - joeynmt.training - Epoch   8, Step:     9000, Batch Loss:     0.899438, Tokens per Sec:    17353, Lr: 0.000329\n",
      "2021-10-09 19:24:19,796 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 19:24:19,797 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 19:24:19,797 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 19:24:20,216 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 19:24:20,216 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 19:24:22,003 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 19:24:22,003 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 19:24:22,003 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 19:24:22,003 - INFO - joeynmt.training - \tHypothesis: Yes , the conscience “ is a man of man ” may be rejected .\n",
      "2021-10-09 19:24:22,003 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 19:24:22,003 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 19:24:22,004 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 19:24:22,004 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 19:24:22,004 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 19:24:22,004 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 19:24:22,004 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 19:24:22,004 - INFO - joeynmt.training - \tHypothesis: That will make us know the differences between righteousness and unrighteous and unrighteous and also know the difference between the wisdom and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 19:24:22,004 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 19:24:22,005 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 19:24:22,005 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 19:24:22,005 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met children in Puerto Rico .\n",
      "2021-10-09 19:24:22,005 - INFO - joeynmt.training - Validation result (greedy) at epoch   8, step     9000: bleu:  29.52, loss: 26420.7246, ppl:   2.5468, duration: 78.0649s\n",
      "2021-10-09 19:24:48,742 - INFO - joeynmt.training - Epoch   8, Step:     9100, Batch Loss:     1.048010, Tokens per Sec:    17316, Lr: 0.000328\n",
      "2021-10-09 19:25:15,170 - INFO - joeynmt.training - Epoch   8, Step:     9200, Batch Loss:     0.994206, Tokens per Sec:    16719, Lr: 0.000326\n",
      "2021-10-09 19:25:41,222 - INFO - joeynmt.training - Epoch   8, Step:     9300, Batch Loss:     1.105716, Tokens per Sec:    17209, Lr: 0.000324\n",
      "2021-10-09 19:26:07,419 - INFO - joeynmt.training - Epoch   8, Step:     9400, Batch Loss:     0.956809, Tokens per Sec:    17211, Lr: 0.000322\n",
      "2021-10-09 19:26:33,551 - INFO - joeynmt.training - Epoch   8, Step:     9500, Batch Loss:     1.065928, Tokens per Sec:    17470, Lr: 0.000321\n",
      "2021-10-09 19:27:47,622 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 19:27:47,623 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 19:27:47,623 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 19:27:48,042 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 19:27:48,042 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 19:27:49,827 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 19:27:49,828 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 19:27:49,828 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 19:27:49,828 - INFO - joeynmt.training - \tHypothesis: Of course , the conscience of “ a man who is in the flesh ” may be rejected .\n",
      "2021-10-09 19:27:49,828 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 19:27:49,828 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 19:27:49,828 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 19:27:49,828 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the teachings that Jesus gave his disciples ?\n",
      "2021-10-09 19:27:49,828 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 19:27:49,829 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 19:27:49,829 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 19:27:49,829 - INFO - joeynmt.training - \tHypothesis: That will make us know the difference between righteousness and wrong and unrighteous and also know the difference between the wisdom and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 19:27:49,829 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 19:27:49,829 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 19:27:49,829 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 19:27:49,829 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met children in Puerto Rico .\n",
      "2021-10-09 19:27:49,829 - INFO - joeynmt.training - Validation result (greedy) at epoch   8, step     9500: bleu:  29.78, loss: 26167.1250, ppl:   2.5241, duration: 76.2779s\n",
      "2021-10-09 19:28:16,232 - INFO - joeynmt.training - Epoch   8, Step:     9600, Batch Loss:     1.036056, Tokens per Sec:    16940, Lr: 0.000319\n",
      "2021-10-09 19:28:42,234 - INFO - joeynmt.training - Epoch   8, Step:     9700, Batch Loss:     1.040934, Tokens per Sec:    17330, Lr: 0.000317\n",
      "2021-10-09 19:29:07,738 - INFO - joeynmt.training - Epoch   8, Step:     9800, Batch Loss:     0.948115, Tokens per Sec:    17564, Lr: 0.000316\n",
      "2021-10-09 19:29:09,990 - INFO - joeynmt.training - Epoch   8: total training loss 1240.76\n",
      "2021-10-09 19:29:09,991 - INFO - joeynmt.training - EPOCH 9\n",
      "2021-10-09 19:29:33,908 - INFO - joeynmt.training - Epoch   9, Step:     9900, Batch Loss:     1.014552, Tokens per Sec:    17094, Lr: 0.000314\n",
      "2021-10-09 19:29:59,830 - INFO - joeynmt.training - Epoch   9, Step:    10000, Batch Loss:     0.839214, Tokens per Sec:    16933, Lr: 0.000313\n",
      "2021-10-09 19:31:14,427 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 19:31:14,427 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 19:31:14,427 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 19:31:14,847 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 19:31:14,847 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 19:31:16,636 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 19:31:16,636 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 19:31:16,636 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 19:31:16,636 - INFO - joeynmt.training - \tHypothesis: Indeed , the conscience of “ a man who is distressed ” may be rejected .\n",
      "2021-10-09 19:31:16,636 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 19:31:16,636 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 19:31:16,637 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 19:31:16,637 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 19:31:16,637 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 19:31:16,637 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 19:31:16,637 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 19:31:16,637 - INFO - joeynmt.training - \tHypothesis: That will make us to know the difference between righteousness and wrong and not to know the difference between the wise and wisdom and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 19:31:16,637 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 19:31:16,637 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 19:31:16,638 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 19:31:16,638 - INFO - joeynmt.training - \tHypothesis: After February in February 1945 , I met children in Puerto Rico .\n",
      "2021-10-09 19:31:16,638 - INFO - joeynmt.training - Validation result (greedy) at epoch   9, step    10000: bleu:  29.98, loss: 25944.0527, ppl:   2.5042, duration: 76.8075s\n",
      "2021-10-09 19:31:42,223 - INFO - joeynmt.training - Epoch   9, Step:    10100, Batch Loss:     1.002673, Tokens per Sec:    17771, Lr: 0.000311\n",
      "2021-10-09 19:32:07,257 - INFO - joeynmt.training - Epoch   9, Step:    10200, Batch Loss:     0.975906, Tokens per Sec:    18092, Lr: 0.000309\n",
      "2021-10-09 19:32:33,178 - INFO - joeynmt.training - Epoch   9, Step:    10300, Batch Loss:     0.922991, Tokens per Sec:    17356, Lr: 0.000308\n",
      "2021-10-09 19:32:59,273 - INFO - joeynmt.training - Epoch   9, Step:    10400, Batch Loss:     0.972438, Tokens per Sec:    17359, Lr: 0.000306\n",
      "2021-10-09 19:33:24,387 - INFO - joeynmt.training - Epoch   9, Step:    10500, Batch Loss:     0.976772, Tokens per Sec:    18075, Lr: 0.000305\n",
      "2021-10-09 19:34:39,518 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 19:34:39,519 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 19:34:39,519 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 19:34:39,939 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 19:34:39,939 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 19:34:42,355 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 19:34:42,356 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 19:34:42,356 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 19:34:42,356 - INFO - joeynmt.training - \tHypothesis: Indeed , the conscience of “ man who is in the heart ” may be rejected .\n",
      "2021-10-09 19:34:42,356 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 19:34:42,356 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 19:34:42,356 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 19:34:42,356 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 19:34:42,356 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 19:34:42,357 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 19:34:42,357 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 19:34:42,357 - INFO - joeynmt.training - \tHypothesis: That will make us know the difference between righteousness and wrong and to know the difference between the wisdom and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 19:34:42,357 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 19:34:42,357 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 19:34:42,357 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 19:34:42,357 - INFO - joeynmt.training - \tHypothesis: After February February 1945 , I met children in Puerto Rico .\n",
      "2021-10-09 19:34:42,358 - INFO - joeynmt.training - Validation result (greedy) at epoch   9, step    10500: bleu:  30.34, loss: 25608.0137, ppl:   2.4746, duration: 77.9688s\n",
      "2021-10-09 19:35:08,870 - INFO - joeynmt.training - Epoch   9, Step:    10600, Batch Loss:     0.942929, Tokens per Sec:    16843, Lr: 0.000304\n",
      "2021-10-09 19:35:34,930 - INFO - joeynmt.training - Epoch   9, Step:    10700, Batch Loss:     1.296004, Tokens per Sec:    17593, Lr: 0.000302\n",
      "2021-10-09 19:36:01,722 - INFO - joeynmt.training - Epoch   9, Step:    10800, Batch Loss:     0.804870, Tokens per Sec:    16675, Lr: 0.000301\n",
      "2021-10-09 19:36:28,000 - INFO - joeynmt.training - Epoch   9, Step:    10900, Batch Loss:     0.962851, Tokens per Sec:    17847, Lr: 0.000299\n",
      "2021-10-09 19:36:53,919 - INFO - joeynmt.training - Epoch   9, Step:    11000, Batch Loss:     0.943522, Tokens per Sec:    16993, Lr: 0.000298\n",
      "2021-10-09 19:38:09,737 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 19:38:09,738 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 19:38:09,738 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 19:38:10,160 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 19:38:10,160 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 19:38:11,914 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 19:38:11,914 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 19:38:11,914 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 19:38:11,914 - INFO - joeynmt.training - \tHypothesis: Indeed , the conscience of “ man who is mouth ” may not reject us .\n",
      "2021-10-09 19:38:11,914 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 19:38:11,915 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 19:38:11,915 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 19:38:11,915 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the teachings Jesus gave his disciples ?\n",
      "2021-10-09 19:38:11,915 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 19:38:11,915 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 19:38:11,915 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 19:38:11,915 - INFO - joeynmt.training - \tHypothesis: That will make us a difference between righteousness and wrong and not to know the difference between the wisdom and wisdom and wisdom of the wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 19:38:11,915 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 19:38:11,916 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 19:38:11,916 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 19:38:11,916 - INFO - joeynmt.training - \tHypothesis: After February in February 1945 , I met children in Puerto Rico .\n",
      "2021-10-09 19:38:11,916 - INFO - joeynmt.training - Validation result (greedy) at epoch   9, step    11000: bleu:  30.52, loss: 25435.7676, ppl:   2.4596, duration: 77.9955s\n",
      "2021-10-09 19:38:22,217 - INFO - joeynmt.training - Epoch   9: total training loss 1213.07\n",
      "2021-10-09 19:38:22,218 - INFO - joeynmt.training - EPOCH 10\n",
      "2021-10-09 19:38:38,469 - INFO - joeynmt.training - Epoch  10, Step:    11100, Batch Loss:     1.020234, Tokens per Sec:    16542, Lr: 0.000297\n",
      "2021-10-09 19:39:04,649 - INFO - joeynmt.training - Epoch  10, Step:    11200, Batch Loss:     0.862996, Tokens per Sec:    17491, Lr: 0.000295\n",
      "2021-10-09 19:39:31,300 - INFO - joeynmt.training - Epoch  10, Step:    11300, Batch Loss:     0.791290, Tokens per Sec:    16527, Lr: 0.000294\n",
      "2021-10-09 19:39:57,530 - INFO - joeynmt.training - Epoch  10, Step:    11400, Batch Loss:     0.961304, Tokens per Sec:    17151, Lr: 0.000293\n",
      "2021-10-09 19:40:23,580 - INFO - joeynmt.training - Epoch  10, Step:    11500, Batch Loss:     0.733054, Tokens per Sec:    16796, Lr: 0.000291\n",
      "2021-10-09 19:41:36,777 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 19:41:36,778 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 19:41:36,778 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 19:41:37,193 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 19:41:37,193 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 19:41:38,945 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 19:41:38,946 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 19:41:38,946 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 19:41:38,946 - INFO - joeynmt.training - \tHypothesis: Indeed , the conscience of “ a man who is sharp ” may be misled .\n",
      "2021-10-09 19:41:38,946 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 19:41:38,946 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 19:41:38,946 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 19:41:38,946 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the teachings Jesus gave his disciples ?\n",
      "2021-10-09 19:41:38,947 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 19:41:38,947 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 19:41:38,947 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 19:41:38,947 - INFO - joeynmt.training - \tHypothesis: That will make us a difference between righteousness and unrighteous and also know the difference between the foolish and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 19:41:38,947 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 19:41:38,947 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 19:41:38,947 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 19:41:38,947 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met children in Puerto Rico .\n",
      "2021-10-09 19:41:38,948 - INFO - joeynmt.training - Validation result (greedy) at epoch  10, step    11500: bleu:  30.47, loss: 25304.3984, ppl:   2.4482, duration: 75.3661s\n",
      "2021-10-09 19:42:05,922 - INFO - joeynmt.training - Epoch  10, Step:    11600, Batch Loss:     1.150223, Tokens per Sec:    17031, Lr: 0.000290\n",
      "2021-10-09 19:42:32,114 - INFO - joeynmt.training - Epoch  10, Step:    11700, Batch Loss:     0.972417, Tokens per Sec:    17310, Lr: 0.000289\n",
      "2021-10-09 19:42:57,557 - INFO - joeynmt.training - Epoch  10, Step:    11800, Batch Loss:     0.893350, Tokens per Sec:    17927, Lr: 0.000288\n",
      "2021-10-09 19:43:22,383 - INFO - joeynmt.training - Epoch  10, Step:    11900, Batch Loss:     0.900245, Tokens per Sec:    18000, Lr: 0.000286\n",
      "2021-10-09 19:43:47,465 - INFO - joeynmt.training - Epoch  10, Step:    12000, Batch Loss:     1.023400, Tokens per Sec:    18245, Lr: 0.000285\n",
      "2021-10-09 19:44:58,744 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 19:44:58,745 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 19:44:58,745 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 19:44:59,160 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 19:44:59,160 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 19:45:00,924 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 19:45:00,924 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 19:45:00,924 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 19:45:00,924 - INFO - joeynmt.training - \tHypothesis: Of course , the conscience of “ a man who is in the flesh ” may be misled .\n",
      "2021-10-09 19:45:00,924 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 19:45:00,925 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 19:45:00,925 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 19:45:00,925 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 19:45:00,925 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 19:45:00,925 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 19:45:00,925 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 19:45:00,925 - INFO - joeynmt.training - \tHypothesis: That will make us know the difference between righteousness and unrighteous and also know the difference between the wisdom and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 19:45:00,925 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 19:45:00,926 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 19:45:00,926 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 19:45:00,926 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met children in Puerto Rico .\n",
      "2021-10-09 19:45:00,926 - INFO - joeynmt.training - Validation result (greedy) at epoch  10, step    12000: bleu:  30.86, loss: 24962.7891, ppl:   2.4188, duration: 73.4596s\n",
      "2021-10-09 19:45:27,726 - INFO - joeynmt.training - Epoch  10, Step:    12100, Batch Loss:     1.035140, Tokens per Sec:    17139, Lr: 0.000284\n",
      "2021-10-09 19:45:53,666 - INFO - joeynmt.training - Epoch  10, Step:    12200, Batch Loss:     0.938628, Tokens per Sec:    17138, Lr: 0.000283\n",
      "2021-10-09 19:46:12,334 - INFO - joeynmt.training - Epoch  10: total training loss 1188.20\n",
      "2021-10-09 19:46:12,334 - INFO - joeynmt.training - EPOCH 11\n",
      "2021-10-09 19:46:20,719 - INFO - joeynmt.training - Epoch  11, Step:    12300, Batch Loss:     0.945950, Tokens per Sec:    17248, Lr: 0.000282\n",
      "2021-10-09 19:46:47,521 - INFO - joeynmt.training - Epoch  11, Step:    12400, Batch Loss:     0.905919, Tokens per Sec:    16853, Lr: 0.000281\n",
      "2021-10-09 19:47:13,395 - INFO - joeynmt.training - Epoch  11, Step:    12500, Batch Loss:     0.819226, Tokens per Sec:    17074, Lr: 0.000280\n",
      "2021-10-09 19:48:27,043 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 19:48:27,044 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 19:48:27,044 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 19:48:27,460 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 19:48:27,460 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 19:48:29,177 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 19:48:29,177 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 19:48:29,177 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 19:48:29,177 - INFO - joeynmt.training - \tHypothesis: Indeed , the conscience of “ a man of man ” may be misled .\n",
      "2021-10-09 19:48:29,178 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 19:48:29,178 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 19:48:29,178 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 19:48:29,178 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 19:48:29,178 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 19:48:29,178 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 19:48:29,178 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 19:48:29,179 - INFO - joeynmt.training - \tHypothesis: That will cause us to know the difference between righteousness and wrong and to know the difference between the wise and discreet and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 19:48:29,179 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 19:48:29,179 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 19:48:29,179 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 19:48:29,179 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met children in Puerto Rico .\n",
      "2021-10-09 19:48:29,179 - INFO - joeynmt.training - Validation result (greedy) at epoch  11, step    12500: bleu:  31.06, loss: 24869.5781, ppl:   2.4108, duration: 75.7832s\n",
      "2021-10-09 19:48:55,865 - INFO - joeynmt.training - Epoch  11, Step:    12600, Batch Loss:     0.939639, Tokens per Sec:    16824, Lr: 0.000278\n",
      "2021-10-09 19:49:21,851 - INFO - joeynmt.training - Epoch  11, Step:    12700, Batch Loss:     0.924510, Tokens per Sec:    17427, Lr: 0.000277\n",
      "2021-10-09 19:49:47,312 - INFO - joeynmt.training - Epoch  11, Step:    12800, Batch Loss:     0.969355, Tokens per Sec:    17514, Lr: 0.000276\n",
      "2021-10-09 19:50:11,159 - INFO - joeynmt.training - Epoch  11, Step:    12900, Batch Loss:     0.891318, Tokens per Sec:    18857, Lr: 0.000275\n",
      "2021-10-09 19:50:37,229 - INFO - joeynmt.training - Epoch  11, Step:    13000, Batch Loss:     0.945633, Tokens per Sec:    17019, Lr: 0.000274\n",
      "2021-10-09 19:51:51,690 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 19:51:51,691 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 19:51:51,691 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 19:51:52,109 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 19:51:52,109 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 19:51:53,861 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 19:51:53,861 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 19:51:53,861 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 19:51:53,861 - INFO - joeynmt.training - \tHypothesis: Yes , the conscience of “ man of the man ” may be misled .\n",
      "2021-10-09 19:51:53,861 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 19:51:53,862 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 19:51:53,862 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 19:51:53,862 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 19:51:53,862 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 19:51:53,862 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 19:51:53,862 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 19:51:53,862 - INFO - joeynmt.training - \tHypothesis: That will make us know the difference between right and wrong and to know the difference between the wisdom and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 19:51:53,862 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 19:51:53,863 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 19:51:53,863 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 19:51:53,863 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met children in Puerto Rico .\n",
      "2021-10-09 19:51:53,863 - INFO - joeynmt.training - Validation result (greedy) at epoch  11, step    13000: bleu:  31.20, loss: 24670.3711, ppl:   2.3939, duration: 76.6329s\n",
      "2021-10-09 19:52:20,638 - INFO - joeynmt.training - Epoch  11, Step:    13100, Batch Loss:     0.846967, Tokens per Sec:    17099, Lr: 0.000273\n",
      "2021-10-09 19:52:46,745 - INFO - joeynmt.training - Epoch  11, Step:    13200, Batch Loss:     0.980265, Tokens per Sec:    17452, Lr: 0.000272\n",
      "2021-10-09 19:53:12,849 - INFO - joeynmt.training - Epoch  11, Step:    13300, Batch Loss:     0.827062, Tokens per Sec:    17616, Lr: 0.000271\n",
      "2021-10-09 19:53:39,022 - INFO - joeynmt.training - Epoch  11, Step:    13400, Batch Loss:     0.997950, Tokens per Sec:    17364, Lr: 0.000270\n",
      "2021-10-09 19:54:05,169 - INFO - joeynmt.training - Epoch  11: total training loss 1165.50\n",
      "2021-10-09 19:54:05,169 - INFO - joeynmt.training - EPOCH 12\n",
      "2021-10-09 19:54:06,017 - INFO - joeynmt.training - Epoch  12, Step:    13500, Batch Loss:     0.927774, Tokens per Sec:    10237, Lr: 0.000269\n",
      "2021-10-09 19:55:15,708 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 19:55:15,708 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 19:55:15,708 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 19:55:16,128 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 19:55:16,128 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 19:55:18,016 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 19:55:18,016 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 19:55:18,016 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 19:55:18,016 - INFO - joeynmt.training - \tHypothesis: Of course , the conscience of “ a man of man ” may be misled .\n",
      "2021-10-09 19:55:18,016 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 19:55:18,017 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 19:55:18,017 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 19:55:18,017 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 19:55:18,017 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 19:55:18,017 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 19:55:18,017 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 19:55:18,017 - INFO - joeynmt.training - \tHypothesis: That will make us know the difference between right and wrong and wrong and also know the difference between the wisdom and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 19:55:18,017 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 19:55:18,018 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 19:55:18,018 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 19:55:18,018 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met children in Puerto Rico .\n",
      "2021-10-09 19:55:18,018 - INFO - joeynmt.training - Validation result (greedy) at epoch  12, step    13500: bleu:  31.43, loss: 24521.0605, ppl:   2.3813, duration: 72.0008s\n",
      "2021-10-09 19:55:43,976 - INFO - joeynmt.training - Epoch  12, Step:    13600, Batch Loss:     0.876270, Tokens per Sec:    16939, Lr: 0.000268\n",
      "2021-10-09 19:56:10,443 - INFO - joeynmt.training - Epoch  12, Step:    13700, Batch Loss:     0.931852, Tokens per Sec:    17313, Lr: 0.000267\n",
      "2021-10-09 19:56:35,253 - INFO - joeynmt.training - Epoch  12, Step:    13800, Batch Loss:     0.880285, Tokens per Sec:    18283, Lr: 0.000266\n",
      "2021-10-09 19:57:01,787 - INFO - joeynmt.training - Epoch  12, Step:    13900, Batch Loss:     0.968730, Tokens per Sec:    16724, Lr: 0.000265\n",
      "2021-10-09 19:57:27,929 - INFO - joeynmt.training - Epoch  12, Step:    14000, Batch Loss:     0.905113, Tokens per Sec:    17630, Lr: 0.000264\n",
      "2021-10-09 19:58:38,684 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 19:58:38,685 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 19:58:38,685 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 19:58:39,100 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 19:58:39,100 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 19:58:40,852 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 19:58:40,852 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 19:58:40,852 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 19:58:40,852 - INFO - joeynmt.training - \tHypothesis: Yes , the conscience of “ a man of man ” may be misled .\n",
      "2021-10-09 19:58:40,853 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 19:58:40,853 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 19:58:40,853 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 19:58:40,853 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 19:58:40,853 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 19:58:40,853 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 19:58:40,853 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 19:58:40,853 - INFO - joeynmt.training - \tHypothesis: That will lead us to know the difference between right and wrong and to know the difference between the wise and discreet and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 19:58:40,854 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 19:58:40,854 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 19:58:40,854 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 19:58:40,854 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met children in Puerto Rico .\n",
      "2021-10-09 19:58:40,854 - INFO - joeynmt.training - Validation result (greedy) at epoch  12, step    14000: bleu:  31.37, loss: 24415.4316, ppl:   2.3724, duration: 72.9242s\n",
      "2021-10-09 19:59:06,735 - INFO - joeynmt.training - Epoch  12, Step:    14100, Batch Loss:     0.907435, Tokens per Sec:    17349, Lr: 0.000263\n",
      "2021-10-09 19:59:32,681 - INFO - joeynmt.training - Epoch  12, Step:    14200, Batch Loss:     0.890005, Tokens per Sec:    17370, Lr: 0.000262\n",
      "2021-10-09 19:59:59,314 - INFO - joeynmt.training - Epoch  12, Step:    14300, Batch Loss:     0.908073, Tokens per Sec:    16910, Lr: 0.000261\n",
      "2021-10-09 20:00:25,216 - INFO - joeynmt.training - Epoch  12, Step:    14400, Batch Loss:     0.971904, Tokens per Sec:    17632, Lr: 0.000260\n",
      "2021-10-09 20:00:51,355 - INFO - joeynmt.training - Epoch  12, Step:    14500, Batch Loss:     0.666781, Tokens per Sec:    17411, Lr: 0.000260\n",
      "2021-10-09 20:02:03,491 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 20:02:03,491 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 20:02:03,491 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 20:02:03,909 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 20:02:03,909 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 20:02:05,665 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 20:02:05,666 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 20:02:05,666 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 20:02:05,666 - INFO - joeynmt.training - \tHypothesis: Indeed , the conscience of “ man who is in the flesh ” may be misled .\n",
      "2021-10-09 20:02:05,666 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 20:02:05,666 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 20:02:05,666 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 20:02:05,666 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 20:02:05,666 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 20:02:05,667 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 20:02:05,667 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 20:02:05,667 - INFO - joeynmt.training - \tHypothesis: That will make us know the difference between right and wrong and wrong and also know the difference between the wisdom and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 20:02:05,667 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 20:02:05,667 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 20:02:05,667 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 20:02:05,667 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met children in Puerto Rico .\n",
      "2021-10-09 20:02:05,667 - INFO - joeynmt.training - Validation result (greedy) at epoch  12, step    14500: bleu:  31.52, loss: 24216.1270, ppl:   2.3557, duration: 74.3116s\n",
      "2021-10-09 20:02:31,860 - INFO - joeynmt.training - Epoch  12, Step:    14600, Batch Loss:     0.871741, Tokens per Sec:    17470, Lr: 0.000259\n",
      "2021-10-09 20:02:58,735 - INFO - joeynmt.training - Epoch  12, Step:    14700, Batch Loss:     0.890860, Tokens per Sec:    16977, Lr: 0.000258\n",
      "2021-10-09 20:03:04,803 - INFO - joeynmt.training - Epoch  12: total training loss 1143.47\n",
      "2021-10-09 20:03:04,804 - INFO - joeynmt.training - EPOCH 13\n",
      "2021-10-09 20:03:25,058 - INFO - joeynmt.training - Epoch  13, Step:    14800, Batch Loss:     0.814538, Tokens per Sec:    16612, Lr: 0.000257\n",
      "2021-10-09 20:03:51,232 - INFO - joeynmt.training - Epoch  13, Step:    14900, Batch Loss:     0.846904, Tokens per Sec:    17321, Lr: 0.000256\n",
      "2021-10-09 20:04:17,599 - INFO - joeynmt.training - Epoch  13, Step:    15000, Batch Loss:     0.894790, Tokens per Sec:    17394, Lr: 0.000255\n",
      "2021-10-09 20:05:29,346 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 20:05:29,346 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 20:05:29,347 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 20:05:29,766 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 20:05:29,766 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 20:05:31,463 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 20:05:31,463 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 20:05:31,463 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 20:05:31,463 - INFO - joeynmt.training - \tHypothesis: Indeed , the conscience of “ man that is in the flesh ” may be misled .\n",
      "2021-10-09 20:05:31,463 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 20:05:31,464 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 20:05:31,464 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 20:05:31,464 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 20:05:31,464 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 20:05:31,464 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 20:05:31,464 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 20:05:31,464 - INFO - joeynmt.training - \tHypothesis: That will make us know the difference between right and wrong and wrong and also know the difference between the wisdom and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 20:05:31,465 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 20:05:31,465 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 20:05:31,465 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 20:05:31,465 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met children in Puerto Rico .\n",
      "2021-10-09 20:05:31,465 - INFO - joeynmt.training - Validation result (greedy) at epoch  13, step    15000: bleu:  32.01, loss: 24195.3027, ppl:   2.3540, duration: 73.8650s\n",
      "2021-10-09 20:05:58,107 - INFO - joeynmt.training - Epoch  13, Step:    15100, Batch Loss:     0.903703, Tokens per Sec:    16633, Lr: 0.000254\n",
      "2021-10-09 20:06:24,247 - INFO - joeynmt.training - Epoch  13, Step:    15200, Batch Loss:     0.926642, Tokens per Sec:    17176, Lr: 0.000253\n",
      "2021-10-09 20:06:51,012 - INFO - joeynmt.training - Epoch  13, Step:    15300, Batch Loss:     0.977699, Tokens per Sec:    16808, Lr: 0.000253\n",
      "2021-10-09 20:07:16,350 - INFO - joeynmt.training - Epoch  13, Step:    15400, Batch Loss:     0.995655, Tokens per Sec:    18164, Lr: 0.000252\n",
      "2021-10-09 20:07:42,306 - INFO - joeynmt.training - Epoch  13, Step:    15500, Batch Loss:     0.882478, Tokens per Sec:    17721, Lr: 0.000251\n",
      "2021-10-09 20:08:51,355 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 20:08:51,356 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 20:08:51,356 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 20:08:51,768 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 20:08:51,769 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 20:08:53,518 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 20:08:53,519 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 20:08:53,519 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 20:08:53,519 - INFO - joeynmt.training - \tHypothesis: Of course , the conscience of “ a man of man ” may be misled .\n",
      "2021-10-09 20:08:53,519 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 20:08:53,519 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 20:08:53,519 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 20:08:53,519 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 20:08:53,520 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 20:08:53,520 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 20:08:53,520 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 20:08:53,520 - INFO - joeynmt.training - \tHypothesis: That will lead us to know the difference between right and wrong and unrighteous and also know the difference between the foolish and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 20:08:53,520 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 20:08:53,520 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 20:08:53,520 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 20:08:53,521 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met the brothers in Puerto Rico .\n",
      "2021-10-09 20:08:53,521 - INFO - joeynmt.training - Validation result (greedy) at epoch  13, step    15500: bleu:  31.98, loss: 24056.7207, ppl:   2.3425, duration: 71.2134s\n",
      "2021-10-09 20:09:19,744 - INFO - joeynmt.training - Epoch  13, Step:    15600, Batch Loss:     0.973734, Tokens per Sec:    17535, Lr: 0.000250\n",
      "2021-10-09 20:09:46,783 - INFO - joeynmt.training - Epoch  13, Step:    15700, Batch Loss:     0.898715, Tokens per Sec:    16925, Lr: 0.000249\n",
      "2021-10-09 20:10:12,811 - INFO - joeynmt.training - Epoch  13, Step:    15800, Batch Loss:     0.927233, Tokens per Sec:    17427, Lr: 0.000249\n",
      "2021-10-09 20:10:39,273 - INFO - joeynmt.training - Epoch  13, Step:    15900, Batch Loss:     1.066235, Tokens per Sec:    16478, Lr: 0.000248\n",
      "2021-10-09 20:10:52,693 - INFO - joeynmt.training - Epoch  13: total training loss 1131.32\n",
      "2021-10-09 20:10:52,693 - INFO - joeynmt.training - EPOCH 14\n",
      "2021-10-09 20:11:05,407 - INFO - joeynmt.training - Epoch  14, Step:    16000, Batch Loss:     0.877180, Tokens per Sec:    17023, Lr: 0.000247\n",
      "2021-10-09 20:12:19,028 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 20:12:19,029 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 20:12:19,029 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 20:12:19,448 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 20:12:19,448 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 20:12:21,200 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 20:12:21,200 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 20:12:21,200 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 20:12:21,201 - INFO - joeynmt.training - \tHypothesis: Yes , the conscience of “ a man who is mere ” may be misled .\n",
      "2021-10-09 20:12:21,201 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 20:12:21,201 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 20:12:21,201 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 20:12:21,201 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 20:12:21,201 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 20:12:21,201 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 20:12:21,201 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 20:12:21,202 - INFO - joeynmt.training - \tHypothesis: That will make us know the difference between what is right and wrong and to know the difference between the wisdom and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 20:12:21,202 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 20:12:21,202 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 20:12:21,202 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 20:12:21,202 - INFO - joeynmt.training - \tHypothesis: After February graduation in 1945 , I met children in Puerto Rico .\n",
      "2021-10-09 20:12:21,202 - INFO - joeynmt.training - Validation result (greedy) at epoch  14, step    16000: bleu:  32.04, loss: 23911.1055, ppl:   2.3304, duration: 75.7944s\n",
      "2021-10-09 20:12:47,223 - INFO - joeynmt.training - Epoch  14, Step:    16100, Batch Loss:     0.890605, Tokens per Sec:    17323, Lr: 0.000246\n",
      "2021-10-09 20:13:13,888 - INFO - joeynmt.training - Epoch  14, Step:    16200, Batch Loss:     0.906173, Tokens per Sec:    16629, Lr: 0.000246\n",
      "2021-10-09 20:13:40,080 - INFO - joeynmt.training - Epoch  14, Step:    16300, Batch Loss:     0.907295, Tokens per Sec:    17411, Lr: 0.000245\n",
      "2021-10-09 20:14:06,036 - INFO - joeynmt.training - Epoch  14, Step:    16400, Batch Loss:     0.884552, Tokens per Sec:    17437, Lr: 0.000244\n",
      "2021-10-09 20:14:31,860 - INFO - joeynmt.training - Epoch  14, Step:    16500, Batch Loss:     0.925929, Tokens per Sec:    17346, Lr: 0.000243\n",
      "2021-10-09 20:15:44,680 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 20:15:44,681 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 20:15:44,681 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 20:15:45,094 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 20:15:45,094 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 20:15:46,989 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 20:15:46,989 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 20:15:46,989 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 20:15:46,989 - INFO - joeynmt.training - \tHypothesis: Yes , the conscience of “ a man of mind ” may be misled .\n",
      "2021-10-09 20:15:46,989 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 20:15:46,989 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 20:15:46,990 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 20:15:46,990 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 20:15:46,990 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 20:15:46,990 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 20:15:46,990 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 20:15:46,990 - INFO - joeynmt.training - \tHypothesis: That will make us know the difference between right and wrong and wrong and also know the difference between the wisdom and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 20:15:46,990 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 20:15:46,991 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 20:15:46,991 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 20:15:46,991 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met children in Puerto Rico .\n",
      "2021-10-09 20:15:46,991 - INFO - joeynmt.training - Validation result (greedy) at epoch  14, step    16500: bleu:  32.27, loss: 23850.9473, ppl:   2.3255, duration: 75.1306s\n",
      "2021-10-09 20:16:12,668 - INFO - joeynmt.training - Epoch  14, Step:    16600, Batch Loss:     0.923736, Tokens per Sec:    17587, Lr: 0.000243\n",
      "2021-10-09 20:16:37,571 - INFO - joeynmt.training - Epoch  14, Step:    16700, Batch Loss:     0.937324, Tokens per Sec:    17775, Lr: 0.000242\n",
      "2021-10-09 20:17:03,507 - INFO - joeynmt.training - Epoch  14, Step:    16800, Batch Loss:     0.956756, Tokens per Sec:    17248, Lr: 0.000241\n",
      "2021-10-09 20:17:29,208 - INFO - joeynmt.training - Epoch  14, Step:    16900, Batch Loss:     0.735177, Tokens per Sec:    17770, Lr: 0.000240\n",
      "2021-10-09 20:17:55,485 - INFO - joeynmt.training - Epoch  14, Step:    17000, Batch Loss:     0.879503, Tokens per Sec:    17451, Lr: 0.000240\n",
      "2021-10-09 20:19:08,803 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 20:19:08,804 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 20:19:08,804 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 20:19:09,221 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 20:19:09,221 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 20:19:10,977 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 20:19:10,977 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 20:19:10,977 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 20:19:10,977 - INFO - joeynmt.training - \tHypothesis: Indeed , the conscience of “ a man of man ” may be misled .\n",
      "2021-10-09 20:19:10,977 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 20:19:10,978 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 20:19:10,978 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 20:19:10,978 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 20:19:10,978 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 20:19:10,978 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 20:19:10,978 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 20:19:10,978 - INFO - joeynmt.training - \tHypothesis: That will lead us to the difference between what is right and wrong and to know the difference between the foolish and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 20:19:10,978 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 20:19:10,979 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 20:19:10,979 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 20:19:10,979 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met children in Puerto Rico .\n",
      "2021-10-09 20:19:10,979 - INFO - joeynmt.training - Validation result (greedy) at epoch  14, step    17000: bleu:  32.40, loss: 23671.1055, ppl:   2.3107, duration: 75.4936s\n",
      "2021-10-09 20:19:37,071 - INFO - joeynmt.training - Epoch  14, Step:    17100, Batch Loss:     0.840495, Tokens per Sec:    17286, Lr: 0.000239\n",
      "2021-10-09 20:19:58,112 - INFO - joeynmt.training - Epoch  14: total training loss 1116.78\n",
      "2021-10-09 20:19:58,113 - INFO - joeynmt.training - EPOCH 15\n",
      "2021-10-09 20:20:03,212 - INFO - joeynmt.training - Epoch  15, Step:    17200, Batch Loss:     0.951901, Tokens per Sec:    16546, Lr: 0.000238\n",
      "2021-10-09 20:20:29,213 - INFO - joeynmt.training - Epoch  15, Step:    17300, Batch Loss:     0.904727, Tokens per Sec:    17513, Lr: 0.000238\n",
      "2021-10-09 20:20:55,484 - INFO - joeynmt.training - Epoch  15, Step:    17400, Batch Loss:     0.992684, Tokens per Sec:    16256, Lr: 0.000237\n",
      "2021-10-09 20:21:21,510 - INFO - joeynmt.training - Epoch  15, Step:    17500, Batch Loss:     1.092959, Tokens per Sec:    17458, Lr: 0.000236\n",
      "2021-10-09 20:22:35,721 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 20:22:35,721 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 20:22:35,721 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 20:22:36,137 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 20:22:36,138 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 20:22:37,896 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 20:22:37,896 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 20:22:37,897 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 20:22:37,897 - INFO - joeynmt.training - \tHypothesis: Indeed , the conscience of “ a man of mind ” may be misled .\n",
      "2021-10-09 20:22:37,897 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 20:22:37,897 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 20:22:37,897 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 20:22:37,897 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 20:22:37,897 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 20:22:37,897 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 20:22:37,898 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 20:22:37,898 - INFO - joeynmt.training - \tHypothesis: That will make us know the difference between right and wrong and wrong and to know the difference between the wisdom and wisdom and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 20:22:37,898 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 20:22:37,898 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 20:22:37,898 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 20:22:37,898 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met children in Puerto Rico .\n",
      "2021-10-09 20:22:37,898 - INFO - joeynmt.training - Validation result (greedy) at epoch  15, step    17500: bleu:  32.58, loss: 23644.3555, ppl:   2.3085, duration: 76.3860s\n",
      "2021-10-09 20:23:04,051 - INFO - joeynmt.training - Epoch  15, Step:    17600, Batch Loss:     0.904114, Tokens per Sec:    17686, Lr: 0.000236\n",
      "2021-10-09 20:23:31,221 - INFO - joeynmt.training - Epoch  15, Step:    17700, Batch Loss:     1.039410, Tokens per Sec:    16964, Lr: 0.000235\n",
      "2021-10-09 20:23:56,995 - INFO - joeynmt.training - Epoch  15, Step:    17800, Batch Loss:     1.162467, Tokens per Sec:    17419, Lr: 0.000234\n",
      "2021-10-09 20:24:22,933 - INFO - joeynmt.training - Epoch  15, Step:    17900, Batch Loss:     0.807396, Tokens per Sec:    17717, Lr: 0.000234\n",
      "2021-10-09 20:24:49,097 - INFO - joeynmt.training - Epoch  15, Step:    18000, Batch Loss:     0.896671, Tokens per Sec:    17231, Lr: 0.000233\n",
      "2021-10-09 20:25:59,791 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 20:25:59,792 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 20:25:59,792 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 20:26:00,212 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 20:26:00,212 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 20:26:01,968 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 20:26:01,968 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 20:26:01,968 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 20:26:01,968 - INFO - joeynmt.training - \tHypothesis: Indeed , the conscience of “ a man of mind ” may be misled .\n",
      "2021-10-09 20:26:01,968 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 20:26:01,969 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 20:26:01,969 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 20:26:01,969 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 20:26:01,969 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 20:26:01,969 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 20:26:01,969 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 20:26:01,969 - INFO - joeynmt.training - \tHypothesis: That will make us know the difference between right and wrong and unrighteous and also know the difference between the wisdom and wisdom and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 20:26:01,969 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 20:26:01,970 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 20:26:01,970 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 20:26:01,970 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met children in Puerto Rico .\n",
      "2021-10-09 20:26:01,970 - INFO - joeynmt.training - Validation result (greedy) at epoch  15, step    18000: bleu:  32.71, loss: 23553.6562, ppl:   2.3011, duration: 72.8720s\n",
      "2021-10-09 20:26:27,592 - INFO - joeynmt.training - Epoch  15, Step:    18100, Batch Loss:     0.786020, Tokens per Sec:    17589, Lr: 0.000232\n",
      "2021-10-09 20:26:53,236 - INFO - joeynmt.training - Epoch  15, Step:    18200, Batch Loss:     0.873600, Tokens per Sec:    17751, Lr: 0.000232\n",
      "2021-10-09 20:27:19,303 - INFO - joeynmt.training - Epoch  15, Step:    18300, Batch Loss:     0.884820, Tokens per Sec:    16988, Lr: 0.000231\n",
      "2021-10-09 20:27:44,616 - INFO - joeynmt.training - Epoch  15, Step:    18400, Batch Loss:     0.948814, Tokens per Sec:    17946, Lr: 0.000230\n",
      "2021-10-09 20:27:46,818 - INFO - joeynmt.training - Epoch  15: total training loss 1103.29\n",
      "2021-10-09 20:27:46,818 - INFO - joeynmt.training - EPOCH 16\n",
      "2021-10-09 20:28:11,129 - INFO - joeynmt.training - Epoch  16, Step:    18500, Batch Loss:     0.755725, Tokens per Sec:    17118, Lr: 0.000230\n",
      "2021-10-09 20:29:23,348 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 20:29:23,349 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 20:29:23,349 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 20:29:23,767 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 20:29:23,767 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 20:29:26,432 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 20:29:26,432 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 20:29:26,432 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 20:29:26,432 - INFO - joeynmt.training - \tHypothesis: Yes , the conscience of “ a man of mind ” may be misled .\n",
      "2021-10-09 20:29:26,432 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 20:29:26,433 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 20:29:26,433 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 20:29:26,433 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 20:29:26,433 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 20:29:26,433 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 20:29:26,433 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 20:29:26,433 - INFO - joeynmt.training - \tHypothesis: That will make us know the difference between right and wrong and to know the differences between the wisdom and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 20:29:26,433 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 20:29:26,434 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 20:29:26,434 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 20:29:26,434 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met children in Puerto Rico .\n",
      "2021-10-09 20:29:26,434 - INFO - joeynmt.training - Validation result (greedy) at epoch  16, step    18500: bleu:  32.85, loss: 23412.3711, ppl:   2.2897, duration: 75.3040s\n",
      "2021-10-09 20:29:53,100 - INFO - joeynmt.training - Epoch  16, Step:    18600, Batch Loss:     0.916115, Tokens per Sec:    16805, Lr: 0.000229\n",
      "2021-10-09 20:30:18,736 - INFO - joeynmt.training - Epoch  16, Step:    18700, Batch Loss:     0.737399, Tokens per Sec:    18085, Lr: 0.000229\n",
      "2021-10-09 20:30:44,802 - INFO - joeynmt.training - Epoch  16, Step:    18800, Batch Loss:     0.976437, Tokens per Sec:    17424, Lr: 0.000228\n",
      "2021-10-09 20:31:09,522 - INFO - joeynmt.training - Epoch  16, Step:    18900, Batch Loss:     0.934847, Tokens per Sec:    18592, Lr: 0.000227\n",
      "2021-10-09 20:31:36,034 - INFO - joeynmt.training - Epoch  16, Step:    19000, Batch Loss:     0.908115, Tokens per Sec:    16733, Lr: 0.000227\n",
      "2021-10-09 20:32:48,228 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 20:32:48,229 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 20:32:48,229 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 20:32:48,648 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 20:32:48,649 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 20:32:50,393 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 20:32:50,393 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 20:32:50,393 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 20:32:50,394 - INFO - joeynmt.training - \tHypothesis: Yes , the conscience of “ a man of mind ” may be misled .\n",
      "2021-10-09 20:32:50,394 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 20:32:50,394 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 20:32:50,394 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 20:32:50,394 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 20:32:50,394 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 20:32:50,394 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 20:32:50,394 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 20:32:50,395 - INFO - joeynmt.training - \tHypothesis: That will lead us to know the difference between right and wrong and to know the difference between foolish and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 20:32:50,395 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 20:32:50,395 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 20:32:50,395 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 20:32:50,395 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met children in Puerto Rico .\n",
      "2021-10-09 20:32:50,395 - INFO - joeynmt.training - Validation result (greedy) at epoch  16, step    19000: bleu:  33.01, loss: 23343.5293, ppl:   2.2841, duration: 74.3606s\n",
      "2021-10-09 20:33:17,082 - INFO - joeynmt.training - Epoch  16, Step:    19100, Batch Loss:     1.008335, Tokens per Sec:    17037, Lr: 0.000226\n",
      "2021-10-09 20:33:41,607 - INFO - joeynmt.training - Epoch  16, Step:    19200, Batch Loss:     1.003703, Tokens per Sec:    18496, Lr: 0.000226\n",
      "2021-10-09 20:34:07,498 - INFO - joeynmt.training - Epoch  16, Step:    19300, Batch Loss:     0.915848, Tokens per Sec:    17494, Lr: 0.000225\n",
      "2021-10-09 20:34:33,487 - INFO - joeynmt.training - Epoch  16, Step:    19400, Batch Loss:     0.825173, Tokens per Sec:    17084, Lr: 0.000224\n",
      "2021-10-09 20:34:58,301 - INFO - joeynmt.training - Epoch  16, Step:    19500, Batch Loss:     0.931469, Tokens per Sec:    17998, Lr: 0.000224\n",
      "2021-10-09 20:36:11,433 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 20:36:11,434 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 20:36:11,434 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 20:36:11,849 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 20:36:11,849 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 20:36:13,627 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 20:36:13,627 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 20:36:13,627 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 20:36:13,627 - INFO - joeynmt.training - \tHypothesis: Indeed , the conscience of “ a man of mind ” may be misled .\n",
      "2021-10-09 20:36:13,627 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 20:36:13,628 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 20:36:13,628 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 20:36:13,628 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 20:36:13,628 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 20:36:13,628 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 20:36:13,628 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 20:36:13,628 - INFO - joeynmt.training - \tHypothesis: That will lead us to the difference between righteousness and wrong and to know the difference between the wisdom and wisdom and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 20:36:13,628 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 20:36:13,629 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 20:36:13,629 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 20:36:13,629 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met children in Puerto Rico .\n",
      "2021-10-09 20:36:13,629 - INFO - joeynmt.training - Validation result (greedy) at epoch  16, step    19500: bleu:  33.17, loss: 23224.8711, ppl:   2.2745, duration: 75.3276s\n",
      "2021-10-09 20:36:39,008 - INFO - joeynmt.training - Epoch  16, Step:    19600, Batch Loss:     1.021790, Tokens per Sec:    17444, Lr: 0.000223\n",
      "2021-10-09 20:36:48,747 - INFO - joeynmt.training - Epoch  16: total training loss 1091.24\n",
      "2021-10-09 20:36:48,748 - INFO - joeynmt.training - EPOCH 17\n",
      "2021-10-09 20:37:06,021 - INFO - joeynmt.training - Epoch  17, Step:    19700, Batch Loss:     0.904308, Tokens per Sec:    16642, Lr: 0.000223\n",
      "2021-10-09 20:37:31,564 - INFO - joeynmt.training - Epoch  17, Step:    19800, Batch Loss:     0.859898, Tokens per Sec:    17427, Lr: 0.000222\n",
      "2021-10-09 20:37:56,206 - INFO - joeynmt.training - Epoch  17, Step:    19900, Batch Loss:     0.934416, Tokens per Sec:    18484, Lr: 0.000222\n",
      "2021-10-09 20:38:22,740 - INFO - joeynmt.training - Epoch  17, Step:    20000, Batch Loss:     0.903047, Tokens per Sec:    17150, Lr: 0.000221\n",
      "2021-10-09 20:39:34,215 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 20:39:34,215 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 20:39:34,215 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 20:39:34,635 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 20:39:34,635 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 20:39:36,441 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 20:39:36,441 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 20:39:36,442 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 20:39:36,442 - INFO - joeynmt.training - \tHypothesis: Indeed , the conscience of “ a man of mind ” may be misled .\n",
      "2021-10-09 20:39:36,442 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 20:39:36,442 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 20:39:36,442 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 20:39:36,442 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 20:39:36,442 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 20:39:36,442 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 20:39:36,443 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 20:39:36,443 - INFO - joeynmt.training - \tHypothesis: That will lead us to know the difference between what is right and wrong and to know the difference between the wisdom and wisdom and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 20:39:36,443 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 20:39:36,443 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 20:39:36,443 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 20:39:36,443 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met children in Puerto Rico .\n",
      "2021-10-09 20:39:36,443 - INFO - joeynmt.training - Validation result (greedy) at epoch  17, step    20000: bleu:  33.42, loss: 23121.7520, ppl:   2.2662, duration: 73.7031s\n",
      "2021-10-09 20:40:02,463 - INFO - joeynmt.training - Epoch  17, Step:    20100, Batch Loss:     0.861693, Tokens per Sec:    17467, Lr: 0.000220\n",
      "2021-10-09 20:40:28,619 - INFO - joeynmt.training - Epoch  17, Step:    20200, Batch Loss:     1.008297, Tokens per Sec:    17309, Lr: 0.000220\n",
      "2021-10-09 20:40:55,230 - INFO - joeynmt.training - Epoch  17, Step:    20300, Batch Loss:     0.831464, Tokens per Sec:    16585, Lr: 0.000219\n",
      "2021-10-09 20:41:21,249 - INFO - joeynmt.training - Epoch  17, Step:    20400, Batch Loss:     0.906310, Tokens per Sec:    17044, Lr: 0.000219\n",
      "2021-10-09 20:41:47,341 - INFO - joeynmt.training - Epoch  17, Step:    20500, Batch Loss:     0.852686, Tokens per Sec:    16959, Lr: 0.000218\n",
      "2021-10-09 20:42:59,752 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 20:42:59,752 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 20:42:59,753 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 20:43:00,171 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 20:43:00,172 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 20:43:03,474 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 20:43:03,474 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 20:43:03,474 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 20:43:03,474 - INFO - joeynmt.training - \tHypothesis: Yes , the conscience of “ a man of mind ” may be misled .\n",
      "2021-10-09 20:43:03,475 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 20:43:03,475 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 20:43:03,475 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 20:43:03,475 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 20:43:03,475 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 20:43:03,475 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 20:43:03,475 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 20:43:03,476 - INFO - joeynmt.training - \tHypothesis: That will make us know the difference between right and wrong and wrong and to know the difference between the foolish and discreet and discre. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 20:43:03,476 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 20:43:03,476 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 20:43:03,476 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 20:43:03,476 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met the children in Puerto Rico .\n",
      "2021-10-09 20:43:03,476 - INFO - joeynmt.training - Validation result (greedy) at epoch  17, step    20500: bleu:  33.57, loss: 23031.8926, ppl:   2.2590, duration: 76.1343s\n",
      "2021-10-09 20:43:29,726 - INFO - joeynmt.training - Epoch  17, Step:    20600, Batch Loss:     0.994227, Tokens per Sec:    17559, Lr: 0.000218\n",
      "2021-10-09 20:43:56,058 - INFO - joeynmt.training - Epoch  17, Step:    20700, Batch Loss:     0.897754, Tokens per Sec:    16841, Lr: 0.000217\n",
      "2021-10-09 20:44:22,204 - INFO - joeynmt.training - Epoch  17, Step:    20800, Batch Loss:     0.878969, Tokens per Sec:    17297, Lr: 0.000217\n",
      "2021-10-09 20:44:40,125 - INFO - joeynmt.training - Epoch  17: total training loss 1083.07\n",
      "2021-10-09 20:44:40,125 - INFO - joeynmt.training - EPOCH 18\n",
      "2021-10-09 20:44:48,583 - INFO - joeynmt.training - Epoch  18, Step:    20900, Batch Loss:     0.837683, Tokens per Sec:    16148, Lr: 0.000216\n",
      "2021-10-09 20:45:14,647 - INFO - joeynmt.training - Epoch  18, Step:    21000, Batch Loss:     0.872881, Tokens per Sec:    17372, Lr: 0.000216\n",
      "2021-10-09 20:46:27,764 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 20:46:27,765 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 20:46:27,765 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 20:46:29,884 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 20:46:29,884 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 20:46:29,884 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 20:46:29,884 - INFO - joeynmt.training - \tHypothesis: Yes , the conscience of “ a man of mind ” may be misled .\n",
      "2021-10-09 20:46:29,884 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 20:46:29,884 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 20:46:29,885 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 20:46:29,885 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 20:46:29,885 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 20:46:29,885 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 20:46:29,885 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 20:46:29,885 - INFO - joeynmt.training - \tHypothesis: That will lead us to know the difference between right and wrong and wrong and to know the difference between foolish and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 20:46:29,885 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 20:46:29,886 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 20:46:29,886 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 20:46:29,886 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met children in Puerto Rico .\n",
      "2021-10-09 20:46:29,886 - INFO - joeynmt.training - Validation result (greedy) at epoch  18, step    21000: bleu:  33.48, loss: 23104.0098, ppl:   2.2648, duration: 75.2382s\n",
      "2021-10-09 20:46:55,969 - INFO - joeynmt.training - Epoch  18, Step:    21100, Batch Loss:     0.887584, Tokens per Sec:    17158, Lr: 0.000215\n",
      "2021-10-09 20:47:22,928 - INFO - joeynmt.training - Epoch  18, Step:    21200, Batch Loss:     0.848362, Tokens per Sec:    16860, Lr: 0.000215\n",
      "2021-10-09 20:47:48,767 - INFO - joeynmt.training - Epoch  18, Step:    21300, Batch Loss:     0.858636, Tokens per Sec:    16812, Lr: 0.000214\n",
      "2021-10-09 20:48:14,994 - INFO - joeynmt.training - Epoch  18, Step:    21400, Batch Loss:     0.950514, Tokens per Sec:    17681, Lr: 0.000214\n",
      "2021-10-09 20:48:40,791 - INFO - joeynmt.training - Epoch  18, Step:    21500, Batch Loss:     0.880692, Tokens per Sec:    16925, Lr: 0.000213\n",
      "2021-10-09 20:49:52,151 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 20:49:52,152 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 20:49:52,152 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 20:49:52,570 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 20:49:52,570 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 20:49:54,377 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 20:49:54,378 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 20:49:54,378 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 20:49:54,378 - INFO - joeynmt.training - \tHypothesis: Indeed , the conscience of “ a man of mind ” may be misled .\n",
      "2021-10-09 20:49:54,378 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 20:49:54,378 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 20:49:54,378 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 20:49:54,378 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 20:49:54,378 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 20:49:54,379 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 20:49:54,379 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 20:49:54,379 - INFO - joeynmt.training - \tHypothesis: That will lead us to know the difference between right and wrong and wrong and to know the difference between foolish and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 20:49:54,379 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 20:49:54,379 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 20:49:54,379 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 20:49:54,379 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met children in Puerto Rico .\n",
      "2021-10-09 20:49:54,380 - INFO - joeynmt.training - Validation result (greedy) at epoch  18, step    21500: bleu:  33.42, loss: 22949.3438, ppl:   2.2525, duration: 73.5874s\n",
      "2021-10-09 20:50:20,379 - INFO - joeynmt.training - Epoch  18, Step:    21600, Batch Loss:     0.838657, Tokens per Sec:    16967, Lr: 0.000213\n",
      "2021-10-09 20:50:46,609 - INFO - joeynmt.training - Epoch  18, Step:    21700, Batch Loss:     0.887098, Tokens per Sec:    17475, Lr: 0.000212\n",
      "2021-10-09 20:51:13,013 - INFO - joeynmt.training - Epoch  18, Step:    21800, Batch Loss:     0.873418, Tokens per Sec:    17402, Lr: 0.000212\n",
      "2021-10-09 20:51:39,130 - INFO - joeynmt.training - Epoch  18, Step:    21900, Batch Loss:     0.874721, Tokens per Sec:    16931, Lr: 0.000211\n",
      "2021-10-09 20:52:04,416 - INFO - joeynmt.training - Epoch  18, Step:    22000, Batch Loss:     0.863258, Tokens per Sec:    18466, Lr: 0.000211\n",
      "2021-10-09 20:53:14,907 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 20:53:14,908 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 20:53:14,908 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 20:53:15,326 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 20:53:15,327 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 20:53:17,140 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 20:53:17,140 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 20:53:17,140 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 20:53:17,140 - INFO - joeynmt.training - \tHypothesis: Indeed , the conscience of “ a man of mind ” may be misled .\n",
      "2021-10-09 20:53:17,140 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 20:53:17,141 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 20:53:17,141 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 20:53:17,141 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 20:53:17,141 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 20:53:17,141 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 20:53:17,141 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 20:53:17,141 - INFO - joeynmt.training - \tHypothesis: That will make us know the difference between right and wrong and wrong and to know difference between the wisdom and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 20:53:17,141 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 20:53:17,142 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 20:53:17,142 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 20:53:17,142 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met children in Puerto Rico .\n",
      "2021-10-09 20:53:17,142 - INFO - joeynmt.training - Validation result (greedy) at epoch  18, step    22000: bleu:  33.86, loss: 22805.7988, ppl:   2.2410, duration: 72.7248s\n",
      "2021-10-09 20:53:43,692 - INFO - joeynmt.training - Epoch  18: total training loss 1073.51\n",
      "2021-10-09 20:53:43,692 - INFO - joeynmt.training - EPOCH 19\n",
      "2021-10-09 20:53:44,238 - INFO - joeynmt.training - Epoch  19, Step:    22100, Batch Loss:     0.835158, Tokens per Sec:     6719, Lr: 0.000210\n",
      "2021-10-09 20:54:10,415 - INFO - joeynmt.training - Epoch  19, Step:    22200, Batch Loss:     0.758250, Tokens per Sec:    17441, Lr: 0.000210\n",
      "2021-10-09 20:54:37,025 - INFO - joeynmt.training - Epoch  19, Step:    22300, Batch Loss:     0.815053, Tokens per Sec:    16874, Lr: 0.000209\n",
      "2021-10-09 20:55:03,473 - INFO - joeynmt.training - Epoch  19, Step:    22400, Batch Loss:     0.885454, Tokens per Sec:    16975, Lr: 0.000209\n",
      "2021-10-09 20:55:29,401 - INFO - joeynmt.training - Epoch  19, Step:    22500, Batch Loss:     0.863472, Tokens per Sec:    16857, Lr: 0.000208\n",
      "2021-10-09 20:56:41,828 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 20:56:41,828 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 20:56:41,828 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 20:56:45,419 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 20:56:45,420 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 20:56:45,420 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 20:56:45,420 - INFO - joeynmt.training - \tHypothesis: Indeed , the conscience of “ a man of mind ” may be misled .\n",
      "2021-10-09 20:56:45,420 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 20:56:45,420 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 20:56:45,420 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 20:56:45,420 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 20:56:45,420 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 20:56:45,421 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 20:56:45,421 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 20:56:45,421 - INFO - joeynmt.training - \tHypothesis: That will make us know the difference between right and wrong and wrong and to know the difference between foolish and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 20:56:45,421 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 20:56:45,421 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 20:56:45,421 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 20:56:45,421 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met children in Puerto Rico .\n",
      "2021-10-09 20:56:45,421 - INFO - joeynmt.training - Validation result (greedy) at epoch  19, step    22500: bleu:  33.82, loss: 22805.9473, ppl:   2.2411, duration: 76.0195s\n",
      "2021-10-09 20:57:12,145 - INFO - joeynmt.training - Epoch  19, Step:    22600, Batch Loss:     0.861094, Tokens per Sec:    17167, Lr: 0.000208\n",
      "2021-10-09 20:57:37,603 - INFO - joeynmt.training - Epoch  19, Step:    22700, Batch Loss:     0.904013, Tokens per Sec:    17166, Lr: 0.000207\n",
      "2021-10-09 20:58:04,315 - INFO - joeynmt.training - Epoch  19, Step:    22800, Batch Loss:     0.844656, Tokens per Sec:    16649, Lr: 0.000207\n",
      "2021-10-09 20:58:31,119 - INFO - joeynmt.training - Epoch  19, Step:    22900, Batch Loss:     0.887009, Tokens per Sec:    17247, Lr: 0.000207\n",
      "2021-10-09 20:58:57,396 - INFO - joeynmt.training - Epoch  19, Step:    23000, Batch Loss:     0.816864, Tokens per Sec:    17371, Lr: 0.000206\n",
      "2021-10-09 21:00:07,911 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 21:00:07,911 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 21:00:07,911 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 21:00:08,329 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 21:00:08,330 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 21:00:10,162 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 21:00:10,163 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 21:00:10,163 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 21:00:10,163 - INFO - joeynmt.training - \tHypothesis: Indeed , the conscience of “ a man of mind ” may be misled .\n",
      "2021-10-09 21:00:10,163 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 21:00:10,163 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 21:00:10,163 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 21:00:10,163 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 21:00:10,163 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 21:00:10,164 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 21:00:10,164 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 21:00:10,164 - INFO - joeynmt.training - \tHypothesis: That will lead us to know the difference between right and wrong and wrong and to know the difference between foolish and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 21:00:10,164 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 21:00:10,164 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 21:00:10,164 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 21:00:10,164 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met children in Puerto Rico .\n",
      "2021-10-09 21:00:10,164 - INFO - joeynmt.training - Validation result (greedy) at epoch  19, step    23000: bleu:  33.94, loss: 22770.7637, ppl:   2.2383, duration: 72.7675s\n",
      "2021-10-09 21:00:36,070 - INFO - joeynmt.training - Epoch  19, Step:    23100, Batch Loss:     0.985703, Tokens per Sec:    17064, Lr: 0.000206\n",
      "2021-10-09 21:01:02,559 - INFO - joeynmt.training - Epoch  19, Step:    23200, Batch Loss:     0.884211, Tokens per Sec:    16611, Lr: 0.000205\n",
      "2021-10-09 21:01:28,709 - INFO - joeynmt.training - Epoch  19, Step:    23300, Batch Loss:     0.868397, Tokens per Sec:    17445, Lr: 0.000205\n",
      "2021-10-09 21:01:37,247 - INFO - joeynmt.training - Epoch  19: total training loss 1065.25\n",
      "2021-10-09 21:01:37,247 - INFO - joeynmt.training - EPOCH 20\n",
      "2021-10-09 21:01:55,402 - INFO - joeynmt.training - Epoch  20, Step:    23400, Batch Loss:     0.885262, Tokens per Sec:    17480, Lr: 0.000204\n",
      "2021-10-09 21:02:21,461 - INFO - joeynmt.training - Epoch  20, Step:    23500, Batch Loss:     0.980029, Tokens per Sec:    17154, Lr: 0.000204\n",
      "2021-10-09 21:03:32,386 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 21:03:32,387 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 21:03:32,387 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 21:03:32,801 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 21:03:32,801 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 21:03:34,608 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 21:03:34,608 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 21:03:34,608 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 21:03:34,608 - INFO - joeynmt.training - \tHypothesis: Indeed , the conscience of “ a man of mind ” may be misled .\n",
      "2021-10-09 21:03:34,608 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 21:03:34,609 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 21:03:34,609 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 21:03:34,609 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 21:03:34,609 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 21:03:34,609 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 21:03:34,609 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 21:03:34,609 - INFO - joeynmt.training - \tHypothesis: That will enable us to know the difference between what is right and wrong and to know the difference between foolish and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 21:03:34,609 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 21:03:34,610 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 21:03:34,610 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 21:03:34,610 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met children in Puerto Rico .\n",
      "2021-10-09 21:03:34,610 - INFO - joeynmt.training - Validation result (greedy) at epoch  20, step    23500: bleu:  33.93, loss: 22644.9043, ppl:   2.2283, duration: 73.1482s\n",
      "2021-10-09 21:04:00,692 - INFO - joeynmt.training - Epoch  20, Step:    23600, Batch Loss:     0.906889, Tokens per Sec:    17233, Lr: 0.000203\n",
      "2021-10-09 21:04:27,375 - INFO - joeynmt.training - Epoch  20, Step:    23700, Batch Loss:     0.884692, Tokens per Sec:    16830, Lr: 0.000203\n",
      "2021-10-09 21:04:53,635 - INFO - joeynmt.training - Epoch  20, Step:    23800, Batch Loss:     0.869014, Tokens per Sec:    17497, Lr: 0.000203\n",
      "2021-10-09 21:05:20,332 - INFO - joeynmt.training - Epoch  20, Step:    23900, Batch Loss:     0.913562, Tokens per Sec:    16603, Lr: 0.000202\n",
      "2021-10-09 21:05:45,121 - INFO - joeynmt.training - Epoch  20, Step:    24000, Batch Loss:     0.860173, Tokens per Sec:    18502, Lr: 0.000202\n",
      "2021-10-09 21:06:56,023 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 21:06:56,024 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 21:06:56,024 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 21:06:56,442 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 21:06:56,442 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 21:06:58,218 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 21:06:58,219 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 21:06:58,219 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 21:06:58,219 - INFO - joeynmt.training - \tHypothesis: Indeed , the conscience of “ a man of mind ” may be misled .\n",
      "2021-10-09 21:06:58,219 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 21:06:58,219 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 21:06:58,219 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 21:06:58,219 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 21:06:58,219 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 21:06:58,220 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 21:06:58,220 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 21:06:58,220 - INFO - joeynmt.training - \tHypothesis: That will lead us to know the difference between right and wrong and wrong and to know the difference between foolish and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 21:06:58,220 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 21:06:58,220 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 21:06:58,220 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 21:06:58,220 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met children in Puerto Rico .\n",
      "2021-10-09 21:06:58,220 - INFO - joeynmt.training - Validation result (greedy) at epoch  20, step    24000: bleu:  34.11, loss: 22595.1328, ppl:   2.2244, duration: 73.0984s\n",
      "2021-10-09 21:07:24,124 - INFO - joeynmt.training - Epoch  20, Step:    24100, Batch Loss:     0.930777, Tokens per Sec:    17464, Lr: 0.000201\n",
      "2021-10-09 21:07:50,297 - INFO - joeynmt.training - Epoch  20, Step:    24200, Batch Loss:     0.869769, Tokens per Sec:    17325, Lr: 0.000201\n",
      "2021-10-09 21:08:16,358 - INFO - joeynmt.training - Epoch  20, Step:    24300, Batch Loss:     0.896607, Tokens per Sec:    16871, Lr: 0.000200\n",
      "2021-10-09 21:08:42,746 - INFO - joeynmt.training - Epoch  20, Step:    24400, Batch Loss:     0.786576, Tokens per Sec:    17319, Lr: 0.000200\n",
      "2021-10-09 21:09:09,552 - INFO - joeynmt.training - Epoch  20, Step:    24500, Batch Loss:     0.802641, Tokens per Sec:    16757, Lr: 0.000200\n",
      "2021-10-09 21:10:18,789 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 21:10:18,790 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 21:10:18,790 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 21:10:19,207 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 21:10:19,207 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 21:10:21,014 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 21:10:21,015 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 21:10:21,015 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 21:10:21,015 - INFO - joeynmt.training - \tHypothesis: Yes , the conscience of “ a man of inner ” may be misled .\n",
      "2021-10-09 21:10:21,015 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 21:10:21,015 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 21:10:21,015 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 21:10:21,016 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 21:10:21,016 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 21:10:21,016 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 21:10:21,016 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 21:10:21,016 - INFO - joeynmt.training - \tHypothesis: That will lead us to know the difference between right and wrong and wrong and to know the difference between foolish and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 21:10:21,016 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 21:10:21,016 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 21:10:21,016 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 21:10:21,017 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met children in Puerto Rico .\n",
      "2021-10-09 21:10:21,017 - INFO - joeynmt.training - Validation result (greedy) at epoch  20, step    24500: bleu:  33.78, loss: 22565.4023, ppl:   2.2221, duration: 71.4645s\n",
      "2021-10-09 21:10:36,386 - INFO - joeynmt.training - Epoch  20: total training loss 1051.60\n",
      "2021-10-09 21:10:36,387 - INFO - joeynmt.training - EPOCH 21\n",
      "2021-10-09 21:10:47,786 - INFO - joeynmt.training - Epoch  21, Step:    24600, Batch Loss:     0.838237, Tokens per Sec:    15823, Lr: 0.000199\n",
      "2021-10-09 21:11:13,797 - INFO - joeynmt.training - Epoch  21, Step:    24700, Batch Loss:     0.827588, Tokens per Sec:    17530, Lr: 0.000199\n",
      "2021-10-09 21:11:40,635 - INFO - joeynmt.training - Epoch  21, Step:    24800, Batch Loss:     0.838444, Tokens per Sec:    16927, Lr: 0.000198\n",
      "2021-10-09 21:12:06,390 - INFO - joeynmt.training - Epoch  21, Step:    24900, Batch Loss:     0.804969, Tokens per Sec:    16852, Lr: 0.000198\n",
      "2021-10-09 21:12:32,525 - INFO - joeynmt.training - Epoch  21, Step:    25000, Batch Loss:     0.888788, Tokens per Sec:    17466, Lr: 0.000198\n",
      "2021-10-09 21:13:46,231 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 21:13:46,232 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 21:13:46,232 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 21:13:46,652 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 21:13:46,652 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 21:13:48,437 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 21:13:48,437 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 21:13:48,437 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 21:13:48,437 - INFO - joeynmt.training - \tHypothesis: Indeed , the conscience of “ a man of inner ” may be misled .\n",
      "2021-10-09 21:13:48,438 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 21:13:48,438 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 21:13:48,438 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 21:13:48,438 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 21:13:48,438 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 21:13:48,438 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 21:13:48,438 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 21:13:48,439 - INFO - joeynmt.training - \tHypothesis: That will enable us to know the difference between right and wrong and wrong and to know the difference between foolish and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 21:13:48,439 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 21:13:48,439 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 21:13:48,439 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 21:13:48,439 - INFO - joeynmt.training - \tHypothesis: After February graduation in 1945 , I met children in Puerto Rico .\n",
      "2021-10-09 21:13:48,439 - INFO - joeynmt.training - Validation result (greedy) at epoch  21, step    25000: bleu:  34.38, loss: 22514.6660, ppl:   2.2181, duration: 75.9133s\n",
      "2021-10-09 21:14:14,487 - INFO - joeynmt.training - Epoch  21, Step:    25100, Batch Loss:     0.940663, Tokens per Sec:    17443, Lr: 0.000197\n",
      "2021-10-09 21:14:40,289 - INFO - joeynmt.training - Epoch  21, Step:    25200, Batch Loss:     0.804925, Tokens per Sec:    17069, Lr: 0.000197\n",
      "2021-10-09 21:15:05,809 - INFO - joeynmt.training - Epoch  21, Step:    25300, Batch Loss:     0.808492, Tokens per Sec:    17892, Lr: 0.000196\n",
      "2021-10-09 21:15:32,677 - INFO - joeynmt.training - Epoch  21, Step:    25400, Batch Loss:     0.838818, Tokens per Sec:    17005, Lr: 0.000196\n",
      "2021-10-09 21:15:59,699 - INFO - joeynmt.training - Epoch  21, Step:    25500, Batch Loss:     0.841161, Tokens per Sec:    17190, Lr: 0.000196\n",
      "2021-10-09 21:17:11,443 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 21:17:11,444 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 21:17:11,444 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 21:17:11,859 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 21:17:11,859 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 21:17:13,667 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 21:17:13,668 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 21:17:13,668 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 21:17:13,668 - INFO - joeynmt.training - \tHypothesis: Yes , the conscience of “ a man of inner ” may be misled .\n",
      "2021-10-09 21:17:13,668 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 21:17:13,668 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 21:17:13,668 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 21:17:13,668 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 21:17:13,668 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 21:17:13,669 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 21:17:13,669 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 21:17:13,669 - INFO - joeynmt.training - \tHypothesis: That will lead us to the difference between right and wrong and wrong and to know differences between foolish and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 21:17:13,669 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 21:17:13,669 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 21:17:13,669 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 21:17:13,669 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met children in Puerto Rico .\n",
      "2021-10-09 21:17:13,669 - INFO - joeynmt.training - Validation result (greedy) at epoch  21, step    25500: bleu:  34.23, loss: 22410.7129, ppl:   2.2099, duration: 73.9701s\n",
      "2021-10-09 21:17:40,210 - INFO - joeynmt.training - Epoch  21, Step:    25600, Batch Loss:     0.946324, Tokens per Sec:    17119, Lr: 0.000195\n",
      "2021-10-09 21:18:06,728 - INFO - joeynmt.training - Epoch  21, Step:    25700, Batch Loss:     0.854639, Tokens per Sec:    17033, Lr: 0.000195\n",
      "2021-10-09 21:18:28,403 - INFO - joeynmt.training - Epoch  21: total training loss 1041.26\n",
      "2021-10-09 21:18:28,404 - INFO - joeynmt.training - EPOCH 22\n",
      "2021-10-09 21:18:33,193 - INFO - joeynmt.training - Epoch  22, Step:    25800, Batch Loss:     0.767478, Tokens per Sec:    15904, Lr: 0.000195\n",
      "2021-10-09 21:18:59,236 - INFO - joeynmt.training - Epoch  22, Step:    25900, Batch Loss:     0.837828, Tokens per Sec:    17479, Lr: 0.000194\n",
      "2021-10-09 21:19:25,281 - INFO - joeynmt.training - Epoch  22, Step:    26000, Batch Loss:     0.885088, Tokens per Sec:    17339, Lr: 0.000194\n",
      "2021-10-09 21:20:35,561 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 21:20:35,562 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 21:20:35,562 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 21:20:35,978 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 21:20:35,979 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 21:20:37,733 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 21:20:37,734 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 21:20:37,734 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 21:20:37,734 - INFO - joeynmt.training - \tHypothesis: Indeed , the conscience of “ a man of inner man ” may be misled .\n",
      "2021-10-09 21:20:37,734 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 21:20:37,734 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 21:20:37,734 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 21:20:37,734 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 21:20:37,734 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 21:20:37,735 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 21:20:37,735 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 21:20:37,735 - INFO - joeynmt.training - \tHypothesis: That will lead us to know the difference between right and wrong and to know differences between foolish and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 21:20:37,735 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 21:20:37,735 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 21:20:37,735 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 21:20:37,735 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met children in Puerto Rico .\n",
      "2021-10-09 21:20:37,736 - INFO - joeynmt.training - Validation result (greedy) at epoch  22, step    26000: bleu:  34.37, loss: 22378.5039, ppl:   2.2074, duration: 72.4539s\n",
      "2021-10-09 21:21:04,394 - INFO - joeynmt.training - Epoch  22, Step:    26100, Batch Loss:     0.921383, Tokens per Sec:    17365, Lr: 0.000193\n",
      "2021-10-09 21:21:30,378 - INFO - joeynmt.training - Epoch  22, Step:    26200, Batch Loss:     0.822198, Tokens per Sec:    17241, Lr: 0.000193\n",
      "2021-10-09 21:21:55,809 - INFO - joeynmt.training - Epoch  22, Step:    26300, Batch Loss:     0.826290, Tokens per Sec:    17681, Lr: 0.000193\n",
      "2021-10-09 21:22:21,108 - INFO - joeynmt.training - Epoch  22, Step:    26400, Batch Loss:     0.857434, Tokens per Sec:    18297, Lr: 0.000192\n",
      "2021-10-09 21:22:45,915 - INFO - joeynmt.training - Epoch  22, Step:    26500, Batch Loss:     0.794539, Tokens per Sec:    17741, Lr: 0.000192\n",
      "2021-10-09 21:24:00,625 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 21:24:00,626 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 21:24:00,626 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 21:24:01,045 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 21:24:01,045 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 21:24:02,864 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 21:24:02,864 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 21:24:02,864 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 21:24:02,864 - INFO - joeynmt.training - \tHypothesis: Yes , the conscience of “ a man of mind ” may be misled .\n",
      "2021-10-09 21:24:02,864 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 21:24:02,864 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 21:24:02,865 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 21:24:02,865 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 21:24:02,865 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 21:24:02,865 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 21:24:02,865 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 21:24:02,865 - INFO - joeynmt.training - \tHypothesis: That will lead us to know the difference between right and wrong and wrong and also know the difference between foolish and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 21:24:02,865 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 21:24:02,866 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 21:24:02,866 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 21:24:02,866 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met children in Puerto Rico .\n",
      "2021-10-09 21:24:02,866 - INFO - joeynmt.training - Validation result (greedy) at epoch  22, step    26500: bleu:  34.36, loss: 22354.0449, ppl:   2.2055, duration: 76.9495s\n",
      "2021-10-09 21:24:29,528 - INFO - joeynmt.training - Epoch  22, Step:    26600, Batch Loss:     0.892312, Tokens per Sec:    16950, Lr: 0.000192\n",
      "2021-10-09 21:24:55,479 - INFO - joeynmt.training - Epoch  22, Step:    26700, Batch Loss:     0.666423, Tokens per Sec:    17155, Lr: 0.000191\n",
      "2021-10-09 21:25:22,042 - INFO - joeynmt.training - Epoch  22, Step:    26800, Batch Loss:     0.801684, Tokens per Sec:    16431, Lr: 0.000191\n",
      "2021-10-09 21:25:48,073 - INFO - joeynmt.training - Epoch  22, Step:    26900, Batch Loss:     0.926615, Tokens per Sec:    17132, Lr: 0.000191\n",
      "2021-10-09 21:26:15,129 - INFO - joeynmt.training - Epoch  22, Step:    27000, Batch Loss:     0.884969, Tokens per Sec:    17592, Lr: 0.000190\n",
      "2021-10-09 21:27:28,910 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 21:27:28,911 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 21:27:28,911 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 21:27:29,330 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 21:27:29,331 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 21:27:31,113 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 21:27:31,113 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 21:27:31,114 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 21:27:31,114 - INFO - joeynmt.training - \tHypothesis: Yes , the conscience of “ a man of inner ” may be misled .\n",
      "2021-10-09 21:27:31,114 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 21:27:31,114 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 21:27:31,114 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 21:27:31,114 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 21:27:31,114 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 21:27:31,114 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 21:27:31,115 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 21:27:31,115 - INFO - joeynmt.training - \tHypothesis: That will make us know the difference between right and wrong and wrong and to know the difference between foolish and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 21:27:31,115 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 21:27:31,115 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 21:27:31,115 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 21:27:31,115 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met children in Puerto Rico .\n",
      "2021-10-09 21:27:31,115 - INFO - joeynmt.training - Validation result (greedy) at epoch  22, step    27000: bleu:  34.64, loss: 22294.8789, ppl:   2.2009, duration: 75.9853s\n",
      "2021-10-09 21:27:33,481 - INFO - joeynmt.training - Epoch  22: total training loss 1036.33\n",
      "2021-10-09 21:27:33,481 - INFO - joeynmt.training - EPOCH 23\n",
      "2021-10-09 21:27:55,566 - INFO - joeynmt.training - Epoch  23, Step:    27100, Batch Loss:     0.849467, Tokens per Sec:    18311, Lr: 0.000190\n",
      "2021-10-09 21:28:21,587 - INFO - joeynmt.training - Epoch  23, Step:    27200, Batch Loss:     0.804948, Tokens per Sec:    17162, Lr: 0.000189\n",
      "2021-10-09 21:28:46,899 - INFO - joeynmt.training - Epoch  23, Step:    27300, Batch Loss:     0.852661, Tokens per Sec:    18386, Lr: 0.000189\n",
      "2021-10-09 21:29:12,369 - INFO - joeynmt.training - Epoch  23, Step:    27400, Batch Loss:     0.782399, Tokens per Sec:    17709, Lr: 0.000189\n",
      "2021-10-09 21:29:37,030 - INFO - joeynmt.training - Epoch  23, Step:    27500, Batch Loss:     0.739659, Tokens per Sec:    17976, Lr: 0.000188\n",
      "2021-10-09 21:30:47,742 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 21:30:47,743 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 21:30:47,743 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 21:30:48,160 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 21:30:48,160 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 21:30:49,897 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 21:30:49,898 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 21:30:49,898 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 21:30:49,898 - INFO - joeynmt.training - \tHypothesis: Yes , the conscience of “ a man of inner man ” may be misled .\n",
      "2021-10-09 21:30:49,898 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 21:30:49,898 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 21:30:49,898 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 21:30:49,898 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 21:30:49,899 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 21:30:49,899 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 21:30:49,899 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 21:30:49,899 - INFO - joeynmt.training - \tHypothesis: That will enable us to know the difference between right and wrong and wrong and to know difference between foolish and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 21:30:49,899 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 21:30:49,899 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 21:30:49,899 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 21:30:49,899 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met children in Puerto Rico .\n",
      "2021-10-09 21:30:49,900 - INFO - joeynmt.training - Validation result (greedy) at epoch  23, step    27500: bleu:  34.59, loss: 22240.0254, ppl:   2.1966, duration: 72.8681s\n",
      "2021-10-09 21:31:15,646 - INFO - joeynmt.training - Epoch  23, Step:    27600, Batch Loss:     0.818092, Tokens per Sec:    17295, Lr: 0.000188\n",
      "2021-10-09 21:31:40,408 - INFO - joeynmt.training - Epoch  23, Step:    27700, Batch Loss:     0.817510, Tokens per Sec:    17917, Lr: 0.000188\n",
      "2021-10-09 21:32:04,480 - INFO - joeynmt.training - Epoch  23, Step:    27800, Batch Loss:     0.847881, Tokens per Sec:    18522, Lr: 0.000187\n",
      "2021-10-09 21:32:30,271 - INFO - joeynmt.training - Epoch  23, Step:    27900, Batch Loss:     0.801281, Tokens per Sec:    17262, Lr: 0.000187\n",
      "2021-10-09 21:32:56,505 - INFO - joeynmt.training - Epoch  23, Step:    28000, Batch Loss:     0.847684, Tokens per Sec:    17395, Lr: 0.000187\n",
      "2021-10-09 21:34:08,408 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 21:34:08,408 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 21:34:08,408 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 21:34:08,826 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 21:34:08,826 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 21:34:10,579 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 21:34:10,579 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 21:34:10,579 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 21:34:10,579 - INFO - joeynmt.training - \tHypothesis: Indeed , the conscience of “ the man of the inner man ” may be misled .\n",
      "2021-10-09 21:34:10,580 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 21:34:10,580 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 21:34:10,580 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 21:34:10,580 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 21:34:10,580 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 21:34:10,580 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 21:34:10,580 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 21:34:10,580 - INFO - joeynmt.training - \tHypothesis: That will make us know the difference between right and wrong and wrong and to know the difference between foolish and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 21:34:10,581 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 21:34:10,581 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 21:34:10,581 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 21:34:10,581 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met children in Puerto Rico .\n",
      "2021-10-09 21:34:10,581 - INFO - joeynmt.training - Validation result (greedy) at epoch  23, step    28000: bleu:  34.57, loss: 22223.3652, ppl:   2.1953, duration: 74.0750s\n",
      "2021-10-09 21:34:36,850 - INFO - joeynmt.training - Epoch  23, Step:    28100, Batch Loss:     0.887740, Tokens per Sec:    17738, Lr: 0.000186\n",
      "2021-10-09 21:35:03,444 - INFO - joeynmt.training - Epoch  23, Step:    28200, Batch Loss:     0.752589, Tokens per Sec:    17214, Lr: 0.000186\n",
      "2021-10-09 21:35:13,616 - INFO - joeynmt.training - Epoch  23: total training loss 1034.07\n",
      "2021-10-09 21:35:13,617 - INFO - joeynmt.training - EPOCH 24\n",
      "2021-10-09 21:35:29,811 - INFO - joeynmt.training - Epoch  24, Step:    28300, Batch Loss:     0.876185, Tokens per Sec:    17305, Lr: 0.000186\n",
      "2021-10-09 21:35:55,004 - INFO - joeynmt.training - Epoch  24, Step:    28400, Batch Loss:     0.825633, Tokens per Sec:    17592, Lr: 0.000185\n",
      "2021-10-09 21:36:21,729 - INFO - joeynmt.training - Epoch  24, Step:    28500, Batch Loss:     0.683828, Tokens per Sec:    16737, Lr: 0.000185\n",
      "2021-10-09 21:37:33,258 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 21:37:33,259 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 21:37:33,259 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 21:37:33,676 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 21:37:33,676 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 21:37:35,433 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 21:37:35,434 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 21:37:35,434 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 21:37:35,434 - INFO - joeynmt.training - \tHypothesis: Indeed , the conscience of “ a man of inner ” may be misled .\n",
      "2021-10-09 21:37:35,434 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 21:37:35,434 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 21:37:35,434 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 21:37:35,434 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 21:37:35,434 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 21:37:35,435 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 21:37:35,435 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 21:37:35,435 - INFO - joeynmt.training - \tHypothesis: That will make us know the difference between right and wrong and wrong and also know differences between foolish and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 21:37:35,435 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 21:37:35,435 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 21:37:35,435 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 21:37:35,435 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met children in Puerto Rico .\n",
      "2021-10-09 21:37:35,435 - INFO - joeynmt.training - Validation result (greedy) at epoch  24, step    28500: bleu:  34.66, loss: 22159.6641, ppl:   2.1904, duration: 73.7053s\n",
      "2021-10-09 21:38:01,721 - INFO - joeynmt.training - Epoch  24, Step:    28600, Batch Loss:     0.819319, Tokens per Sec:    17577, Lr: 0.000185\n",
      "2021-10-09 21:38:27,742 - INFO - joeynmt.training - Epoch  24, Step:    28700, Batch Loss:     0.909203, Tokens per Sec:    17309, Lr: 0.000184\n",
      "2021-10-09 21:38:53,862 - INFO - joeynmt.training - Epoch  24, Step:    28800, Batch Loss:     0.856203, Tokens per Sec:    17513, Lr: 0.000184\n",
      "2021-10-09 21:39:20,197 - INFO - joeynmt.training - Epoch  24, Step:    28900, Batch Loss:     0.756984, Tokens per Sec:    17303, Lr: 0.000184\n",
      "2021-10-09 21:39:46,332 - INFO - joeynmt.training - Epoch  24, Step:    29000, Batch Loss:     0.879015, Tokens per Sec:    16842, Lr: 0.000184\n",
      "2021-10-09 21:40:59,359 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 21:40:59,359 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 21:40:59,359 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 21:40:59,774 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 21:40:59,774 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 21:41:01,501 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 21:41:01,502 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 21:41:01,502 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 21:41:01,502 - INFO - joeynmt.training - \tHypothesis: Yes , the conscience of “ a man of inner ” may be misled .\n",
      "2021-10-09 21:41:01,502 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 21:41:01,502 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 21:41:01,502 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 21:41:01,503 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 21:41:01,503 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 21:41:01,503 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 21:41:01,503 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 21:41:01,503 - INFO - joeynmt.training - \tHypothesis: That will lead us to know the difference between right and wrong and to know the difference between foolish and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 21:41:01,503 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 21:41:01,503 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 21:41:01,503 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 21:41:01,504 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met children in Puerto Rico .\n",
      "2021-10-09 21:41:01,504 - INFO - joeynmt.training - Validation result (greedy) at epoch  24, step    29000: bleu:  34.87, loss: 22076.3848, ppl:   2.1839, duration: 75.1705s\n",
      "2021-10-09 21:41:27,673 - INFO - joeynmt.training - Epoch  24, Step:    29100, Batch Loss:     0.826990, Tokens per Sec:    16988, Lr: 0.000183\n",
      "2021-10-09 21:41:53,556 - INFO - joeynmt.training - Epoch  24, Step:    29200, Batch Loss:     0.843430, Tokens per Sec:    17860, Lr: 0.000183\n",
      "2021-10-09 21:42:19,780 - INFO - joeynmt.training - Epoch  24, Step:    29300, Batch Loss:     0.801549, Tokens per Sec:    17269, Lr: 0.000183\n",
      "2021-10-09 21:42:46,292 - INFO - joeynmt.training - Epoch  24, Step:    29400, Batch Loss:     0.871963, Tokens per Sec:    16759, Lr: 0.000182\n",
      "2021-10-09 21:43:04,139 - INFO - joeynmt.training - Epoch  24: total training loss 1026.93\n",
      "2021-10-09 21:43:04,140 - INFO - joeynmt.training - EPOCH 25\n",
      "2021-10-09 21:43:12,397 - INFO - joeynmt.training - Epoch  25, Step:    29500, Batch Loss:     0.865699, Tokens per Sec:    16608, Lr: 0.000182\n",
      "2021-10-09 21:44:22,937 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 21:44:22,938 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 21:44:22,938 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 21:44:23,355 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 21:44:23,355 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 21:44:26,155 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 21:44:26,156 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 21:44:26,156 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 21:44:26,156 - INFO - joeynmt.training - \tHypothesis: Yes , the conscience of “ a man of inner ” may be misled .\n",
      "2021-10-09 21:44:26,156 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 21:44:26,156 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 21:44:26,156 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 21:44:26,156 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 21:44:26,156 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 21:44:26,157 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 21:44:26,157 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 21:44:26,157 - INFO - joeynmt.training - \tHypothesis: That will lead us to the difference between right and wrong and wrong and to know the difference between foolish and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 21:44:26,157 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 21:44:26,157 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 21:44:26,157 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 21:44:26,157 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met children in Puerto Rico .\n",
      "2021-10-09 21:44:26,157 - INFO - joeynmt.training - Validation result (greedy) at epoch  25, step    29500: bleu:  34.46, loss: 22066.4238, ppl:   2.1832, duration: 73.7591s\n",
      "2021-10-09 21:44:52,068 - INFO - joeynmt.training - Epoch  25, Step:    29600, Batch Loss:     0.873925, Tokens per Sec:    17426, Lr: 0.000182\n",
      "2021-10-09 21:45:18,157 - INFO - joeynmt.training - Epoch  25, Step:    29700, Batch Loss:     0.750610, Tokens per Sec:    17278, Lr: 0.000181\n",
      "2021-10-09 21:45:44,110 - INFO - joeynmt.training - Epoch  25, Step:    29800, Batch Loss:     0.882626, Tokens per Sec:    17066, Lr: 0.000181\n",
      "2021-10-09 21:46:10,596 - INFO - joeynmt.training - Epoch  25, Step:    29900, Batch Loss:     0.873194, Tokens per Sec:    16939, Lr: 0.000181\n",
      "2021-10-09 21:46:35,448 - INFO - joeynmt.training - Epoch  25, Step:    30000, Batch Loss:     0.667873, Tokens per Sec:    17997, Lr: 0.000180\n",
      "2021-10-09 21:47:46,005 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 21:47:46,005 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 21:47:46,005 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 21:47:46,423 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 21:47:46,423 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 21:47:48,609 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 21:47:48,610 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 21:47:48,610 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 21:47:48,610 - INFO - joeynmt.training - \tHypothesis: Yes , the conscience of “ a man of inner ” may be misled .\n",
      "2021-10-09 21:47:48,610 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 21:47:48,610 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 21:47:48,610 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 21:47:48,610 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 21:47:48,610 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 21:47:48,611 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 21:47:48,611 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 21:47:48,611 - INFO - joeynmt.training - \tHypothesis: That will lead us to know the difference between right and wrong and wrong and to know differences between foolish and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 21:47:48,611 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 21:47:48,611 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 21:47:48,611 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 21:47:48,611 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met children in Puerto Rico .\n",
      "2021-10-09 21:47:48,612 - INFO - joeynmt.training - Validation result (greedy) at epoch  25, step    30000: bleu:  34.79, loss: 22022.5488, ppl:   2.1798, duration: 73.1630s\n",
      "2021-10-09 21:48:15,526 - INFO - joeynmt.training - Epoch  25, Step:    30100, Batch Loss:     0.727141, Tokens per Sec:    17135, Lr: 0.000180\n",
      "2021-10-09 21:48:42,263 - INFO - joeynmt.training - Epoch  25, Step:    30200, Batch Loss:     0.921767, Tokens per Sec:    17216, Lr: 0.000180\n",
      "2021-10-09 21:49:08,293 - INFO - joeynmt.training - Epoch  25, Step:    30300, Batch Loss:     0.795099, Tokens per Sec:    17609, Lr: 0.000180\n",
      "2021-10-09 21:49:34,934 - INFO - joeynmt.training - Epoch  25, Step:    30400, Batch Loss:     0.837391, Tokens per Sec:    17308, Lr: 0.000179\n",
      "2021-10-09 21:50:01,688 - INFO - joeynmt.training - Epoch  25, Step:    30500, Batch Loss:     0.858024, Tokens per Sec:    16648, Lr: 0.000179\n",
      "2021-10-09 21:51:13,427 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 21:51:13,428 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 21:51:13,428 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 21:51:13,847 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 21:51:13,847 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 21:51:15,599 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 21:51:15,599 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 21:51:15,599 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 21:51:15,599 - INFO - joeynmt.training - \tHypothesis: Yes , the conscience of “ a man of inner ” may be misled .\n",
      "2021-10-09 21:51:15,599 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 21:51:15,600 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 21:51:15,600 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 21:51:15,600 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 21:51:15,600 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 21:51:15,600 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 21:51:15,600 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 21:51:15,600 - INFO - joeynmt.training - \tHypothesis: That will enable us to know the difference between right and wrong and wrong and to know the difference between foolish and discreet and discreet . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 21:51:15,600 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 21:51:15,601 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 21:51:15,601 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 21:51:15,601 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met children in Puerto Rico .\n",
      "2021-10-09 21:51:15,601 - INFO - joeynmt.training - Validation result (greedy) at epoch  25, step    30500: bleu:  34.87, loss: 21906.1543, ppl:   2.1708, duration: 73.9126s\n",
      "2021-10-09 21:51:41,960 - INFO - joeynmt.training - Epoch  25, Step:    30600, Batch Loss:     0.883870, Tokens per Sec:    17381, Lr: 0.000179\n",
      "2021-10-09 21:52:05,618 - INFO - joeynmt.training - Epoch  25: total training loss 1016.14\n",
      "2021-10-09 21:52:05,619 - INFO - joeynmt.training - EPOCH 26\n",
      "2021-10-09 21:52:07,088 - INFO - joeynmt.training - Epoch  26, Step:    30700, Batch Loss:     0.692847, Tokens per Sec:    13658, Lr: 0.000178\n",
      "2021-10-09 21:52:31,363 - INFO - joeynmt.training - Epoch  26, Step:    30800, Batch Loss:     0.781192, Tokens per Sec:    18794, Lr: 0.000178\n",
      "2021-10-09 21:52:57,875 - INFO - joeynmt.training - Epoch  26, Step:    30900, Batch Loss:     0.839686, Tokens per Sec:    17092, Lr: 0.000178\n",
      "2021-10-09 21:53:21,969 - INFO - joeynmt.training - Epoch  26, Step:    31000, Batch Loss:     0.791740, Tokens per Sec:    18557, Lr: 0.000177\n",
      "2021-10-09 21:54:34,543 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 21:54:34,544 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 21:54:34,544 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 21:54:36,690 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 21:54:36,690 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 21:54:36,690 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 21:54:36,690 - INFO - joeynmt.training - \tHypothesis: Yes , the conscience of “ a man of inner man ” may be misled .\n",
      "2021-10-09 21:54:36,690 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 21:54:36,691 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 21:54:36,691 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 21:54:36,691 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave to his disciples ?\n",
      "2021-10-09 21:54:36,691 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 21:54:36,691 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 21:54:36,691 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 21:54:36,691 - INFO - joeynmt.training - \tHypothesis: That will enable us to know the difference between what is right and wrong and to know the difference between foolish and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 21:54:36,691 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 21:54:36,692 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 21:54:36,692 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 21:54:36,692 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met children in Puerto Rico .\n",
      "2021-10-09 21:54:36,692 - INFO - joeynmt.training - Validation result (greedy) at epoch  26, step    31000: bleu:  35.08, loss: 21963.9473, ppl:   2.1753, duration: 74.7222s\n",
      "2021-10-09 21:55:03,462 - INFO - joeynmt.training - Epoch  26, Step:    31100, Batch Loss:     0.847449, Tokens per Sec:    17094, Lr: 0.000177\n",
      "2021-10-09 21:55:29,382 - INFO - joeynmt.training - Epoch  26, Step:    31200, Batch Loss:     0.844963, Tokens per Sec:    17325, Lr: 0.000177\n",
      "2021-10-09 21:55:56,221 - INFO - joeynmt.training - Epoch  26, Step:    31300, Batch Loss:     0.829981, Tokens per Sec:    16860, Lr: 0.000177\n",
      "2021-10-09 21:56:22,245 - INFO - joeynmt.training - Epoch  26, Step:    31400, Batch Loss:     0.780106, Tokens per Sec:    17419, Lr: 0.000176\n",
      "2021-10-09 21:56:48,186 - INFO - joeynmt.training - Epoch  26, Step:    31500, Batch Loss:     0.772724, Tokens per Sec:    17192, Lr: 0.000176\n",
      "2021-10-09 21:57:59,475 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 21:57:59,476 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 21:57:59,476 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 21:57:59,894 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 21:57:59,894 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 21:58:01,722 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 21:58:01,723 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 21:58:01,723 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 21:58:01,723 - INFO - joeynmt.training - \tHypothesis: Yes , the conscience of “ a man of inner ” may be misled .\n",
      "2021-10-09 21:58:01,723 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 21:58:01,723 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 21:58:01,723 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 21:58:01,723 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 21:58:01,723 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 21:58:01,724 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 21:58:01,724 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 21:58:01,724 - INFO - joeynmt.training - \tHypothesis: That will enable us to know the difference between right and wrong and to know the difference between foolish and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 21:58:01,724 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 21:58:01,724 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 21:58:01,724 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 21:58:01,724 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met children in Puerto Rico .\n",
      "2021-10-09 21:58:01,724 - INFO - joeynmt.training - Validation result (greedy) at epoch  26, step    31500: bleu:  35.21, loss: 21893.3867, ppl:   2.1699, duration: 73.5376s\n",
      "2021-10-09 21:58:28,202 - INFO - joeynmt.training - Epoch  26, Step:    31600, Batch Loss:     0.819395, Tokens per Sec:    16969, Lr: 0.000176\n",
      "2021-10-09 21:58:54,284 - INFO - joeynmt.training - Epoch  26, Step:    31700, Batch Loss:     0.880465, Tokens per Sec:    17638, Lr: 0.000176\n",
      "2021-10-09 21:59:20,441 - INFO - joeynmt.training - Epoch  26, Step:    31800, Batch Loss:     0.879299, Tokens per Sec:    17490, Lr: 0.000175\n",
      "2021-10-09 21:59:46,307 - INFO - joeynmt.training - Epoch  26, Step:    31900, Batch Loss:     0.869264, Tokens per Sec:    16804, Lr: 0.000175\n",
      "2021-10-09 21:59:52,680 - INFO - joeynmt.training - Epoch  26: total training loss 1015.09\n",
      "2021-10-09 21:59:52,681 - INFO - joeynmt.training - EPOCH 27\n",
      "2021-10-09 22:00:13,502 - INFO - joeynmt.training - Epoch  27, Step:    32000, Batch Loss:     0.838972, Tokens per Sec:    16360, Lr: 0.000175\n",
      "2021-10-09 22:01:22,795 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 22:01:22,795 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 22:01:22,796 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 22:01:23,215 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 22:01:23,215 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 22:01:24,993 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 22:01:24,994 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 22:01:24,994 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 22:01:24,994 - INFO - joeynmt.training - \tHypothesis: Yes , the conscience of “ a man of inner ” may be misled .\n",
      "2021-10-09 22:01:24,994 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 22:01:24,994 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 22:01:24,994 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 22:01:24,994 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 22:01:24,994 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 22:01:24,995 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 22:01:24,995 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 22:01:24,995 - INFO - joeynmt.training - \tHypothesis: That will lead us to the difference between right and wrong and what is right and also to know differences between foolish and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 22:01:24,995 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 22:01:24,995 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 22:01:24,995 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 22:01:24,995 - INFO - joeynmt.training - \tHypothesis: After finishing February 1945 , I met the brothers in Puerto Rico .\n",
      "2021-10-09 22:01:24,995 - INFO - joeynmt.training - Validation result (greedy) at epoch  27, step    32000: bleu:  35.34, loss: 21840.2949, ppl:   2.1658, duration: 71.4925s\n",
      "2021-10-09 22:01:51,010 - INFO - joeynmt.training - Epoch  27, Step:    32100, Batch Loss:     0.834765, Tokens per Sec:    17417, Lr: 0.000174\n",
      "2021-10-09 22:02:17,123 - INFO - joeynmt.training - Epoch  27, Step:    32200, Batch Loss:     0.830795, Tokens per Sec:    17496, Lr: 0.000174\n",
      "2021-10-09 22:02:43,885 - INFO - joeynmt.training - Epoch  27, Step:    32300, Batch Loss:     0.763747, Tokens per Sec:    17213, Lr: 0.000174\n",
      "2021-10-09 22:03:09,916 - INFO - joeynmt.training - Epoch  27, Step:    32400, Batch Loss:     0.868606, Tokens per Sec:    17619, Lr: 0.000174\n",
      "2021-10-09 22:03:35,588 - INFO - joeynmt.training - Epoch  27, Step:    32500, Batch Loss:     0.793459, Tokens per Sec:    17433, Lr: 0.000173\n",
      "2021-10-09 22:04:47,008 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 22:04:47,009 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 22:04:47,009 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 22:04:47,431 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 22:04:47,432 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 22:04:49,217 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 22:04:49,218 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 22:04:49,218 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 22:04:49,218 - INFO - joeynmt.training - \tHypothesis: Yes , the conscience of “ a man of inner flesh ” may be misled .\n",
      "2021-10-09 22:04:49,218 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 22:04:49,218 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 22:04:49,218 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 22:04:49,218 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 22:04:49,219 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 22:04:49,219 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 22:04:49,219 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 22:04:49,219 - INFO - joeynmt.training - \tHypothesis: That will lead us to know the difference between right and wrong and unrighteous and also to know differences between foolish and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 22:04:49,219 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 22:04:49,219 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 22:04:49,219 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 22:04:49,219 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met children in Puerto Rico .\n",
      "2021-10-09 22:04:49,220 - INFO - joeynmt.training - Validation result (greedy) at epoch  27, step    32500: bleu:  35.39, loss: 21825.2051, ppl:   2.1646, duration: 73.6306s\n",
      "2021-10-09 22:05:16,239 - INFO - joeynmt.training - Epoch  27, Step:    32600, Batch Loss:     0.756862, Tokens per Sec:    16839, Lr: 0.000173\n",
      "2021-10-09 22:05:42,697 - INFO - joeynmt.training - Epoch  27, Step:    32700, Batch Loss:     0.806832, Tokens per Sec:    16484, Lr: 0.000173\n",
      "2021-10-09 22:06:08,436 - INFO - joeynmt.training - Epoch  27, Step:    32800, Batch Loss:     0.812974, Tokens per Sec:    17419, Lr: 0.000173\n",
      "2021-10-09 22:06:34,356 - INFO - joeynmt.training - Epoch  27, Step:    32900, Batch Loss:     0.825513, Tokens per Sec:    17389, Lr: 0.000172\n",
      "2021-10-09 22:07:00,330 - INFO - joeynmt.training - Epoch  27, Step:    33000, Batch Loss:     0.792867, Tokens per Sec:    17203, Lr: 0.000172\n",
      "2021-10-09 22:08:12,576 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 22:08:12,577 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 22:08:12,577 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 22:08:12,985 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 22:08:12,986 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 22:08:14,675 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 22:08:14,676 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 22:08:14,676 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 22:08:14,676 - INFO - joeynmt.training - \tHypothesis: Yes , the conscience of “ a man of inner ” may be misled .\n",
      "2021-10-09 22:08:14,676 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 22:08:14,676 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 22:08:14,676 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 22:08:14,676 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 22:08:14,676 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 22:08:14,677 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 22:08:14,677 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 22:08:14,677 - INFO - joeynmt.training - \tHypothesis: That will enable us to know the difference between right and wrong and to know differences between foolish and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 22:08:14,677 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 22:08:14,677 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 22:08:14,677 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 22:08:14,677 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met children in Puerto Rico .\n",
      "2021-10-09 22:08:14,677 - INFO - joeynmt.training - Validation result (greedy) at epoch  27, step    33000: bleu:  35.17, loss: 21739.8555, ppl:   2.1581, duration: 74.3463s\n",
      "2021-10-09 22:08:40,610 - INFO - joeynmt.training - Epoch  27, Step:    33100, Batch Loss:     0.835736, Tokens per Sec:    17198, Lr: 0.000172\n",
      "2021-10-09 22:08:54,239 - INFO - joeynmt.training - Epoch  27: total training loss 1009.27\n",
      "2021-10-09 22:08:54,240 - INFO - joeynmt.training - EPOCH 28\n",
      "2021-10-09 22:09:07,691 - INFO - joeynmt.training - Epoch  28, Step:    33200, Batch Loss:     0.814823, Tokens per Sec:    15741, Lr: 0.000172\n",
      "2021-10-09 22:09:33,669 - INFO - joeynmt.training - Epoch  28, Step:    33300, Batch Loss:     0.793830, Tokens per Sec:    17310, Lr: 0.000171\n",
      "2021-10-09 22:09:59,755 - INFO - joeynmt.training - Epoch  28, Step:    33400, Batch Loss:     0.706574, Tokens per Sec:    17179, Lr: 0.000171\n",
      "2021-10-09 22:10:25,735 - INFO - joeynmt.training - Epoch  28, Step:    33500, Batch Loss:     0.867623, Tokens per Sec:    17247, Lr: 0.000171\n",
      "2021-10-09 22:11:37,616 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 22:11:37,617 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 22:11:37,617 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 22:11:39,735 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 22:11:39,735 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 22:11:39,735 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 22:11:39,735 - INFO - joeynmt.training - \tHypothesis: Indeed , the conscience of “ a man of inner flesh ” may be misled .\n",
      "2021-10-09 22:11:39,735 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 22:11:39,736 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 22:11:39,736 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 22:11:39,736 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 22:11:39,736 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 22:11:39,736 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 22:11:39,736 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 22:11:39,736 - INFO - joeynmt.training - \tHypothesis: That will enable us to know the difference between right and wrong and wrong and to know differences between foolish and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 22:11:39,736 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 22:11:39,737 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 22:11:39,737 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 22:11:39,737 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met children in Puerto Rico .\n",
      "2021-10-09 22:11:39,737 - INFO - joeynmt.training - Validation result (greedy) at epoch  28, step    33500: bleu:  35.04, loss: 21766.6758, ppl:   2.1601, duration: 74.0010s\n",
      "2021-10-09 22:12:05,513 - INFO - joeynmt.training - Epoch  28, Step:    33600, Batch Loss:     0.759771, Tokens per Sec:    17078, Lr: 0.000170\n",
      "2021-10-09 22:12:31,237 - INFO - joeynmt.training - Epoch  28, Step:    33700, Batch Loss:     0.801393, Tokens per Sec:    17619, Lr: 0.000170\n",
      "2021-10-09 22:12:55,279 - INFO - joeynmt.training - Epoch  28, Step:    33800, Batch Loss:     0.728541, Tokens per Sec:    19060, Lr: 0.000170\n",
      "2021-10-09 22:13:21,448 - INFO - joeynmt.training - Epoch  28, Step:    33900, Batch Loss:     0.806955, Tokens per Sec:    17257, Lr: 0.000170\n",
      "2021-10-09 22:13:47,459 - INFO - joeynmt.training - Epoch  28, Step:    34000, Batch Loss:     0.883537, Tokens per Sec:    17367, Lr: 0.000169\n",
      "2021-10-09 22:15:00,949 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 22:15:00,950 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 22:15:00,950 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 22:15:01,368 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 22:15:01,369 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 22:15:03,195 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 22:15:03,195 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 22:15:03,195 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 22:15:03,195 - INFO - joeynmt.training - \tHypothesis: Yes , the conscience of “ a man of inner flesh ” may mislead us .\n",
      "2021-10-09 22:15:03,195 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 22:15:03,196 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 22:15:03,196 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 22:15:03,196 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 22:15:03,196 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 22:15:03,196 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 22:15:03,196 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 22:15:03,196 - INFO - joeynmt.training - \tHypothesis: That will enable us to know the difference between right and wrong and wrong and to know differences between foolish and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 22:15:03,197 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 22:15:03,197 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 22:15:03,197 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 22:15:03,197 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met the brothers in Puerto Rico .\n",
      "2021-10-09 22:15:03,197 - INFO - joeynmt.training - Validation result (greedy) at epoch  28, step    34000: bleu:  35.36, loss: 21706.2422, ppl:   2.1555, duration: 75.7372s\n",
      "2021-10-09 22:15:29,119 - INFO - joeynmt.training - Epoch  28, Step:    34100, Batch Loss:     0.786740, Tokens per Sec:    17399, Lr: 0.000169\n",
      "2021-10-09 22:15:55,708 - INFO - joeynmt.training - Epoch  28, Step:    34200, Batch Loss:     0.622799, Tokens per Sec:    17035, Lr: 0.000169\n",
      "2021-10-09 22:16:21,652 - INFO - joeynmt.training - Epoch  28, Step:    34300, Batch Loss:     0.805958, Tokens per Sec:    17198, Lr: 0.000169\n",
      "2021-10-09 22:16:43,453 - INFO - joeynmt.training - Epoch  28: total training loss 1006.80\n",
      "2021-10-09 22:16:43,453 - INFO - joeynmt.training - EPOCH 29\n",
      "2021-10-09 22:16:48,254 - INFO - joeynmt.training - Epoch  29, Step:    34400, Batch Loss:     0.812911, Tokens per Sec:    16708, Lr: 0.000168\n",
      "2021-10-09 22:17:13,164 - INFO - joeynmt.training - Epoch  29, Step:    34500, Batch Loss:     0.912704, Tokens per Sec:    18154, Lr: 0.000168\n",
      "2021-10-09 22:18:25,542 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 22:18:25,543 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 22:18:25,543 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 22:18:25,958 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 22:18:25,958 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 22:18:27,688 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 22:18:27,688 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 22:18:27,688 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 22:18:27,688 - INFO - joeynmt.training - \tHypothesis: Indeed , the conscience of “ a man of inner man ” may mislead us .\n",
      "2021-10-09 22:18:27,688 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 22:18:27,689 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 22:18:27,689 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 22:18:27,689 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 22:18:27,689 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 22:18:27,689 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 22:18:27,689 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 22:18:27,689 - INFO - joeynmt.training - \tHypothesis: That will lead us to know the difference between right and wrong and wrong and to know differences between foolish and discreet and discreet . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 22:18:27,689 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 22:18:27,690 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 22:18:27,690 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 22:18:27,690 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met the brothers in Puerto Rico .\n",
      "2021-10-09 22:18:27,690 - INFO - joeynmt.training - Validation result (greedy) at epoch  29, step    34500: bleu:  35.48, loss: 21616.2539, ppl:   2.1487, duration: 74.5249s\n",
      "2021-10-09 22:18:53,848 - INFO - joeynmt.training - Epoch  29, Step:    34600, Batch Loss:     0.808697, Tokens per Sec:    17705, Lr: 0.000168\n",
      "2021-10-09 22:19:20,606 - INFO - joeynmt.training - Epoch  29, Step:    34700, Batch Loss:     0.824659, Tokens per Sec:    17162, Lr: 0.000168\n",
      "2021-10-09 22:19:46,666 - INFO - joeynmt.training - Epoch  29, Step:    34800, Batch Loss:     0.795784, Tokens per Sec:    17260, Lr: 0.000168\n",
      "2021-10-09 22:20:13,207 - INFO - joeynmt.training - Epoch  29, Step:    34900, Batch Loss:     0.801136, Tokens per Sec:    16711, Lr: 0.000167\n",
      "2021-10-09 22:20:39,003 - INFO - joeynmt.training - Epoch  29, Step:    35000, Batch Loss:     0.849047, Tokens per Sec:    17907, Lr: 0.000167\n",
      "2021-10-09 22:21:49,378 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 22:21:49,378 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 22:21:49,378 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 22:21:49,796 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 22:21:49,796 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 22:21:51,568 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 22:21:51,569 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 22:21:51,569 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 22:21:51,569 - INFO - joeynmt.training - \tHypothesis: Yes , the conscience of “ a man of inner flesh ” may mislead us .\n",
      "2021-10-09 22:21:51,569 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 22:21:51,569 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 22:21:51,569 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 22:21:51,569 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 22:21:51,570 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 22:21:51,570 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 22:21:51,570 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 22:21:51,570 - INFO - joeynmt.training - \tHypothesis: That will lead us to the difference between right and wrong and unrighteous and also to know differences between foolish and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 22:21:51,570 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 22:21:51,570 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 22:21:51,570 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 22:21:51,570 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met children in Puerto Rico .\n",
      "2021-10-09 22:21:51,571 - INFO - joeynmt.training - Validation result (greedy) at epoch  29, step    35000: bleu:  35.54, loss: 21614.8145, ppl:   2.1486, duration: 72.5669s\n",
      "2021-10-09 22:22:16,502 - INFO - joeynmt.training - Epoch  29, Step:    35100, Batch Loss:     0.787185, Tokens per Sec:    17442, Lr: 0.000167\n",
      "2021-10-09 22:22:43,108 - INFO - joeynmt.training - Epoch  29, Step:    35200, Batch Loss:     0.760699, Tokens per Sec:    16991, Lr: 0.000167\n",
      "2021-10-09 22:23:09,078 - INFO - joeynmt.training - Epoch  29, Step:    35300, Batch Loss:     0.855978, Tokens per Sec:    17538, Lr: 0.000166\n",
      "2021-10-09 22:23:34,950 - INFO - joeynmt.training - Epoch  29, Step:    35400, Batch Loss:     0.747710, Tokens per Sec:    16838, Lr: 0.000166\n",
      "2021-10-09 22:24:00,993 - INFO - joeynmt.training - Epoch  29, Step:    35500, Batch Loss:     0.779655, Tokens per Sec:    17644, Lr: 0.000166\n",
      "2021-10-09 22:25:13,624 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 22:25:13,625 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 22:25:13,625 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 22:25:14,044 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 22:25:14,044 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 22:25:15,803 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 22:25:15,803 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 22:25:15,803 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 22:25:15,803 - INFO - joeynmt.training - \tHypothesis: Yes , the conscience of “ a man of inner flesh ” may mislead us .\n",
      "2021-10-09 22:25:15,803 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 22:25:15,804 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 22:25:15,804 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 22:25:15,804 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 22:25:15,804 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 22:25:15,804 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 22:25:15,804 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 22:25:15,804 - INFO - joeynmt.training - \tHypothesis: That will enable us to know the difference between right and wrong and to know differences between foolish and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 22:25:15,804 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 22:25:15,805 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 22:25:15,805 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 22:25:15,805 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met children in Puerto Rico .\n",
      "2021-10-09 22:25:15,805 - INFO - joeynmt.training - Validation result (greedy) at epoch  29, step    35500: bleu:  35.54, loss: 21569.6387, ppl:   2.1451, duration: 74.8115s\n",
      "2021-10-09 22:25:40,691 - INFO - joeynmt.training - Epoch  29, Step:    35600, Batch Loss:     0.809158, Tokens per Sec:    18297, Lr: 0.000166\n",
      "2021-10-09 22:25:43,030 - INFO - joeynmt.training - Epoch  29: total training loss 997.39\n",
      "2021-10-09 22:25:43,031 - INFO - joeynmt.training - EPOCH 30\n",
      "2021-10-09 22:26:07,968 - INFO - joeynmt.training - Epoch  30, Step:    35700, Batch Loss:     0.748328, Tokens per Sec:    16874, Lr: 0.000165\n",
      "2021-10-09 22:26:34,425 - INFO - joeynmt.training - Epoch  30, Step:    35800, Batch Loss:     0.819019, Tokens per Sec:    16709, Lr: 0.000165\n",
      "2021-10-09 22:27:00,167 - INFO - joeynmt.training - Epoch  30, Step:    35900, Batch Loss:     0.840587, Tokens per Sec:    17077, Lr: 0.000165\n",
      "2021-10-09 22:27:26,146 - INFO - joeynmt.training - Epoch  30, Step:    36000, Batch Loss:     0.818451, Tokens per Sec:    17398, Lr: 0.000165\n",
      "2021-10-09 22:28:39,312 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 22:28:39,313 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 22:28:39,313 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 22:28:41,388 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 22:28:41,388 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 22:28:41,388 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 22:28:41,389 - INFO - joeynmt.training - \tHypothesis: Yes , the conscience of “ a man of inner flesh ” may mislead us .\n",
      "2021-10-09 22:28:41,389 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 22:28:41,389 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 22:28:41,389 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 22:28:41,389 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 22:28:41,389 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 22:28:41,389 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 22:28:41,389 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 22:28:41,389 - INFO - joeynmt.training - \tHypothesis: That will enable us to know the difference between right and wrong and wrong and to know the difference between foolish and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 22:28:41,389 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 22:28:41,390 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 22:28:41,390 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 22:28:41,390 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met children in Puerto Rico .\n",
      "2021-10-09 22:28:41,390 - INFO - joeynmt.training - Validation result (greedy) at epoch  30, step    36000: bleu:  35.70, loss: 21604.7559, ppl:   2.1478, duration: 75.2427s\n",
      "2021-10-09 22:29:05,632 - INFO - joeynmt.training - Epoch  30, Step:    36100, Batch Loss:     0.825920, Tokens per Sec:    18386, Lr: 0.000164\n",
      "2021-10-09 22:29:30,950 - INFO - joeynmt.training - Epoch  30, Step:    36200, Batch Loss:     0.861789, Tokens per Sec:    17947, Lr: 0.000164\n",
      "2021-10-09 22:29:56,905 - INFO - joeynmt.training - Epoch  30, Step:    36300, Batch Loss:     0.789696, Tokens per Sec:    17275, Lr: 0.000164\n",
      "2021-10-09 22:30:21,745 - INFO - joeynmt.training - Epoch  30, Step:    36400, Batch Loss:     0.873157, Tokens per Sec:    17901, Lr: 0.000164\n",
      "2021-10-09 22:30:47,578 - INFO - joeynmt.training - Epoch  30, Step:    36500, Batch Loss:     0.722210, Tokens per Sec:    17806, Lr: 0.000164\n",
      "2021-10-09 22:32:00,119 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 22:32:00,119 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 22:32:00,119 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 22:32:00,533 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 22:32:00,534 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 22:32:02,361 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 22:32:02,362 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 22:32:02,362 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 22:32:02,362 - INFO - joeynmt.training - \tHypothesis: Yes , the conscience of “ a man of inside ” may mislead us .\n",
      "2021-10-09 22:32:02,362 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 22:32:02,362 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 22:32:02,362 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 22:32:02,362 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 22:32:02,362 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 22:32:02,363 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 22:32:02,363 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 22:32:02,363 - INFO - joeynmt.training - \tHypothesis: That will enable us to know the difference between right and wrong and wrong and to know differences between foolish and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 22:32:02,363 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 22:32:02,363 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 22:32:02,363 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 22:32:02,363 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met children in Puerto Rico .\n",
      "2021-10-09 22:32:02,363 - INFO - joeynmt.training - Validation result (greedy) at epoch  30, step    36500: bleu:  35.62, loss: 21522.2852, ppl:   2.1415, duration: 74.7848s\n",
      "2021-10-09 22:32:28,448 - INFO - joeynmt.training - Epoch  30, Step:    36600, Batch Loss:     0.806741, Tokens per Sec:    17619, Lr: 0.000163\n",
      "2021-10-09 22:32:53,310 - INFO - joeynmt.training - Epoch  30, Step:    36700, Batch Loss:     0.875949, Tokens per Sec:    18184, Lr: 0.000163\n",
      "2021-10-09 22:33:19,336 - INFO - joeynmt.training - Epoch  30, Step:    36800, Batch Loss:     0.709165, Tokens per Sec:    17279, Lr: 0.000163\n",
      "2021-10-09 22:33:29,472 - INFO - joeynmt.training - Epoch  30: total training loss 995.84\n",
      "2021-10-09 22:33:29,472 - INFO - joeynmt.training - Training ended after  30 epochs.\n",
      "2021-10-09 22:33:29,472 - INFO - joeynmt.training - Best validation result (greedy) at step    36500:   2.14 ppl.\n",
      "2021-10-09 22:33:29,503 - INFO - joeynmt.prediction - Process device: cuda, n_gpu: 2, batch_size per device: 9000 (with beam_size)\n",
      "2021-10-09 22:33:29,734 - INFO - joeynmt.model - Building an encoder-decoder model...\n",
      "2021-10-09 22:33:30,594 - INFO - joeynmt.model - Enc-dec model built.\n",
      "2021-10-09 22:33:30,694 - INFO - joeynmt.prediction - Decoding on dev set (data/veen/dev.bpe.en)...\n",
      "2021-10-09 22:34:45,215 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 22:34:45,215 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 22:34:45,215 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 22:34:45,616 - INFO - joeynmt.prediction -  dev bleu[13a]:  36.42 [Beam search decoding with beam size = 5 and alpha = 1.0]\n",
      "2021-10-09 22:34:45,621 - INFO - joeynmt.prediction - Translations saved to: models/veen_reverse_transformer_first/00036500.hyps.dev\n",
      "2021-10-09 22:34:45,621 - INFO - joeynmt.prediction - Decoding on test set (data/veen/test.bpe.en)...\n",
      "2021-10-09 22:36:46,107 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 22:36:46,108 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 22:36:46,108 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 22:36:46,963 - INFO - joeynmt.prediction - test bleu[13a]:  42.42 [Beam search decoding with beam size = 5 and alpha = 1.0]\n",
      "2021-10-09 22:36:46,972 - INFO - joeynmt.prediction - Translations saved to: models/veen_reverse_transformer_first/00036500.hyps.test\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "# You can press Ctrl-C to stop. And then run the next cell to save your checkpoints! \n",
    "!cd joeynmt; python3 -m joeynmt train configs/transformer_reverse_$tgt$src.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['FILE'] = f\"{os.environ['gdrive_path']}/models/{os.environ['src']}{os.environ['tgt']}_first/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "MBoDS09JM807"
   },
   "outputs": [],
   "source": [
    "# Copy the created models from the notebook storage to google drive for persistant storage\n",
    "!mkdir -p \"$FILE\"\n",
    "\n",
    "!cp -r joeynmt/models/${tgt}${src}_reverse_transformer_first/* \"$FILE\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n94wlrCjVc17",
    "outputId": "bb8462a5-241e-4b73-e9a8-3096816d0151",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps: 500\tLoss: 65836.41406\tPPL: 10.27284\tbleu: 0.04423\tLR: 0.00049411\t*\n",
      "Steps: 1000\tLoss: 52995.42969\tPPL: 6.52178\tbleu: 3.34765\tLR: 0.00098821\t*\n",
      "Steps: 1500\tLoss: 43618.91797\tPPL: 4.68037\tbleu: 12.14845\tLR: 0.00080687\t*\n",
      "Steps: 2000\tLoss: 39516.89453\tPPL: 4.04805\tbleu: 14.60299\tLR: 0.00069877\t*\n",
      "Steps: 2500\tLoss: 37229.36719\tPPL: 3.73331\tbleu: 16.51895\tLR: 0.00062500\t*\n",
      "Steps: 3000\tLoss: 35082.86719\tPPL: 3.46026\tbleu: 19.81935\tLR: 0.00057054\t*\n",
      "Steps: 3500\tLoss: 33461.75000\tPPL: 3.26736\tbleu: 20.98494\tLR: 0.00052822\t*\n",
      "Steps: 4000\tLoss: 32055.19727\tPPL: 3.10873\tbleu: 23.04268\tLR: 0.00049411\t*\n",
      "Steps: 4500\tLoss: 31113.91797\tPPL: 3.00690\tbleu: 23.87975\tLR: 0.00046585\t*\n",
      "Steps: 5000\tLoss: 30167.18359\tPPL: 2.90784\tbleu: 25.36679\tLR: 0.00044194\t*\n",
      "Steps: 5500\tLoss: 29528.31641\tPPL: 2.84285\tbleu: 25.67867\tLR: 0.00042137\t*\n",
      "Steps: 6000\tLoss: 28828.91406\tPPL: 2.77336\tbleu: 26.88260\tLR: 0.00040344\t*\n",
      "Steps: 6500\tLoss: 28289.84570\tPPL: 2.72096\tbleu: 27.51473\tLR: 0.00038761\t*\n",
      "Steps: 7000\tLoss: 27854.03711\tPPL: 2.67933\tbleu: 28.29880\tLR: 0.00037351\t*\n",
      "Steps: 7500\tLoss: 27349.57227\tPPL: 2.63192\tbleu: 28.46387\tLR: 0.00036084\t*\n",
      "Steps: 8000\tLoss: 27033.08203\tPPL: 2.60262\tbleu: 28.76278\tLR: 0.00034939\t*\n",
      "Steps: 8500\tLoss: 26791.65625\tPPL: 2.58048\tbleu: 29.15038\tLR: 0.00033895\t*\n",
      "Steps: 9000\tLoss: 26420.72461\tPPL: 2.54683\tbleu: 29.51505\tLR: 0.00032940\t*\n",
      "Steps: 9500\tLoss: 26167.12500\tPPL: 2.52408\tbleu: 29.77782\tLR: 0.00032062\t*\n",
      "Steps: 10000\tLoss: 25944.05273\tPPL: 2.50424\tbleu: 29.97554\tLR: 0.00031250\t*\n",
      "Steps: 10500\tLoss: 25608.01367\tPPL: 2.47464\tbleu: 30.33681\tLR: 0.00030497\t*\n",
      "Steps: 11000\tLoss: 25435.76758\tPPL: 2.45960\tbleu: 30.51964\tLR: 0.00029796\t*\n",
      "Steps: 11500\tLoss: 25304.39844\tPPL: 2.44819\tbleu: 30.46971\tLR: 0.00029141\t*\n",
      "Steps: 12000\tLoss: 24962.78906\tPPL: 2.41878\tbleu: 30.86010\tLR: 0.00028527\t*\n",
      "Steps: 12500\tLoss: 24869.57812\tPPL: 2.41082\tbleu: 31.05545\tLR: 0.00027951\t*\n",
      "Steps: 13000\tLoss: 24670.37109\tPPL: 2.39388\tbleu: 31.19541\tLR: 0.00027408\t*\n",
      "Steps: 13500\tLoss: 24521.06055\tPPL: 2.38127\tbleu: 31.43018\tLR: 0.00026896\t*\n",
      "Steps: 14000\tLoss: 24415.43164\tPPL: 2.37239\tbleu: 31.37051\tLR: 0.00026411\t*\n",
      "Steps: 14500\tLoss: 24216.12695\tPPL: 2.35571\tbleu: 31.52288\tLR: 0.00025952\t*\n",
      "Steps: 15000\tLoss: 24195.30273\tPPL: 2.35398\tbleu: 32.00693\tLR: 0.00025516\t*\n",
      "Steps: 15500\tLoss: 24056.72070\tPPL: 2.34246\tbleu: 31.98436\tLR: 0.00025101\t*\n",
      "Steps: 16000\tLoss: 23911.10547\tPPL: 2.33043\tbleu: 32.04414\tLR: 0.00024705\t*\n",
      "Steps: 16500\tLoss: 23850.94727\tPPL: 2.32547\tbleu: 32.26943\tLR: 0.00024328\t*\n",
      "Steps: 17000\tLoss: 23671.10547\tPPL: 2.31072\tbleu: 32.39678\tLR: 0.00023968\t*\n",
      "Steps: 17500\tLoss: 23644.35547\tPPL: 2.30853\tbleu: 32.58011\tLR: 0.00023623\t*\n",
      "Steps: 18000\tLoss: 23553.65625\tPPL: 2.30114\tbleu: 32.71348\tLR: 0.00023292\t*\n",
      "Steps: 18500\tLoss: 23412.37109\tPPL: 2.28966\tbleu: 32.85099\tLR: 0.00022975\t*\n",
      "Steps: 19000\tLoss: 23343.52930\tPPL: 2.28409\tbleu: 33.01081\tLR: 0.00022671\t*\n",
      "Steps: 19500\tLoss: 23224.87109\tPPL: 2.27452\tbleu: 33.16833\tLR: 0.00022379\t*\n",
      "Steps: 20000\tLoss: 23121.75195\tPPL: 2.26624\tbleu: 33.41535\tLR: 0.00022097\t*\n",
      "Steps: 20500\tLoss: 23031.89258\tPPL: 2.25904\tbleu: 33.56530\tLR: 0.00021826\t*\n",
      "Steps: 21000\tLoss: 23104.00977\tPPL: 2.26482\tbleu: 33.48072\tLR: 0.00021565\t\n",
      "Steps: 21500\tLoss: 22949.34375\tPPL: 2.25246\tbleu: 33.41844\tLR: 0.00021312\t*\n",
      "Steps: 22000\tLoss: 22805.79883\tPPL: 2.24104\tbleu: 33.86451\tLR: 0.00021069\t*\n",
      "Steps: 22500\tLoss: 22805.94727\tPPL: 2.24106\tbleu: 33.81690\tLR: 0.00020833\t\n",
      "Steps: 23000\tLoss: 22770.76367\tPPL: 2.23827\tbleu: 33.93948\tLR: 0.00020606\t*\n",
      "Steps: 23500\tLoss: 22644.90430\tPPL: 2.22832\tbleu: 33.93119\tLR: 0.00020385\t*\n",
      "Steps: 24000\tLoss: 22595.13281\tPPL: 2.22440\tbleu: 34.11342\tLR: 0.00020172\t*\n",
      "Steps: 24500\tLoss: 22565.40234\tPPL: 2.22206\tbleu: 33.78215\tLR: 0.00019965\t*\n",
      "Steps: 25000\tLoss: 22514.66602\tPPL: 2.21808\tbleu: 34.38157\tLR: 0.00019764\t*\n",
      "Steps: 25500\tLoss: 22410.71289\tPPL: 2.20993\tbleu: 34.22569\tLR: 0.00019570\t*\n",
      "Steps: 26000\tLoss: 22378.50391\tPPL: 2.20742\tbleu: 34.37007\tLR: 0.00019380\t*\n",
      "Steps: 26500\tLoss: 22354.04492\tPPL: 2.20551\tbleu: 34.36357\tLR: 0.00019197\t*\n",
      "Steps: 27000\tLoss: 22294.87891\tPPL: 2.20090\tbleu: 34.64000\tLR: 0.00019018\t*\n",
      "Steps: 27500\tLoss: 22240.02539\tPPL: 2.19663\tbleu: 34.58764\tLR: 0.00018844\t*\n",
      "Steps: 28000\tLoss: 22223.36523\tPPL: 2.19533\tbleu: 34.57242\tLR: 0.00018675\t*\n",
      "Steps: 28500\tLoss: 22159.66406\tPPL: 2.19039\tbleu: 34.65662\tLR: 0.00018511\t*\n",
      "Steps: 29000\tLoss: 22076.38477\tPPL: 2.18395\tbleu: 34.87124\tLR: 0.00018351\t*\n",
      "Steps: 29500\tLoss: 22066.42383\tPPL: 2.18318\tbleu: 34.45542\tLR: 0.00018194\t*\n",
      "Steps: 30000\tLoss: 22022.54883\tPPL: 2.17979\tbleu: 34.78803\tLR: 0.00018042\t*\n",
      "Steps: 30500\tLoss: 21906.15430\tPPL: 2.17083\tbleu: 34.87412\tLR: 0.00017894\t*\n",
      "Steps: 31000\tLoss: 21963.94727\tPPL: 2.17527\tbleu: 35.07911\tLR: 0.00017749\t\n",
      "Steps: 31500\tLoss: 21893.38672\tPPL: 2.16985\tbleu: 35.21341\tLR: 0.00017607\t*\n",
      "Steps: 32000\tLoss: 21840.29492\tPPL: 2.16578\tbleu: 35.33719\tLR: 0.00017469\t*\n",
      "Steps: 32500\tLoss: 21825.20508\tPPL: 2.16462\tbleu: 35.38612\tLR: 0.00017334\t*\n",
      "Steps: 33000\tLoss: 21739.85547\tPPL: 2.15809\tbleu: 35.16586\tLR: 0.00017203\t*\n",
      "Steps: 33500\tLoss: 21766.67578\tPPL: 2.16014\tbleu: 35.04353\tLR: 0.00017074\t\n",
      "Steps: 34000\tLoss: 21706.24219\tPPL: 2.15553\tbleu: 35.36369\tLR: 0.00016948\t*\n",
      "Steps: 34500\tLoss: 21616.25391\tPPL: 2.14868\tbleu: 35.47548\tLR: 0.00016824\t*\n",
      "Steps: 35000\tLoss: 21614.81445\tPPL: 2.14857\tbleu: 35.54380\tLR: 0.00016704\t*\n",
      "Steps: 35500\tLoss: 21569.63867\tPPL: 2.14514\tbleu: 35.53996\tLR: 0.00016586\t*\n",
      "Steps: 36000\tLoss: 21604.75586\tPPL: 2.14780\tbleu: 35.69683\tLR: 0.00016470\t\n",
      "Steps: 36500\tLoss: 21522.28516\tPPL: 2.14154\tbleu: 35.61815\tLR: 0.00016357\t*\n"
     ]
    }
   ],
   "source": [
    "# Output our validation accuracy\n",
    "! cat \"$FILE/validations.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "66WhRE9lIhoD",
    "outputId": "b4297dba-67ae-48be-9068-4a0e92c4f98e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-09 22:36:59,349 - INFO - root - Hello! This is Joey-NMT (version 1.3).\n",
      "2021-10-09 22:36:59,351 - INFO - joeynmt.data - Building vocabulary...\n",
      "2021-10-09 22:36:59,630 - INFO - joeynmt.data - Loading dev data...\n",
      "2021-10-09 22:36:59,646 - INFO - joeynmt.data - Loading test data...\n",
      "2021-10-09 22:36:59,680 - INFO - joeynmt.data - Data loaded.\n",
      "2021-10-09 22:36:59,738 - INFO - joeynmt.prediction - Process device: cuda, n_gpu: 2, batch_size per device: 9000 (with beam_size)\n",
      "2021-10-09 22:37:02,841 - INFO - joeynmt.model - Building an encoder-decoder model...\n",
      "2021-10-09 22:37:03,130 - INFO - joeynmt.model - Enc-dec model built.\n",
      "2021-10-09 22:37:03,232 - INFO - joeynmt.prediction - Decoding on dev set (data/veen/dev.bpe.en)...\n",
      "2021-10-09 22:38:19,866 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 22:38:19,866 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 22:38:19,866 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 22:38:20,283 - INFO - joeynmt.prediction -  dev bleu[13a]:  36.42 [Beam search decoding with beam size = 5 and alpha = 1.0]\n",
      "2021-10-09 22:38:20,283 - INFO - joeynmt.prediction - Decoding on test set (data/veen/test.bpe.en)...\n",
      "2021-10-09 22:40:20,025 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 22:40:20,026 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 22:40:20,026 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 22:40:21,046 - INFO - joeynmt.prediction - test bleu[13a]:  42.42 [Beam search decoding with beam size = 5 and alpha = 1.0]\n"
     ]
    }
   ],
   "source": [
    "# Test our model\n",
    "! cd joeynmt; python3 -m joeynmt test ../\"$FILE/config.yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try and experiment with the parameters => Make the model bigger.\n",
    "\n",
    "\n",
    "Here we implement some of the suggestions for the configuration, and generally increase the size of the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates the config file for our JoeyNMT system. It might seem overwhelming so we've provided a couple of useful parameters you'll need to update\n",
    "# (You can of course play with all the parameters if you'd like!)\n",
    "\n",
    "name = '%s%s' % (target_language, source_language)\n",
    "# gdrive_path = os.environ[\"gdrive_path\"]\n",
    "\n",
    "# Create the config\n",
    "config = \"\"\"\n",
    "name: \"{target_language}{source_language}_reverse_transformer\"\n",
    "\n",
    "data:\n",
    "    src: \"{target_language}\"\n",
    "    trg: \"{source_language}\"\n",
    "    train: \"data/{name}/train.bpe\"\n",
    "    dev:   \"data/{name}/dev.bpe\"\n",
    "    test:  \"data/{name}/test.bpe\"\n",
    "    level: \"bpe\"\n",
    "    lowercase: False\n",
    "    max_sent_length: 100\n",
    "    src_vocab: \"data/{name}/vocab.txt\"\n",
    "    trg_vocab: \"data/{name}/vocab.txt\"\n",
    "\n",
    "testing:\n",
    "    beam_size: 5\n",
    "    alpha: 1.0\n",
    "\n",
    "training:\n",
    "    random_seed: 42\n",
    "    optimizer: \"adam\"\n",
    "    normalization: \"tokens\"\n",
    "    adam_betas: [0.9, 0.999] \n",
    "    scheduling: \"noam\"           # TODO: try switching from plateau to Noam scheduling\n",
    "    patience: 5                     # For plateau: decrease learning rate by decrease_factor if validation score has not improved for this many validation rounds.\n",
    "    learning_rate_factor: 0.5       # factor for Noam scheduler (used with Transformer)\n",
    "    learning_rate_warmup: 1000      # warmup steps for Noam scheduler (used with Transformer)\n",
    "    decrease_factor: 0.7\n",
    "    loss: \"crossentropy\"\n",
    "    learning_rate: 0.0003\n",
    "    learning_rate_min: 0.00000001\n",
    "    weight_decay: 0.0\n",
    "    label_smoothing: 0.1\n",
    "    batch_size: 8192\n",
    "    batch_type: \"token\"\n",
    "    eval_batch_size: 3600\n",
    "    eval_batch_type: \"token\"\n",
    "    batch_multiplier: 1\n",
    "    early_stopping_metric: \"ppl\"\n",
    "    epochs: 100                  # TODO: Decrease for when playing around and checking of working. Around 30 is sufficient to check if its working at all\n",
    "    validation_freq: 500          # TODO: Set to at least once per epoch.\n",
    "    logging_freq: 100\n",
    "    eval_metric: \"bleu\"\n",
    "    model_dir: \"models/{name}_reverse_transformer_second\"\n",
    "    overwrite: True              # TODO: Set to True if you want to overwrite possibly existing models. \n",
    "    shuffle: True\n",
    "    use_cuda: True\n",
    "    max_output_length: 100\n",
    "    print_valid_sents: [0, 1, 2, 3]\n",
    "    keep_last_ckpts: 3\n",
    "\n",
    "model:\n",
    "    initializer: \"xavier\"\n",
    "    bias_initializer: \"zeros\"\n",
    "    init_gain: 1.0\n",
    "    embed_initializer: \"xavier\"\n",
    "    embed_init_gain: 1.0\n",
    "    tied_embeddings: True\n",
    "    tied_softmax: True\n",
    "    encoder:\n",
    "        type: \"transformer\"\n",
    "        num_layers: 6\n",
    "        num_heads: 8             # TODO: Increase to 8 for larger data.\n",
    "        embeddings:\n",
    "            embedding_dim: 512   # TODO: Increase to 512 for larger data.\n",
    "            scale: True\n",
    "            dropout: 0.2\n",
    "        # typically ff_size = 4 x hidden_size\n",
    "        hidden_size: 512         # TODO: Increase to 512 for larger data.\n",
    "        ff_size: 2048            # TODO: Increase to 2048 for larger data.\n",
    "        dropout: 0.3\n",
    "    decoder:\n",
    "        type: \"transformer\"\n",
    "        num_layers: 6\n",
    "        num_heads: 8              # TODO: Increase to 8 for larger data.\n",
    "        embeddings:\n",
    "            embedding_dim: 512    # TODO: Increase to 512 for larger data.\n",
    "            scale: True\n",
    "            dropout: 0.2\n",
    "        # typically ff_size = 4 x hidden_size\n",
    "        hidden_size: 512         # TODO: Increase to 512 for larger data.\n",
    "        ff_size: 2048            # TODO: Increase to 2048 for larger data.\n",
    "        dropout: 0.3\n",
    "\"\"\".format(name=name, gdriv=e_path=os.environ[\"gdrive_path\"], source_language=source_language, target_language=target_language)\n",
    "with open(\"joeynmt/configs/transformer_reverse_{name}.yaml\".format(name=name),'w') as f:\n",
    "    f.write(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-09 22:40:24,442 - INFO - root - Hello! This is Joey-NMT (version 1.3).\n",
      "2021-10-09 22:40:24,505 - INFO - joeynmt.data - Loading training data...\n",
      "2021-10-09 22:40:28,778 - INFO - joeynmt.data - Building vocabulary...\n",
      "2021-10-09 22:40:29,063 - INFO - joeynmt.data - Loading dev data...\n",
      "2021-10-09 22:40:29,086 - INFO - joeynmt.data - Loading test data...\n",
      "2021-10-09 22:40:29,131 - INFO - joeynmt.data - Data loaded.\n",
      "2021-10-09 22:40:29,131 - INFO - joeynmt.model - Building an encoder-decoder model...\n",
      "2021-10-09 22:40:30,115 - INFO - joeynmt.model - Enc-dec model built.\n",
      "2021-10-09 22:40:30,130 - INFO - joeynmt.training - Total params: 46325248\n",
      "2021-10-09 22:40:33,162 - INFO - joeynmt.helpers - cfg.name                           : veen_reverse_transformer\n",
      "2021-10-09 22:40:33,162 - INFO - joeynmt.helpers - cfg.data.src                       : ve\n",
      "2021-10-09 22:40:33,162 - INFO - joeynmt.helpers - cfg.data.trg                       : en\n",
      "2021-10-09 22:40:33,163 - INFO - joeynmt.helpers - cfg.data.train                     : data/veen/train.bpe\n",
      "2021-10-09 22:40:33,163 - INFO - joeynmt.helpers - cfg.data.dev                       : data/veen/dev.bpe\n",
      "2021-10-09 22:40:33,163 - INFO - joeynmt.helpers - cfg.data.test                      : data/veen/test.bpe\n",
      "2021-10-09 22:40:33,163 - INFO - joeynmt.helpers - cfg.data.level                     : bpe\n",
      "2021-10-09 22:40:33,163 - INFO - joeynmt.helpers - cfg.data.lowercase                 : False\n",
      "2021-10-09 22:40:33,164 - INFO - joeynmt.helpers - cfg.data.max_sent_length           : 100\n",
      "2021-10-09 22:40:33,164 - INFO - joeynmt.helpers - cfg.data.src_vocab                 : data/veen/vocab.txt\n",
      "2021-10-09 22:40:33,164 - INFO - joeynmt.helpers - cfg.data.trg_vocab                 : data/veen/vocab.txt\n",
      "2021-10-09 22:40:33,164 - INFO - joeynmt.helpers - cfg.testing.beam_size              : 5\n",
      "2021-10-09 22:40:33,165 - INFO - joeynmt.helpers - cfg.testing.alpha                  : 1.0\n",
      "2021-10-09 22:40:33,165 - INFO - joeynmt.helpers - cfg.training.random_seed           : 42\n",
      "2021-10-09 22:40:33,165 - INFO - joeynmt.helpers - cfg.training.optimizer             : adam\n",
      "2021-10-09 22:40:33,165 - INFO - joeynmt.helpers - cfg.training.normalization         : tokens\n",
      "2021-10-09 22:40:33,165 - INFO - joeynmt.helpers - cfg.training.adam_betas            : [0.9, 0.999]\n",
      "2021-10-09 22:40:33,166 - INFO - joeynmt.helpers - cfg.training.scheduling            : noam\n",
      "2021-10-09 22:40:33,166 - INFO - joeynmt.helpers - cfg.training.patience              : 5\n",
      "2021-10-09 22:40:33,166 - INFO - joeynmt.helpers - cfg.training.learning_rate_factor  : 0.5\n",
      "2021-10-09 22:40:33,166 - INFO - joeynmt.helpers - cfg.training.learning_rate_warmup  : 1000\n",
      "2021-10-09 22:40:33,166 - INFO - joeynmt.helpers - cfg.training.decrease_factor       : 0.7\n",
      "2021-10-09 22:40:33,167 - INFO - joeynmt.helpers - cfg.training.loss                  : crossentropy\n",
      "2021-10-09 22:40:33,167 - INFO - joeynmt.helpers - cfg.training.learning_rate         : 0.0003\n",
      "2021-10-09 22:40:33,167 - INFO - joeynmt.helpers - cfg.training.learning_rate_min     : 1e-08\n",
      "2021-10-09 22:40:33,167 - INFO - joeynmt.helpers - cfg.training.weight_decay          : 0.0\n",
      "2021-10-09 22:40:33,167 - INFO - joeynmt.helpers - cfg.training.label_smoothing       : 0.1\n",
      "2021-10-09 22:40:33,168 - INFO - joeynmt.helpers - cfg.training.batch_size            : 8192\n",
      "2021-10-09 22:40:33,168 - INFO - joeynmt.helpers - cfg.training.batch_type            : token\n",
      "2021-10-09 22:40:33,168 - INFO - joeynmt.helpers - cfg.training.eval_batch_size       : 3600\n",
      "2021-10-09 22:40:33,168 - INFO - joeynmt.helpers - cfg.training.eval_batch_type       : token\n",
      "2021-10-09 22:40:33,169 - INFO - joeynmt.helpers - cfg.training.batch_multiplier      : 1\n",
      "2021-10-09 22:40:33,169 - INFO - joeynmt.helpers - cfg.training.early_stopping_metric : ppl\n",
      "2021-10-09 22:40:33,169 - INFO - joeynmt.helpers - cfg.training.epochs                : 100\n",
      "2021-10-09 22:40:33,169 - INFO - joeynmt.helpers - cfg.training.validation_freq       : 500\n",
      "2021-10-09 22:40:33,169 - INFO - joeynmt.helpers - cfg.training.logging_freq          : 100\n",
      "2021-10-09 22:40:33,169 - INFO - joeynmt.helpers - cfg.training.eval_metric           : bleu\n",
      "2021-10-09 22:40:33,170 - INFO - joeynmt.helpers - cfg.training.model_dir             : models/veen_reverse_transformer_second\n",
      "2021-10-09 22:40:33,170 - INFO - joeynmt.helpers - cfg.training.overwrite             : True\n",
      "2021-10-09 22:40:33,170 - INFO - joeynmt.helpers - cfg.training.shuffle               : True\n",
      "2021-10-09 22:40:33,170 - INFO - joeynmt.helpers - cfg.training.use_cuda              : True\n",
      "2021-10-09 22:40:33,170 - INFO - joeynmt.helpers - cfg.training.max_output_length     : 100\n",
      "2021-10-09 22:40:33,171 - INFO - joeynmt.helpers - cfg.training.print_valid_sents     : [0, 1, 2, 3]\n",
      "2021-10-09 22:40:33,171 - INFO - joeynmt.helpers - cfg.training.keep_last_ckpts       : 3\n",
      "2021-10-09 22:40:33,171 - INFO - joeynmt.helpers - cfg.model.initializer              : xavier\n",
      "2021-10-09 22:40:33,171 - INFO - joeynmt.helpers - cfg.model.bias_initializer         : zeros\n",
      "2021-10-09 22:40:33,172 - INFO - joeynmt.helpers - cfg.model.init_gain                : 1.0\n",
      "2021-10-09 22:40:33,172 - INFO - joeynmt.helpers - cfg.model.embed_initializer        : xavier\n",
      "2021-10-09 22:40:33,172 - INFO - joeynmt.helpers - cfg.model.embed_init_gain          : 1.0\n",
      "2021-10-09 22:40:33,172 - INFO - joeynmt.helpers - cfg.model.tied_embeddings          : True\n",
      "2021-10-09 22:40:33,172 - INFO - joeynmt.helpers - cfg.model.tied_softmax             : True\n",
      "2021-10-09 22:40:33,173 - INFO - joeynmt.helpers - cfg.model.encoder.type             : transformer\n",
      "2021-10-09 22:40:33,173 - INFO - joeynmt.helpers - cfg.model.encoder.num_layers       : 6\n",
      "2021-10-09 22:40:33,173 - INFO - joeynmt.helpers - cfg.model.encoder.num_heads        : 8\n",
      "2021-10-09 22:40:33,173 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.embedding_dim : 512\n",
      "2021-10-09 22:40:33,173 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.scale : True\n",
      "2021-10-09 22:40:33,174 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.dropout : 0.2\n",
      "2021-10-09 22:40:33,174 - INFO - joeynmt.helpers - cfg.model.encoder.hidden_size      : 512\n",
      "2021-10-09 22:40:33,174 - INFO - joeynmt.helpers - cfg.model.encoder.ff_size          : 2048\n",
      "2021-10-09 22:40:33,174 - INFO - joeynmt.helpers - cfg.model.encoder.dropout          : 0.3\n",
      "2021-10-09 22:40:33,174 - INFO - joeynmt.helpers - cfg.model.decoder.type             : transformer\n",
      "2021-10-09 22:40:33,175 - INFO - joeynmt.helpers - cfg.model.decoder.num_layers       : 6\n",
      "2021-10-09 22:40:33,175 - INFO - joeynmt.helpers - cfg.model.decoder.num_heads        : 8\n",
      "2021-10-09 22:40:33,175 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.embedding_dim : 512\n",
      "2021-10-09 22:40:33,175 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.scale : True\n",
      "2021-10-09 22:40:33,175 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.dropout : 0.2\n",
      "2021-10-09 22:40:33,175 - INFO - joeynmt.helpers - cfg.model.decoder.hidden_size      : 512\n",
      "2021-10-09 22:40:33,175 - INFO - joeynmt.helpers - cfg.model.decoder.ff_size          : 2048\n",
      "2021-10-09 22:40:33,176 - INFO - joeynmt.helpers - cfg.model.decoder.dropout          : 0.3\n",
      "2021-10-09 22:40:33,176 - INFO - joeynmt.helpers - Data set sizes: \n",
      "\ttrain 201103,\n",
      "\tvalid 1000,\n",
      "\ttest 2719\n",
      "2021-10-09 22:40:33,176 - INFO - joeynmt.helpers - First training example:\n",
      "\t[SRC] Nga ṅwambo wa uri ndangulo ya Mudzimu i khou aluwa , “ mukoma a fulufhedzeaho ” o vhea vhanna vha fan@@ eleaho vha “ dziṅwe nngu ” dza Yesu sa vhal@@ a@@ vhelesi . — Luka 12 : 42 - 44 ; Yohane 10 : 16 .\n",
      "\t[TRG] Because God ’ s organization has gro@@ wn , “ the faithful ste@@ ward ” has also appointed qu@@ ali@@ fied men of Jesus ’ “ other sheep ” as overse@@ er@@ s. — Luke 12 : 4@@ 2-@@ 44 ; John 10 : 16 .\n",
      "2021-10-09 22:40:33,176 - INFO - joeynmt.helpers - First 10 words (src): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) . (5) , (6) a (7) u (8) vha (9) the\n",
      "2021-10-09 22:40:33,176 - INFO - joeynmt.helpers - First 10 words (trg): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) . (5) , (6) a (7) u (8) vha (9) the\n",
      "2021-10-09 22:40:33,176 - INFO - joeynmt.helpers - Number of Src words (types): 4267\n",
      "2021-10-09 22:40:33,176 - INFO - joeynmt.helpers - Number of Trg words (types): 4267\n",
      "2021-10-09 22:40:33,176 - INFO - joeynmt.training - Model(\n",
      "\tencoder=TransformerEncoder(num_layers=6, num_heads=8),\n",
      "\tdecoder=TransformerDecoder(num_layers=6, num_heads=8),\n",
      "\tsrc_embed=Embeddings(embedding_dim=512, vocab_size=4267),\n",
      "\ttrg_embed=Embeddings(embedding_dim=512, vocab_size=4267))\n",
      "2021-10-09 22:40:33,233 - INFO - joeynmt.training - Train stats:\n",
      "\tdevice: cuda\n",
      "\tn_gpu: 2\n",
      "\t16-bits training: False\n",
      "\tgradient accumulation: 1\n",
      "\tbatch size per device: 4096\n",
      "\ttotal batch size (w. parallel & accumulation): 8192\n",
      "2021-10-09 22:40:33,233 - INFO - joeynmt.training - EPOCH 1\n",
      "/home-mscluster/mbeukman/anaconda3/envs/nlp_q2/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "2021-10-09 22:41:30,190 - INFO - joeynmt.training - Epoch   1, Step:      100, Batch Loss:     2.869401, Tokens per Sec:     7979, Lr: 0.000070\n",
      "2021-10-09 22:42:24,435 - INFO - joeynmt.training - Epoch   1, Step:      200, Batch Loss:     2.664483, Tokens per Sec:     8199, Lr: 0.000140\n",
      "2021-10-09 22:43:18,246 - INFO - joeynmt.training - Epoch   1, Step:      300, Batch Loss:     2.639706, Tokens per Sec:     8399, Lr: 0.000210\n",
      "2021-10-09 22:44:11,282 - INFO - joeynmt.training - Epoch   1, Step:      400, Batch Loss:     2.464817, Tokens per Sec:     8380, Lr: 0.000280\n",
      "2021-10-09 22:45:04,902 - INFO - joeynmt.training - Epoch   1, Step:      500, Batch Loss:     2.163641, Tokens per Sec:     8330, Lr: 0.000349\n",
      "2021-10-09 22:48:04,072 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 22:48:04,073 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 22:48:04,073 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 22:48:04,498 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 22:48:04,498 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 22:48:10,681 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 22:48:10,682 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 22:48:10,682 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 22:48:10,682 - INFO - joeynmt.training - \tHypothesis: “ The Bible , he is the Bible , ” is the Bible . ”\n",
      "2021-10-09 22:48:10,682 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 22:48:10,682 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 22:48:10,682 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 22:48:10,682 - INFO - joeynmt.training - \tHypothesis: How can we do we do ?\n",
      "2021-10-09 22:48:10,682 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 22:48:10,683 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 22:48:10,683 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 22:48:10,683 - INFO - joeynmt.training - \tHypothesis: The Bible : “ The Bible : “ The Bible : “ Jehovah ’ s Word , we have be be be be be be be be to be be be be be be to be be be to be be be to be him . — 1 : 4 : 4 : 17 .\n",
      "2021-10-09 22:48:10,683 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 22:48:10,683 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 22:48:10,683 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 22:48:10,683 - INFO - joeynmt.training - \tHypothesis: The Bible , I was a sttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt@@\n",
      "2021-10-09 22:48:10,683 - INFO - joeynmt.training - Validation result (greedy) at epoch   1, step      500: bleu:   0.51, loss: 62454.5391, ppl:   9.1143, duration: 185.7808s\n",
      "2021-10-09 22:49:04,543 - INFO - joeynmt.training - Epoch   1, Step:      600, Batch Loss:     1.904595, Tokens per Sec:     8455, Lr: 0.000419\n",
      "2021-10-09 22:49:58,523 - INFO - joeynmt.training - Epoch   1, Step:      700, Batch Loss:     2.010003, Tokens per Sec:     8497, Lr: 0.000489\n",
      "2021-10-09 22:50:53,769 - INFO - joeynmt.training - Epoch   1, Step:      800, Batch Loss:     1.969702, Tokens per Sec:     8370, Lr: 0.000559\n",
      "2021-10-09 22:51:48,175 - INFO - joeynmt.training - Epoch   1, Step:      900, Batch Loss:     1.829710, Tokens per Sec:     8389, Lr: 0.000629\n",
      "2021-10-09 22:52:42,282 - INFO - joeynmt.training - Epoch   1, Step:     1000, Batch Loss:     1.722535, Tokens per Sec:     8344, Lr: 0.000699\n",
      "2021-10-09 22:55:33,509 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 22:55:33,509 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 22:55:33,510 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 22:55:33,981 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 22:55:33,981 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 22:55:40,092 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 22:55:40,092 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 22:55:40,092 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 22:55:40,093 - INFO - joeynmt.training - \tHypothesis: Yes , the help of the “ great tribulation ” is “ a great man ” and “ the end of the heart of the heart of the heart of the heart .\n",
      "2021-10-09 22:55:40,093 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 22:55:40,093 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 22:55:40,093 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 22:55:40,093 - INFO - joeynmt.training - \tHypothesis: • How can we learn from Jesus ’ disciples to his disciples ?\n",
      "2021-10-09 22:55:40,093 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 22:55:40,093 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 22:55:40,093 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 22:55:40,094 - INFO - joeynmt.training - \tHypothesis: It will be sure that we will be a great great tribulation of the world and to be a great tribulation of the world and to be a great tribulation of the world . — 1 Corinthians 5 : 15 ; 1 : 15 ; 1 : 16 .\n",
      "2021-10-09 22:55:40,094 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 22:55:40,094 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 22:55:40,094 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 22:55:40,094 - INFO - joeynmt.training - \tHypothesis: Then , I had been a bried of the church of the family of the Sarch of the Sarea of the Sarah .\n",
      "2021-10-09 22:55:40,094 - INFO - joeynmt.training - Validation result (greedy) at epoch   1, step     1000: bleu:   4.98, loss: 47953.6094, ppl:   5.4562, duration: 177.8109s\n",
      "2021-10-09 22:56:33,294 - INFO - joeynmt.training - Epoch   1, Step:     1100, Batch Loss:     1.828969, Tokens per Sec:     8366, Lr: 0.000666\n",
      "2021-10-09 22:57:26,755 - INFO - joeynmt.training - Epoch   1, Step:     1200, Batch Loss:     1.640811, Tokens per Sec:     8364, Lr: 0.000638\n",
      "2021-10-09 22:57:41,552 - INFO - joeynmt.training - Epoch   1: total training loss 2693.17\n",
      "2021-10-09 22:57:41,553 - INFO - joeynmt.training - EPOCH 2\n",
      "2021-10-09 22:58:22,151 - INFO - joeynmt.training - Epoch   2, Step:     1300, Batch Loss:     1.565477, Tokens per Sec:     8168, Lr: 0.000613\n",
      "2021-10-09 22:59:16,054 - INFO - joeynmt.training - Epoch   2, Step:     1400, Batch Loss:     1.317938, Tokens per Sec:     8525, Lr: 0.000591\n",
      "2021-10-09 23:00:10,099 - INFO - joeynmt.training - Epoch   2, Step:     1500, Batch Loss:     1.540588, Tokens per Sec:     8350, Lr: 0.000571\n",
      "2021-10-09 23:02:08,076 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 23:02:08,076 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 23:02:08,076 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 23:02:08,496 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 23:02:08,496 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 23:02:14,679 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 23:02:14,679 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 23:02:14,679 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 23:02:14,679 - INFO - joeynmt.training - \tHypothesis: Of course , the conscience “ a man ” can be “ a person .\n",
      "2021-10-09 23:02:14,680 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 23:02:14,680 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 23:02:14,680 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 23:02:14,680 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from Jesus ’ teachings to the disciples ?\n",
      "2021-10-09 23:02:14,680 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 23:02:14,680 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 23:02:14,680 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 23:02:14,680 - INFO - joeynmt.training - \tHypothesis: That will be sure that we know that the right and the righteous and the righteous and our heart is not a wise and wrong and the wise and the wise and the wise and the wisdom of the righteous and the wisdom of the righteous . — Heb . 5 : 14 ; 14 : 15 .\n",
      "2021-10-09 23:02:14,681 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 23:02:14,681 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 23:02:14,681 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 23:02:14,681 - INFO - joeynmt.training - \tHypothesis: After the cases of the Guuuttttttttttttoms , I was a Christian .\n",
      "2021-10-09 23:02:14,681 - INFO - joeynmt.training - Validation result (greedy) at epoch   2, step     1500: bleu:  14.92, loss: 39419.2500, ppl:   4.0341, duration: 124.5813s\n",
      "2021-10-09 23:03:07,678 - INFO - joeynmt.training - Epoch   2, Step:     1600, Batch Loss:     1.506357, Tokens per Sec:     8337, Lr: 0.000552\n",
      "2021-10-09 23:04:01,786 - INFO - joeynmt.training - Epoch   2, Step:     1700, Batch Loss:     1.344074, Tokens per Sec:     8296, Lr: 0.000536\n",
      "2021-10-09 23:04:57,079 - INFO - joeynmt.training - Epoch   2, Step:     1800, Batch Loss:     1.362658, Tokens per Sec:     8179, Lr: 0.000521\n",
      "2021-10-09 23:05:50,610 - INFO - joeynmt.training - Epoch   2, Step:     1900, Batch Loss:     1.338569, Tokens per Sec:     8318, Lr: 0.000507\n",
      "2021-10-09 23:06:45,216 - INFO - joeynmt.training - Epoch   2, Step:     2000, Batch Loss:     1.263086, Tokens per Sec:     8369, Lr: 0.000494\n",
      "2021-10-09 23:08:44,057 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 23:08:44,058 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 23:08:44,058 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 23:08:44,495 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 23:08:44,495 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 23:08:50,900 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 23:08:50,901 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 23:08:50,901 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 23:08:50,901 - INFO - joeynmt.training - \tHypothesis: Indeed , the conscience of “ the man ” may be able to be guided by the way .\n",
      "2021-10-09 23:08:50,901 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 23:08:50,901 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 23:08:50,902 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 23:08:50,902 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from Jesus ’ disciples to give his disciples ?\n",
      "2021-10-09 23:08:50,902 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 23:08:50,902 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 23:08:50,902 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 23:08:50,902 - INFO - joeynmt.training - \tHypothesis: That will be able to know that we are not righteous and bad and not to know what we know and are not wise to be wise and discreet . — Heb . 5 : 14 ; 14 : 15 ; 5 : 15 .\n",
      "2021-10-09 23:08:50,902 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 23:08:50,903 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 23:08:50,903 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 23:08:50,903 - INFO - joeynmt.training - \tHypothesis: After the sexual text , I was in 1945 , I was able to visit the brothers in Picica .\n",
      "2021-10-09 23:08:50,903 - INFO - joeynmt.training - Validation result (greedy) at epoch   2, step     2000: bleu:  17.48, loss: 35529.7578, ppl:   3.5154, duration: 125.6860s\n",
      "2021-10-09 23:09:44,574 - INFO - joeynmt.training - Epoch   2, Step:     2100, Batch Loss:     1.173596, Tokens per Sec:     8626, Lr: 0.000482\n",
      "2021-10-09 23:10:37,244 - INFO - joeynmt.training - Epoch   2, Step:     2200, Batch Loss:     1.015461, Tokens per Sec:     8153, Lr: 0.000471\n",
      "2021-10-09 23:11:31,612 - INFO - joeynmt.training - Epoch   2, Step:     2300, Batch Loss:     1.220113, Tokens per Sec:     8511, Lr: 0.000461\n",
      "2021-10-09 23:12:25,072 - INFO - joeynmt.training - Epoch   2, Step:     2400, Batch Loss:     1.255629, Tokens per Sec:     8240, Lr: 0.000451\n",
      "2021-10-09 23:12:56,955 - INFO - joeynmt.training - Epoch   2: total training loss 1686.12\n",
      "2021-10-09 23:12:56,955 - INFO - joeynmt.training - EPOCH 3\n",
      "2021-10-09 23:13:19,831 - INFO - joeynmt.training - Epoch   3, Step:     2500, Batch Loss:     1.164995, Tokens per Sec:     8222, Lr: 0.000442\n",
      "2021-10-09 23:15:48,322 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 23:15:48,323 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 23:15:48,323 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 23:15:48,784 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 23:15:48,784 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 23:15:55,599 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 23:15:55,599 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 23:15:55,599 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 23:15:55,599 - INFO - joeynmt.training - \tHypothesis: Of course , the “ conscience ” can be “ a man of a person . ”\n",
      "2021-10-09 23:15:55,599 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 23:15:55,600 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 23:15:55,600 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 23:15:55,600 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from Jesus ’ teachings given disciples ?\n",
      "2021-10-09 23:15:55,600 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 23:15:55,600 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 23:15:55,600 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 23:15:55,600 - INFO - joeynmt.training - \tHypothesis: That will do so to know that the matter of the righteous and the righteous one is not the right and the wisdom of the wisdom of the wisdom of the wisdom of the wisdom of the wisdom of the wisdom and wisdom that we know and the wisdom of the wisdom of the Ephesians 5 : 14 ; 1 Thess .\n",
      "2021-10-09 23:15:55,601 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 23:15:55,601 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 23:15:55,601 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 23:15:55,601 - INFO - joeynmt.training - \tHypothesis: After the Buuubbbbbbbbbbbbbbbus , I was able to attend the brothers in Portutuary .\n",
      "2021-10-09 23:15:55,601 - INFO - joeynmt.training - Validation result (greedy) at epoch   3, step     2500: bleu:  17.68, loss: 33582.7227, ppl:   3.2814, duration: 155.7697s\n",
      "2021-10-09 23:16:48,122 - INFO - joeynmt.training - Epoch   3, Step:     2600, Batch Loss:     1.406957, Tokens per Sec:     8466, Lr: 0.000433\n",
      "2021-10-09 23:17:42,364 - INFO - joeynmt.training - Epoch   3, Step:     2700, Batch Loss:     1.037800, Tokens per Sec:     8187, Lr: 0.000425\n",
      "2021-10-09 23:18:35,786 - INFO - joeynmt.training - Epoch   3, Step:     2800, Batch Loss:     1.351496, Tokens per Sec:     8482, Lr: 0.000418\n",
      "2021-10-09 23:19:30,025 - INFO - joeynmt.training - Epoch   3, Step:     2900, Batch Loss:     1.218572, Tokens per Sec:     8317, Lr: 0.000410\n",
      "2021-10-09 23:20:24,068 - INFO - joeynmt.training - Epoch   3, Step:     3000, Batch Loss:     1.271179, Tokens per Sec:     8465, Lr: 0.000403\n",
      "2021-10-09 23:22:16,591 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 23:22:16,591 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 23:22:16,592 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 23:22:17,024 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 23:22:17,024 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 23:22:23,273 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 23:22:23,274 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 23:22:23,274 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 23:22:23,274 - INFO - joeynmt.training - \tHypothesis: Of course , the conscience “ is a man ” can lead us to us .\n",
      "2021-10-09 23:22:23,274 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 23:22:23,274 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 23:22:23,275 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 23:22:23,275 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the teachings of Jesus ’ disciples ?\n",
      "2021-10-09 23:22:23,275 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 23:22:23,275 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 23:22:23,275 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 23:22:23,275 - INFO - joeynmt.training - \tHypothesis: That will result in the way we know the righteous and what is bad and what we know is also the wisdom of the wisdom of the wisdom and wisdom of the wisdom of the Ephesians 5 : 14 ; Heb . 5 : 15 .\n",
      "2021-10-09 23:22:23,275 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 23:22:23,276 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 23:22:23,276 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 23:22:23,276 - INFO - joeynmt.training - \tHypothesis: After the Baal Buillion , I had been attended in 1945 , and the children in Pictutures in Pictutuagan .\n",
      "2021-10-09 23:22:23,276 - INFO - joeynmt.training - Validation result (greedy) at epoch   3, step     3000: bleu:  22.38, loss: 31119.5039, ppl:   3.0075, duration: 119.2066s\n",
      "2021-10-09 23:23:15,684 - INFO - joeynmt.training - Epoch   3, Step:     3100, Batch Loss:     1.302832, Tokens per Sec:     8461, Lr: 0.000397\n",
      "2021-10-09 23:24:10,043 - INFO - joeynmt.training - Epoch   3, Step:     3200, Batch Loss:     1.182220, Tokens per Sec:     8386, Lr: 0.000391\n",
      "2021-10-09 23:25:04,322 - INFO - joeynmt.training - Epoch   3, Step:     3300, Batch Loss:     0.950489, Tokens per Sec:     8422, Lr: 0.000385\n",
      "2021-10-09 23:25:58,601 - INFO - joeynmt.training - Epoch   3, Step:     3400, Batch Loss:     1.205770, Tokens per Sec:     8421, Lr: 0.000379\n",
      "2021-10-09 23:26:52,251 - INFO - joeynmt.training - Epoch   3, Step:     3500, Batch Loss:     0.895811, Tokens per Sec:     8471, Lr: 0.000374\n",
      "2021-10-09 23:28:58,514 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 23:28:58,514 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 23:28:58,515 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 23:28:58,943 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 23:28:58,944 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 23:29:05,145 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 23:29:05,146 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 23:29:05,146 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 23:29:05,146 - INFO - joeynmt.training - \tHypothesis: Indeed , the conscience “ is like a man ” can be able to guide us .\n",
      "2021-10-09 23:29:05,146 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 23:29:05,146 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 23:29:05,146 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 23:29:05,146 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the teaching Jesus gave his disciples ?\n",
      "2021-10-09 23:29:05,146 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 23:29:05,147 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 23:29:05,147 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 23:29:05,147 - INFO - joeynmt.training - \tHypothesis: That will cause us to know the difference between the righteous and righteous and what is right and not to know the wisdom of the wise and wisdom between the Ephesians 5 : 14 ; Heb . 5 : 15 .\n",
      "2021-10-09 23:29:05,147 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 23:29:05,147 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 23:29:05,147 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 23:29:05,147 - INFO - joeynmt.training - \tHypothesis: After the February 1945 , I met the brothers in Perictual .\n",
      "2021-10-09 23:29:05,147 - INFO - joeynmt.training - Validation result (greedy) at epoch   3, step     3500: bleu:  23.72, loss: 29664.8164, ppl:   2.8566, duration: 132.8956s\n",
      "2021-10-09 23:29:59,293 - INFO - joeynmt.training - Epoch   3, Step:     3600, Batch Loss:     1.300224, Tokens per Sec:     8504, Lr: 0.000368\n",
      "2021-10-09 23:30:44,482 - INFO - joeynmt.training - Epoch   3: total training loss 1411.23\n",
      "2021-10-09 23:30:44,483 - INFO - joeynmt.training - EPOCH 4\n",
      "2021-10-09 23:30:53,570 - INFO - joeynmt.training - Epoch   4, Step:     3700, Batch Loss:     1.220938, Tokens per Sec:     8489, Lr: 0.000363\n",
      "2021-10-09 23:31:47,847 - INFO - joeynmt.training - Epoch   4, Step:     3800, Batch Loss:     1.073390, Tokens per Sec:     8455, Lr: 0.000358\n",
      "2021-10-09 23:32:42,510 - INFO - joeynmt.training - Epoch   4, Step:     3900, Batch Loss:     1.112914, Tokens per Sec:     8182, Lr: 0.000354\n",
      "2021-10-09 23:33:36,479 - INFO - joeynmt.training - Epoch   4, Step:     4000, Batch Loss:     0.995721, Tokens per Sec:     8325, Lr: 0.000349\n",
      "2021-10-09 23:35:09,140 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 23:35:09,141 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 23:35:09,141 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 23:35:09,527 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 23:35:09,527 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 23:35:15,653 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 23:35:15,653 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 23:35:15,653 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 23:35:15,653 - INFO - joeynmt.training - \tHypothesis: Yes , the conscience of “ a man ” can be able to guide us .\n",
      "2021-10-09 23:35:15,654 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 23:35:15,654 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 23:35:15,654 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 23:35:15,654 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 23:35:15,654 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 23:35:15,654 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 23:35:15,654 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 23:35:15,654 - INFO - joeynmt.training - \tHypothesis: That will make us know the difference between righteousness and righteousness and righteousness and the wisdom of the wisdom that we know between the wisdom and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 23:35:15,655 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 23:35:15,655 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 23:35:15,655 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 23:35:15,655 - INFO - joeynmt.training - \tHypothesis: After the front of February 1945 , I met with the brothers in Public .\n",
      "2021-10-09 23:35:15,655 - INFO - joeynmt.training - Validation result (greedy) at epoch   4, step     4000: bleu:  25.63, loss: 28529.2480, ppl:   2.7441, duration: 99.1754s\n",
      "2021-10-09 23:36:08,767 - INFO - joeynmt.training - Epoch   4, Step:     4100, Batch Loss:     1.137721, Tokens per Sec:     8698, Lr: 0.000345\n",
      "2021-10-09 23:37:03,158 - INFO - joeynmt.training - Epoch   4, Step:     4200, Batch Loss:     1.043462, Tokens per Sec:     8221, Lr: 0.000341\n",
      "2021-10-09 23:37:57,043 - INFO - joeynmt.training - Epoch   4, Step:     4300, Batch Loss:     1.043385, Tokens per Sec:     8544, Lr: 0.000337\n",
      "2021-10-09 23:38:51,750 - INFO - joeynmt.training - Epoch   4, Step:     4400, Batch Loss:     1.011190, Tokens per Sec:     8218, Lr: 0.000333\n",
      "2021-10-09 23:39:45,745 - INFO - joeynmt.training - Epoch   4, Step:     4500, Batch Loss:     1.021948, Tokens per Sec:     8342, Lr: 0.000329\n",
      "2021-10-09 23:41:36,752 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 23:41:36,752 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 23:41:36,753 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 23:41:37,177 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 23:41:37,177 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 23:41:47,171 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 23:41:47,171 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 23:41:47,171 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 23:41:47,171 - INFO - joeynmt.training - \tHypothesis: Indeed , the conscience of “ a man who is in a man ” may not have a guard .\n",
      "2021-10-09 23:41:47,171 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 23:41:47,172 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 23:41:47,172 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 23:41:47,172 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from training Jesus gave his disciples ?\n",
      "2021-10-09 23:41:47,172 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 23:41:47,172 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 23:41:47,172 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 23:41:47,172 - INFO - joeynmt.training - \tHypothesis: That will result in knowing the difference between righteousness and righteousness and righteousness and the insight of the wisdom of the Ephesians and the wisdom of the wise and discreet and discreet Christ. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 23:41:47,172 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 23:41:47,173 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 23:41:47,173 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 23:41:47,173 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met with the children in Public .\n",
      "2021-10-09 23:41:47,173 - INFO - joeynmt.training - Validation result (greedy) at epoch   4, step     4500: bleu:  26.25, loss: 27524.7227, ppl:   2.6483, duration: 121.4270s\n",
      "2021-10-09 23:42:41,600 - INFO - joeynmt.training - Epoch   4, Step:     4600, Batch Loss:     1.072852, Tokens per Sec:     8359, Lr: 0.000326\n",
      "2021-10-09 23:43:35,152 - INFO - joeynmt.training - Epoch   4, Step:     4700, Batch Loss:     1.056963, Tokens per Sec:     8261, Lr: 0.000322\n",
      "2021-10-09 23:44:29,617 - INFO - joeynmt.training - Epoch   4, Step:     4800, Batch Loss:     1.068901, Tokens per Sec:     8465, Lr: 0.000319\n",
      "2021-10-09 23:45:23,426 - INFO - joeynmt.training - Epoch   4, Step:     4900, Batch Loss:     1.024642, Tokens per Sec:     8480, Lr: 0.000316\n",
      "2021-10-09 23:45:27,203 - INFO - joeynmt.training - Epoch   4: total training loss 1269.68\n",
      "2021-10-09 23:45:27,203 - INFO - joeynmt.training - EPOCH 5\n",
      "2021-10-09 23:46:17,941 - INFO - joeynmt.training - Epoch   5, Step:     5000, Batch Loss:     1.140948, Tokens per Sec:     8357, Lr: 0.000313\n",
      "2021-10-09 23:48:03,383 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 23:48:03,384 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 23:48:03,384 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 23:48:03,809 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 23:48:03,809 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 23:48:10,097 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 23:48:10,097 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 23:48:10,098 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 23:48:10,098 - INFO - joeynmt.training - \tHypothesis: Indeed , the conscience of “ a man who is in a sense ” may not be misled .\n",
      "2021-10-09 23:48:10,098 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 23:48:10,098 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 23:48:10,098 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 23:48:10,098 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the teachings that Jesus gave his disciples ?\n",
      "2021-10-09 23:48:10,098 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 23:48:10,098 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 23:48:10,099 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 23:48:10,099 - INFO - joeynmt.training - \tHypothesis: That will cause us to know the difference between righteousness and wrong and knowledge of the wisdom between the wisdom and wisdom and wisdom and wisdom and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 23:48:10,099 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 23:48:10,099 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 23:48:10,099 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 23:48:10,099 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met the children in Puercia .\n",
      "2021-10-09 23:48:10,099 - INFO - joeynmt.training - Validation result (greedy) at epoch   5, step     5000: bleu:  27.76, loss: 26613.3047, ppl:   2.5642, duration: 112.1578s\n",
      "2021-10-09 23:49:03,677 - INFO - joeynmt.training - Epoch   5, Step:     5100, Batch Loss:     0.902253, Tokens per Sec:     8458, Lr: 0.000309\n",
      "2021-10-09 23:49:57,850 - INFO - joeynmt.training - Epoch   5, Step:     5200, Batch Loss:     0.959959, Tokens per Sec:     8268, Lr: 0.000306\n",
      "2021-10-09 23:50:51,837 - INFO - joeynmt.training - Epoch   5, Step:     5300, Batch Loss:     0.922112, Tokens per Sec:     8505, Lr: 0.000304\n",
      "2021-10-09 23:51:45,784 - INFO - joeynmt.training - Epoch   5, Step:     5400, Batch Loss:     0.959866, Tokens per Sec:     8476, Lr: 0.000301\n",
      "2021-10-09 23:52:39,107 - INFO - joeynmt.training - Epoch   5, Step:     5500, Batch Loss:     0.939166, Tokens per Sec:     8473, Lr: 0.000298\n",
      "2021-10-09 23:54:34,658 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-09 23:54:34,659 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-09 23:54:34,659 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-09 23:54:35,037 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-09 23:54:35,037 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-09 23:54:41,089 - INFO - joeynmt.training - Example #0\n",
      "2021-10-09 23:54:41,090 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-09 23:54:41,090 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-09 23:54:41,090 - INFO - joeynmt.training - \tHypothesis: Yes , the conscience of “ a man ” may not be misled .\n",
      "2021-10-09 23:54:41,090 - INFO - joeynmt.training - Example #1\n",
      "2021-10-09 23:54:41,090 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-09 23:54:41,090 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-09 23:54:41,090 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the teachings that Jesus gave his disciples ?\n",
      "2021-10-09 23:54:41,091 - INFO - joeynmt.training - Example #2\n",
      "2021-10-09 23:54:41,091 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-09 23:54:41,091 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 23:54:41,091 - INFO - joeynmt.training - \tHypothesis: That will make us know the differences between the righteous and the righteous and the intelligent contrast between the wisdom and wisdom and wisdom and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-09 23:54:41,091 - INFO - joeynmt.training - Example #3\n",
      "2021-10-09 23:54:41,091 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-09 23:54:41,091 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-09 23:54:41,092 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met with the brothers in Puera Rico .\n",
      "2021-10-09 23:54:41,092 - INFO - joeynmt.training - Validation result (greedy) at epoch   5, step     5500: bleu:  28.56, loss: 26080.0098, ppl:   2.5163, duration: 121.9842s\n",
      "2021-10-09 23:55:33,473 - INFO - joeynmt.training - Epoch   5, Step:     5600, Batch Loss:     1.123466, Tokens per Sec:     8431, Lr: 0.000295\n",
      "2021-10-09 23:56:27,767 - INFO - joeynmt.training - Epoch   5, Step:     5700, Batch Loss:     0.940825, Tokens per Sec:     8457, Lr: 0.000293\n",
      "2021-10-09 23:57:21,526 - INFO - joeynmt.training - Epoch   5, Step:     5800, Batch Loss:     0.802351, Tokens per Sec:     8561, Lr: 0.000290\n",
      "2021-10-09 23:58:14,774 - INFO - joeynmt.training - Epoch   5, Step:     5900, Batch Loss:     0.808088, Tokens per Sec:     8461, Lr: 0.000288\n",
      "2021-10-09 23:59:07,704 - INFO - joeynmt.training - Epoch   5, Step:     6000, Batch Loss:     1.018795, Tokens per Sec:     8570, Lr: 0.000285\n",
      "2021-10-10 00:00:37,951 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-10 00:00:37,952 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-10 00:00:37,952 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-10 00:00:38,375 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-10 00:00:38,375 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-10 00:00:44,555 - INFO - joeynmt.training - Example #0\n",
      "2021-10-10 00:00:44,556 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-10 00:00:44,556 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-10 00:00:44,556 - INFO - joeynmt.training - \tHypothesis: Indeed , the conscience of “ a man who is in a man ” may be misled .\n",
      "2021-10-10 00:00:44,556 - INFO - joeynmt.training - Example #1\n",
      "2021-10-10 00:00:44,557 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-10 00:00:44,557 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 00:00:44,557 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from training that Jesus gave his disciples ?\n",
      "2021-10-10 00:00:44,557 - INFO - joeynmt.training - Example #2\n",
      "2021-10-10 00:00:44,557 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-10 00:00:44,557 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 00:00:44,557 - INFO - joeynmt.training - \tHypothesis: That will make us know the difference between the righteous and wrong and the intelligent difference between the wisdom and wisdom and wisdom and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 00:00:44,557 - INFO - joeynmt.training - Example #3\n",
      "2021-10-10 00:00:44,558 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-10 00:00:44,558 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-10 00:00:44,558 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met with the brothers in Puercia Rico .\n",
      "2021-10-10 00:00:44,558 - INFO - joeynmt.training - Validation result (greedy) at epoch   5, step     6000: bleu:  28.84, loss: 25459.9395, ppl:   2.4617, duration: 96.8528s\n",
      "2021-10-10 00:01:37,423 - INFO - joeynmt.training - Epoch   5, Step:     6100, Batch Loss:     0.992270, Tokens per Sec:     8251, Lr: 0.000283\n",
      "2021-10-10 00:01:55,405 - INFO - joeynmt.training - Epoch   5: total training loss 1182.94\n",
      "2021-10-10 00:01:55,406 - INFO - joeynmt.training - EPOCH 6\n",
      "2021-10-10 00:02:30,209 - INFO - joeynmt.training - Epoch   6, Step:     6200, Batch Loss:     0.970248, Tokens per Sec:     8435, Lr: 0.000281\n",
      "2021-10-10 00:03:24,322 - INFO - joeynmt.training - Epoch   6, Step:     6300, Batch Loss:     0.879114, Tokens per Sec:     8580, Lr: 0.000278\n",
      "2021-10-10 00:04:17,818 - INFO - joeynmt.training - Epoch   6, Step:     6400, Batch Loss:     0.922254, Tokens per Sec:     8623, Lr: 0.000276\n",
      "2021-10-10 00:05:12,834 - INFO - joeynmt.training - Epoch   6, Step:     6500, Batch Loss:     1.000635, Tokens per Sec:     8534, Lr: 0.000274\n",
      "2021-10-10 00:06:57,628 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-10 00:06:57,629 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-10 00:06:57,629 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-10 00:06:58,054 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-10 00:06:58,054 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-10 00:07:04,149 - INFO - joeynmt.training - Example #0\n",
      "2021-10-10 00:07:04,150 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-10 00:07:04,150 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-10 00:07:04,150 - INFO - joeynmt.training - \tHypothesis: Indeed , the conscience of “ a man who is lacking ” may be misled .\n",
      "2021-10-10 00:07:04,150 - INFO - joeynmt.training - Example #1\n",
      "2021-10-10 00:07:04,150 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-10 00:07:04,150 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 00:07:04,150 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the teachings Jesus gave his disciples ?\n",
      "2021-10-10 00:07:04,151 - INFO - joeynmt.training - Example #2\n",
      "2021-10-10 00:07:04,151 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-10 00:07:04,151 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 00:07:04,151 - INFO - joeynmt.training - \tHypothesis: That will make us know the difference between what is right and wrong and what is right and what we know in the contrast between the wise and wise and discreet personal. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 00:07:04,151 - INFO - joeynmt.training - Example #3\n",
      "2021-10-10 00:07:04,151 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-10 00:07:04,151 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-10 00:07:04,152 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met the children in Puerto Rico .\n",
      "2021-10-10 00:07:04,152 - INFO - joeynmt.training - Validation result (greedy) at epoch   6, step     6500: bleu:  29.72, loss: 24791.6133, ppl:   2.4042, duration: 111.3167s\n",
      "2021-10-10 00:07:57,162 - INFO - joeynmt.training - Epoch   6, Step:     6600, Batch Loss:     0.876450, Tokens per Sec:     8496, Lr: 0.000272\n",
      "2021-10-10 00:08:49,876 - INFO - joeynmt.training - Epoch   6, Step:     6700, Batch Loss:     0.901201, Tokens per Sec:     8514, Lr: 0.000270\n",
      "2021-10-10 00:09:43,339 - INFO - joeynmt.training - Epoch   6, Step:     6800, Batch Loss:     0.907621, Tokens per Sec:     8297, Lr: 0.000268\n",
      "2021-10-10 00:10:36,929 - INFO - joeynmt.training - Epoch   6, Step:     6900, Batch Loss:     0.915599, Tokens per Sec:     8325, Lr: 0.000266\n",
      "2021-10-10 00:11:30,612 - INFO - joeynmt.training - Epoch   6, Step:     7000, Batch Loss:     0.904676, Tokens per Sec:     8473, Lr: 0.000264\n",
      "2021-10-10 00:13:11,843 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-10 00:13:11,849 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-10 00:13:11,849 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-10 00:13:12,273 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-10 00:13:12,273 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-10 00:13:18,582 - INFO - joeynmt.training - Example #0\n",
      "2021-10-10 00:13:18,583 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-10 00:13:18,583 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-10 00:13:18,583 - INFO - joeynmt.training - \tHypothesis: Indeed , the conscience of “ a man who is lacking ” may be misled .\n",
      "2021-10-10 00:13:18,583 - INFO - joeynmt.training - Example #1\n",
      "2021-10-10 00:13:18,583 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-10 00:13:18,583 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 00:13:18,583 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 00:13:18,583 - INFO - joeynmt.training - Example #2\n",
      "2021-10-10 00:13:18,584 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-10 00:13:18,584 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 00:13:18,584 - INFO - joeynmt.training - \tHypothesis: That will enable us to know the differences between righteousness and what is right and to know the difference between the wise and discreet and discreet personal. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 00:13:18,584 - INFO - joeynmt.training - Example #3\n",
      "2021-10-10 00:13:18,584 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-10 00:13:18,584 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-10 00:13:18,584 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met the children in Puerto Rico .\n",
      "2021-10-10 00:13:18,584 - INFO - joeynmt.training - Validation result (greedy) at epoch   6, step     7000: bleu:  30.55, loss: 24460.2773, ppl:   2.3762, duration: 107.9713s\n",
      "2021-10-10 00:14:12,103 - INFO - joeynmt.training - Epoch   6, Step:     7100, Batch Loss:     0.865815, Tokens per Sec:     8440, Lr: 0.000262\n",
      "2021-10-10 00:15:05,620 - INFO - joeynmt.training - Epoch   6, Step:     7200, Batch Loss:     1.021117, Tokens per Sec:     8468, Lr: 0.000260\n",
      "2021-10-10 00:15:58,508 - INFO - joeynmt.training - Epoch   6, Step:     7300, Batch Loss:     0.855407, Tokens per Sec:     8429, Lr: 0.000259\n",
      "2021-10-10 00:16:29,517 - INFO - joeynmt.training - Epoch   6: total training loss 1114.77\n",
      "2021-10-10 00:16:29,524 - INFO - joeynmt.training - EPOCH 7\n",
      "2021-10-10 00:16:52,638 - INFO - joeynmt.training - Epoch   7, Step:     7400, Batch Loss:     0.825359, Tokens per Sec:     8609, Lr: 0.000257\n",
      "2021-10-10 00:17:45,908 - INFO - joeynmt.training - Epoch   7, Step:     7500, Batch Loss:     0.886627, Tokens per Sec:     8610, Lr: 0.000255\n",
      "2021-10-10 00:19:30,115 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-10 00:19:30,116 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-10 00:19:30,116 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-10 00:19:30,496 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-10 00:19:30,496 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-10 00:19:36,605 - INFO - joeynmt.training - Example #0\n",
      "2021-10-10 00:19:36,606 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-10 00:19:36,606 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-10 00:19:36,606 - INFO - joeynmt.training - \tHypothesis: Indeed , the conscience of “ the man of the heart ” may be misleading us .\n",
      "2021-10-10 00:19:36,606 - INFO - joeynmt.training - Example #1\n",
      "2021-10-10 00:19:36,606 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-10 00:19:36,606 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 00:19:36,607 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 00:19:36,607 - INFO - joeynmt.training - Example #2\n",
      "2021-10-10 00:19:36,607 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-10 00:19:36,607 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 00:19:36,607 - INFO - joeynmt.training - \tHypothesis: That will make us know the difference between right and wrong and wrong and knowing the difference between the wise and discreet and discreet and discreet reason. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 00:19:36,607 - INFO - joeynmt.training - Example #3\n",
      "2021-10-10 00:19:36,607 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-10 00:19:36,608 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-10 00:19:36,608 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met the children in Puerto Rico .\n",
      "2021-10-10 00:19:36,608 - INFO - joeynmt.training - Validation result (greedy) at epoch   7, step     7500: bleu:  30.78, loss: 23934.0938, ppl:   2.3323, duration: 110.6987s\n",
      "2021-10-10 00:20:29,980 - INFO - joeynmt.training - Epoch   7, Step:     7600, Batch Loss:     0.864470, Tokens per Sec:     8548, Lr: 0.000253\n",
      "2021-10-10 00:21:23,732 - INFO - joeynmt.training - Epoch   7, Step:     7700, Batch Loss:     0.845313, Tokens per Sec:     8425, Lr: 0.000252\n",
      "2021-10-10 00:22:17,480 - INFO - joeynmt.training - Epoch   7, Step:     7800, Batch Loss:     0.902929, Tokens per Sec:     8627, Lr: 0.000250\n",
      "2021-10-10 00:23:09,989 - INFO - joeynmt.training - Epoch   7, Step:     7900, Batch Loss:     0.914342, Tokens per Sec:     8438, Lr: 0.000249\n",
      "2021-10-10 00:24:03,853 - INFO - joeynmt.training - Epoch   7, Step:     8000, Batch Loss:     0.859005, Tokens per Sec:     8366, Lr: 0.000247\n",
      "2021-10-10 00:25:42,916 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-10 00:25:42,917 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-10 00:25:42,917 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-10 00:25:43,308 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-10 00:25:43,309 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-10 00:25:49,497 - INFO - joeynmt.training - Example #0\n",
      "2021-10-10 00:25:49,497 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-10 00:25:49,497 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-10 00:25:49,497 - INFO - joeynmt.training - \tHypothesis: Indeed , the conscience of “ a man who is in a sense ” may be misled .\n",
      "2021-10-10 00:25:49,497 - INFO - joeynmt.training - Example #1\n",
      "2021-10-10 00:25:49,498 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-10 00:25:49,498 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 00:25:49,498 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 00:25:49,498 - INFO - joeynmt.training - Example #2\n",
      "2021-10-10 00:25:49,498 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-10 00:25:49,498 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 00:25:49,498 - INFO - joeynmt.training - \tHypothesis: That will lead us to know the difference between right and wrong and to know the difference between the wise and discreet and discreet reason. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 00:25:49,498 - INFO - joeynmt.training - Example #3\n",
      "2021-10-10 00:25:49,499 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-10 00:25:49,499 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-10 00:25:49,499 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met our children in Puerto Rico .\n",
      "2021-10-10 00:25:49,499 - INFO - joeynmt.training - Validation result (greedy) at epoch   7, step     8000: bleu:  31.16, loss: 23792.8789, ppl:   2.3207, duration: 105.6454s\n",
      "2021-10-10 00:26:42,204 - INFO - joeynmt.training - Epoch   7, Step:     8100, Batch Loss:     0.866932, Tokens per Sec:     8626, Lr: 0.000246\n",
      "2021-10-10 00:27:36,002 - INFO - joeynmt.training - Epoch   7, Step:     8200, Batch Loss:     0.859804, Tokens per Sec:     8516, Lr: 0.000244\n",
      "2021-10-10 00:28:28,369 - INFO - joeynmt.training - Epoch   7, Step:     8300, Batch Loss:     0.914769, Tokens per Sec:     8447, Lr: 0.000243\n",
      "2021-10-10 00:29:21,973 - INFO - joeynmt.training - Epoch   7, Step:     8400, Batch Loss:     0.822323, Tokens per Sec:     8268, Lr: 0.000241\n",
      "2021-10-10 00:30:15,206 - INFO - joeynmt.training - Epoch   7, Step:     8500, Batch Loss:     0.788051, Tokens per Sec:     8534, Lr: 0.000240\n",
      "2021-10-10 00:31:54,527 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-10 00:31:54,528 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-10 00:31:54,528 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-10 00:31:54,856 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-10 00:31:54,856 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-10 00:32:00,904 - INFO - joeynmt.training - Example #0\n",
      "2021-10-10 00:32:00,904 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-10 00:32:00,904 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-10 00:32:00,904 - INFO - joeynmt.training - \tHypothesis: Indeed , the conscience of “ a man of distressing ” may be misled .\n",
      "2021-10-10 00:32:00,904 - INFO - joeynmt.training - Example #1\n",
      "2021-10-10 00:32:00,905 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-10 00:32:00,905 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 00:32:00,905 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the teachings Jesus gave his disciples ?\n",
      "2021-10-10 00:32:00,905 - INFO - joeynmt.training - Example #2\n",
      "2021-10-10 00:32:00,905 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-10 00:32:00,905 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 00:32:00,905 - INFO - joeynmt.training - \tHypothesis: That will make us know the difference between the righteous and wrong and what is bad and we know between the wisdom and wisdom and wisdom and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 00:32:00,905 - INFO - joeynmt.training - Example #3\n",
      "2021-10-10 00:32:00,906 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-10 00:32:00,906 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-10 00:32:00,906 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met the brothers in Puerto Rico .\n",
      "2021-10-10 00:32:00,906 - INFO - joeynmt.training - Validation result (greedy) at epoch   7, step     8500: bleu:  31.92, loss: 23359.5449, ppl:   2.2854, duration: 105.6989s\n",
      "2021-10-10 00:32:43,597 - INFO - joeynmt.training - Epoch   7: total training loss 1067.81\n",
      "2021-10-10 00:32:43,598 - INFO - joeynmt.training - EPOCH 8\n",
      "2021-10-10 00:32:53,745 - INFO - joeynmt.training - Epoch   8, Step:     8600, Batch Loss:     0.862255, Tokens per Sec:     8378, Lr: 0.000238\n",
      "2021-10-10 00:33:46,711 - INFO - joeynmt.training - Epoch   8, Step:     8700, Batch Loss:     0.861098, Tokens per Sec:     8646, Lr: 0.000237\n",
      "2021-10-10 00:34:40,357 - INFO - joeynmt.training - Epoch   8, Step:     8800, Batch Loss:     0.899514, Tokens per Sec:     8429, Lr: 0.000236\n",
      "2021-10-10 00:35:34,178 - INFO - joeynmt.training - Epoch   8, Step:     8900, Batch Loss:     0.737449, Tokens per Sec:     8295, Lr: 0.000234\n",
      "2021-10-10 00:36:27,364 - INFO - joeynmt.training - Epoch   8, Step:     9000, Batch Loss:     0.752565, Tokens per Sec:     8539, Lr: 0.000233\n",
      "2021-10-10 00:38:16,057 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-10 00:38:16,057 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-10 00:38:16,057 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-10 00:38:16,381 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-10 00:38:16,381 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-10 00:38:26,682 - INFO - joeynmt.training - Example #0\n",
      "2021-10-10 00:38:26,685 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-10 00:38:26,685 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-10 00:38:26,686 - INFO - joeynmt.training - \tHypothesis: Yes , the conscience of “ a man of mind ” may be misled .\n",
      "2021-10-10 00:38:26,686 - INFO - joeynmt.training - Example #1\n",
      "2021-10-10 00:38:26,686 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-10 00:38:26,686 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 00:38:26,686 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 00:38:26,686 - INFO - joeynmt.training - Example #2\n",
      "2021-10-10 00:38:26,686 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-10 00:38:26,686 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 00:38:26,687 - INFO - joeynmt.training - \tHypothesis: That will enable us to know the differences between right and wrong and to know the differences between the wisdom and wisdom and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 00:38:26,687 - INFO - joeynmt.training - Example #3\n",
      "2021-10-10 00:38:26,687 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-10 00:38:26,687 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-10 00:38:26,687 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met the brothers in Puerto Rico .\n",
      "2021-10-10 00:38:26,687 - INFO - joeynmt.training - Validation result (greedy) at epoch   8, step     9000: bleu:  32.00, loss: 23080.7832, ppl:   2.2630, duration: 119.3227s\n",
      "2021-10-10 00:39:20,673 - INFO - joeynmt.training - Epoch   8, Step:     9100, Batch Loss:     0.873342, Tokens per Sec:     8576, Lr: 0.000232\n",
      "2021-10-10 00:40:13,088 - INFO - joeynmt.training - Epoch   8, Step:     9200, Batch Loss:     0.809788, Tokens per Sec:     8430, Lr: 0.000230\n",
      "2021-10-10 00:41:06,311 - INFO - joeynmt.training - Epoch   8, Step:     9300, Batch Loss:     0.907617, Tokens per Sec:     8423, Lr: 0.000229\n",
      "2021-10-10 00:41:59,058 - INFO - joeynmt.training - Epoch   8, Step:     9400, Batch Loss:     0.800489, Tokens per Sec:     8548, Lr: 0.000228\n",
      "2021-10-10 00:42:52,213 - INFO - joeynmt.training - Epoch   8, Step:     9500, Batch Loss:     0.903769, Tokens per Sec:     8588, Lr: 0.000227\n",
      "2021-10-10 00:44:35,788 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-10 00:44:35,789 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-10 00:44:35,789 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-10 00:44:36,172 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-10 00:44:36,172 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-10 00:44:42,206 - INFO - joeynmt.training - Example #0\n",
      "2021-10-10 00:44:42,206 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-10 00:44:42,206 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-10 00:44:42,207 - INFO - joeynmt.training - \tHypothesis: Of course , the conscience of “ the man of the man ” may be misleading us .\n",
      "2021-10-10 00:44:42,207 - INFO - joeynmt.training - Example #1\n",
      "2021-10-10 00:44:42,207 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-10 00:44:42,207 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 00:44:42,207 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 00:44:42,207 - INFO - joeynmt.training - Example #2\n",
      "2021-10-10 00:44:42,207 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-10 00:44:42,207 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 00:44:42,208 - INFO - joeynmt.training - \tHypothesis: That will enable us to know the difference between right and wrong and to know the difference between the foolish and discreet personals. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 00:44:42,208 - INFO - joeynmt.training - Example #3\n",
      "2021-10-10 00:44:42,208 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-10 00:44:42,208 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-10 00:44:42,208 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met the brothers in Puerto Rico .\n",
      "2021-10-10 00:44:42,208 - INFO - joeynmt.training - Validation result (greedy) at epoch   8, step     9500: bleu:  32.25, loss: 22659.1094, ppl:   2.2294, duration: 109.9945s\n",
      "2021-10-10 00:45:34,344 - INFO - joeynmt.training - Epoch   8, Step:     9600, Batch Loss:     0.864616, Tokens per Sec:     8579, Lr: 0.000226\n",
      "2021-10-10 00:46:28,417 - INFO - joeynmt.training - Epoch   8, Step:     9700, Batch Loss:     0.873027, Tokens per Sec:     8334, Lr: 0.000224\n",
      "2021-10-10 00:47:21,849 - INFO - joeynmt.training - Epoch   8, Step:     9800, Batch Loss:     0.780117, Tokens per Sec:     8383, Lr: 0.000223\n",
      "2021-10-10 00:47:26,647 - INFO - joeynmt.training - Epoch   8: total training loss 1029.03\n",
      "2021-10-10 00:47:26,648 - INFO - joeynmt.training - EPOCH 9\n",
      "2021-10-10 00:48:15,085 - INFO - joeynmt.training - Epoch   9, Step:     9900, Batch Loss:     0.841575, Tokens per Sec:     8441, Lr: 0.000222\n",
      "2021-10-10 00:49:07,280 - INFO - joeynmt.training - Epoch   9, Step:    10000, Batch Loss:     0.701049, Tokens per Sec:     8409, Lr: 0.000221\n",
      "2021-10-10 00:50:51,214 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-10 00:50:51,215 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-10 00:50:51,215 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-10 00:50:51,641 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-10 00:50:51,641 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-10 00:50:57,760 - INFO - joeynmt.training - Example #0\n",
      "2021-10-10 00:50:57,761 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-10 00:50:57,761 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-10 00:50:57,761 - INFO - joeynmt.training - \tHypothesis: Indeed , the conscience of “ a man who is slow ” may be misled .\n",
      "2021-10-10 00:50:57,761 - INFO - joeynmt.training - Example #1\n",
      "2021-10-10 00:50:57,761 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-10 00:50:57,761 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 00:50:57,761 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 00:50:57,762 - INFO - joeynmt.training - Example #2\n",
      "2021-10-10 00:50:57,762 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-10 00:50:57,762 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 00:50:57,762 - INFO - joeynmt.training - \tHypothesis: That will enable us to know the difference between what is right and wrong and to know the difference between the foolish and discreet personal. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 00:50:57,762 - INFO - joeynmt.training - Example #3\n",
      "2021-10-10 00:50:57,762 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-10 00:50:57,762 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-10 00:50:57,762 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met the brothers in Puerto Rico Rico .\n",
      "2021-10-10 00:50:57,763 - INFO - joeynmt.training - Validation result (greedy) at epoch   9, step    10000: bleu:  33.31, loss: 22559.5820, ppl:   2.2216, duration: 110.4824s\n",
      "2021-10-10 00:51:50,698 - INFO - joeynmt.training - Epoch   9, Step:    10100, Batch Loss:     0.843401, Tokens per Sec:     8589, Lr: 0.000220\n",
      "2021-10-10 00:52:44,155 - INFO - joeynmt.training - Epoch   9, Step:    10200, Batch Loss:     0.805691, Tokens per Sec:     8472, Lr: 0.000219\n",
      "2021-10-10 00:53:37,264 - INFO - joeynmt.training - Epoch   9, Step:    10300, Batch Loss:     0.754238, Tokens per Sec:     8471, Lr: 0.000218\n",
      "2021-10-10 00:54:30,879 - INFO - joeynmt.training - Epoch   9, Step:    10400, Batch Loss:     0.793305, Tokens per Sec:     8449, Lr: 0.000217\n",
      "2021-10-10 00:55:24,714 - INFO - joeynmt.training - Epoch   9, Step:    10500, Batch Loss:     0.797647, Tokens per Sec:     8432, Lr: 0.000216\n",
      "2021-10-10 00:57:10,147 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-10 00:57:10,147 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-10 00:57:10,147 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-10 00:57:10,533 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-10 00:57:10,533 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-10 00:57:16,632 - INFO - joeynmt.training - Example #0\n",
      "2021-10-10 00:57:16,633 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-10 00:57:16,633 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-10 00:57:16,633 - INFO - joeynmt.training - \tHypothesis: Indeed , the conscience of “ a man that is in a sense ” may be misled .\n",
      "2021-10-10 00:57:16,634 - INFO - joeynmt.training - Example #1\n",
      "2021-10-10 00:57:16,634 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-10 00:57:16,634 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 00:57:16,634 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 00:57:16,634 - INFO - joeynmt.training - Example #2\n",
      "2021-10-10 00:57:16,634 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-10 00:57:16,634 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 00:57:16,634 - INFO - joeynmt.training - \tHypothesis: That will enable us to know the difference between what is right and wrong and to know the difference between the foolish and wisdom and wisdom and wisdom and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 00:57:16,635 - INFO - joeynmt.training - Example #3\n",
      "2021-10-10 00:57:16,635 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-10 00:57:16,635 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-10 00:57:16,635 - INFO - joeynmt.training - \tHypothesis: After February graduation in February 1945 , I met young brothers in Puerto Rico .\n",
      "2021-10-10 00:57:16,635 - INFO - joeynmt.training - Validation result (greedy) at epoch   9, step    10500: bleu:  33.22, loss: 22240.1348, ppl:   2.1966, duration: 111.9207s\n",
      "2021-10-10 00:58:09,183 - INFO - joeynmt.training - Epoch   9, Step:    10600, Batch Loss:     0.771456, Tokens per Sec:     8498, Lr: 0.000215\n",
      "2021-10-10 00:59:01,808 - INFO - joeynmt.training - Epoch   9, Step:    10700, Batch Loss:     1.068393, Tokens per Sec:     8713, Lr: 0.000214\n",
      "2021-10-10 00:59:55,143 - INFO - joeynmt.training - Epoch   9, Step:    10800, Batch Loss:     0.650446, Tokens per Sec:     8376, Lr: 0.000213\n",
      "2021-10-10 01:00:49,473 - INFO - joeynmt.training - Epoch   9, Step:    10900, Batch Loss:     0.782789, Tokens per Sec:     8632, Lr: 0.000212\n",
      "2021-10-10 01:01:42,188 - INFO - joeynmt.training - Epoch   9, Step:    11000, Batch Loss:     0.767197, Tokens per Sec:     8355, Lr: 0.000211\n",
      "2021-10-10 01:03:28,035 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-10 01:03:28,036 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-10 01:03:28,036 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-10 01:03:28,361 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-10 01:03:28,361 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-10 01:03:34,520 - INFO - joeynmt.training - Example #0\n",
      "2021-10-10 01:03:34,521 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-10 01:03:34,521 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-10 01:03:34,521 - INFO - joeynmt.training - \tHypothesis: Indeed , the conscience of “ a man that is tired ” may not mislead us .\n",
      "2021-10-10 01:03:34,521 - INFO - joeynmt.training - Example #1\n",
      "2021-10-10 01:03:34,522 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-10 01:03:34,522 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 01:03:34,522 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 01:03:34,522 - INFO - joeynmt.training - Example #2\n",
      "2021-10-10 01:03:34,522 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-10 01:03:34,522 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 01:03:34,522 - INFO - joeynmt.training - \tHypothesis: That will enable us to know the difference between right and wrong and to know the difference between the foolish and discreet reason. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 01:03:34,522 - INFO - joeynmt.training - Example #3\n",
      "2021-10-10 01:03:34,523 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-10 01:03:34,523 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-10 01:03:34,523 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met the brothers in Puerto Rico .\n",
      "2021-10-10 01:03:34,523 - INFO - joeynmt.training - Validation result (greedy) at epoch   9, step    11000: bleu:  33.83, loss: 22062.5508, ppl:   2.1829, duration: 112.3342s\n",
      "2021-10-10 01:03:55,296 - INFO - joeynmt.training - Epoch   9: total training loss 997.03\n",
      "2021-10-10 01:03:55,297 - INFO - joeynmt.training - EPOCH 10\n",
      "2021-10-10 01:04:27,274 - INFO - joeynmt.training - Epoch  10, Step:    11100, Batch Loss:     0.842167, Tokens per Sec:     8407, Lr: 0.000210\n",
      "2021-10-10 01:05:20,139 - INFO - joeynmt.training - Epoch  10, Step:    11200, Batch Loss:     0.713221, Tokens per Sec:     8661, Lr: 0.000209\n",
      "2021-10-10 01:06:12,281 - INFO - joeynmt.training - Epoch  10, Step:    11300, Batch Loss:     0.644962, Tokens per Sec:     8447, Lr: 0.000208\n",
      "2021-10-10 01:07:05,682 - INFO - joeynmt.training - Epoch  10, Step:    11400, Batch Loss:     0.768865, Tokens per Sec:     8424, Lr: 0.000207\n",
      "2021-10-10 01:07:58,256 - INFO - joeynmt.training - Epoch  10, Step:    11500, Batch Loss:     0.587068, Tokens per Sec:     8323, Lr: 0.000206\n",
      "2021-10-10 01:09:42,767 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-10 01:09:42,768 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-10 01:09:42,768 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-10 01:09:43,095 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-10 01:09:43,095 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-10 01:09:49,173 - INFO - joeynmt.training - Example #0\n",
      "2021-10-10 01:09:49,173 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-10 01:09:49,174 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-10 01:09:49,174 - INFO - joeynmt.training - \tHypothesis: Indeed , the conscience of “ a man of injury ” may be misled .\n",
      "2021-10-10 01:09:49,174 - INFO - joeynmt.training - Example #1\n",
      "2021-10-10 01:09:49,174 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-10 01:09:49,174 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 01:09:49,174 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 01:09:49,174 - INFO - joeynmt.training - Example #2\n",
      "2021-10-10 01:09:49,174 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-10 01:09:49,175 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 01:09:49,175 - INFO - joeynmt.training - \tHypothesis: That will enable us to know the difference between right and wrong and to know the difference between the foolish and discreet and discreet personals. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 01:09:49,175 - INFO - joeynmt.training - Example #3\n",
      "2021-10-10 01:09:49,175 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-10 01:09:49,175 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-10 01:09:49,175 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met our children in Puerto Rico .\n",
      "2021-10-10 01:09:49,175 - INFO - joeynmt.training - Validation result (greedy) at epoch  10, step    11500: bleu:  34.14, loss: 21862.3047, ppl:   2.1675, duration: 110.9189s\n",
      "2021-10-10 01:10:43,233 - INFO - joeynmt.training - Epoch  10, Step:    11600, Batch Loss:     0.924723, Tokens per Sec:     8499, Lr: 0.000205\n",
      "2021-10-10 01:11:36,607 - INFO - joeynmt.training - Epoch  10, Step:    11700, Batch Loss:     0.803156, Tokens per Sec:     8494, Lr: 0.000204\n",
      "2021-10-10 01:12:29,785 - INFO - joeynmt.training - Epoch  10, Step:    11800, Batch Loss:     0.725513, Tokens per Sec:     8577, Lr: 0.000203\n",
      "2021-10-10 01:13:22,180 - INFO - joeynmt.training - Epoch  10, Step:    11900, Batch Loss:     0.717318, Tokens per Sec:     8529, Lr: 0.000203\n",
      "2021-10-10 01:14:15,829 - INFO - joeynmt.training - Epoch  10, Step:    12000, Batch Loss:     0.824409, Tokens per Sec:     8530, Lr: 0.000202\n",
      "2021-10-10 01:15:55,245 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-10 01:15:55,254 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-10 01:15:55,254 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-10 01:15:55,584 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-10 01:15:55,584 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-10 01:16:02,833 - INFO - joeynmt.training - Example #0\n",
      "2021-10-10 01:16:02,834 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-10 01:16:02,834 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-10 01:16:02,834 - INFO - joeynmt.training - \tHypothesis: Indeed , the conscience of “ a man who is tired ” may be misleading us .\n",
      "2021-10-10 01:16:02,834 - INFO - joeynmt.training - Example #1\n",
      "2021-10-10 01:16:02,834 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-10 01:16:02,834 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 01:16:02,835 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 01:16:02,835 - INFO - joeynmt.training - Example #2\n",
      "2021-10-10 01:16:02,835 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-10 01:16:02,835 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 01:16:02,835 - INFO - joeynmt.training - \tHypothesis: That will enable us to know the difference between right and wrong and to know the difference between the foolish and discreet personals. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 01:16:02,835 - INFO - joeynmt.training - Example #3\n",
      "2021-10-10 01:16:02,835 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-10 01:16:02,836 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-10 01:16:02,836 - INFO - joeynmt.training - \tHypothesis: After February graduation in February 1945 , I met young brothers in Puerto Rico .\n",
      "2021-10-10 01:16:02,836 - INFO - joeynmt.training - Validation result (greedy) at epoch  10, step    12000: bleu:  34.21, loss: 21539.0449, ppl:   2.1428, duration: 107.0066s\n",
      "2021-10-10 01:16:55,629 - INFO - joeynmt.training - Epoch  10, Step:    12100, Batch Loss:     0.847119, Tokens per Sec:     8701, Lr: 0.000201\n",
      "2021-10-10 01:17:48,512 - INFO - joeynmt.training - Epoch  10, Step:    12200, Batch Loss:     0.776620, Tokens per Sec:     8406, Lr: 0.000200\n",
      "2021-10-10 01:18:25,125 - INFO - joeynmt.training - Epoch  10: total training loss 969.48\n",
      "2021-10-10 01:18:25,126 - INFO - joeynmt.training - EPOCH 11\n",
      "2021-10-10 01:18:41,949 - INFO - joeynmt.training - Epoch  11, Step:    12300, Batch Loss:     0.762841, Tokens per Sec:     8596, Lr: 0.000199\n",
      "2021-10-10 01:19:34,697 - INFO - joeynmt.training - Epoch  11, Step:    12400, Batch Loss:     0.728366, Tokens per Sec:     8563, Lr: 0.000198\n",
      "2021-10-10 01:20:26,897 - INFO - joeynmt.training - Epoch  11, Step:    12500, Batch Loss:     0.663210, Tokens per Sec:     8463, Lr: 0.000198\n",
      "2021-10-10 01:22:11,033 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-10 01:22:11,033 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-10 01:22:11,034 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-10 01:22:11,358 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-10 01:22:11,358 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-10 01:22:20,401 - INFO - joeynmt.training - Example #0\n",
      "2021-10-10 01:22:20,404 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-10 01:22:20,404 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-10 01:22:20,405 - INFO - joeynmt.training - \tHypothesis: Indeed , the conscience of “ the man of the inside ” may be misled .\n",
      "2021-10-10 01:22:20,405 - INFO - joeynmt.training - Example #1\n",
      "2021-10-10 01:22:20,405 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-10 01:22:20,405 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 01:22:20,405 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 01:22:20,405 - INFO - joeynmt.training - Example #2\n",
      "2021-10-10 01:22:20,405 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-10 01:22:20,405 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 01:22:20,406 - INFO - joeynmt.training - \tHypothesis: That will enable us to know the difference between right and wrong and to know the difference between the foolish and discreet and discreet and discreet personals. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 01:22:20,406 - INFO - joeynmt.training - Example #3\n",
      "2021-10-10 01:22:20,406 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-10 01:22:20,406 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-10 01:22:20,406 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met the brothers in Puerto Rico .\n",
      "2021-10-10 01:22:20,406 - INFO - joeynmt.training - Validation result (greedy) at epoch  11, step    12500: bleu:  34.47, loss: 21391.6660, ppl:   2.1317, duration: 113.5080s\n",
      "2021-10-10 01:23:12,315 - INFO - joeynmt.training - Epoch  11, Step:    12600, Batch Loss:     0.760068, Tokens per Sec:     8649, Lr: 0.000197\n",
      "2021-10-10 01:24:05,407 - INFO - joeynmt.training - Epoch  11, Step:    12700, Batch Loss:     0.750592, Tokens per Sec:     8530, Lr: 0.000196\n",
      "2021-10-10 01:24:58,456 - INFO - joeynmt.training - Epoch  11, Step:    12800, Batch Loss:     0.790368, Tokens per Sec:     8406, Lr: 0.000195\n",
      "2021-10-10 01:25:51,599 - INFO - joeynmt.training - Epoch  11, Step:    12900, Batch Loss:     0.711746, Tokens per Sec:     8462, Lr: 0.000195\n",
      "2021-10-10 01:26:44,115 - INFO - joeynmt.training - Epoch  11, Step:    13000, Batch Loss:     0.775698, Tokens per Sec:     8449, Lr: 0.000194\n",
      "2021-10-10 01:28:27,937 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-10 01:28:27,938 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-10 01:28:27,938 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-10 01:28:28,359 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-10 01:28:28,359 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-10 01:28:34,529 - INFO - joeynmt.training - Example #0\n",
      "2021-10-10 01:28:34,530 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-10 01:28:34,530 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-10 01:28:34,530 - INFO - joeynmt.training - \tHypothesis: Yes , the conscience of “ the man of the heart ” may mislead us .\n",
      "2021-10-10 01:28:34,530 - INFO - joeynmt.training - Example #1\n",
      "2021-10-10 01:28:34,530 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-10 01:28:34,530 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 01:28:34,530 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 01:28:34,531 - INFO - joeynmt.training - Example #2\n",
      "2021-10-10 01:28:34,531 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-10 01:28:34,531 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 01:28:34,531 - INFO - joeynmt.training - \tHypothesis: That will enable us to know the difference between right and wrong and to know the difference between the foolish and discreet personals. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 01:28:34,531 - INFO - joeynmt.training - Example #3\n",
      "2021-10-10 01:28:34,531 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-10 01:28:34,531 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-10 01:28:34,531 - INFO - joeynmt.training - \tHypothesis: After February graduation in 1945 , I met the brothers in Puerto Rico .\n",
      "2021-10-10 01:28:34,532 - INFO - joeynmt.training - Validation result (greedy) at epoch  11, step    13000: bleu:  34.41, loss: 21216.1992, ppl:   2.1185, duration: 110.4159s\n",
      "2021-10-10 01:29:27,718 - INFO - joeynmt.training - Epoch  11, Step:    13100, Batch Loss:     0.680241, Tokens per Sec:     8608, Lr: 0.000193\n",
      "2021-10-10 01:30:20,855 - INFO - joeynmt.training - Epoch  11, Step:    13200, Batch Loss:     0.810047, Tokens per Sec:     8574, Lr: 0.000192\n",
      "2021-10-10 01:31:13,888 - INFO - joeynmt.training - Epoch  11, Step:    13300, Batch Loss:     0.676767, Tokens per Sec:     8671, Lr: 0.000192\n",
      "2021-10-10 01:32:06,922 - INFO - joeynmt.training - Epoch  11, Step:    13400, Batch Loss:     0.801284, Tokens per Sec:     8569, Lr: 0.000191\n",
      "2021-10-10 01:32:59,865 - INFO - joeynmt.training - Epoch  11: total training loss 943.84\n",
      "2021-10-10 01:32:59,865 - INFO - joeynmt.training - EPOCH 12\n",
      "2021-10-10 01:33:01,144 - INFO - joeynmt.training - Epoch  12, Step:    13500, Batch Loss:     0.732108, Tokens per Sec:     6783, Lr: 0.000190\n",
      "2021-10-10 01:34:43,776 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-10 01:34:43,777 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-10 01:34:43,777 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-10 01:34:44,103 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-10 01:34:44,104 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-10 01:34:50,142 - INFO - joeynmt.training - Example #0\n",
      "2021-10-10 01:34:50,143 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-10 01:34:50,143 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-10 01:34:50,143 - INFO - joeynmt.training - \tHypothesis: Of course , the conscience of “ a man that is inside ” may mislead us .\n",
      "2021-10-10 01:34:50,143 - INFO - joeynmt.training - Example #1\n",
      "2021-10-10 01:34:50,143 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-10 01:34:50,143 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 01:34:50,144 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 01:34:50,144 - INFO - joeynmt.training - Example #2\n",
      "2021-10-10 01:34:50,144 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-10 01:34:50,144 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 01:34:50,144 - INFO - joeynmt.training - \tHypothesis: That will enable us to know the difference between right and wrong and to know the difference between the foolish and discreet personals. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 01:34:50,144 - INFO - joeynmt.training - Example #3\n",
      "2021-10-10 01:34:50,144 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-10 01:34:50,145 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-10 01:34:50,145 - INFO - joeynmt.training - \tHypothesis: After February graduated in February 1945 , I met the brothers in Puerto Rico .\n",
      "2021-10-10 01:34:50,145 - INFO - joeynmt.training - Validation result (greedy) at epoch  12, step    13500: bleu:  34.86, loss: 21019.0664, ppl:   2.1038, duration: 109.0006s\n",
      "2021-10-10 01:35:42,863 - INFO - joeynmt.training - Epoch  12, Step:    13600, Batch Loss:     0.709551, Tokens per Sec:     8341, Lr: 0.000189\n",
      "2021-10-10 01:36:36,283 - INFO - joeynmt.training - Epoch  12, Step:    13700, Batch Loss:     0.748999, Tokens per Sec:     8578, Lr: 0.000189\n",
      "2021-10-10 01:37:29,641 - INFO - joeynmt.training - Epoch  12, Step:    13800, Batch Loss:     0.713048, Tokens per Sec:     8500, Lr: 0.000188\n",
      "2021-10-10 01:38:22,567 - INFO - joeynmt.training - Epoch  12, Step:    13900, Batch Loss:     0.782922, Tokens per Sec:     8384, Lr: 0.000187\n",
      "2021-10-10 01:39:16,035 - INFO - joeynmt.training - Epoch  12, Step:    14000, Batch Loss:     0.738379, Tokens per Sec:     8620, Lr: 0.000187\n",
      "2021-10-10 01:40:58,753 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-10 01:40:58,753 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-10 01:40:58,753 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-10 01:40:59,176 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-10 01:40:59,176 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-10 01:41:05,397 - INFO - joeynmt.training - Example #0\n",
      "2021-10-10 01:41:05,397 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-10 01:41:05,397 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-10 01:41:05,398 - INFO - joeynmt.training - \tHypothesis: Yes , the conscience of a “ man that is tired ” may mislead us .\n",
      "2021-10-10 01:41:05,398 - INFO - joeynmt.training - Example #1\n",
      "2021-10-10 01:41:05,398 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-10 01:41:05,398 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 01:41:05,398 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 01:41:05,398 - INFO - joeynmt.training - Example #2\n",
      "2021-10-10 01:41:05,398 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-10 01:41:05,399 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 01:41:05,399 - INFO - joeynmt.training - \tHypothesis: That will enable us to know the difference between right and wrong and to know the difference between the foolish and discreet and discreet and discreet and discreet pe. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 01:41:05,399 - INFO - joeynmt.training - Example #3\n",
      "2021-10-10 01:41:05,399 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-10 01:41:05,399 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-10 01:41:05,399 - INFO - joeynmt.training - \tHypothesis: After February gradually in 1945 , I met the brothers in Puerto Rico .\n",
      "2021-10-10 01:41:05,399 - INFO - joeynmt.training - Validation result (greedy) at epoch  12, step    14000: bleu:  35.46, loss: 20968.4277, ppl:   2.1000, duration: 109.3635s\n",
      "2021-10-10 01:41:57,540 - INFO - joeynmt.training - Epoch  12, Step:    14100, Batch Loss:     0.730904, Tokens per Sec:     8612, Lr: 0.000186\n",
      "2021-10-10 01:42:50,712 - INFO - joeynmt.training - Epoch  12, Step:    14200, Batch Loss:     0.717918, Tokens per Sec:     8476, Lr: 0.000185\n",
      "2021-10-10 01:43:44,048 - INFO - joeynmt.training - Epoch  12, Step:    14300, Batch Loss:     0.726980, Tokens per Sec:     8444, Lr: 0.000185\n",
      "2021-10-10 01:44:36,860 - INFO - joeynmt.training - Epoch  12, Step:    14400, Batch Loss:     0.792072, Tokens per Sec:     8647, Lr: 0.000184\n",
      "2021-10-10 01:45:30,403 - INFO - joeynmt.training - Epoch  12, Step:    14500, Batch Loss:     0.513867, Tokens per Sec:     8500, Lr: 0.000184\n",
      "2021-10-10 01:47:12,565 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-10 01:47:12,566 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-10 01:47:12,566 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-10 01:47:12,986 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-10 01:47:12,986 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-10 01:47:19,256 - INFO - joeynmt.training - Example #0\n",
      "2021-10-10 01:47:19,256 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-10 01:47:19,256 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-10 01:47:19,257 - INFO - joeynmt.training - \tHypothesis: Indeed , the conscience of “ the man of the inside ” may be misled .\n",
      "2021-10-10 01:47:19,257 - INFO - joeynmt.training - Example #1\n",
      "2021-10-10 01:47:19,257 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-10 01:47:19,257 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 01:47:19,257 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 01:47:19,257 - INFO - joeynmt.training - Example #2\n",
      "2021-10-10 01:47:19,257 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-10 01:47:19,257 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 01:47:19,258 - INFO - joeynmt.training - \tHypothesis: That will enable us to know the difference between right and wrong and to know the difference between foolish and wisdom and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 01:47:19,258 - INFO - joeynmt.training - Example #3\n",
      "2021-10-10 01:47:19,258 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-10 01:47:19,258 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-10 01:47:19,258 - INFO - joeynmt.training - \tHypothesis: After February graduation in 1945 , I met the brothers in Puerto Rico .\n",
      "2021-10-10 01:47:19,258 - INFO - joeynmt.training - Validation result (greedy) at epoch  12, step    14500: bleu:  35.44, loss: 20770.3555, ppl:   2.0853, duration: 108.8542s\n",
      "2021-10-10 01:48:12,185 - INFO - joeynmt.training - Epoch  12, Step:    14600, Batch Loss:     0.713746, Tokens per Sec:     8645, Lr: 0.000183\n",
      "2021-10-10 01:49:05,359 - INFO - joeynmt.training - Epoch  12, Step:    14700, Batch Loss:     0.719545, Tokens per Sec:     8580, Lr: 0.000182\n",
      "2021-10-10 01:49:17,544 - INFO - joeynmt.training - Epoch  12: total training loss 920.00\n",
      "2021-10-10 01:49:17,545 - INFO - joeynmt.training - EPOCH 13\n",
      "2021-10-10 01:49:57,290 - INFO - joeynmt.training - Epoch  13, Step:    14800, Batch Loss:     0.658668, Tokens per Sec:     8465, Lr: 0.000182\n",
      "2021-10-10 01:50:50,608 - INFO - joeynmt.training - Epoch  13, Step:    14900, Batch Loss:     0.665854, Tokens per Sec:     8503, Lr: 0.000181\n",
      "2021-10-10 01:51:44,354 - INFO - joeynmt.training - Epoch  13, Step:    15000, Batch Loss:     0.712797, Tokens per Sec:     8533, Lr: 0.000180\n",
      "2021-10-10 01:53:31,102 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-10 01:53:31,103 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-10 01:53:31,103 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-10 01:53:31,508 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-10 01:53:31,508 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-10 01:53:37,606 - INFO - joeynmt.training - Example #0\n",
      "2021-10-10 01:53:37,607 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-10 01:53:37,607 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-10 01:53:37,607 - INFO - joeynmt.training - \tHypothesis: Of course , the conscience of “ a man of injustice ” may be misled .\n",
      "2021-10-10 01:53:37,607 - INFO - joeynmt.training - Example #1\n",
      "2021-10-10 01:53:37,607 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-10 01:53:37,607 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 01:53:37,607 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 01:53:37,607 - INFO - joeynmt.training - Example #2\n",
      "2021-10-10 01:53:37,608 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-10 01:53:37,608 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 01:53:37,608 - INFO - joeynmt.training - \tHypothesis: That will enable us to know the difference between right and wrong and to know the difference between the foolish and wisdom and wisdom and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 01:53:37,608 - INFO - joeynmt.training - Example #3\n",
      "2021-10-10 01:53:37,608 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-10 01:53:37,608 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-10 01:53:37,608 - INFO - joeynmt.training - \tHypothesis: After February graduation in February 1945 , I met the brothers in Puerto Rico .\n",
      "2021-10-10 01:53:37,608 - INFO - joeynmt.training - Validation result (greedy) at epoch  13, step    15000: bleu:  35.60, loss: 20737.1543, ppl:   2.0829, duration: 113.2537s\n",
      "2021-10-10 01:54:30,101 - INFO - joeynmt.training - Epoch  13, Step:    15100, Batch Loss:     0.726789, Tokens per Sec:     8442, Lr: 0.000180\n",
      "2021-10-10 01:55:22,439 - INFO - joeynmt.training - Epoch  13, Step:    15200, Batch Loss:     0.751723, Tokens per Sec:     8578, Lr: 0.000179\n",
      "2021-10-10 01:56:15,550 - INFO - joeynmt.training - Epoch  13, Step:    15300, Batch Loss:     0.790216, Tokens per Sec:     8470, Lr: 0.000179\n",
      "2021-10-10 01:57:08,499 - INFO - joeynmt.training - Epoch  13, Step:    15400, Batch Loss:     0.786533, Tokens per Sec:     8692, Lr: 0.000178\n",
      "2021-10-10 01:58:01,891 - INFO - joeynmt.training - Epoch  13, Step:    15500, Batch Loss:     0.701736, Tokens per Sec:     8614, Lr: 0.000177\n",
      "2021-10-10 01:59:47,168 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-10 01:59:47,169 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-10 01:59:47,169 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-10 01:59:47,494 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-10 01:59:47,494 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-10 01:59:53,657 - INFO - joeynmt.training - Example #0\n",
      "2021-10-10 01:59:53,657 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-10 01:59:53,657 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-10 01:59:53,657 - INFO - joeynmt.training - \tHypothesis: Of course , the conscience of “ a man who is inside ” may be misled .\n",
      "2021-10-10 01:59:53,658 - INFO - joeynmt.training - Example #1\n",
      "2021-10-10 01:59:53,658 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-10 01:59:53,658 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 01:59:53,658 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 01:59:53,658 - INFO - joeynmt.training - Example #2\n",
      "2021-10-10 01:59:53,658 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-10 01:59:53,658 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 01:59:53,658 - INFO - joeynmt.training - \tHypothesis: That will enable us to know the difference between right and wrong and to know the difference between the foolish and wisdom and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 01:59:53,659 - INFO - joeynmt.training - Example #3\n",
      "2021-10-10 01:59:53,659 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-10 01:59:53,659 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-10 01:59:53,659 - INFO - joeynmt.training - \tHypothesis: After February graduation in February 1945 , I met the brothers in Puerto Rico .\n",
      "2021-10-10 01:59:53,659 - INFO - joeynmt.training - Validation result (greedy) at epoch  13, step    15500: bleu:  35.33, loss: 20590.0117, ppl:   2.0721, duration: 111.7669s\n",
      "2021-10-10 02:00:46,837 - INFO - joeynmt.training - Epoch  13, Step:    15600, Batch Loss:     0.782706, Tokens per Sec:     8647, Lr: 0.000177\n",
      "2021-10-10 02:01:40,194 - INFO - joeynmt.training - Epoch  13, Step:    15700, Batch Loss:     0.732002, Tokens per Sec:     8577, Lr: 0.000176\n",
      "2021-10-10 02:02:33,681 - INFO - joeynmt.training - Epoch  13, Step:    15800, Batch Loss:     0.746306, Tokens per Sec:     8480, Lr: 0.000176\n",
      "2021-10-10 02:03:26,258 - INFO - joeynmt.training - Epoch  13, Step:    15900, Batch Loss:     0.853683, Tokens per Sec:     8294, Lr: 0.000175\n",
      "2021-10-10 02:03:52,960 - INFO - joeynmt.training - Epoch  13: total training loss 904.59\n",
      "2021-10-10 02:03:52,961 - INFO - joeynmt.training - EPOCH 14\n",
      "2021-10-10 02:04:19,594 - INFO - joeynmt.training - Epoch  14, Step:    16000, Batch Loss:     0.712539, Tokens per Sec:     8126, Lr: 0.000175\n",
      "2021-10-10 02:06:01,616 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-10 02:06:01,616 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-10 02:06:01,616 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-10 02:06:01,944 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-10 02:06:01,944 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-10 02:06:08,007 - INFO - joeynmt.training - Example #0\n",
      "2021-10-10 02:06:08,008 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-10 02:06:08,008 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-10 02:06:08,008 - INFO - joeynmt.training - \tHypothesis: Yes , the conscience of “ the man of the inside ” may mislead us .\n",
      "2021-10-10 02:06:08,008 - INFO - joeynmt.training - Example #1\n",
      "2021-10-10 02:06:08,008 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-10 02:06:08,008 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 02:06:08,008 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 02:06:08,008 - INFO - joeynmt.training - Example #2\n",
      "2021-10-10 02:06:08,009 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-10 02:06:08,009 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 02:06:08,009 - INFO - joeynmt.training - \tHypothesis: That will enable us to know the difference between right and wrong and to know the difference between foolish and wise and wise . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 02:06:08,009 - INFO - joeynmt.training - Example #3\n",
      "2021-10-10 02:06:08,009 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-10 02:06:08,009 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-10 02:06:08,009 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met the brothers in Puerto Rico .\n",
      "2021-10-10 02:06:08,009 - INFO - joeynmt.training - Validation result (greedy) at epoch  14, step    16000: bleu:  35.78, loss: 20417.3633, ppl:   2.0594, duration: 108.4152s\n",
      "2021-10-10 02:07:01,038 - INFO - joeynmt.training - Epoch  14, Step:    16100, Batch Loss:     0.722726, Tokens per Sec:     8500, Lr: 0.000174\n",
      "2021-10-10 02:07:54,037 - INFO - joeynmt.training - Epoch  14, Step:    16200, Batch Loss:     0.721225, Tokens per Sec:     8367, Lr: 0.000174\n",
      "2021-10-10 02:08:47,751 - INFO - joeynmt.training - Epoch  14, Step:    16300, Batch Loss:     0.713758, Tokens per Sec:     8490, Lr: 0.000173\n",
      "2021-10-10 02:09:40,818 - INFO - joeynmt.training - Epoch  14, Step:    16400, Batch Loss:     0.698170, Tokens per Sec:     8528, Lr: 0.000173\n",
      "2021-10-10 02:10:33,871 - INFO - joeynmt.training - Epoch  14, Step:    16500, Batch Loss:     0.737096, Tokens per Sec:     8443, Lr: 0.000172\n",
      "2021-10-10 02:12:25,329 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-10 02:12:25,330 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-10 02:12:25,330 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-10 02:12:25,656 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-10 02:12:25,656 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-10 02:12:31,721 - INFO - joeynmt.training - Example #0\n",
      "2021-10-10 02:12:31,722 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-10 02:12:31,722 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-10 02:12:31,722 - INFO - joeynmt.training - \tHypothesis: Yes , the conscience of “ a man of injustice ” may mislead us .\n",
      "2021-10-10 02:12:31,722 - INFO - joeynmt.training - Example #1\n",
      "2021-10-10 02:12:31,723 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-10 02:12:31,723 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 02:12:31,723 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 02:12:31,723 - INFO - joeynmt.training - Example #2\n",
      "2021-10-10 02:12:31,723 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-10 02:12:31,724 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 02:12:31,724 - INFO - joeynmt.training - \tHypothesis: That will enable us to know the difference between right and wrong and to know the difference between foolish and discreet wisdom and wisdom and wisdom . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 02:12:31,724 - INFO - joeynmt.training - Example #3\n",
      "2021-10-10 02:12:31,724 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-10 02:12:31,724 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-10 02:12:31,724 - INFO - joeynmt.training - \tHypothesis: After February in 1945 , I met the brothers in Puerto Rico .\n",
      "2021-10-10 02:12:31,724 - INFO - joeynmt.training - Validation result (greedy) at epoch  14, step    16500: bleu:  35.93, loss: 20260.5645, ppl:   2.0480, duration: 117.8525s\n",
      "2021-10-10 02:13:24,244 - INFO - joeynmt.training - Epoch  14, Step:    16600, Batch Loss:     0.715655, Tokens per Sec:     8598, Lr: 0.000172\n",
      "2021-10-10 02:14:16,847 - INFO - joeynmt.training - Epoch  14, Step:    16700, Batch Loss:     0.760817, Tokens per Sec:     8415, Lr: 0.000171\n",
      "2021-10-10 02:15:09,304 - INFO - joeynmt.training - Epoch  14, Step:    16800, Batch Loss:     0.767770, Tokens per Sec:     8528, Lr: 0.000170\n",
      "2021-10-10 02:16:02,189 - INFO - joeynmt.training - Epoch  14, Step:    16900, Batch Loss:     0.581460, Tokens per Sec:     8635, Lr: 0.000170\n",
      "2021-10-10 02:16:55,609 - INFO - joeynmt.training - Epoch  14, Step:    17000, Batch Loss:     0.701065, Tokens per Sec:     8584, Lr: 0.000169\n",
      "2021-10-10 02:18:38,130 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-10 02:18:38,130 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-10 02:18:38,130 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-10 02:18:38,508 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-10 02:18:38,508 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-10 02:18:44,787 - INFO - joeynmt.training - Example #0\n",
      "2021-10-10 02:18:44,788 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-10 02:18:44,788 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-10 02:18:44,788 - INFO - joeynmt.training - \tHypothesis: Indeed , the conscience of “ a man of inside ” may mislead us .\n",
      "2021-10-10 02:18:44,788 - INFO - joeynmt.training - Example #1\n",
      "2021-10-10 02:18:44,788 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-10 02:18:44,788 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 02:18:44,789 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 02:18:44,789 - INFO - joeynmt.training - Example #2\n",
      "2021-10-10 02:18:44,789 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-10 02:18:44,789 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 02:18:44,789 - INFO - joeynmt.training - \tHypothesis: That will enable us to know the difference between what is right and what is wrong and to know the difference between foolish and discreet and discreet and discreet matter. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 02:18:44,789 - INFO - joeynmt.training - Example #3\n",
      "2021-10-10 02:18:44,789 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-10 02:18:44,790 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-10 02:18:44,790 - INFO - joeynmt.training - \tHypothesis: After February graduation in February 1945 , I met our children in Puerto Rico .\n",
      "2021-10-10 02:18:44,790 - INFO - joeynmt.training - Validation result (greedy) at epoch  14, step    17000: bleu:  36.18, loss: 20187.5410, ppl:   2.0428, duration: 109.1797s\n",
      "2021-10-10 02:19:37,830 - INFO - joeynmt.training - Epoch  14, Step:    17100, Batch Loss:     0.665359, Tokens per Sec:     8503, Lr: 0.000169\n",
      "2021-10-10 02:20:20,418 - INFO - joeynmt.training - Epoch  14: total training loss 888.75\n",
      "2021-10-10 02:20:20,419 - INFO - joeynmt.training - EPOCH 15\n",
      "2021-10-10 02:20:31,418 - INFO - joeynmt.training - Epoch  15, Step:    17200, Batch Loss:     0.766790, Tokens per Sec:     7670, Lr: 0.000168\n",
      "2021-10-10 02:21:24,732 - INFO - joeynmt.training - Epoch  15, Step:    17300, Batch Loss:     0.717473, Tokens per Sec:     8540, Lr: 0.000168\n",
      "2021-10-10 02:22:16,397 - INFO - joeynmt.training - Epoch  15, Step:    17400, Batch Loss:     0.793047, Tokens per Sec:     8266, Lr: 0.000168\n",
      "2021-10-10 02:23:09,112 - INFO - joeynmt.training - Epoch  15, Step:    17500, Batch Loss:     0.834139, Tokens per Sec:     8619, Lr: 0.000167\n",
      "2021-10-10 02:24:53,532 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-10 02:24:53,533 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-10 02:24:53,533 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-10 02:24:53,856 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-10 02:24:53,856 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-10 02:24:59,862 - INFO - joeynmt.training - Example #0\n",
      "2021-10-10 02:24:59,862 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-10 02:24:59,862 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-10 02:24:59,862 - INFO - joeynmt.training - \tHypothesis: Indeed , the conscience of “ the man of the inner man ” may mislead us .\n",
      "2021-10-10 02:24:59,863 - INFO - joeynmt.training - Example #1\n",
      "2021-10-10 02:24:59,863 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-10 02:24:59,863 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 02:24:59,863 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 02:24:59,863 - INFO - joeynmt.training - Example #2\n",
      "2021-10-10 02:24:59,863 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-10 02:24:59,863 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 02:24:59,864 - INFO - joeynmt.training - \tHypothesis: That will enable us to know the difference between right and wrong and to know the difference between foolish and discreet and discreet and discreet personals. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 02:24:59,864 - INFO - joeynmt.training - Example #3\n",
      "2021-10-10 02:24:59,864 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-10 02:24:59,864 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-10 02:24:59,864 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met the brothers in Puerto Rico .\n",
      "2021-10-10 02:24:59,864 - INFO - joeynmt.training - Validation result (greedy) at epoch  15, step    17500: bleu:  36.09, loss: 20154.5195, ppl:   2.0404, duration: 110.7516s\n",
      "2021-10-10 02:25:52,711 - INFO - joeynmt.training - Epoch  15, Step:    17600, Batch Loss:     0.725978, Tokens per Sec:     8752, Lr: 0.000167\n",
      "2021-10-10 02:26:46,528 - INFO - joeynmt.training - Epoch  15, Step:    17700, Batch Loss:     0.807607, Tokens per Sec:     8564, Lr: 0.000166\n",
      "2021-10-10 02:27:39,411 - INFO - joeynmt.training - Epoch  15, Step:    17800, Batch Loss:     0.880488, Tokens per Sec:     8489, Lr: 0.000166\n",
      "2021-10-10 02:28:33,330 - INFO - joeynmt.training - Epoch  15, Step:    17900, Batch Loss:     0.639149, Tokens per Sec:     8523, Lr: 0.000165\n",
      "2021-10-10 02:29:26,266 - INFO - joeynmt.training - Epoch  15, Step:    18000, Batch Loss:     0.727562, Tokens per Sec:     8516, Lr: 0.000165\n",
      "2021-10-10 02:31:09,316 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-10 02:31:09,316 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-10 02:31:09,316 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-10 02:31:09,642 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-10 02:31:09,642 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-10 02:31:15,726 - INFO - joeynmt.training - Example #0\n",
      "2021-10-10 02:31:15,726 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-10 02:31:15,726 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-10 02:31:15,726 - INFO - joeynmt.training - \tHypothesis: Indeed , the conscience of “ the man of the inner inside ” may mislead us .\n",
      "2021-10-10 02:31:15,726 - INFO - joeynmt.training - Example #1\n",
      "2021-10-10 02:31:15,727 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-10 02:31:15,727 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 02:31:15,727 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 02:31:15,727 - INFO - joeynmt.training - Example #2\n",
      "2021-10-10 02:31:15,727 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-10 02:31:15,727 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 02:31:15,727 - INFO - joeynmt.training - \tHypothesis: That will enable us to know the difference between right and wrong and to know the difference between foolish and discreet and discreet and discreet personality. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 02:31:15,728 - INFO - joeynmt.training - Example #3\n",
      "2021-10-10 02:31:15,728 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-10 02:31:15,728 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-10 02:31:15,728 - INFO - joeynmt.training - \tHypothesis: After February graduates in February 1945 , I met the brothers in Puerto Rico .\n",
      "2021-10-10 02:31:15,728 - INFO - joeynmt.training - Validation result (greedy) at epoch  15, step    18000: bleu:  36.71, loss: 19984.2266, ppl:   2.0281, duration: 109.4610s\n",
      "2021-10-10 02:32:08,933 - INFO - joeynmt.training - Epoch  15, Step:    18100, Batch Loss:     0.609975, Tokens per Sec:     8471, Lr: 0.000164\n",
      "2021-10-10 02:33:02,307 - INFO - joeynmt.training - Epoch  15, Step:    18200, Batch Loss:     0.713885, Tokens per Sec:     8529, Lr: 0.000164\n",
      "2021-10-10 02:33:54,738 - INFO - joeynmt.training - Epoch  15, Step:    18300, Batch Loss:     0.697167, Tokens per Sec:     8444, Lr: 0.000163\n",
      "2021-10-10 02:34:48,763 - INFO - joeynmt.training - Epoch  15, Step:    18400, Batch Loss:     0.737961, Tokens per Sec:     8408, Lr: 0.000163\n",
      "2021-10-10 02:34:53,006 - INFO - joeynmt.training - Epoch  15: total training loss 873.10\n",
      "2021-10-10 02:34:53,007 - INFO - joeynmt.training - EPOCH 16\n",
      "2021-10-10 02:35:41,892 - INFO - joeynmt.training - Epoch  16, Step:    18500, Batch Loss:     0.591653, Tokens per Sec:     8512, Lr: 0.000162\n",
      "2021-10-10 02:37:27,255 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-10 02:37:27,256 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-10 02:37:27,256 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-10 02:37:27,676 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-10 02:37:27,676 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-10 02:37:33,895 - INFO - joeynmt.training - Example #0\n",
      "2021-10-10 02:37:33,896 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-10 02:37:33,896 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-10 02:37:33,896 - INFO - joeynmt.training - \tHypothesis: Indeed , the conscience of “ a man of injustice ” may be misleading us .\n",
      "2021-10-10 02:37:33,896 - INFO - joeynmt.training - Example #1\n",
      "2021-10-10 02:37:33,896 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-10 02:37:33,896 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 02:37:33,896 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 02:37:33,896 - INFO - joeynmt.training - Example #2\n",
      "2021-10-10 02:37:33,897 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-10 02:37:33,897 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 02:37:33,897 - INFO - joeynmt.training - \tHypothesis: That will enable us to know the difference between right and wrong and to know the difference between the stupid and discreet and discreet personals. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 02:37:33,897 - INFO - joeynmt.training - Example #3\n",
      "2021-10-10 02:37:33,897 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-10 02:37:33,897 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-10 02:37:33,897 - INFO - joeynmt.training - \tHypothesis: After February graduation in 1945 , I met the brothers in Puerto Rico .\n",
      "2021-10-10 02:37:33,897 - INFO - joeynmt.training - Validation result (greedy) at epoch  16, step    18500: bleu:  36.41, loss: 19924.4434, ppl:   2.0238, duration: 112.0045s\n",
      "2021-10-10 02:38:26,571 - INFO - joeynmt.training - Epoch  16, Step:    18600, Batch Loss:     0.723147, Tokens per Sec:     8508, Lr: 0.000162\n",
      "2021-10-10 02:39:21,010 - INFO - joeynmt.training - Epoch  16, Step:    18700, Batch Loss:     0.585516, Tokens per Sec:     8516, Lr: 0.000162\n",
      "2021-10-10 02:40:14,135 - INFO - joeynmt.training - Epoch  16, Step:    18800, Batch Loss:     0.773026, Tokens per Sec:     8549, Lr: 0.000161\n",
      "2021-10-10 02:41:08,118 - INFO - joeynmt.training - Epoch  16, Step:    18900, Batch Loss:     0.736913, Tokens per Sec:     8514, Lr: 0.000161\n",
      "2021-10-10 02:42:01,747 - INFO - joeynmt.training - Epoch  16, Step:    19000, Batch Loss:     0.716770, Tokens per Sec:     8272, Lr: 0.000160\n",
      "2021-10-10 02:43:44,251 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-10 02:43:44,251 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-10 02:43:44,252 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-10 02:43:44,675 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-10 02:43:44,675 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-10 02:43:50,841 - INFO - joeynmt.training - Example #0\n",
      "2021-10-10 02:43:50,841 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-10 02:43:50,842 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-10 02:43:50,842 - INFO - joeynmt.training - \tHypothesis: Indeed , the conscience of “ the man of the inside ” may be misled .\n",
      "2021-10-10 02:43:50,842 - INFO - joeynmt.training - Example #1\n",
      "2021-10-10 02:43:50,842 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-10 02:43:50,842 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 02:43:50,842 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 02:43:50,842 - INFO - joeynmt.training - Example #2\n",
      "2021-10-10 02:43:50,842 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-10 02:43:50,843 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 02:43:50,843 - INFO - joeynmt.training - \tHypothesis: That will enable us to know the difference between right and wrong and to know the difference between foolish and wise and wise . — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 02:43:50,843 - INFO - joeynmt.training - Example #3\n",
      "2021-10-10 02:43:50,843 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-10 02:43:50,843 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-10 02:43:50,843 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met the brothers in Puerto Rico .\n",
      "2021-10-10 02:43:50,843 - INFO - joeynmt.training - Validation result (greedy) at epoch  16, step    19000: bleu:  36.46, loss: 19830.5996, ppl:   2.0171, duration: 109.0957s\n",
      "2021-10-10 02:44:43,844 - INFO - joeynmt.training - Epoch  16, Step:    19100, Batch Loss:     0.786260, Tokens per Sec:     8579, Lr: 0.000160\n",
      "2021-10-10 02:45:36,408 - INFO - joeynmt.training - Epoch  16, Step:    19200, Batch Loss:     0.780701, Tokens per Sec:     8630, Lr: 0.000159\n",
      "2021-10-10 02:46:29,609 - INFO - joeynmt.training - Epoch  16, Step:    19300, Batch Loss:     0.714690, Tokens per Sec:     8514, Lr: 0.000159\n",
      "2021-10-10 02:47:22,967 - INFO - joeynmt.training - Epoch  16, Step:    19400, Batch Loss:     0.658642, Tokens per Sec:     8321, Lr: 0.000159\n",
      "2021-10-10 02:48:15,686 - INFO - joeynmt.training - Epoch  16, Step:    19500, Batch Loss:     0.734485, Tokens per Sec:     8471, Lr: 0.000158\n",
      "2021-10-10 02:50:00,509 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-10 02:50:00,510 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-10 02:50:00,510 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-10 02:50:00,836 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-10 02:50:00,836 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-10 02:50:07,015 - INFO - joeynmt.training - Example #0\n",
      "2021-10-10 02:50:07,016 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-10 02:50:07,016 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-10 02:50:07,016 - INFO - joeynmt.training - \tHypothesis: Indeed , the conscience of “ the man of the inner man ” may mislead us .\n",
      "2021-10-10 02:50:07,016 - INFO - joeynmt.training - Example #1\n",
      "2021-10-10 02:50:07,017 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-10 02:50:07,017 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 02:50:07,017 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 02:50:07,017 - INFO - joeynmt.training - Example #2\n",
      "2021-10-10 02:50:07,017 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-10 02:50:07,017 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 02:50:07,017 - INFO - joeynmt.training - \tHypothesis: That will enable us to know the difference between right and wrong and to know the difference between foolish and discreet and discreet and discreet personals. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 02:50:07,017 - INFO - joeynmt.training - Example #3\n",
      "2021-10-10 02:50:07,018 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-10 02:50:07,018 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-10 02:50:07,018 - INFO - joeynmt.training - \tHypothesis: After February in February 1945 , I met our children in Puerto Rico .\n",
      "2021-10-10 02:50:07,018 - INFO - joeynmt.training - Validation result (greedy) at epoch  16, step    19500: bleu:  36.92, loss: 19686.7812, ppl:   2.0069, duration: 111.3315s\n",
      "2021-10-10 02:50:59,783 - INFO - joeynmt.training - Epoch  16, Step:    19600, Batch Loss:     0.800430, Tokens per Sec:     8390, Lr: 0.000158\n",
      "2021-10-10 02:51:19,326 - INFO - joeynmt.training - Epoch  16: total training loss 859.52\n",
      "2021-10-10 02:51:19,326 - INFO - joeynmt.training - EPOCH 17\n",
      "2021-10-10 02:51:53,363 - INFO - joeynmt.training - Epoch  17, Step:    19700, Batch Loss:     0.696007, Tokens per Sec:     8445, Lr: 0.000157\n",
      "2021-10-10 02:52:46,508 - INFO - joeynmt.training - Epoch  17, Step:    19800, Batch Loss:     0.682793, Tokens per Sec:     8376, Lr: 0.000157\n",
      "2021-10-10 02:53:41,480 - INFO - joeynmt.training - Epoch  17, Step:    19900, Batch Loss:     0.733936, Tokens per Sec:     8286, Lr: 0.000157\n",
      "2021-10-10 02:54:34,399 - INFO - joeynmt.training - Epoch  17, Step:    20000, Batch Loss:     0.701179, Tokens per Sec:     8599, Lr: 0.000156\n",
      "2021-10-10 02:56:22,059 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-10 02:56:22,060 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-10 02:56:22,060 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-10 02:56:22,474 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-10 02:56:22,474 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-10 02:56:28,540 - INFO - joeynmt.training - Example #0\n",
      "2021-10-10 02:56:28,540 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-10 02:56:28,540 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-10 02:56:28,540 - INFO - joeynmt.training - \tHypothesis: Indeed , the conscience of “ the man of the inside ” may mislead us .\n",
      "2021-10-10 02:56:28,541 - INFO - joeynmt.training - Example #1\n",
      "2021-10-10 02:56:28,541 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-10 02:56:28,541 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 02:56:28,541 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave to his disciples ?\n",
      "2021-10-10 02:56:28,541 - INFO - joeynmt.training - Example #2\n",
      "2021-10-10 02:56:28,541 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-10 02:56:28,541 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 02:56:28,542 - INFO - joeynmt.training - \tHypothesis: That will enable us to know the difference between right and wrong and to know the difference between foolish and discreet and discreet personals. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 02:56:28,542 - INFO - joeynmt.training - Example #3\n",
      "2021-10-10 02:56:28,542 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-10 02:56:28,542 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-10 02:56:28,542 - INFO - joeynmt.training - \tHypothesis: After February graduation in 1945 , I met our children in Puerto Rico .\n",
      "2021-10-10 02:56:28,542 - INFO - joeynmt.training - Validation result (greedy) at epoch  17, step    20000: bleu:  36.68, loss: 19612.9004, ppl:   2.0016, duration: 114.1419s\n",
      "2021-10-10 02:57:21,000 - INFO - joeynmt.training - Epoch  17, Step:    20100, Batch Loss:     0.683455, Tokens per Sec:     8664, Lr: 0.000156\n",
      "2021-10-10 02:58:14,444 - INFO - joeynmt.training - Epoch  17, Step:    20200, Batch Loss:     0.785646, Tokens per Sec:     8470, Lr: 0.000155\n",
      "2021-10-10 02:59:07,138 - INFO - joeynmt.training - Epoch  17, Step:    20300, Batch Loss:     0.648937, Tokens per Sec:     8376, Lr: 0.000155\n",
      "2021-10-10 03:00:00,128 - INFO - joeynmt.training - Epoch  17, Step:    20400, Batch Loss:     0.721242, Tokens per Sec:     8369, Lr: 0.000155\n",
      "2021-10-10 03:00:52,557 - INFO - joeynmt.training - Epoch  17, Step:    20500, Batch Loss:     0.673328, Tokens per Sec:     8440, Lr: 0.000154\n",
      "2021-10-10 03:02:38,133 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-10 03:02:38,133 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-10 03:02:38,134 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-10 03:02:38,556 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-10 03:02:38,556 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-10 03:02:44,649 - INFO - joeynmt.training - Example #0\n",
      "2021-10-10 03:02:44,650 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-10 03:02:44,650 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-10 03:02:44,650 - INFO - joeynmt.training - \tHypothesis: Yes , the conscience of “ the man of the inside ” may be misled .\n",
      "2021-10-10 03:02:44,650 - INFO - joeynmt.training - Example #1\n",
      "2021-10-10 03:02:44,650 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-10 03:02:44,650 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 03:02:44,650 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave to his disciples ?\n",
      "2021-10-10 03:02:44,650 - INFO - joeynmt.training - Example #2\n",
      "2021-10-10 03:02:44,651 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-10 03:02:44,651 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 03:02:44,651 - INFO - joeynmt.training - \tHypothesis: That will enable us to know the difference between right and wrong and to know the difference between foolish and discreet personals. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 03:02:44,651 - INFO - joeynmt.training - Example #3\n",
      "2021-10-10 03:02:44,651 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-10 03:02:44,651 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-10 03:02:44,651 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met our brothers in Puerto Rico .\n",
      "2021-10-10 03:02:44,651 - INFO - joeynmt.training - Validation result (greedy) at epoch  17, step    20500: bleu:  37.06, loss: 19564.3535, ppl:   1.9982, duration: 112.0934s\n",
      "2021-10-10 03:03:39,329 - INFO - joeynmt.training - Epoch  17, Step:    20600, Batch Loss:     0.770753, Tokens per Sec:     8430, Lr: 0.000154\n",
      "2021-10-10 03:04:31,549 - INFO - joeynmt.training - Epoch  17, Step:    20700, Batch Loss:     0.705510, Tokens per Sec:     8492, Lr: 0.000154\n",
      "2021-10-10 03:05:24,407 - INFO - joeynmt.training - Epoch  17, Step:    20800, Batch Loss:     0.672634, Tokens per Sec:     8556, Lr: 0.000153\n",
      "2021-10-10 03:06:01,155 - INFO - joeynmt.training - Epoch  17: total training loss 849.40\n",
      "2021-10-10 03:06:01,156 - INFO - joeynmt.training - EPOCH 18\n",
      "2021-10-10 03:06:17,578 - INFO - joeynmt.training - Epoch  18, Step:    20900, Batch Loss:     0.661197, Tokens per Sec:     8315, Lr: 0.000153\n",
      "2021-10-10 03:07:10,473 - INFO - joeynmt.training - Epoch  18, Step:    21000, Batch Loss:     0.686094, Tokens per Sec:     8560, Lr: 0.000152\n",
      "2021-10-10 03:08:56,221 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-10 03:08:56,222 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-10 03:08:56,222 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-10 03:08:56,606 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-10 03:08:56,606 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-10 03:09:02,733 - INFO - joeynmt.training - Example #0\n",
      "2021-10-10 03:09:02,733 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-10 03:09:02,734 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-10 03:09:02,734 - INFO - joeynmt.training - \tHypothesis: Of course , the conscience of “ the man of the inside ” may mislead us .\n",
      "2021-10-10 03:09:02,734 - INFO - joeynmt.training - Example #1\n",
      "2021-10-10 03:09:02,734 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-10 03:09:02,734 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 03:09:02,734 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 03:09:02,734 - INFO - joeynmt.training - Example #2\n",
      "2021-10-10 03:09:02,735 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-10 03:09:02,735 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 03:09:02,735 - INFO - joeynmt.training - \tHypothesis: That will enable us to know the difference between right and wrong and to know the difference between foolish and discreet and discreet personals. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 03:09:02,735 - INFO - joeynmt.training - Example #3\n",
      "2021-10-10 03:09:02,735 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-10 03:09:02,736 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-10 03:09:02,736 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met our brothers in Puerto Rico .\n",
      "2021-10-10 03:09:02,736 - INFO - joeynmt.training - Validation result (greedy) at epoch  18, step    21000: bleu:  37.02, loss: 19558.2559, ppl:   1.9978, duration: 112.2619s\n",
      "2021-10-10 03:09:56,488 - INFO - joeynmt.training - Epoch  18, Step:    21100, Batch Loss:     0.678441, Tokens per Sec:     8326, Lr: 0.000152\n",
      "2021-10-10 03:10:49,713 - INFO - joeynmt.training - Epoch  18, Step:    21200, Batch Loss:     0.656398, Tokens per Sec:     8539, Lr: 0.000152\n",
      "2021-10-10 03:11:42,523 - INFO - joeynmt.training - Epoch  18, Step:    21300, Batch Loss:     0.665398, Tokens per Sec:     8226, Lr: 0.000151\n",
      "2021-10-10 03:12:35,791 - INFO - joeynmt.training - Epoch  18, Step:    21400, Batch Loss:     0.754287, Tokens per Sec:     8706, Lr: 0.000151\n",
      "2021-10-10 03:13:28,227 - INFO - joeynmt.training - Epoch  18, Step:    21500, Batch Loss:     0.698608, Tokens per Sec:     8327, Lr: 0.000151\n",
      "2021-10-10 03:15:14,883 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-10 03:15:14,883 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-10 03:15:14,883 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-10 03:15:15,211 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-10 03:15:15,211 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-10 03:15:21,263 - INFO - joeynmt.training - Example #0\n",
      "2021-10-10 03:15:21,263 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-10 03:15:21,264 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-10 03:15:21,264 - INFO - joeynmt.training - \tHypothesis: Yes , the conscience of “ the man of the inside ” may be misled .\n",
      "2021-10-10 03:15:21,264 - INFO - joeynmt.training - Example #1\n",
      "2021-10-10 03:15:21,264 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-10 03:15:21,264 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 03:15:21,264 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 03:15:21,264 - INFO - joeynmt.training - Example #2\n",
      "2021-10-10 03:15:21,265 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-10 03:15:21,265 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 03:15:21,265 - INFO - joeynmt.training - \tHypothesis: That will enable us to know the difference between right and wrong and to know the difference between foolish and discreet and discreet personals. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 03:15:21,265 - INFO - joeynmt.training - Example #3\n",
      "2021-10-10 03:15:21,265 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-10 03:15:21,265 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-10 03:15:21,265 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met our brothers in Puerto Rico .\n",
      "2021-10-10 03:15:21,265 - INFO - joeynmt.training - Validation result (greedy) at epoch  18, step    21500: bleu:  37.37, loss: 19412.9766, ppl:   1.9875, duration: 113.0380s\n",
      "2021-10-10 03:16:13,765 - INFO - joeynmt.training - Epoch  18, Step:    21600, Batch Loss:     0.658505, Tokens per Sec:     8403, Lr: 0.000150\n",
      "2021-10-10 03:17:07,591 - INFO - joeynmt.training - Epoch  18, Step:    21700, Batch Loss:     0.693647, Tokens per Sec:     8516, Lr: 0.000150\n",
      "2021-10-10 03:18:01,055 - INFO - joeynmt.training - Epoch  18, Step:    21800, Batch Loss:     0.689643, Tokens per Sec:     8594, Lr: 0.000150\n",
      "2021-10-10 03:18:53,651 - INFO - joeynmt.training - Epoch  18, Step:    21900, Batch Loss:     0.692315, Tokens per Sec:     8407, Lr: 0.000149\n",
      "2021-10-10 03:19:47,837 - INFO - joeynmt.training - Epoch  18, Step:    22000, Batch Loss:     0.680442, Tokens per Sec:     8614, Lr: 0.000149\n",
      "2021-10-10 03:21:30,419 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-10 03:21:30,420 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-10 03:21:30,420 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-10 03:21:30,848 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-10 03:21:30,848 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-10 03:21:37,706 - INFO - joeynmt.training - Example #0\n",
      "2021-10-10 03:21:37,707 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-10 03:21:37,707 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-10 03:21:37,707 - INFO - joeynmt.training - \tHypothesis: Of course , the conscience of “ the man of the inside ” may mislead us .\n",
      "2021-10-10 03:21:37,707 - INFO - joeynmt.training - Example #1\n",
      "2021-10-10 03:21:37,707 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-10 03:21:37,707 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 03:21:37,707 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 03:21:37,708 - INFO - joeynmt.training - Example #2\n",
      "2021-10-10 03:21:37,708 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-10 03:21:37,708 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 03:21:37,708 - INFO - joeynmt.training - \tHypothesis: That will enable us to know the difference between right and wrong and to know the difference between foolish and discreet and discreet personal. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 03:21:37,708 - INFO - joeynmt.training - Example #3\n",
      "2021-10-10 03:21:37,708 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-10 03:21:37,708 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-10 03:21:37,709 - INFO - joeynmt.training - \tHypothesis: After finishing in February 1945 , I met the brothers in Puerto Rico .\n",
      "2021-10-10 03:21:37,709 - INFO - joeynmt.training - Validation result (greedy) at epoch  18, step    22000: bleu:  37.25, loss: 19302.9609, ppl:   1.9798, duration: 109.8703s\n",
      "2021-10-10 03:22:30,190 - INFO - joeynmt.training - Epoch  18: total training loss 837.19\n",
      "2021-10-10 03:22:30,191 - INFO - joeynmt.training - EPOCH 19\n",
      "2021-10-10 03:22:30,900 - INFO - joeynmt.training - Epoch  19, Step:    22100, Batch Loss:     0.656769, Tokens per Sec:     5175, Lr: 0.000149\n",
      "2021-10-10 03:23:24,288 - INFO - joeynmt.training - Epoch  19, Step:    22200, Batch Loss:     0.579663, Tokens per Sec:     8551, Lr: 0.000148\n",
      "2021-10-10 03:24:17,255 - INFO - joeynmt.training - Epoch  19, Step:    22300, Batch Loss:     0.636427, Tokens per Sec:     8477, Lr: 0.000148\n",
      "2021-10-10 03:25:10,421 - INFO - joeynmt.training - Epoch  19, Step:    22400, Batch Loss:     0.691276, Tokens per Sec:     8444, Lr: 0.000148\n",
      "2021-10-10 03:26:03,565 - INFO - joeynmt.training - Epoch  19, Step:    22500, Batch Loss:     0.673645, Tokens per Sec:     8224, Lr: 0.000147\n",
      "2021-10-10 03:27:49,155 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-10 03:27:49,156 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-10 03:27:49,156 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-10 03:27:55,676 - INFO - joeynmt.training - Example #0\n",
      "2021-10-10 03:27:55,677 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-10 03:27:55,677 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-10 03:27:55,677 - INFO - joeynmt.training - \tHypothesis: Yes , the conscience of “ the man of the inner person ” may mislead us .\n",
      "2021-10-10 03:27:55,677 - INFO - joeynmt.training - Example #1\n",
      "2021-10-10 03:27:55,678 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-10 03:27:55,678 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 03:27:55,678 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave to his disciples ?\n",
      "2021-10-10 03:27:55,678 - INFO - joeynmt.training - Example #2\n",
      "2021-10-10 03:27:55,678 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-10 03:27:55,678 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 03:27:55,678 - INFO - joeynmt.training - \tHypothesis: That will enable us to know the difference between right and wrong and to know the difference between foolish and discreet wisdom and discreet God. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 03:27:55,678 - INFO - joeynmt.training - Example #3\n",
      "2021-10-10 03:27:55,678 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-10 03:27:55,678 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-10 03:27:55,678 - INFO - joeynmt.training - \tHypothesis: After graduating in February 1945 , I met the brothers in Puerto Rico .\n",
      "2021-10-10 03:27:55,679 - INFO - joeynmt.training - Validation result (greedy) at epoch  19, step    22500: bleu:  37.66, loss: 19403.7266, ppl:   1.9869, duration: 112.1131s\n",
      "2021-10-10 03:28:49,046 - INFO - joeynmt.training - Epoch  19, Step:    22600, Batch Loss:     0.667634, Tokens per Sec:     8596, Lr: 0.000147\n",
      "2021-10-10 03:29:40,935 - INFO - joeynmt.training - Epoch  19, Step:    22700, Batch Loss:     0.712947, Tokens per Sec:     8422, Lr: 0.000147\n",
      "2021-10-10 03:30:34,315 - INFO - joeynmt.training - Epoch  19, Step:    22800, Batch Loss:     0.657903, Tokens per Sec:     8331, Lr: 0.000146\n",
      "2021-10-10 03:31:27,961 - INFO - joeynmt.training - Epoch  19, Step:    22900, Batch Loss:     0.689413, Tokens per Sec:     8617, Lr: 0.000146\n",
      "2021-10-10 03:32:21,557 - INFO - joeynmt.training - Epoch  19, Step:    23000, Batch Loss:     0.642717, Tokens per Sec:     8516, Lr: 0.000146\n",
      "2021-10-10 03:34:05,203 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-10 03:34:05,204 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-10 03:34:05,204 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-10 03:34:05,628 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-10 03:34:05,628 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-10 03:34:11,976 - INFO - joeynmt.training - Example #0\n",
      "2021-10-10 03:34:11,977 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-10 03:34:11,977 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-10 03:34:11,977 - INFO - joeynmt.training - \tHypothesis: Indeed , the conscience of “ the man of the inside ” may mislead us .\n",
      "2021-10-10 03:34:11,977 - INFO - joeynmt.training - Example #1\n",
      "2021-10-10 03:34:11,977 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-10 03:34:11,977 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 03:34:11,977 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave to his disciples ?\n",
      "2021-10-10 03:34:11,977 - INFO - joeynmt.training - Example #2\n",
      "2021-10-10 03:34:11,978 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-10 03:34:11,978 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 03:34:11,978 - INFO - joeynmt.training - \tHypothesis: That will enable us to know the difference between right and wrong and to know the difference between foolish and discreet and discreet personal. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 03:34:11,978 - INFO - joeynmt.training - Example #3\n",
      "2021-10-10 03:34:11,978 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-10 03:34:11,978 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-10 03:34:11,978 - INFO - joeynmt.training - \tHypothesis: After graduating in February 1945 , I met our brothers in Puerto Rico .\n",
      "2021-10-10 03:34:11,978 - INFO - joeynmt.training - Validation result (greedy) at epoch  19, step    23000: bleu:  37.72, loss: 19221.3301, ppl:   1.9741, duration: 110.4209s\n",
      "2021-10-10 03:35:04,980 - INFO - joeynmt.training - Epoch  19, Step:    23100, Batch Loss:     0.742402, Tokens per Sec:     8340, Lr: 0.000145\n",
      "2021-10-10 03:35:57,107 - INFO - joeynmt.training - Epoch  19, Step:    23200, Batch Loss:     0.670806, Tokens per Sec:     8438, Lr: 0.000145\n",
      "2021-10-10 03:36:49,839 - INFO - joeynmt.training - Epoch  19, Step:    23300, Batch Loss:     0.664527, Tokens per Sec:     8651, Lr: 0.000145\n",
      "2021-10-10 03:37:07,045 - INFO - joeynmt.training - Epoch  19: total training loss 827.79\n",
      "2021-10-10 03:37:07,046 - INFO - joeynmt.training - EPOCH 20\n",
      "2021-10-10 03:37:44,232 - INFO - joeynmt.training - Epoch  20, Step:    23400, Batch Loss:     0.675044, Tokens per Sec:     8534, Lr: 0.000144\n",
      "2021-10-10 03:38:37,958 - INFO - joeynmt.training - Epoch  20, Step:    23500, Batch Loss:     0.729739, Tokens per Sec:     8320, Lr: 0.000144\n",
      "2021-10-10 03:40:24,272 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-10 03:40:24,272 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-10 03:40:24,273 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-10 03:40:24,600 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-10 03:40:24,600 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-10 03:40:30,666 - INFO - joeynmt.training - Example #0\n",
      "2021-10-10 03:40:30,667 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-10 03:40:30,668 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-10 03:40:30,668 - INFO - joeynmt.training - \tHypothesis: Indeed , the conscience of “ the inside ” may mislead us .\n",
      "2021-10-10 03:40:30,668 - INFO - joeynmt.training - Example #1\n",
      "2021-10-10 03:40:30,668 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-10 03:40:30,668 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 03:40:30,668 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave to his disciples ?\n",
      "2021-10-10 03:40:30,668 - INFO - joeynmt.training - Example #2\n",
      "2021-10-10 03:40:30,669 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-10 03:40:30,669 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 03:40:30,669 - INFO - joeynmt.training - \tHypothesis: That will enable us to know the difference between right and wrong and to know the difference between foolish and discreet and discreet God. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 03:40:30,669 - INFO - joeynmt.training - Example #3\n",
      "2021-10-10 03:40:30,669 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-10 03:40:30,669 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-10 03:40:30,669 - INFO - joeynmt.training - \tHypothesis: After finishing in February 1945 , I met the brothers in Puerto Rico .\n",
      "2021-10-10 03:40:30,669 - INFO - joeynmt.training - Validation result (greedy) at epoch  20, step    23500: bleu:  37.74, loss: 19170.0488, ppl:   1.9705, duration: 112.7107s\n",
      "2021-10-10 03:41:23,243 - INFO - joeynmt.training - Epoch  20, Step:    23600, Batch Loss:     0.701207, Tokens per Sec:     8549, Lr: 0.000144\n",
      "2021-10-10 03:42:16,140 - INFO - joeynmt.training - Epoch  20, Step:    23700, Batch Loss:     0.695929, Tokens per Sec:     8489, Lr: 0.000144\n",
      "2021-10-10 03:43:10,072 - INFO - joeynmt.training - Epoch  20, Step:    23800, Batch Loss:     0.664740, Tokens per Sec:     8519, Lr: 0.000143\n",
      "2021-10-10 03:44:02,720 - INFO - joeynmt.training - Epoch  20, Step:    23900, Batch Loss:     0.704484, Tokens per Sec:     8419, Lr: 0.000143\n",
      "2021-10-10 03:44:56,409 - INFO - joeynmt.training - Epoch  20, Step:    24000, Batch Loss:     0.673488, Tokens per Sec:     8543, Lr: 0.000143\n",
      "2021-10-10 03:46:41,229 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-10 03:46:41,229 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-10 03:46:41,229 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-10 03:46:41,609 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-10 03:46:41,610 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-10 03:46:47,699 - INFO - joeynmt.training - Example #0\n",
      "2021-10-10 03:46:47,699 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-10 03:46:47,699 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-10 03:46:47,699 - INFO - joeynmt.training - \tHypothesis: Yes , the conscience of “ the man of the inside ” may mislead us .\n",
      "2021-10-10 03:46:47,700 - INFO - joeynmt.training - Example #1\n",
      "2021-10-10 03:46:47,700 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-10 03:46:47,700 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 03:46:47,700 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave to his disciples ?\n",
      "2021-10-10 03:46:47,700 - INFO - joeynmt.training - Example #2\n",
      "2021-10-10 03:46:47,700 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-10 03:46:47,700 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 03:46:47,700 - INFO - joeynmt.training - \tHypothesis: That will enable us to know the difference between right and wrong and to know the difference between foolish and discreet and discreet personality. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 03:46:47,701 - INFO - joeynmt.training - Example #3\n",
      "2021-10-10 03:46:47,701 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-10 03:46:47,701 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-10 03:46:47,701 - INFO - joeynmt.training - \tHypothesis: After finishing in February 1945 , I met the brothers in Puerto Rico .\n",
      "2021-10-10 03:46:47,701 - INFO - joeynmt.training - Validation result (greedy) at epoch  20, step    24000: bleu:  38.01, loss: 19041.7227, ppl:   1.9616, duration: 111.2918s\n",
      "2021-10-10 03:47:40,606 - INFO - joeynmt.training - Epoch  20, Step:    24100, Batch Loss:     0.710144, Tokens per Sec:     8551, Lr: 0.000142\n",
      "2021-10-10 03:48:33,849 - INFO - joeynmt.training - Epoch  20, Step:    24200, Batch Loss:     0.691503, Tokens per Sec:     8516, Lr: 0.000142\n",
      "2021-10-10 03:49:26,930 - INFO - joeynmt.training - Epoch  20, Step:    24300, Batch Loss:     0.701909, Tokens per Sec:     8283, Lr: 0.000142\n",
      "2021-10-10 03:50:20,545 - INFO - joeynmt.training - Epoch  20, Step:    24400, Batch Loss:     0.601801, Tokens per Sec:     8524, Lr: 0.000141\n",
      "2021-10-10 03:51:14,006 - INFO - joeynmt.training - Epoch  20, Step:    24500, Batch Loss:     0.627401, Tokens per Sec:     8402, Lr: 0.000141\n",
      "2021-10-10 03:53:01,197 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-10 03:53:01,198 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-10 03:53:01,198 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-10 03:53:01,624 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-10 03:53:01,624 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-10 03:53:08,509 - INFO - joeynmt.training - Example #0\n",
      "2021-10-10 03:53:08,509 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-10 03:53:08,509 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-10 03:53:08,510 - INFO - joeynmt.training - \tHypothesis: Yes , the conscience of “ the man of the inside ” may mislead us .\n",
      "2021-10-10 03:53:08,510 - INFO - joeynmt.training - Example #1\n",
      "2021-10-10 03:53:08,510 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-10 03:53:08,510 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 03:53:08,510 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave to his disciples ?\n",
      "2021-10-10 03:53:08,510 - INFO - joeynmt.training - Example #2\n",
      "2021-10-10 03:53:08,510 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-10 03:53:08,510 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 03:53:08,511 - INFO - joeynmt.training - \tHypothesis: That will enable us to know the difference between right and wrong and to know the difference between foolish and discreet and discreet you. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 03:53:08,511 - INFO - joeynmt.training - Example #3\n",
      "2021-10-10 03:53:08,511 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-10 03:53:08,511 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-10 03:53:08,511 - INFO - joeynmt.training - \tHypothesis: After graduating in February 1945 , I met our brothers in Puerto Rico .\n",
      "2021-10-10 03:53:08,511 - INFO - joeynmt.training - Validation result (greedy) at epoch  20, step    24500: bleu:  37.50, loss: 19011.6855, ppl:   1.9595, duration: 114.5042s\n",
      "2021-10-10 03:53:40,073 - INFO - joeynmt.training - Epoch  20: total training loss 813.76\n",
      "2021-10-10 03:53:40,074 - INFO - joeynmt.training - EPOCH 21\n",
      "2021-10-10 03:54:01,729 - INFO - joeynmt.training - Epoch  21, Step:    24600, Batch Loss:     0.620677, Tokens per Sec:     8329, Lr: 0.000141\n",
      "2021-10-10 03:54:54,166 - INFO - joeynmt.training - Epoch  21, Step:    24700, Batch Loss:     0.644950, Tokens per Sec:     8696, Lr: 0.000141\n",
      "2021-10-10 03:55:47,397 - INFO - joeynmt.training - Epoch  21, Step:    24800, Batch Loss:     0.648650, Tokens per Sec:     8534, Lr: 0.000140\n",
      "2021-10-10 03:56:40,115 - INFO - joeynmt.training - Epoch  21, Step:    24900, Batch Loss:     0.617410, Tokens per Sec:     8232, Lr: 0.000140\n",
      "2021-10-10 03:57:33,005 - INFO - joeynmt.training - Epoch  21, Step:    25000, Batch Loss:     0.683892, Tokens per Sec:     8630, Lr: 0.000140\n",
      "2021-10-10 03:59:19,808 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-10 03:59:19,809 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-10 03:59:19,809 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-10 03:59:20,194 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-10 03:59:20,194 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-10 03:59:26,349 - INFO - joeynmt.training - Example #0\n",
      "2021-10-10 03:59:26,350 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-10 03:59:26,350 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-10 03:59:26,350 - INFO - joeynmt.training - \tHypothesis: Indeed , the conscience of “ the inner person ” may mislead us .\n",
      "2021-10-10 03:59:26,350 - INFO - joeynmt.training - Example #1\n",
      "2021-10-10 03:59:26,350 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-10 03:59:26,350 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 03:59:26,351 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave to his disciples ?\n",
      "2021-10-10 03:59:26,351 - INFO - joeynmt.training - Example #2\n",
      "2021-10-10 03:59:26,351 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-10 03:59:26,351 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 03:59:26,351 - INFO - joeynmt.training - \tHypothesis: That will enable us to know the difference between right and wrong and to know the difference between foolish and discreet and discreet power. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 03:59:26,351 - INFO - joeynmt.training - Example #3\n",
      "2021-10-10 03:59:26,351 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-10 03:59:26,352 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-10 03:59:26,352 - INFO - joeynmt.training - \tHypothesis: After February 1945 , I met our brothers in Puerto Rico .\n",
      "2021-10-10 03:59:26,352 - INFO - joeynmt.training - Validation result (greedy) at epoch  21, step    25000: bleu:  37.91, loss: 19008.0664, ppl:   1.9593, duration: 113.3458s\n",
      "2021-10-10 04:00:19,275 - INFO - joeynmt.training - Epoch  21, Step:    25100, Batch Loss:     0.727990, Tokens per Sec:     8585, Lr: 0.000139\n",
      "2021-10-10 04:01:11,972 - INFO - joeynmt.training - Epoch  21, Step:    25200, Batch Loss:     0.634886, Tokens per Sec:     8357, Lr: 0.000139\n",
      "2021-10-10 04:02:04,736 - INFO - joeynmt.training - Epoch  21, Step:    25300, Batch Loss:     0.620296, Tokens per Sec:     8654, Lr: 0.000139\n",
      "2021-10-10 04:02:57,677 - INFO - joeynmt.training - Epoch  21, Step:    25400, Batch Loss:     0.638939, Tokens per Sec:     8630, Lr: 0.000139\n",
      "2021-10-10 04:03:50,646 - INFO - joeynmt.training - Epoch  21, Step:    25500, Batch Loss:     0.652122, Tokens per Sec:     8769, Lr: 0.000138\n",
      "2021-10-10 04:05:41,838 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-10 04:05:41,839 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-10 04:05:41,839 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-10 04:05:42,165 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-10 04:05:42,165 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-10 04:05:48,270 - INFO - joeynmt.training - Example #0\n",
      "2021-10-10 04:05:48,271 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-10 04:05:48,271 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-10 04:05:48,271 - INFO - joeynmt.training - \tHypothesis: Indeed , the conscience of “ the man of the inside ” may mislead us .\n",
      "2021-10-10 04:05:48,271 - INFO - joeynmt.training - Example #1\n",
      "2021-10-10 04:05:48,271 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-10 04:05:48,271 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 04:05:48,271 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave to his disciples ?\n",
      "2021-10-10 04:05:48,272 - INFO - joeynmt.training - Example #2\n",
      "2021-10-10 04:05:48,272 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-10 04:05:48,272 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 04:05:48,272 - INFO - joeynmt.training - \tHypothesis: That will enable us to know the difference between right and wrong and to know the difference between foolish and discreet wisdom and discreet it. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 04:05:48,272 - INFO - joeynmt.training - Example #3\n",
      "2021-10-10 04:05:48,272 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-10 04:05:48,272 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-10 04:05:48,272 - INFO - joeynmt.training - \tHypothesis: After graduating in February 1945 , I met the brothers in Puerto Rico .\n",
      "2021-10-10 04:05:48,273 - INFO - joeynmt.training - Validation result (greedy) at epoch  21, step    25500: bleu:  37.88, loss: 18895.0293, ppl:   1.9514, duration: 117.6261s\n",
      "2021-10-10 04:06:41,464 - INFO - joeynmt.training - Epoch  21, Step:    25600, Batch Loss:     0.715720, Tokens per Sec:     8542, Lr: 0.000138\n",
      "2021-10-10 04:07:34,656 - INFO - joeynmt.training - Epoch  21, Step:    25700, Batch Loss:     0.655899, Tokens per Sec:     8492, Lr: 0.000138\n",
      "2021-10-10 04:08:18,903 - INFO - joeynmt.training - Epoch  21: total training loss 802.67\n",
      "2021-10-10 04:08:18,904 - INFO - joeynmt.training - EPOCH 22\n",
      "2021-10-10 04:08:28,151 - INFO - joeynmt.training - Epoch  22, Step:    25800, Batch Loss:     0.583575, Tokens per Sec:     8236, Lr: 0.000138\n",
      "2021-10-10 04:09:21,058 - INFO - joeynmt.training - Epoch  22, Step:    25900, Batch Loss:     0.640646, Tokens per Sec:     8604, Lr: 0.000137\n",
      "2021-10-10 04:10:14,768 - INFO - joeynmt.training - Epoch  22, Step:    26000, Batch Loss:     0.683481, Tokens per Sec:     8408, Lr: 0.000137\n",
      "2021-10-10 04:12:03,916 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-10 04:12:03,917 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-10 04:12:03,917 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-10 04:12:04,336 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-10 04:12:04,336 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-10 04:12:10,418 - INFO - joeynmt.training - Example #0\n",
      "2021-10-10 04:12:10,419 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-10 04:12:10,419 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-10 04:12:10,419 - INFO - joeynmt.training - \tHypothesis: Indeed , the conscience of “ the man of the inside ” may mislead us .\n",
      "2021-10-10 04:12:10,419 - INFO - joeynmt.training - Example #1\n",
      "2021-10-10 04:12:10,419 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-10 04:12:10,419 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 04:12:10,420 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave to his disciples ?\n",
      "2021-10-10 04:12:10,420 - INFO - joeynmt.training - Example #2\n",
      "2021-10-10 04:12:10,420 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-10 04:12:10,420 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 04:12:10,420 - INFO - joeynmt.training - \tHypothesis: That will enable us to get to know the difference between right and wrong and to know the difference between foolish and discreet and discreet personality. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 04:12:10,420 - INFO - joeynmt.training - Example #3\n",
      "2021-10-10 04:12:10,420 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-10 04:12:10,420 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-10 04:12:10,421 - INFO - joeynmt.training - \tHypothesis: After graduating in February 1945 , I met the brothers in Puerto Rico .\n",
      "2021-10-10 04:12:10,421 - INFO - joeynmt.training - Validation result (greedy) at epoch  22, step    26000: bleu:  38.36, loss: 18891.6758, ppl:   1.9512, duration: 115.6523s\n",
      "2021-10-10 04:13:03,656 - INFO - joeynmt.training - Epoch  22, Step:    26100, Batch Loss:     0.726447, Tokens per Sec:     8696, Lr: 0.000137\n",
      "2021-10-10 04:13:55,968 - INFO - joeynmt.training - Epoch  22, Step:    26200, Batch Loss:     0.642941, Tokens per Sec:     8564, Lr: 0.000137\n",
      "2021-10-10 04:14:48,647 - INFO - joeynmt.training - Epoch  22, Step:    26300, Batch Loss:     0.623974, Tokens per Sec:     8536, Lr: 0.000136\n",
      "2021-10-10 04:15:42,600 - INFO - joeynmt.training - Epoch  22, Step:    26400, Batch Loss:     0.657637, Tokens per Sec:     8580, Lr: 0.000136\n",
      "2021-10-10 04:16:34,821 - INFO - joeynmt.training - Epoch  22, Step:    26500, Batch Loss:     0.591229, Tokens per Sec:     8428, Lr: 0.000136\n",
      "2021-10-10 04:18:22,134 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-10 04:18:22,134 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-10 04:18:22,135 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-10 04:18:22,462 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-10 04:18:22,462 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-10 04:18:28,600 - INFO - joeynmt.training - Example #0\n",
      "2021-10-10 04:18:28,601 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-10 04:18:28,601 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-10 04:18:28,601 - INFO - joeynmt.training - \tHypothesis: Yes , the conscience of “ the inner person ” may mislead us .\n",
      "2021-10-10 04:18:28,601 - INFO - joeynmt.training - Example #1\n",
      "2021-10-10 04:18:28,602 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-10 04:18:28,602 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 04:18:28,602 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 04:18:28,602 - INFO - joeynmt.training - Example #2\n",
      "2021-10-10 04:18:28,602 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-10 04:18:28,602 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 04:18:28,602 - INFO - joeynmt.training - \tHypothesis: That will enable us to know the difference between right and wrong and to know the difference between foolish and discreet and discreet personals. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 04:18:28,603 - INFO - joeynmt.training - Example #3\n",
      "2021-10-10 04:18:28,603 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-10 04:18:28,603 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-10 04:18:28,603 - INFO - joeynmt.training - \tHypothesis: After graduating in February 1945 , I met the brothers in Puerto Rico .\n",
      "2021-10-10 04:18:28,603 - INFO - joeynmt.training - Validation result (greedy) at epoch  22, step    26500: bleu:  38.34, loss: 18845.4414, ppl:   1.9480, duration: 113.7809s\n",
      "2021-10-10 04:19:21,528 - INFO - joeynmt.training - Epoch  22, Step:    26600, Batch Loss:     0.692587, Tokens per Sec:     8539, Lr: 0.000135\n",
      "2021-10-10 04:20:14,950 - INFO - joeynmt.training - Epoch  22, Step:    26700, Batch Loss:     0.497006, Tokens per Sec:     8333, Lr: 0.000135\n",
      "2021-10-10 04:21:07,625 - INFO - joeynmt.training - Epoch  22, Step:    26800, Batch Loss:     0.612647, Tokens per Sec:     8286, Lr: 0.000135\n",
      "2021-10-10 04:22:00,381 - INFO - joeynmt.training - Epoch  22, Step:    26900, Batch Loss:     0.722871, Tokens per Sec:     8454, Lr: 0.000135\n",
      "2021-10-10 04:22:54,147 - INFO - joeynmt.training - Epoch  22, Step:    27000, Batch Loss:     0.672686, Tokens per Sec:     8853, Lr: 0.000134\n",
      "2021-10-10 04:24:40,701 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-10 04:24:40,701 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-10 04:24:40,701 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-10 04:24:41,028 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-10 04:24:41,028 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-10 04:24:47,073 - INFO - joeynmt.training - Example #0\n",
      "2021-10-10 04:24:47,074 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-10 04:24:47,074 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-10 04:24:47,074 - INFO - joeynmt.training - \tHypothesis: Of course , the conscience of “ the inside ” may mislead us .\n",
      "2021-10-10 04:24:47,074 - INFO - joeynmt.training - Example #1\n",
      "2021-10-10 04:24:47,074 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-10 04:24:47,074 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 04:24:47,075 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave to his disciples ?\n",
      "2021-10-10 04:24:47,075 - INFO - joeynmt.training - Example #2\n",
      "2021-10-10 04:24:47,075 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-10 04:24:47,075 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 04:24:47,075 - INFO - joeynmt.training - \tHypothesis: That will enable us to know the difference between right and wrong and to know the difference between foolish and discreet and discreet God. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 04:24:47,075 - INFO - joeynmt.training - Example #3\n",
      "2021-10-10 04:24:47,075 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-10 04:24:47,076 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-10 04:24:47,076 - INFO - joeynmt.training - \tHypothesis: After graduating in February 1945 , I met our brothers in Puerto Rico .\n",
      "2021-10-10 04:24:47,076 - INFO - joeynmt.training - Validation result (greedy) at epoch  22, step    27000: bleu:  38.15, loss: 18758.9414, ppl:   1.9421, duration: 112.9282s\n",
      "2021-10-10 04:24:51,992 - INFO - joeynmt.training - Epoch  22: total training loss 795.70\n",
      "2021-10-10 04:24:51,992 - INFO - joeynmt.training - EPOCH 23\n",
      "2021-10-10 04:25:39,933 - INFO - joeynmt.training - Epoch  23, Step:    27100, Batch Loss:     0.654098, Tokens per Sec:     8435, Lr: 0.000134\n",
      "2021-10-10 04:26:32,876 - INFO - joeynmt.training - Epoch  23, Step:    27200, Batch Loss:     0.624034, Tokens per Sec:     8435, Lr: 0.000134\n",
      "2021-10-10 04:27:25,581 - INFO - joeynmt.training - Epoch  23, Step:    27300, Batch Loss:     0.672309, Tokens per Sec:     8830, Lr: 0.000134\n",
      "2021-10-10 04:28:18,035 - INFO - joeynmt.training - Epoch  23, Step:    27400, Batch Loss:     0.601143, Tokens per Sec:     8599, Lr: 0.000133\n",
      "2021-10-10 04:29:11,022 - INFO - joeynmt.training - Epoch  23, Step:    27500, Batch Loss:     0.556836, Tokens per Sec:     8366, Lr: 0.000133\n",
      "2021-10-10 04:30:56,109 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-10 04:30:56,110 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-10 04:30:56,110 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-10 04:30:56,438 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-10 04:30:56,438 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-10 04:31:02,799 - INFO - joeynmt.training - Example #0\n",
      "2021-10-10 04:31:02,799 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-10 04:31:02,799 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-10 04:31:02,799 - INFO - joeynmt.training - \tHypothesis: Yes , the conscience of “ the man of the inside ” may mislead us .\n",
      "2021-10-10 04:31:02,800 - INFO - joeynmt.training - Example #1\n",
      "2021-10-10 04:31:02,800 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-10 04:31:02,800 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 04:31:02,800 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave to his disciples ?\n",
      "2021-10-10 04:31:02,800 - INFO - joeynmt.training - Example #2\n",
      "2021-10-10 04:31:02,800 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-10 04:31:02,800 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 04:31:02,800 - INFO - joeynmt.training - \tHypothesis: That will enable us to know the difference between right and wrong and to know the difference between foolish and discreet and discreet personals. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 04:31:02,801 - INFO - joeynmt.training - Example #3\n",
      "2021-10-10 04:31:02,801 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-10 04:31:02,801 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-10 04:31:02,801 - INFO - joeynmt.training - \tHypothesis: After graduating in February 1945 , I met our brothers in Puerto Rico .\n",
      "2021-10-10 04:31:02,801 - INFO - joeynmt.training - Validation result (greedy) at epoch  23, step    27500: bleu:  38.47, loss: 18708.7012, ppl:   1.9386, duration: 111.7780s\n",
      "2021-10-10 04:31:55,885 - INFO - joeynmt.training - Epoch  23, Step:    27600, Batch Loss:     0.628777, Tokens per Sec:     8388, Lr: 0.000133\n",
      "2021-10-10 04:32:47,953 - INFO - joeynmt.training - Epoch  23, Step:    27700, Batch Loss:     0.624414, Tokens per Sec:     8521, Lr: 0.000133\n",
      "2021-10-10 04:33:41,039 - INFO - joeynmt.training - Epoch  23, Step:    27800, Batch Loss:     0.643541, Tokens per Sec:     8399, Lr: 0.000133\n",
      "2021-10-10 04:34:33,006 - INFO - joeynmt.training - Epoch  23, Step:    27900, Batch Loss:     0.613859, Tokens per Sec:     8566, Lr: 0.000132\n",
      "2021-10-10 04:35:26,728 - INFO - joeynmt.training - Epoch  23, Step:    28000, Batch Loss:     0.651891, Tokens per Sec:     8495, Lr: 0.000132\n",
      "2021-10-10 04:37:09,348 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-10 04:37:09,349 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-10 04:37:09,349 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-10 04:37:09,763 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-10 04:37:09,763 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-10 04:37:15,813 - INFO - joeynmt.training - Example #0\n",
      "2021-10-10 04:37:15,813 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-10 04:37:15,813 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-10 04:37:15,813 - INFO - joeynmt.training - \tHypothesis: Of course , the conscience of “ the inside one ” may mislead us .\n",
      "2021-10-10 04:37:15,814 - INFO - joeynmt.training - Example #1\n",
      "2021-10-10 04:37:15,814 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-10 04:37:15,814 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 04:37:15,814 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 04:37:15,814 - INFO - joeynmt.training - Example #2\n",
      "2021-10-10 04:37:15,814 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-10 04:37:15,814 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 04:37:15,814 - INFO - joeynmt.training - \tHypothesis: That will enable us to get to know the difference between right and wrong and to know the difference between foolish and discreet and discreet God. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 04:37:15,814 - INFO - joeynmt.training - Example #3\n",
      "2021-10-10 04:37:15,815 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-10 04:37:15,815 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-10 04:37:15,815 - INFO - joeynmt.training - \tHypothesis: After graduating in February 1945 , I met our brothers in Puerto Rico .\n",
      "2021-10-10 04:37:15,815 - INFO - joeynmt.training - Validation result (greedy) at epoch  23, step    28000: bleu:  38.82, loss: 18679.0957, ppl:   1.9366, duration: 109.0865s\n",
      "2021-10-10 04:38:09,585 - INFO - joeynmt.training - Epoch  23, Step:    28100, Batch Loss:     0.680018, Tokens per Sec:     8666, Lr: 0.000132\n",
      "2021-10-10 04:39:02,526 - INFO - joeynmt.training - Epoch  23, Step:    28200, Batch Loss:     0.572256, Tokens per Sec:     8648, Lr: 0.000132\n",
      "2021-10-10 04:39:23,056 - INFO - joeynmt.training - Epoch  23: total training loss 790.99\n",
      "2021-10-10 04:39:23,057 - INFO - joeynmt.training - EPOCH 24\n",
      "2021-10-10 04:39:55,430 - INFO - joeynmt.training - Epoch  24, Step:    28300, Batch Loss:     0.666428, Tokens per Sec:     8656, Lr: 0.000131\n",
      "2021-10-10 04:40:47,704 - INFO - joeynmt.training - Epoch  24, Step:    28400, Batch Loss:     0.637116, Tokens per Sec:     8478, Lr: 0.000131\n",
      "2021-10-10 04:41:40,194 - INFO - joeynmt.training - Epoch  24, Step:    28500, Batch Loss:     0.516647, Tokens per Sec:     8521, Lr: 0.000131\n",
      "2021-10-10 04:43:26,440 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-10 04:43:26,440 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-10 04:43:26,440 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-10 04:43:26,770 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-10 04:43:26,770 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-10 04:43:32,923 - INFO - joeynmt.training - Example #0\n",
      "2021-10-10 04:43:32,924 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-10 04:43:32,924 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-10 04:43:32,924 - INFO - joeynmt.training - \tHypothesis: Of course , the conscience of “ the inside ” may be misleading us .\n",
      "2021-10-10 04:43:32,924 - INFO - joeynmt.training - Example #1\n",
      "2021-10-10 04:43:32,925 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-10 04:43:32,925 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 04:43:32,925 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave to his disciples ?\n",
      "2021-10-10 04:43:32,925 - INFO - joeynmt.training - Example #2\n",
      "2021-10-10 04:43:32,925 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-10 04:43:32,925 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 04:43:32,925 - INFO - joeynmt.training - \tHypothesis: That will enable us to know the difference between right and wrong and to know the difference between foolish and discreet and discreet distings. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 04:43:32,925 - INFO - joeynmt.training - Example #3\n",
      "2021-10-10 04:43:32,926 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-10 04:43:32,926 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-10 04:43:32,926 - INFO - joeynmt.training - \tHypothesis: After graduating on February 1945 , I met our brothers in Puerto Rico .\n",
      "2021-10-10 04:43:32,926 - INFO - joeynmt.training - Validation result (greedy) at epoch  24, step    28500: bleu:  38.46, loss: 18618.4277, ppl:   1.9324, duration: 112.7307s\n",
      "2021-10-10 04:44:25,844 - INFO - joeynmt.training - Epoch  24, Step:    28600, Batch Loss:     0.633231, Tokens per Sec:     8731, Lr: 0.000131\n",
      "2021-10-10 04:45:18,847 - INFO - joeynmt.training - Epoch  24, Step:    28700, Batch Loss:     0.710251, Tokens per Sec:     8497, Lr: 0.000130\n",
      "2021-10-10 04:46:12,579 - INFO - joeynmt.training - Epoch  24, Step:    28800, Batch Loss:     0.652319, Tokens per Sec:     8513, Lr: 0.000130\n",
      "2021-10-10 04:47:05,542 - INFO - joeynmt.training - Epoch  24, Step:    28900, Batch Loss:     0.570491, Tokens per Sec:     8604, Lr: 0.000130\n",
      "2021-10-10 04:47:58,198 - INFO - joeynmt.training - Epoch  24, Step:    29000, Batch Loss:     0.664838, Tokens per Sec:     8359, Lr: 0.000130\n",
      "2021-10-10 04:49:44,993 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-10 04:49:44,994 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-10 04:49:44,994 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-10 04:49:45,320 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-10 04:49:45,320 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-10 04:49:51,497 - INFO - joeynmt.training - Example #0\n",
      "2021-10-10 04:49:51,497 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-10 04:49:51,497 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-10 04:49:51,498 - INFO - joeynmt.training - \tHypothesis: Of course , the conscience of “ the inside one ” may mislead us .\n",
      "2021-10-10 04:49:51,498 - INFO - joeynmt.training - Example #1\n",
      "2021-10-10 04:49:51,498 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-10 04:49:51,498 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 04:49:51,498 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave to his disciples ?\n",
      "2021-10-10 04:49:51,498 - INFO - joeynmt.training - Example #2\n",
      "2021-10-10 04:49:51,498 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-10 04:49:51,498 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 04:49:51,499 - INFO - joeynmt.training - \tHypothesis: That will enable us to know the difference between right and wrong and to know the difference between foolish and discreet and discreet personals. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 04:49:51,499 - INFO - joeynmt.training - Example #3\n",
      "2021-10-10 04:49:51,499 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-10 04:49:51,499 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-10 04:49:51,499 - INFO - joeynmt.training - \tHypothesis: After graduating in February 1945 , I met the brothers in Puerto Rico .\n",
      "2021-10-10 04:49:51,499 - INFO - joeynmt.training - Validation result (greedy) at epoch  24, step    29000: bleu:  38.34, loss: 18559.4297, ppl:   1.9284, duration: 113.3003s\n",
      "2021-10-10 04:50:44,117 - INFO - joeynmt.training - Epoch  24, Step:    29100, Batch Loss:     0.631444, Tokens per Sec:     8449, Lr: 0.000130\n",
      "2021-10-10 04:51:36,989 - INFO - joeynmt.training - Epoch  24, Step:    29200, Batch Loss:     0.649414, Tokens per Sec:     8743, Lr: 0.000129\n",
      "2021-10-10 04:52:30,962 - INFO - joeynmt.training - Epoch  24, Step:    29300, Batch Loss:     0.593162, Tokens per Sec:     8391, Lr: 0.000129\n",
      "2021-10-10 04:53:24,130 - INFO - joeynmt.training - Epoch  24, Step:    29400, Batch Loss:     0.663373, Tokens per Sec:     8356, Lr: 0.000129\n",
      "2021-10-10 04:54:01,097 - INFO - joeynmt.training - Epoch  24: total training loss 782.84\n",
      "2021-10-10 04:54:01,098 - INFO - joeynmt.training - EPOCH 25\n",
      "2021-10-10 04:54:18,052 - INFO - joeynmt.training - Epoch  25, Step:    29500, Batch Loss:     0.665725, Tokens per Sec:     8089, Lr: 0.000129\n",
      "2021-10-10 04:56:00,249 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-10 04:56:00,249 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-10 04:56:00,250 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-10 04:56:00,673 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-10 04:56:00,673 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-10 04:56:06,927 - INFO - joeynmt.training - Example #0\n",
      "2021-10-10 04:56:06,927 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-10 04:56:06,928 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-10 04:56:06,928 - INFO - joeynmt.training - \tHypothesis: Yes , the conscience of “ the inside ” may be misled .\n",
      "2021-10-10 04:56:06,928 - INFO - joeynmt.training - Example #1\n",
      "2021-10-10 04:56:06,928 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-10 04:56:06,928 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 04:56:06,928 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave to his disciples ?\n",
      "2021-10-10 04:56:06,928 - INFO - joeynmt.training - Example #2\n",
      "2021-10-10 04:56:06,929 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-10 04:56:06,929 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 04:56:06,929 - INFO - joeynmt.training - \tHypothesis: That will enable us to know the difference between right and wrong and to know the difference between foolish and discreet and discreet God. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 04:56:06,929 - INFO - joeynmt.training - Example #3\n",
      "2021-10-10 04:56:06,929 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-10 04:56:06,929 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-10 04:56:06,929 - INFO - joeynmt.training - \tHypothesis: After graduating on February 1945 , I met the brothers in Puerto Rico .\n",
      "2021-10-10 04:56:06,929 - INFO - joeynmt.training - Validation result (greedy) at epoch  25, step    29500: bleu:  38.60, loss: 18558.8359, ppl:   1.9284, duration: 108.8770s\n",
      "2021-10-10 04:56:59,864 - INFO - joeynmt.training - Epoch  25, Step:    29600, Batch Loss:     0.675686, Tokens per Sec:     8530, Lr: 0.000128\n",
      "2021-10-10 04:57:53,186 - INFO - joeynmt.training - Epoch  25, Step:    29700, Batch Loss:     0.582541, Tokens per Sec:     8453, Lr: 0.000128\n",
      "2021-10-10 04:58:45,496 - INFO - joeynmt.training - Epoch  25, Step:    29800, Batch Loss:     0.675058, Tokens per Sec:     8467, Lr: 0.000128\n",
      "2021-10-10 04:59:38,850 - INFO - joeynmt.training - Epoch  25, Step:    29900, Batch Loss:     0.679147, Tokens per Sec:     8409, Lr: 0.000128\n",
      "2021-10-10 05:00:31,458 - INFO - joeynmt.training - Epoch  25, Step:    30000, Batch Loss:     0.499666, Tokens per Sec:     8499, Lr: 0.000128\n",
      "2021-10-10 05:02:16,222 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-10 05:02:16,222 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-10 05:02:16,222 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-10 05:02:16,549 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-10 05:02:16,549 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-10 05:02:22,638 - INFO - joeynmt.training - Example #0\n",
      "2021-10-10 05:02:22,639 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-10 05:02:22,639 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-10 05:02:22,639 - INFO - joeynmt.training - \tHypothesis: Yes , the conscience of “ the inside one ” may mislead us .\n",
      "2021-10-10 05:02:22,639 - INFO - joeynmt.training - Example #1\n",
      "2021-10-10 05:02:22,639 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-10 05:02:22,640 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 05:02:22,640 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave to his disciples ?\n",
      "2021-10-10 05:02:22,640 - INFO - joeynmt.training - Example #2\n",
      "2021-10-10 05:02:22,640 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-10 05:02:22,640 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 05:02:22,640 - INFO - joeynmt.training - \tHypothesis: That will enable us to know the difference between right and wrong and to know the difference between foolish and discreet discretion. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 05:02:22,640 - INFO - joeynmt.training - Example #3\n",
      "2021-10-10 05:02:22,641 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-10 05:02:22,641 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-10 05:02:22,641 - INFO - joeynmt.training - \tHypothesis: After graduating in February 1945 , I met the brothers in Puerto Rico .\n",
      "2021-10-10 05:02:22,641 - INFO - joeynmt.training - Validation result (greedy) at epoch  25, step    30000: bleu:  38.94, loss: 18493.4121, ppl:   1.9239, duration: 111.1825s\n",
      "2021-10-10 05:03:15,624 - INFO - joeynmt.training - Epoch  25, Step:    30100, Batch Loss:     0.551204, Tokens per Sec:     8704, Lr: 0.000127\n",
      "2021-10-10 05:04:08,636 - INFO - joeynmt.training - Epoch  25, Step:    30200, Batch Loss:     0.720366, Tokens per Sec:     8683, Lr: 0.000127\n",
      "2021-10-10 05:05:01,096 - INFO - joeynmt.training - Epoch  25, Step:    30300, Batch Loss:     0.595336, Tokens per Sec:     8737, Lr: 0.000127\n",
      "2021-10-10 05:05:54,470 - INFO - joeynmt.training - Epoch  25, Step:    30400, Batch Loss:     0.641931, Tokens per Sec:     8639, Lr: 0.000127\n",
      "2021-10-10 05:06:47,134 - INFO - joeynmt.training - Epoch  25, Step:    30500, Batch Loss:     0.660719, Tokens per Sec:     8457, Lr: 0.000127\n",
      "2021-10-10 05:08:31,107 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-10 05:08:31,107 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-10 05:08:31,107 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-10 05:08:31,485 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-10 05:08:31,485 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-10 05:08:37,677 - INFO - joeynmt.training - Example #0\n",
      "2021-10-10 05:08:37,678 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-10 05:08:37,678 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-10 05:08:37,678 - INFO - joeynmt.training - \tHypothesis: Yes , the conscience of “ the inside ” may be misled .\n",
      "2021-10-10 05:08:37,678 - INFO - joeynmt.training - Example #1\n",
      "2021-10-10 05:08:37,678 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-10 05:08:37,678 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 05:08:37,679 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave to his disciples ?\n",
      "2021-10-10 05:08:37,679 - INFO - joeynmt.training - Example #2\n",
      "2021-10-10 05:08:37,679 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-10 05:08:37,679 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 05:08:37,679 - INFO - joeynmt.training - \tHypothesis: That will enable us to get to know the difference between right and wrong and to know the difference between foolishness and wisdom and discreet things. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 05:08:37,679 - INFO - joeynmt.training - Example #3\n",
      "2021-10-10 05:08:37,679 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-10 05:08:37,680 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-10 05:08:37,680 - INFO - joeynmt.training - \tHypothesis: After graduating in February 1945 , I met our brothers in Puerto Rico .\n",
      "2021-10-10 05:08:37,680 - INFO - joeynmt.training - Validation result (greedy) at epoch  25, step    30500: bleu:  39.14, loss: 18373.1484, ppl:   1.9157, duration: 110.5445s\n",
      "2021-10-10 05:09:30,938 - INFO - joeynmt.training - Epoch  25, Step:    30600, Batch Loss:     0.672530, Tokens per Sec:     8602, Lr: 0.000126\n",
      "2021-10-10 05:10:20,728 - INFO - joeynmt.training - Epoch  25: total training loss 772.20\n",
      "2021-10-10 05:10:20,729 - INFO - joeynmt.training - EPOCH 26\n",
      "2021-10-10 05:10:23,533 - INFO - joeynmt.training - Epoch  26, Step:    30700, Batch Loss:     0.503167, Tokens per Sec:     7152, Lr: 0.000126\n",
      "2021-10-10 05:11:16,688 - INFO - joeynmt.training - Epoch  26, Step:    30800, Batch Loss:     0.583159, Tokens per Sec:     8583, Lr: 0.000126\n",
      "2021-10-10 05:12:09,833 - INFO - joeynmt.training - Epoch  26, Step:    30900, Batch Loss:     0.631086, Tokens per Sec:     8527, Lr: 0.000126\n",
      "2021-10-10 05:13:02,076 - INFO - joeynmt.training - Epoch  26, Step:    31000, Batch Loss:     0.582560, Tokens per Sec:     8558, Lr: 0.000126\n",
      "2021-10-10 05:14:50,368 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-10 05:14:50,372 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-10 05:14:50,372 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-10 05:14:50,796 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-10 05:14:50,796 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-10 05:14:56,970 - INFO - joeynmt.training - Example #0\n",
      "2021-10-10 05:14:56,971 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-10 05:14:56,971 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-10 05:14:56,971 - INFO - joeynmt.training - \tHypothesis: Yes , the conscience of “ the inside one ’ s inside ” may mislead us .\n",
      "2021-10-10 05:14:56,971 - INFO - joeynmt.training - Example #1\n",
      "2021-10-10 05:14:56,971 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-10 05:14:56,972 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 05:14:56,972 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 05:14:56,972 - INFO - joeynmt.training - Example #2\n",
      "2021-10-10 05:14:56,972 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-10 05:14:56,972 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 05:14:56,972 - INFO - joeynmt.training - \tHypothesis: That will enable us to discern the difference between right and wrong and to know the difference between foolish and discreet and discreet personals. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 05:14:56,972 - INFO - joeynmt.training - Example #3\n",
      "2021-10-10 05:14:56,973 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-10 05:14:56,973 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-10 05:14:56,973 - INFO - joeynmt.training - \tHypothesis: After graduating in February 1945 , I met the brothers in Puerto Rico .\n",
      "2021-10-10 05:14:56,973 - INFO - joeynmt.training - Validation result (greedy) at epoch  26, step    31000: bleu:  39.13, loss: 18362.9395, ppl:   1.9150, duration: 114.8959s\n",
      "2021-10-10 05:15:50,096 - INFO - joeynmt.training - Epoch  26, Step:    31100, Batch Loss:     0.656195, Tokens per Sec:     8614, Lr: 0.000125\n",
      "2021-10-10 05:16:43,186 - INFO - joeynmt.training - Epoch  26, Step:    31200, Batch Loss:     0.632237, Tokens per Sec:     8458, Lr: 0.000125\n",
      "2021-10-10 05:17:36,602 - INFO - joeynmt.training - Epoch  26, Step:    31300, Batch Loss:     0.639179, Tokens per Sec:     8472, Lr: 0.000125\n",
      "2021-10-10 05:18:29,199 - INFO - joeynmt.training - Epoch  26, Step:    31400, Batch Loss:     0.598615, Tokens per Sec:     8618, Lr: 0.000125\n",
      "2021-10-10 05:19:21,517 - INFO - joeynmt.training - Epoch  26, Step:    31500, Batch Loss:     0.588000, Tokens per Sec:     8524, Lr: 0.000125\n",
      "2021-10-10 05:21:04,742 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-10 05:21:04,742 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-10 05:21:04,742 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-10 05:21:05,072 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-10 05:21:05,072 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-10 05:21:11,172 - INFO - joeynmt.training - Example #0\n",
      "2021-10-10 05:21:11,172 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-10 05:21:11,173 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-10 05:21:11,173 - INFO - joeynmt.training - \tHypothesis: Yes , the conscience of “ the inner person ” may mislead us .\n",
      "2021-10-10 05:21:11,173 - INFO - joeynmt.training - Example #1\n",
      "2021-10-10 05:21:11,173 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-10 05:21:11,173 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 05:21:11,173 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 05:21:11,173 - INFO - joeynmt.training - Example #2\n",
      "2021-10-10 05:21:11,173 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-10 05:21:11,173 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 05:21:11,173 - INFO - joeynmt.training - \tHypothesis: That will enable us to know the difference between right and wrong and to know the difference between foolish and discreet and discreet personals. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 05:21:11,174 - INFO - joeynmt.training - Example #3\n",
      "2021-10-10 05:21:11,174 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-10 05:21:11,174 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-10 05:21:11,174 - INFO - joeynmt.training - \tHypothesis: After graduating in February 1945 , I met the brothers in Puerto Rico .\n",
      "2021-10-10 05:21:11,174 - INFO - joeynmt.training - Validation result (greedy) at epoch  26, step    31500: bleu:  39.19, loss: 18362.4297, ppl:   1.9150, duration: 109.6568s\n",
      "2021-10-10 05:22:04,158 - INFO - joeynmt.training - Epoch  26, Step:    31600, Batch Loss:     0.629077, Tokens per Sec:     8480, Lr: 0.000124\n",
      "2021-10-10 05:22:56,886 - INFO - joeynmt.training - Epoch  26, Step:    31700, Batch Loss:     0.666795, Tokens per Sec:     8725, Lr: 0.000124\n",
      "2021-10-10 05:23:50,065 - INFO - joeynmt.training - Epoch  26, Step:    31800, Batch Loss:     0.667389, Tokens per Sec:     8602, Lr: 0.000124\n",
      "2021-10-10 05:24:42,609 - INFO - joeynmt.training - Epoch  26, Step:    31900, Batch Loss:     0.653987, Tokens per Sec:     8272, Lr: 0.000124\n",
      "2021-10-10 05:24:55,705 - INFO - joeynmt.training - Epoch  26: total training loss 768.46\n",
      "2021-10-10 05:24:55,706 - INFO - joeynmt.training - EPOCH 27\n",
      "2021-10-10 05:25:36,738 - INFO - joeynmt.training - Epoch  27, Step:    32000, Batch Loss:     0.633447, Tokens per Sec:     8302, Lr: 0.000124\n",
      "2021-10-10 05:27:22,189 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-10 05:27:22,190 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-10 05:27:22,190 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-10 05:27:28,640 - INFO - joeynmt.training - Example #0\n",
      "2021-10-10 05:27:28,641 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-10 05:27:28,641 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-10 05:27:28,641 - INFO - joeynmt.training - \tHypothesis: Yes , the conscience of “ the inside ” may be misled .\n",
      "2021-10-10 05:27:28,641 - INFO - joeynmt.training - Example #1\n",
      "2021-10-10 05:27:28,641 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-10 05:27:28,641 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 05:27:28,641 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave to his disciples ?\n",
      "2021-10-10 05:27:28,641 - INFO - joeynmt.training - Example #2\n",
      "2021-10-10 05:27:28,642 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-10 05:27:28,642 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 05:27:28,642 - INFO - joeynmt.training - \tHypothesis: That will enable us to know the difference between right and wrong and to know the difference between foolish and discreet and discreet personals. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 05:27:28,642 - INFO - joeynmt.training - Example #3\n",
      "2021-10-10 05:27:28,642 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-10 05:27:28,642 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-10 05:27:28,642 - INFO - joeynmt.training - \tHypothesis: After graduating on February 1945 , I met our brothers in Puerto Rico .\n",
      "2021-10-10 05:27:28,642 - INFO - joeynmt.training - Validation result (greedy) at epoch  27, step    32000: bleu:  38.52, loss: 18376.8809, ppl:   1.9160, duration: 111.9036s\n",
      "2021-10-10 05:28:22,017 - INFO - joeynmt.training - Epoch  27, Step:    32100, Batch Loss:     0.631317, Tokens per Sec:     8489, Lr: 0.000123\n",
      "2021-10-10 05:29:14,759 - INFO - joeynmt.training - Epoch  27, Step:    32200, Batch Loss:     0.617775, Tokens per Sec:     8662, Lr: 0.000123\n",
      "2021-10-10 05:30:08,007 - INFO - joeynmt.training - Epoch  27, Step:    32300, Batch Loss:     0.574850, Tokens per Sec:     8652, Lr: 0.000123\n",
      "2021-10-10 05:31:00,754 - INFO - joeynmt.training - Epoch  27, Step:    32400, Batch Loss:     0.652147, Tokens per Sec:     8695, Lr: 0.000123\n",
      "2021-10-10 05:31:53,887 - INFO - joeynmt.training - Epoch  27, Step:    32500, Batch Loss:     0.594799, Tokens per Sec:     8423, Lr: 0.000123\n",
      "2021-10-10 05:33:38,121 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-10 05:33:38,122 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-10 05:33:38,122 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-10 05:33:38,456 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-10 05:33:38,456 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-10 05:33:44,693 - INFO - joeynmt.training - Example #0\n",
      "2021-10-10 05:33:44,694 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-10 05:33:44,694 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-10 05:33:44,694 - INFO - joeynmt.training - \tHypothesis: Of course , the conscience of “ the inside ” may mislead us .\n",
      "2021-10-10 05:33:44,694 - INFO - joeynmt.training - Example #1\n",
      "2021-10-10 05:33:44,694 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-10 05:33:44,694 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 05:33:44,694 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 05:33:44,694 - INFO - joeynmt.training - Example #2\n",
      "2021-10-10 05:33:44,694 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-10 05:33:44,694 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 05:33:44,694 - INFO - joeynmt.training - \tHypothesis: That will enable us to know the difference between right and wrong and to know the difference between foolishness and wisdom and wisdom and discreet things. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 05:33:44,695 - INFO - joeynmt.training - Example #3\n",
      "2021-10-10 05:33:44,695 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-10 05:33:44,695 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-10 05:33:44,695 - INFO - joeynmt.training - \tHypothesis: After graduating in February 1945 , I met the brothers in Puerto Rico .\n",
      "2021-10-10 05:33:44,695 - INFO - joeynmt.training - Validation result (greedy) at epoch  27, step    32500: bleu:  39.16, loss: 18301.5801, ppl:   1.9109, duration: 110.8075s\n",
      "2021-10-10 05:34:37,698 - INFO - joeynmt.training - Epoch  27, Step:    32600, Batch Loss:     0.575526, Tokens per Sec:     8584, Lr: 0.000122\n",
      "2021-10-10 05:35:30,464 - INFO - joeynmt.training - Epoch  27, Step:    32700, Batch Loss:     0.613383, Tokens per Sec:     8265, Lr: 0.000122\n",
      "2021-10-10 05:36:23,140 - INFO - joeynmt.training - Epoch  27, Step:    32800, Batch Loss:     0.619945, Tokens per Sec:     8511, Lr: 0.000122\n",
      "2021-10-10 05:37:15,674 - INFO - joeynmt.training - Epoch  27, Step:    32900, Batch Loss:     0.616230, Tokens per Sec:     8580, Lr: 0.000122\n",
      "2021-10-10 05:38:08,777 - INFO - joeynmt.training - Epoch  27, Step:    33000, Batch Loss:     0.598139, Tokens per Sec:     8415, Lr: 0.000122\n",
      "2021-10-10 05:39:55,425 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-10 05:39:55,426 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-10 05:39:55,426 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-10 05:39:55,751 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-10 05:39:55,751 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-10 05:40:01,939 - INFO - joeynmt.training - Example #0\n",
      "2021-10-10 05:40:01,939 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-10 05:40:01,939 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-10 05:40:01,940 - INFO - joeynmt.training - \tHypothesis: Yes , the conscience of “ the inner person ” may mislead us .\n",
      "2021-10-10 05:40:01,940 - INFO - joeynmt.training - Example #1\n",
      "2021-10-10 05:40:01,940 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-10 05:40:01,940 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 05:40:01,940 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave to his disciples ?\n",
      "2021-10-10 05:40:01,940 - INFO - joeynmt.training - Example #2\n",
      "2021-10-10 05:40:01,940 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-10 05:40:01,940 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 05:40:01,941 - INFO - joeynmt.training - \tHypothesis: That will enable us to know the difference between right and wrong and to know the difference between foolish and discreet and discreet personals. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 05:40:01,941 - INFO - joeynmt.training - Example #3\n",
      "2021-10-10 05:40:01,941 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-10 05:40:01,941 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-10 05:40:01,941 - INFO - joeynmt.training - \tHypothesis: After graduating in February 1945 , I met our brothers in Puerto Rico .\n",
      "2021-10-10 05:40:01,941 - INFO - joeynmt.training - Validation result (greedy) at epoch  27, step    33000: bleu:  38.91, loss: 18219.0859, ppl:   1.9053, duration: 113.1632s\n",
      "2021-10-10 05:40:54,882 - INFO - joeynmt.training - Epoch  27, Step:    33100, Batch Loss:     0.627779, Tokens per Sec:     8424, Lr: 0.000121\n",
      "2021-10-10 05:41:22,830 - INFO - joeynmt.training - Epoch  27: total training loss 761.69\n",
      "2021-10-10 05:41:22,831 - INFO - joeynmt.training - EPOCH 28\n",
      "2021-10-10 05:41:48,743 - INFO - joeynmt.training - Epoch  28, Step:    33200, Batch Loss:     0.616141, Tokens per Sec:     8171, Lr: 0.000121\n",
      "2021-10-10 05:42:42,056 - INFO - joeynmt.training - Epoch  28, Step:    33300, Batch Loss:     0.589497, Tokens per Sec:     8435, Lr: 0.000121\n",
      "2021-10-10 05:43:34,698 - INFO - joeynmt.training - Epoch  28, Step:    33400, Batch Loss:     0.518845, Tokens per Sec:     8513, Lr: 0.000121\n",
      "2021-10-10 05:44:27,494 - INFO - joeynmt.training - Epoch  28, Step:    33500, Batch Loss:     0.631122, Tokens per Sec:     8487, Lr: 0.000121\n",
      "2021-10-10 05:46:15,834 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-10 05:46:15,834 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-10 05:46:15,835 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-10 05:46:22,232 - INFO - joeynmt.training - Example #0\n",
      "2021-10-10 05:46:22,232 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-10 05:46:22,233 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-10 05:46:22,233 - INFO - joeynmt.training - \tHypothesis: Of course , the conscience of “ the inner man ” may mislead us .\n",
      "2021-10-10 05:46:22,233 - INFO - joeynmt.training - Example #1\n",
      "2021-10-10 05:46:22,233 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-10 05:46:22,233 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 05:46:22,233 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave to his disciples ?\n",
      "2021-10-10 05:46:22,233 - INFO - joeynmt.training - Example #2\n",
      "2021-10-10 05:46:22,233 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-10 05:46:22,233 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 05:46:22,233 - INFO - joeynmt.training - \tHypothesis: That will enable us to discern the difference between right and wrong and to know the difference between foolish and discreet and discreet personality. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 05:46:22,233 - INFO - joeynmt.training - Example #3\n",
      "2021-10-10 05:46:22,234 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-10 05:46:22,234 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-10 05:46:22,234 - INFO - joeynmt.training - \tHypothesis: After graduating in February 1945 , I met our brothers in Puerto Rico .\n",
      "2021-10-10 05:46:22,234 - INFO - joeynmt.training - Validation result (greedy) at epoch  28, step    33500: bleu:  39.14, loss: 18248.8730, ppl:   1.9073, duration: 114.7390s\n",
      "2021-10-10 05:47:14,166 - INFO - joeynmt.training - Epoch  28, Step:    33600, Batch Loss:     0.569773, Tokens per Sec:     8477, Lr: 0.000121\n",
      "2021-10-10 05:48:07,573 - INFO - joeynmt.training - Epoch  28, Step:    33700, Batch Loss:     0.602701, Tokens per Sec:     8486, Lr: 0.000120\n",
      "2021-10-10 05:49:00,748 - INFO - joeynmt.training - Epoch  28, Step:    33800, Batch Loss:     0.546398, Tokens per Sec:     8617, Lr: 0.000120\n",
      "2021-10-10 05:49:54,207 - INFO - joeynmt.training - Epoch  28, Step:    33900, Batch Loss:     0.605664, Tokens per Sec:     8447, Lr: 0.000120\n",
      "2021-10-10 05:50:46,880 - INFO - joeynmt.training - Epoch  28, Step:    34000, Batch Loss:     0.685055, Tokens per Sec:     8576, Lr: 0.000120\n",
      "2021-10-10 05:52:29,145 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-10 05:52:29,146 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-10 05:52:29,146 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-10 05:52:29,474 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-10 05:52:29,474 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-10 05:52:35,826 - INFO - joeynmt.training - Example #0\n",
      "2021-10-10 05:52:35,827 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-10 05:52:35,827 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-10 05:52:35,827 - INFO - joeynmt.training - \tHypothesis: Yes , the conscience of “ the inside ” may mislead us .\n",
      "2021-10-10 05:52:35,827 - INFO - joeynmt.training - Example #1\n",
      "2021-10-10 05:52:35,827 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-10 05:52:35,827 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 05:52:35,827 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave to his disciples ?\n",
      "2021-10-10 05:52:35,827 - INFO - joeynmt.training - Example #2\n",
      "2021-10-10 05:52:35,828 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-10 05:52:35,828 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 05:52:35,828 - INFO - joeynmt.training - \tHypothesis: That will enable us to get to know the difference between right and wrong and to know the difference between foolish and discreet and discreet and discreet personals. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 05:52:35,828 - INFO - joeynmt.training - Example #3\n",
      "2021-10-10 05:52:35,828 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-10 05:52:35,828 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-10 05:52:35,828 - INFO - joeynmt.training - \tHypothesis: After graduating on February 1945 , I met the brothers in Puerto Rico .\n",
      "2021-10-10 05:52:35,828 - INFO - joeynmt.training - Validation result (greedy) at epoch  28, step    34000: bleu:  38.97, loss: 18185.2637, ppl:   1.9030, duration: 108.9475s\n",
      "2021-10-10 05:53:28,483 - INFO - joeynmt.training - Epoch  28, Step:    34100, Batch Loss:     0.579792, Tokens per Sec:     8565, Lr: 0.000120\n",
      "2021-10-10 05:54:20,867 - INFO - joeynmt.training - Epoch  28, Step:    34200, Batch Loss:     0.442351, Tokens per Sec:     8647, Lr: 0.000119\n",
      "2021-10-10 05:55:13,950 - INFO - joeynmt.training - Epoch  28, Step:    34300, Batch Loss:     0.616671, Tokens per Sec:     8405, Lr: 0.000119\n",
      "2021-10-10 05:55:58,708 - INFO - joeynmt.training - Epoch  28: total training loss 757.61\n",
      "2021-10-10 05:55:58,709 - INFO - joeynmt.training - EPOCH 29\n",
      "2021-10-10 05:56:08,059 - INFO - joeynmt.training - Epoch  29, Step:    34400, Batch Loss:     0.613739, Tokens per Sec:     8577, Lr: 0.000119\n",
      "2021-10-10 05:57:00,800 - INFO - joeynmt.training - Epoch  29, Step:    34500, Batch Loss:     0.693824, Tokens per Sec:     8574, Lr: 0.000119\n",
      "2021-10-10 05:58:45,104 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-10 05:58:45,104 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-10 05:58:45,104 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-10 05:58:45,433 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-10 05:58:45,433 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-10 05:58:51,498 - INFO - joeynmt.training - Example #0\n",
      "2021-10-10 05:58:51,499 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-10 05:58:51,499 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-10 05:58:51,499 - INFO - joeynmt.training - \tHypothesis: Indeed , the conscience of “ the man in the inner person ” may mislead us .\n",
      "2021-10-10 05:58:51,499 - INFO - joeynmt.training - Example #1\n",
      "2021-10-10 05:58:51,499 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-10 05:58:51,499 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 05:58:51,500 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 05:58:51,500 - INFO - joeynmt.training - Example #2\n",
      "2021-10-10 05:58:51,500 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-10 05:58:51,500 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 05:58:51,500 - INFO - joeynmt.training - \tHypothesis: That will enable us to know the difference between right and wrong and to know the difference between foolishness and wisdom and discreet personals. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 05:58:51,500 - INFO - joeynmt.training - Example #3\n",
      "2021-10-10 05:58:51,500 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-10 05:58:51,501 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-10 05:58:51,501 - INFO - joeynmt.training - \tHypothesis: After graduating in February 1945 , I met the brothers in Puerto Rico .\n",
      "2021-10-10 05:58:51,501 - INFO - joeynmt.training - Validation result (greedy) at epoch  29, step    34500: bleu:  39.35, loss: 18063.8203, ppl:   1.8949, duration: 110.6999s\n",
      "2021-10-10 05:59:44,614 - INFO - joeynmt.training - Epoch  29, Step:    34600, Batch Loss:     0.610122, Tokens per Sec:     8720, Lr: 0.000119\n",
      "2021-10-10 06:00:38,002 - INFO - joeynmt.training - Epoch  29, Step:    34700, Batch Loss:     0.632738, Tokens per Sec:     8602, Lr: 0.000119\n",
      "2021-10-10 06:01:30,626 - INFO - joeynmt.training - Epoch  29, Step:    34800, Batch Loss:     0.605076, Tokens per Sec:     8547, Lr: 0.000118\n",
      "2021-10-10 06:02:22,910 - INFO - joeynmt.training - Epoch  29, Step:    34900, Batch Loss:     0.613313, Tokens per Sec:     8483, Lr: 0.000118\n",
      "2021-10-10 06:03:16,628 - INFO - joeynmt.training - Epoch  29, Step:    35000, Batch Loss:     0.656458, Tokens per Sec:     8599, Lr: 0.000118\n",
      "2021-10-10 06:05:02,370 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-10 06:05:02,371 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-10 06:05:02,371 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-10 06:05:08,863 - INFO - joeynmt.training - Example #0\n",
      "2021-10-10 06:05:08,864 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-10 06:05:08,864 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-10 06:05:08,864 - INFO - joeynmt.training - \tHypothesis: Indeed , the conscience of “ the inside ” may mislead us .\n",
      "2021-10-10 06:05:08,864 - INFO - joeynmt.training - Example #1\n",
      "2021-10-10 06:05:08,864 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-10 06:05:08,864 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 06:05:08,864 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave to his disciples ?\n",
      "2021-10-10 06:05:08,864 - INFO - joeynmt.training - Example #2\n",
      "2021-10-10 06:05:08,865 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-10 06:05:08,865 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 06:05:08,865 - INFO - joeynmt.training - \tHypothesis: That will enable us to get to know the difference between right and wrong and to know the difference between foolishness and wisdom and discreet personality. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 06:05:08,865 - INFO - joeynmt.training - Example #3\n",
      "2021-10-10 06:05:08,865 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-10 06:05:08,865 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-10 06:05:08,865 - INFO - joeynmt.training - \tHypothesis: After graduating in February 1945 , I met the brothers in Puerto Rico .\n",
      "2021-10-10 06:05:08,865 - INFO - joeynmt.training - Validation result (greedy) at epoch  29, step    35000: bleu:  39.30, loss: 18095.1367, ppl:   1.8970, duration: 112.2364s\n",
      "2021-10-10 06:06:00,439 - INFO - joeynmt.training - Epoch  29, Step:    35100, Batch Loss:     0.607321, Tokens per Sec:     8432, Lr: 0.000118\n",
      "2021-10-10 06:06:53,799 - INFO - joeynmt.training - Epoch  29, Step:    35200, Batch Loss:     0.574546, Tokens per Sec:     8472, Lr: 0.000118\n",
      "2021-10-10 06:07:47,170 - INFO - joeynmt.training - Epoch  29, Step:    35300, Batch Loss:     0.652758, Tokens per Sec:     8534, Lr: 0.000118\n",
      "2021-10-10 06:08:40,226 - INFO - joeynmt.training - Epoch  29, Step:    35400, Batch Loss:     0.569948, Tokens per Sec:     8211, Lr: 0.000117\n",
      "2021-10-10 06:09:34,190 - INFO - joeynmt.training - Epoch  29, Step:    35500, Batch Loss:     0.586135, Tokens per Sec:     8515, Lr: 0.000117\n",
      "2021-10-10 06:11:21,830 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-10 06:11:21,830 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-10 06:11:21,830 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-10 06:11:22,159 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!\n",
      "2021-10-10 06:11:22,159 - INFO - joeynmt.training - Saving new checkpoint.\n",
      "2021-10-10 06:11:28,460 - INFO - joeynmt.training - Example #0\n",
      "2021-10-10 06:11:28,461 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-10 06:11:28,461 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-10 06:11:28,461 - INFO - joeynmt.training - \tHypothesis: Yes , the conscience of “ the man in the inner person ” may mislead us .\n",
      "2021-10-10 06:11:28,461 - INFO - joeynmt.training - Example #1\n",
      "2021-10-10 06:11:28,461 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-10 06:11:28,461 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 06:11:28,461 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave to his disciples ?\n",
      "2021-10-10 06:11:28,461 - INFO - joeynmt.training - Example #2\n",
      "2021-10-10 06:11:28,462 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-10 06:11:28,462 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 06:11:28,462 - INFO - joeynmt.training - \tHypothesis: That will enable us to discern the difference between right and wrong and to know the difference between foolishness and wisdom and discreet personal. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 06:11:28,462 - INFO - joeynmt.training - Example #3\n",
      "2021-10-10 06:11:28,462 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-10 06:11:28,462 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-10 06:11:28,462 - INFO - joeynmt.training - \tHypothesis: After graduating in February 1945 , I met our brothers in Puerto Rico .\n",
      "2021-10-10 06:11:28,462 - INFO - joeynmt.training - Validation result (greedy) at epoch  29, step    35500: bleu:  39.23, loss: 18049.5039, ppl:   1.8939, duration: 114.2720s\n",
      "2021-10-10 06:12:21,282 - INFO - joeynmt.training - Epoch  29, Step:    35600, Batch Loss:     0.606000, Tokens per Sec:     8621, Lr: 0.000117\n",
      "2021-10-10 06:12:26,245 - INFO - joeynmt.training - Epoch  29: total training loss 748.43\n",
      "2021-10-10 06:12:26,245 - INFO - joeynmt.training - EPOCH 30\n",
      "2021-10-10 06:13:15,773 - INFO - joeynmt.training - Epoch  30, Step:    35700, Batch Loss:     0.560345, Tokens per Sec:     8496, Lr: 0.000117\n",
      "2021-10-10 06:14:09,717 - INFO - joeynmt.training - Epoch  30, Step:    35800, Batch Loss:     0.605207, Tokens per Sec:     8195, Lr: 0.000117\n",
      "2021-10-10 06:15:03,946 - INFO - joeynmt.training - Epoch  30, Step:    35900, Batch Loss:     0.636039, Tokens per Sec:     8106, Lr: 0.000117\n",
      "2021-10-10 06:15:58,511 - INFO - joeynmt.training - Epoch  30, Step:    36000, Batch Loss:     0.630279, Tokens per Sec:     8284, Lr: 0.000116\n",
      "2021-10-10 06:17:45,216 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-10 06:17:45,216 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-10 06:17:45,216 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-10 06:17:51,574 - INFO - joeynmt.training - Example #0\n",
      "2021-10-10 06:17:51,575 - INFO - joeynmt.training - \tSource:     Vhukuma , luvalo lwa ‘ muthu wa nga ngomu ’ lu nga kha ḓi ri xedza .\n",
      "2021-10-10 06:17:51,575 - INFO - joeynmt.training - \tReference:  Yes , the voice of “ the man we are inside ” may fail us .\n",
      "2021-10-10 06:17:51,575 - INFO - joeynmt.training - \tHypothesis: Yes , the conscience of “ the inner man ” may mislead us .\n",
      "2021-10-10 06:17:51,575 - INFO - joeynmt.training - Example #1\n",
      "2021-10-10 06:17:51,575 - INFO - joeynmt.training - \tSource:     • Ri nga vhuyelwa hani nga vhugudisi he Yesu a vhu ṋea vhafunziwa vhawe ?\n",
      "2021-10-10 06:17:51,576 - INFO - joeynmt.training - \tReference:  • How can we benefit from the training Jesus gave his disciples ?\n",
      "2021-10-10 06:17:51,576 - INFO - joeynmt.training - \tHypothesis: • How can we benefit from the training Jesus gave to his disciples ?\n",
      "2021-10-10 06:17:51,576 - INFO - joeynmt.training - Example #2\n",
      "2021-10-10 06:17:51,576 - INFO - joeynmt.training - \tSource:     Zwenezwo zwi ḓo ita uri ri kone u ḓivha phambano vhukati ha zwo lugaho na zwi songo lugaho na u dovha ra ḓivha phambano vhukati ha vhutsilu na vhuṱali . — Vhaheb . 5 : 14 ; Vhaef . 5 : 15 .\n",
      "2021-10-10 06:17:51,576 - INFO - joeynmt.training - \tReference:  To remain blameless in today ’ s complex and wicked world , we must train our “ powers of discernment ” so that we can distinguish not just right from wrong but also wise from unwise. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 06:17:51,576 - INFO - joeynmt.training - \tHypothesis: That will enable us to know the difference between right and wrong and to know the difference between foolishness and wisdom and discreet peated. — Heb . 5 : 14 ; Eph . 5 : 15 .\n",
      "2021-10-10 06:17:51,576 - INFO - joeynmt.training - Example #3\n",
      "2021-10-10 06:17:51,577 - INFO - joeynmt.training - \tSource:     Nga murahu ha u ṱhaphudza nga February 1945 , ndo mbo ḓi ṱangana na vhana vhahashu ngei Puerto Rico .\n",
      "2021-10-10 06:17:51,577 - INFO - joeynmt.training - \tReference:  After graduating in February 1945 , I joined my siblings in Puerto Rico .\n",
      "2021-10-10 06:17:51,577 - INFO - joeynmt.training - \tHypothesis: After graduating on February 1945 , I met our brothers in Puerto Rico .\n",
      "2021-10-10 06:17:51,577 - INFO - joeynmt.training - Validation result (greedy) at epoch  30, step    36000: bleu:  39.19, loss: 18108.1953, ppl:   1.8979, duration: 113.0653s\n",
      "2021-10-10 06:18:44,528 - INFO - joeynmt.training - Epoch  30, Step:    36100, Batch Loss:     0.621499, Tokens per Sec:     8417, Lr: 0.000116\n",
      "2021-10-10 06:19:38,598 - INFO - joeynmt.training - Epoch  30, Step:    36200, Batch Loss:     0.642587, Tokens per Sec:     8403, Lr: 0.000116\n",
      "2021-10-10 06:20:33,817 - INFO - joeynmt.training - Epoch  30, Step:    36300, Batch Loss:     0.591686, Tokens per Sec:     8120, Lr: 0.000116\n",
      "2021-10-10 06:21:28,493 - INFO - joeynmt.training - Epoch  30, Step:    36400, Batch Loss:     0.659998, Tokens per Sec:     8133, Lr: 0.000116\n"
     ]
    }
   ],
   "source": [
    "!cd joeynmt; python3 -m joeynmt train configs/transformer_reverse_$tgt$src.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nlp_things/masakhane/ve-en-run_v3/models/enve_second/\n"
     ]
    }
   ],
   "source": [
    "os.environ['FILE'] = f\"{os.environ['gdrive_path']}/models/{os.environ['src']}{os.environ['tgt']}_second/\"\n",
    "!echo $FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "MBoDS09JM807"
   },
   "outputs": [],
   "source": [
    "# Copy the created models from the notebook storage to google drive for persistant storage\n",
    "!mkdir -p \"$FILE\"\n",
    "\n",
    "!cp -r joeynmt/models/${tgt}${src}_reverse_transformer_second/* \"$FILE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n94wlrCjVc17",
    "outputId": "bb8462a5-241e-4b73-e9a8-3096816d0151"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps: 500\tLoss: 62454.53906\tPPL: 9.11427\tbleu: 0.50940\tLR: 0.00034939\t*\n",
      "Steps: 1000\tLoss: 47953.60938\tPPL: 5.45620\tbleu: 4.98143\tLR: 0.00069877\t*\n",
      "Steps: 1500\tLoss: 39419.25000\tPPL: 4.03408\tbleu: 14.91646\tLR: 0.00057054\t*\n",
      "Steps: 2000\tLoss: 35529.75781\tPPL: 3.51541\tbleu: 17.48222\tLR: 0.00049411\t*\n",
      "Steps: 2500\tLoss: 33582.72266\tPPL: 3.28138\tbleu: 17.68024\tLR: 0.00044194\t*\n",
      "Steps: 3000\tLoss: 31119.50391\tPPL: 3.00750\tbleu: 22.38277\tLR: 0.00040344\t*\n",
      "Steps: 3500\tLoss: 29664.81641\tPPL: 2.85661\tbleu: 23.71770\tLR: 0.00037351\t*\n",
      "Steps: 4000\tLoss: 28529.24805\tPPL: 2.74411\tbleu: 25.62853\tLR: 0.00034939\t*\n",
      "Steps: 4500\tLoss: 27524.72266\tPPL: 2.64829\tbleu: 26.25328\tLR: 0.00032940\t*\n",
      "Steps: 5000\tLoss: 26613.30469\tPPL: 2.56424\tbleu: 27.75998\tLR: 0.00031250\t*\n",
      "Steps: 5500\tLoss: 26080.00977\tPPL: 2.51631\tbleu: 28.56380\tLR: 0.00029796\t*\n",
      "Steps: 6000\tLoss: 25459.93945\tPPL: 2.46170\tbleu: 28.83571\tLR: 0.00028527\t*\n",
      "Steps: 6500\tLoss: 24791.61328\tPPL: 2.40417\tbleu: 29.72020\tLR: 0.00027408\t*\n",
      "Steps: 7000\tLoss: 24460.27734\tPPL: 2.37615\tbleu: 30.55081\tLR: 0.00026411\t*\n",
      "Steps: 7500\tLoss: 23934.09375\tPPL: 2.33232\tbleu: 30.78033\tLR: 0.00025516\t*\n",
      "Steps: 8000\tLoss: 23792.87891\tPPL: 2.32070\tbleu: 31.15932\tLR: 0.00024705\t*\n",
      "Steps: 8500\tLoss: 23359.54492\tPPL: 2.28539\tbleu: 31.91944\tLR: 0.00023968\t*\n",
      "Steps: 9000\tLoss: 23080.78320\tPPL: 2.26296\tbleu: 32.00034\tLR: 0.00023292\t*\n",
      "Steps: 9500\tLoss: 22659.10938\tPPL: 2.22944\tbleu: 32.25359\tLR: 0.00022671\t*\n",
      "Steps: 10000\tLoss: 22559.58203\tPPL: 2.22161\tbleu: 33.30772\tLR: 0.00022097\t*\n",
      "Steps: 10500\tLoss: 22240.13477\tPPL: 2.19664\tbleu: 33.21791\tLR: 0.00021565\t*\n",
      "Steps: 11000\tLoss: 22062.55078\tPPL: 2.18288\tbleu: 33.82596\tLR: 0.00021069\t*\n",
      "Steps: 11500\tLoss: 21862.30469\tPPL: 2.16746\tbleu: 34.13609\tLR: 0.00020606\t*\n",
      "Steps: 12000\tLoss: 21539.04492\tPPL: 2.14281\tbleu: 34.20948\tLR: 0.00020172\t*\n",
      "Steps: 12500\tLoss: 21391.66602\tPPL: 2.13167\tbleu: 34.46685\tLR: 0.00019764\t*\n",
      "Steps: 13000\tLoss: 21216.19922\tPPL: 2.11848\tbleu: 34.41061\tLR: 0.00019380\t*\n",
      "Steps: 13500\tLoss: 21019.06641\tPPL: 2.10375\tbleu: 34.86470\tLR: 0.00019018\t*\n",
      "Steps: 14000\tLoss: 20968.42773\tPPL: 2.09998\tbleu: 35.46497\tLR: 0.00018675\t*\n",
      "Steps: 14500\tLoss: 20770.35547\tPPL: 2.08532\tbleu: 35.44304\tLR: 0.00018351\t*\n",
      "Steps: 15000\tLoss: 20737.15430\tPPL: 2.08287\tbleu: 35.59996\tLR: 0.00018042\t*\n",
      "Steps: 15500\tLoss: 20590.01172\tPPL: 2.07205\tbleu: 35.32666\tLR: 0.00017749\t*\n",
      "Steps: 16000\tLoss: 20417.36328\tPPL: 2.05943\tbleu: 35.77805\tLR: 0.00017469\t*\n",
      "Steps: 16500\tLoss: 20260.56445\tPPL: 2.04804\tbleu: 35.92699\tLR: 0.00017203\t*\n",
      "Steps: 17000\tLoss: 20187.54102\tPPL: 2.04276\tbleu: 36.17817\tLR: 0.00016948\t*\n",
      "Steps: 17500\tLoss: 20154.51953\tPPL: 2.04037\tbleu: 36.08708\tLR: 0.00016704\t*\n",
      "Steps: 18000\tLoss: 19984.22656\tPPL: 2.02811\tbleu: 36.71314\tLR: 0.00016470\t*\n",
      "Steps: 18500\tLoss: 19924.44336\tPPL: 2.02383\tbleu: 36.41138\tLR: 0.00016246\t*\n",
      "Steps: 19000\tLoss: 19830.59961\tPPL: 2.01712\tbleu: 36.45924\tLR: 0.00016031\t*\n",
      "Steps: 19500\tLoss: 19686.78125\tPPL: 2.00688\tbleu: 36.91640\tLR: 0.00015824\t*\n",
      "Steps: 20000\tLoss: 19612.90039\tPPL: 2.00164\tbleu: 36.67733\tLR: 0.00015625\t*\n",
      "Steps: 20500\tLoss: 19564.35352\tPPL: 1.99821\tbleu: 37.05867\tLR: 0.00015433\t*\n",
      "Steps: 21000\tLoss: 19558.25586\tPPL: 1.99777\tbleu: 37.02195\tLR: 0.00015248\t*\n",
      "Steps: 21500\tLoss: 19412.97656\tPPL: 1.98753\tbleu: 37.37305\tLR: 0.00015070\t*\n",
      "Steps: 22000\tLoss: 19302.96094\tPPL: 1.97981\tbleu: 37.25183\tLR: 0.00014898\t*\n",
      "Steps: 22500\tLoss: 19403.72656\tPPL: 1.98688\tbleu: 37.65528\tLR: 0.00014731\t\n",
      "Steps: 23000\tLoss: 19221.33008\tPPL: 1.97410\tbleu: 37.71637\tLR: 0.00014570\t*\n",
      "Steps: 23500\tLoss: 19170.04883\tPPL: 1.97052\tbleu: 37.74217\tLR: 0.00014415\t*\n",
      "Steps: 24000\tLoss: 19041.72266\tPPL: 1.96159\tbleu: 38.00887\tLR: 0.00014264\t*\n",
      "Steps: 24500\tLoss: 19011.68555\tPPL: 1.95951\tbleu: 37.49637\tLR: 0.00014117\t*\n",
      "Steps: 25000\tLoss: 19008.06641\tPPL: 1.95926\tbleu: 37.91385\tLR: 0.00013975\t*\n",
      "Steps: 25500\tLoss: 18895.02930\tPPL: 1.95144\tbleu: 37.87969\tLR: 0.00013838\t*\n",
      "Steps: 26000\tLoss: 18891.67578\tPPL: 1.95121\tbleu: 38.36376\tLR: 0.00013704\t*\n",
      "Steps: 26500\tLoss: 18845.44141\tPPL: 1.94802\tbleu: 38.34205\tLR: 0.00013574\t*\n",
      "Steps: 27000\tLoss: 18758.94141\tPPL: 1.94206\tbleu: 38.15185\tLR: 0.00013448\t*\n",
      "Steps: 27500\tLoss: 18708.70117\tPPL: 1.93861\tbleu: 38.47042\tLR: 0.00013325\t*\n",
      "Steps: 28000\tLoss: 18679.09570\tPPL: 1.93659\tbleu: 38.82072\tLR: 0.00013206\t*\n",
      "Steps: 28500\tLoss: 18618.42773\tPPL: 1.93243\tbleu: 38.46111\tLR: 0.00013089\t*\n",
      "Steps: 29000\tLoss: 18559.42969\tPPL: 1.92840\tbleu: 38.33539\tLR: 0.00012976\t*\n",
      "Steps: 29500\tLoss: 18558.83594\tPPL: 1.92836\tbleu: 38.60409\tLR: 0.00012865\t*\n",
      "Steps: 30000\tLoss: 18493.41211\tPPL: 1.92390\tbleu: 38.93626\tLR: 0.00012758\t*\n",
      "Steps: 30500\tLoss: 18373.14844\tPPL: 1.91573\tbleu: 39.14012\tLR: 0.00012653\t*\n",
      "Steps: 31000\tLoss: 18362.93945\tPPL: 1.91504\tbleu: 39.13039\tLR: 0.00012550\t*\n",
      "Steps: 31500\tLoss: 18362.42969\tPPL: 1.91501\tbleu: 39.18972\tLR: 0.00012450\t*\n",
      "Steps: 32000\tLoss: 18376.88086\tPPL: 1.91599\tbleu: 38.51899\tLR: 0.00012353\t\n",
      "Steps: 32500\tLoss: 18301.58008\tPPL: 1.91089\tbleu: 39.15942\tLR: 0.00012257\t*\n",
      "Steps: 33000\tLoss: 18219.08594\tPPL: 1.90532\tbleu: 38.90874\tLR: 0.00012164\t*\n",
      "Steps: 33500\tLoss: 18248.87305\tPPL: 1.90733\tbleu: 39.14426\tLR: 0.00012073\t\n",
      "Steps: 34000\tLoss: 18185.26367\tPPL: 1.90304\tbleu: 38.96760\tLR: 0.00011984\t*\n",
      "Steps: 34500\tLoss: 18063.82031\tPPL: 1.89488\tbleu: 39.34826\tLR: 0.00011897\t*\n",
      "Steps: 35000\tLoss: 18095.13672\tPPL: 1.89698\tbleu: 39.29887\tLR: 0.00011811\t\n",
      "Steps: 35500\tLoss: 18049.50391\tPPL: 1.89392\tbleu: 39.22597\tLR: 0.00011728\t*\n",
      "Steps: 36000\tLoss: 18108.19531\tPPL: 1.89786\tbleu: 39.19432\tLR: 0.00011646\t\n",
      "Steps: 36500\tLoss: 18048.61133\tPPL: 1.89386\tbleu: 39.30005\tLR: 0.00011566\t*\n",
      "Steps: 37000\tLoss: 17998.46875\tPPL: 1.89050\tbleu: 39.30977\tLR: 0.00011488\t*\n",
      "Steps: 37500\tLoss: 17987.01953\tPPL: 1.88974\tbleu: 39.68132\tLR: 0.00011411\t*\n"
     ]
    }
   ],
   "source": [
    "# Output our validation accuracy\n",
    "! cat \"$FILE/validations.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "66WhRE9lIhoD",
    "outputId": "b4297dba-67ae-48be-9068-4a0e92c4f98e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-10 08:03:15,268 - INFO - root - Hello! This is Joey-NMT (version 1.3).\n",
      "2021-10-10 08:03:15,270 - INFO - joeynmt.data - Building vocabulary...\n",
      "2021-10-10 08:03:15,576 - INFO - joeynmt.data - Loading dev data...\n",
      "2021-10-10 08:03:15,668 - INFO - joeynmt.data - Loading test data...\n",
      "2021-10-10 08:03:15,779 - INFO - joeynmt.data - Data loaded.\n",
      "2021-10-10 08:03:15,831 - INFO - joeynmt.prediction - Process device: cuda, n_gpu: 1, batch_size per device: 18000 (with beam_size)\n",
      "2021-10-10 08:03:18,710 - INFO - joeynmt.model - Building an encoder-decoder model...\n",
      "2021-10-10 08:03:19,470 - INFO - joeynmt.model - Enc-dec model built.\n",
      "2021-10-10 08:03:19,658 - INFO - joeynmt.prediction - Decoding on dev set (data/veen/dev.bpe.en)...\n",
      "2021-10-10 08:04:38,725 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-10 08:04:38,725 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-10 08:04:38,726 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-10 08:04:39,050 - INFO - joeynmt.prediction -  dev bleu[13a]:  40.20 [Beam search decoding with beam size = 5 and alpha = 1.0]\n",
      "2021-10-10 08:04:39,051 - INFO - joeynmt.prediction - Decoding on test set (data/veen/test.bpe.en)...\n",
      "2021-10-10 08:06:45,227 - WARNING - sacrebleu - That's 100 lines that end in a tokenized period ('.')\n",
      "2021-10-10 08:06:45,228 - WARNING - sacrebleu - It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "2021-10-10 08:06:45,228 - WARNING - sacrebleu - If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n",
      "2021-10-10 08:06:46,025 - INFO - joeynmt.prediction - test bleu[13a]:  46.82 [Beam search decoding with beam size = 5 and alpha = 1.0]\n"
     ]
    }
   ],
   "source": [
    "# Test our model\n",
    "! cd joeynmt; python3 -m joeynmt test ../\"$FILE/config.yaml\""
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "starter_notebook_into_English_training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
