{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "starter_notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ruohoruotsi/masakhane/blob/master/en-iso/jw300-baseline/English_to_Isoko_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Igc5itf-xMGj"
      },
      "source": [
        "# Masakhane - Machine Translation for African Languages (Using JoeyNMT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "x4fXCKCf36IK"
      },
      "source": [
        "## Note before beginning:\n",
        "### - The idea is that you should be able to make minimal changes to this in order to get SOME result for your own translation corpus. \n",
        "\n",
        "### - The tl;dr: Go to the **\"TODO\"** comments which will tell you what to update to get up and running\n",
        "\n",
        "### - If you actually want to have a clue what you're doing, read the text and peek at the links\n",
        "\n",
        "### - With 100 epochs, it should take around 7 hours to run in Google Colab\n",
        "\n",
        "### - Once you've gotten a result for your language, please attach and email your notebook that generated it to masakhanetranslation@gmail.com\n",
        "\n",
        "### - If you care enough and get a chance, doing a brief background on your language would be amazing. See examples in  [(Martinus, 2019)](https://arxiv.org/abs/1906.05685)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "l929HimrxS0a"
      },
      "source": [
        "## Retrieve your data & make a parallel corpus\n",
        "\n",
        "If you are wanting to use the JW300 data referenced on the Masakhane website or in our GitHub repo, you can use `opus-tools` to convert the data into a convenient format. `opus_read` from that package provides a convenient tool for reading the native aligned XML files and to convert them to TMX format. The tool can also be used to fetch relevant files from OPUS on the fly and to filter the data as necessary. [Read the documentation](https://pypi.org/project/opustools-pkg/) for more details.\n",
        "\n",
        "Once you have your corpus files in TMX format (an xml structure which will include the sentences in your target language and your source language in a single file), we recommend reading them into a pandas dataframe. Thankfully, Jade wrote a silly `tmx2dataframe` package which converts your tmx file to a pandas dataframe. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oGRmDELn7Az0",
        "outputId": "67ba102c-b196-4142-a98f-26493403ebaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Cn3tgQLzUxwn",
        "colab": {}
      },
      "source": [
        "# TODO: Set your source and target languages. Keep in mind, these traditionally use language codes as found here:\n",
        "# These will also become the suffix's of all vocab and corpus files used throughout\n",
        "import os\n",
        "source_language = \"en\"\n",
        "target_language = \"iso\" \n",
        "lc = False  # If True, lowercase the data.\n",
        "seed = 42  # Random seed for shuffling.\n",
        "tag = \"baseline\" # Give a unique name to your folder - this is to ensure you don't rewrite any models you've already submitted\n",
        "\n",
        "os.environ[\"src\"] = source_language # Sets them in bash as well, since we often use bash scripts\n",
        "os.environ[\"tgt\"] = target_language\n",
        "os.environ[\"tag\"] = tag\n",
        "\n",
        "# This will save it to a folder in our gdrive instead!\n",
        "!mkdir -p \"/content/drive/My Drive/masakhane/$src-$tgt-$tag\"\n",
        "os.environ[\"gdrive_path\"] = \"/content/drive/My Drive/masakhane/%s-%s-%s\" % (source_language, target_language, tag)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kBSgJHEw7Nvx",
        "outputId": "11f957be-66db-4077-9fe6-e21cf6d63315",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!echo $gdrive_path"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/masakhane/en-iso-baseline\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gA75Fs9ys8Y9",
        "outputId": "85f1a7de-5ab8-45b9-cdb0-9ae3199df91b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# Install opus-tools\n",
        "! pip install opustools-pkg"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting opustools-pkg\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/9f/e829a0cceccc603450cd18e1ff80807b6237a88d9a8df2c0bb320796e900/opustools_pkg-0.0.52-py3-none-any.whl (80kB)\n",
            "\r\u001b[K     |████                            | 10kB 23.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 30kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 61kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 71kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 2.5MB/s \n",
            "\u001b[?25hInstalling collected packages: opustools-pkg\n",
            "Successfully installed opustools-pkg-0.0.52\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xq-tDZVks7ZD",
        "outputId": "9d17c9e1-b6a7-43f4-ee1e-3ea9a8559c27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Downloading our corpus\n",
        "! opus_read -d JW300 -s $src -t $tgt -wm moses -w jw300.$src jw300.$tgt -q\n",
        "\n",
        "# extract the corpus file\n",
        "! gunzip JW300_latest_xml_$src-$tgt.xml.gz"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Alignment file /proj/nlpl/data/OPUS/JW300/latest/xml/en-iso.xml.gz not found. The following files are available for downloading:\n",
            "\n",
            "   2 MB https://object.pouta.csc.fi/OPUS-JW300/v1/xml/en-iso.xml.gz\n",
            " 263 MB https://object.pouta.csc.fi/OPUS-JW300/v1/xml/en.zip\n",
            "  26 MB https://object.pouta.csc.fi/OPUS-JW300/v1/xml/iso.zip\n",
            "\n",
            " 291 MB Total size\n",
            "./JW300_latest_xml_en-iso.xml.gz ... 100% of 2 MB\n",
            "./JW300_latest_xml_en.zip ... 100% of 263 MB\n",
            "./JW300_latest_xml_iso.zip ... 100% of 26 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n48GDRnP8y2G",
        "colab_type": "code",
        "outputId": "8949fb1b-854c-4644-a03c-43fdb68dbc42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "source": [
        "# Download the global test set.\n",
        "! wget https://raw.githubusercontent.com/juliakreutzer/masakhane/master/jw300_utils/test/test.en-any.en\n",
        "  \n",
        "# And the specific test set for this language pair.\n",
        "os.environ[\"trg\"] = target_language \n",
        "os.environ[\"src\"] = source_language \n",
        "\n",
        "! wget https://raw.githubusercontent.com/juliakreutzer/masakhane/master/jw300_utils/test/test.en-$trg.en \n",
        "! mv test.en-$trg.en test.en\n",
        "! wget https://raw.githubusercontent.com/juliakreutzer/masakhane/master/jw300_utils/test/test.en-$trg.$trg \n",
        "! mv test.en-$trg.$trg test.$trg"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-17 04:59:50--  https://raw.githubusercontent.com/juliakreutzer/masakhane/master/jw300_utils/test/test.en-any.en\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 277791 (271K) [text/plain]\n",
            "Saving to: ‘test.en-any.en’\n",
            "\n",
            "\rtest.en-any.en        0%[                    ]       0  --.-KB/s               \rtest.en-any.en      100%[===================>] 271.28K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2020-01-17 04:59:51 (5.15 MB/s) - ‘test.en-any.en’ saved [277791/277791]\n",
            "\n",
            "--2020-01-17 04:59:52--  https://raw.githubusercontent.com/juliakreutzer/masakhane/master/jw300_utils/test/test.en-iso.en\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 205488 (201K) [text/plain]\n",
            "Saving to: ‘test.en-iso.en’\n",
            "\n",
            "test.en-iso.en      100%[===================>] 200.67K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2020-01-17 04:59:52 (5.30 MB/s) - ‘test.en-iso.en’ saved [205488/205488]\n",
            "\n",
            "--2020-01-17 04:59:54--  https://raw.githubusercontent.com/juliakreutzer/masakhane/master/jw300_utils/test/test.en-iso.iso\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 251918 (246K) [text/plain]\n",
            "Saving to: ‘test.en-iso.iso’\n",
            "\n",
            "test.en-iso.iso     100%[===================>] 246.01K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2020-01-17 04:59:55 (4.68 MB/s) - ‘test.en-iso.iso’ saved [251918/251918]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqDG-CI28y2L",
        "colab_type": "code",
        "outputId": "44ef9271-b0fc-418d-dc5f-04c90e4e38cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Read the test data to filter from train and dev splits.\n",
        "# Store english portion in set for quick filtering checks.\n",
        "en_test_sents = set()\n",
        "filter_test_sents = \"test.en-any.en\"\n",
        "j = 0\n",
        "with open(filter_test_sents) as f:\n",
        "  for line in f:\n",
        "    en_test_sents.add(line.strip())\n",
        "    j += 1\n",
        "print('Loaded {} global test sentences to filter from the training/dev data.'.format(j))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded 3571 global test sentences to filter from the training/dev data.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3CNdwLBCfSIl",
        "outputId": "fcf09810-26de-481b-8ba0-39853c4378b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# TMX file to dataframe\n",
        "source_file = 'jw300.' + source_language\n",
        "target_file = 'jw300.' + target_language\n",
        "\n",
        "source = []\n",
        "target = []\n",
        "skip_lines = []  # Collect the line numbers of the source portion to skip the same lines for the target portion.\n",
        "with open(source_file) as f:\n",
        "    for i, line in enumerate(f):\n",
        "        # Skip sentences that are contained in the test set.\n",
        "        if line.strip() not in en_test_sents:\n",
        "            source.append(line.strip())\n",
        "        else:\n",
        "            skip_lines.append(i)             \n",
        "with open(target_file) as f:\n",
        "    for j, line in enumerate(f):\n",
        "        # Only add to corpus if corresponding source was not skipped.\n",
        "        if j not in skip_lines:\n",
        "            target.append(line.strip())\n",
        "    \n",
        "print('Loaded data and skipped {}/{} lines since contained in test set.'.format(len(skip_lines), i))\n",
        "    \n",
        "df = pd.DataFrame(zip(source, target), columns=['source_sentence', 'target_sentence'])\n",
        "# if you get TypeError: data argument can't be an iterator is because of your zip version run this below\n",
        "#df = pd.DataFrame(list(zip(source, target)), columns=['source_sentence', 'target_sentence'])\n",
        "df.head(3)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded data and skipped 5685/243487 lines since contained in test set.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source_sentence</th>\n",
              "      <th>target_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>“ Only One of the Many Lives That You Touched ”</td>\n",
              "      <td>“ Omọvo Ahwo Buobu nọ Who Duobọ te Uzuazọ Riẹ ”</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BACK in January 1996 , Carol was sick with a b...</td>\n",
              "      <td>EVAỌ January 1996 , Carol ọ jẹ mọ ẹyao ẹvori .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>She was in her 60 ’ s and until then had alway...</td>\n",
              "      <td>Ọ kpako te ikpe 60 no yọ oke yena kpobi ọ jọ a...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     source_sentence                                    target_sentence\n",
              "0    “ Only One of the Many Lives That You Touched ”    “ Omọvo Ahwo Buobu nọ Who Duobọ te Uzuazọ Riẹ ”\n",
              "1  BACK in January 1996 , Carol was sick with a b...     EVAỌ January 1996 , Carol ọ jẹ mọ ẹyao ẹvori .\n",
              "2  She was in her 60 ’ s and until then had alway...  Ọ kpako te ikpe 60 no yọ oke yena kpobi ọ jọ a..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YkuK3B4p2AkN"
      },
      "source": [
        "## Pre-processing and export\n",
        "\n",
        "It is generally a good idea to remove duplicate translations and conflicting translations from the corpus. In practice, these public corpora include some number of these that need to be cleaned.\n",
        "\n",
        "In addition we will split our data into dev/test/train and export to the filesystem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "M_2ouEOH1_1q",
        "outputId": "b109ef42-7557-4c8c-8952-874ac33ed667",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# drop duplicate translations\n",
        "df_pp = df.drop_duplicates()\n",
        "\n",
        "# drop conflicting translations\n",
        "# (this is optional and something that you might want to comment out \n",
        "# depending on the size of your corpus)\n",
        "df_pp.drop_duplicates(subset='source_sentence', inplace=True)\n",
        "df_pp.drop_duplicates(subset='target_sentence', inplace=True)\n",
        "\n",
        "# Shuffle the data to remove bias in dev set selection.\n",
        "df_pp = df_pp.sample(frac=1, random_state=seed).reset_index(drop=True)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_1BwAApEtMk",
        "colab_type": "code",
        "outputId": "175b8c38-2c43-47f7-bccc-0cffe0336959",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Install fuzzy wuzzy to remove \"almost duplicate\" sentences in the\n",
        "# test and training sets.\n",
        "! pip install fuzzywuzzy\n",
        "! pip install python-Levenshtein\n",
        "import time\n",
        "from fuzzywuzzy import process\n",
        "import numpy as np\n",
        "\n",
        "# reset the index of the training set after previous filtering\n",
        "df_pp.reset_index(drop=False, inplace=True)\n",
        "\n",
        "# Remove samples from the training data set if they \"almost overlap\" with the\n",
        "# samples in the test set.\n",
        "\n",
        "# Filtering function. Adjust pad to narrow down the candidate matches to\n",
        "# within a certain length of characters of the given sample.\n",
        "def fuzzfilter(sample, candidates, pad):\n",
        "  candidates = [x for x in candidates if len(x) <= len(sample)+pad and len(x) >= len(sample)-pad] \n",
        "  if len(candidates) > 0:\n",
        "    return process.extractOne(sample, candidates)[1]\n",
        "  else:\n",
        "    return np.nan\n",
        "\n",
        "# NOTE - This might run slow depending on the size of your training set. We are\n",
        "# printing some information to help you track how long it would take. \n",
        "scores = []\n",
        "start_time = time.time()\n",
        "for idx, row in df_pp.iterrows():\n",
        "  scores.append(fuzzfilter(row['source_sentence'], list(en_test_sents), 5))\n",
        "  if idx % 1000 == 0:\n",
        "    hours, rem = divmod(time.time() - start_time, 3600)\n",
        "    minutes, seconds = divmod(rem, 60)\n",
        "    print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds), \"%0.2f percent complete\" % (100.0*float(idx)/float(len(df_pp))))\n",
        "\n",
        "# Filter out \"almost overlapping samples\"\n",
        "df_pp['scores'] = scores\n",
        "df_pp = df_pp[df_pp['scores'] < 95]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fuzzywuzzy\n",
            "  Downloading https://files.pythonhosted.org/packages/d8/f1/5a267addb30ab7eaa1beab2b9323073815da4551076554ecc890a3595ec9/fuzzywuzzy-0.17.0-py2.py3-none-any.whl\n",
            "Installing collected packages: fuzzywuzzy\n",
            "Successfully installed fuzzywuzzy-0.17.0\n",
            "Collecting python-Levenshtein\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/a9/d1785c85ebf9b7dfacd08938dd028209c34a0ea3b1bcdb895208bd40a67d/python-Levenshtein-0.12.0.tar.gz (48kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 1.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from python-Levenshtein) (42.0.2)\n",
            "Building wheels for collected packages: python-Levenshtein\n",
            "  Building wheel for python-Levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-Levenshtein: filename=python_Levenshtein-0.12.0-cp36-cp36m-linux_x86_64.whl size=144672 sha256=27cc679925e9ea7d499147fe08f2564ad8e4295a570a1a075b46139a669d35bc\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/c2/93/660fd5f7559049268ad2dc6d81c4e39e9e36518766eaf7e342\n",
            "Successfully built python-Levenshtein\n",
            "Installing collected packages: python-Levenshtein\n",
            "Successfully installed python-Levenshtein-0.12.0\n",
            "00:00:00.10 0.00 percent complete\n",
            "00:00:23.78 0.46 percent complete\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '']\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "00:00:47.40 0.92 percent complete\n",
            "00:01:10.57 1.39 percent complete\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '*']\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "00:01:33.67 1.85 percent complete\n",
            "00:01:56.94 2.31 percent complete\n",
            "00:02:20.72 2.77 percent complete\n",
            "00:02:43.97 3.23 percent complete\n",
            "00:03:07.38 3.70 percent complete\n",
            "00:03:31.62 4.16 percent complete\n",
            "00:03:56.02 4.62 percent complete\n",
            "00:04:19.06 5.08 percent complete\n",
            "00:04:42.39 5.54 percent complete\n",
            "00:05:06.25 6.00 percent complete\n",
            "00:05:30.46 6.47 percent complete\n",
            "00:05:53.63 6.93 percent complete\n",
            "00:06:17.23 7.39 percent complete\n",
            "00:06:41.67 7.85 percent complete\n",
            "00:07:05.22 8.31 percent complete\n",
            "00:07:29.08 8.78 percent complete\n",
            "00:07:52.78 9.24 percent complete\n",
            "00:08:16.19 9.70 percent complete\n",
            "00:08:39.44 10.16 percent complete\n",
            "00:09:03.31 10.62 percent complete\n",
            "00:09:26.40 11.09 percent complete\n",
            "00:09:51.25 11.55 percent complete\n",
            "00:10:15.14 12.01 percent complete\n",
            "00:10:38.52 12.47 percent complete\n",
            "00:11:02.41 12.93 percent complete\n",
            "00:11:26.41 13.40 percent complete\n",
            "00:11:50.05 13.86 percent complete\n",
            "00:12:13.38 14.32 percent complete\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '․ ․ ․ ․ ․']\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "00:12:37.46 14.78 percent complete\n",
            "00:13:01.81 15.24 percent complete\n",
            "00:13:25.69 15.70 percent complete\n",
            "00:13:49.63 16.17 percent complete\n",
            "00:14:13.48 16.63 percent complete\n",
            "00:14:37.29 17.09 percent complete\n",
            "00:15:01.50 17.55 percent complete\n",
            "00:15:25.57 18.01 percent complete\n",
            "00:15:49.18 18.48 percent complete\n",
            "00:16:13.51 18.94 percent complete\n",
            "00:16:37.01 19.40 percent complete\n",
            "00:17:00.10 19.86 percent complete\n",
            "00:17:23.41 20.32 percent complete\n",
            "00:17:47.00 20.79 percent complete\n",
            "00:18:10.96 21.25 percent complete\n",
            "00:18:34.67 21.71 percent complete\n",
            "00:18:59.32 22.17 percent complete\n",
            "00:19:23.61 22.63 percent complete\n",
            "00:19:47.81 23.10 percent complete\n",
            "00:20:12.35 23.56 percent complete\n",
            "00:20:36.05 24.02 percent complete\n",
            "00:20:59.50 24.48 percent complete\n",
            "00:21:23.22 24.94 percent complete\n",
            "00:21:47.62 25.40 percent complete\n",
            "00:22:11.51 25.87 percent complete\n",
            "00:22:35.28 26.33 percent complete\n",
            "00:22:58.71 26.79 percent complete\n",
            "00:23:22.48 27.25 percent complete\n",
            "00:23:46.81 27.71 percent complete\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '․ ․ ․ ․ ․ ․ ․ ․']\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "00:24:10.94 28.18 percent complete\n",
            "00:24:34.16 28.64 percent complete\n",
            "00:24:58.34 29.10 percent complete\n",
            "00:25:22.14 29.56 percent complete\n",
            "00:25:46.52 30.02 percent complete\n",
            "00:26:09.90 30.49 percent complete\n",
            "00:26:34.10 30.95 percent complete\n",
            "00:26:58.06 31.41 percent complete\n",
            "00:27:21.26 31.87 percent complete\n",
            "00:27:45.50 32.33 percent complete\n",
            "00:28:09.00 32.79 percent complete\n",
            "00:28:32.87 33.26 percent complete\n",
            "00:28:57.11 33.72 percent complete\n",
            "00:29:21.37 34.18 percent complete\n",
            "00:29:45.41 34.64 percent complete\n",
            "00:30:08.93 35.10 percent complete\n",
            "00:30:32.97 35.57 percent complete\n",
            "00:30:56.46 36.03 percent complete\n",
            "00:31:19.93 36.49 percent complete\n",
            "00:31:44.33 36.95 percent complete\n",
            "00:32:07.88 37.41 percent complete\n",
            "00:32:32.08 37.88 percent complete\n",
            "00:32:56.34 38.34 percent complete\n",
            "00:33:20.79 38.80 percent complete\n",
            "00:33:44.59 39.26 percent complete\n",
            "00:34:08.98 39.72 percent complete\n",
            "00:34:32.93 40.19 percent complete\n",
            "00:34:56.72 40.65 percent complete\n",
            "00:35:21.12 41.11 percent complete\n",
            "00:35:45.38 41.57 percent complete\n",
            "00:36:09.10 42.03 percent complete\n",
            "00:36:33.30 42.49 percent complete\n",
            "00:36:57.68 42.96 percent complete\n",
            "00:37:21.90 43.42 percent complete\n",
            "00:37:45.21 43.88 percent complete\n",
            "00:38:09.01 44.34 percent complete\n",
            "00:38:33.14 44.80 percent complete\n",
            "00:38:57.65 45.27 percent complete\n",
            "00:39:21.34 45.73 percent complete\n",
            "00:39:45.27 46.19 percent complete\n",
            "00:40:09.16 46.65 percent complete\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '․ ․']\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "00:40:32.51 47.11 percent complete\n",
            "00:40:56.64 47.58 percent complete\n",
            "00:41:20.36 48.04 percent complete\n",
            "00:41:44.61 48.50 percent complete\n",
            "00:42:08.32 48.96 percent complete\n",
            "00:42:31.93 49.42 percent complete\n",
            "00:42:56.28 49.89 percent complete\n",
            "00:43:20.24 50.35 percent complete\n",
            "00:43:44.62 50.81 percent complete\n",
            "00:44:08.91 51.27 percent complete\n",
            "00:44:32.54 51.73 percent complete\n",
            "00:44:56.09 52.19 percent complete\n",
            "00:45:20.95 52.66 percent complete\n",
            "00:45:44.71 53.12 percent complete\n",
            "00:46:08.30 53.58 percent complete\n",
            "00:46:32.61 54.04 percent complete\n",
            "00:46:56.86 54.50 percent complete\n",
            "00:47:20.82 54.97 percent complete\n",
            "00:47:44.99 55.43 percent complete\n",
            "00:48:08.38 55.89 percent complete\n",
            "00:48:32.48 56.35 percent complete\n",
            "00:48:56.67 56.81 percent complete\n",
            "00:49:20.35 57.28 percent complete\n",
            "00:49:44.61 57.74 percent complete\n",
            "00:50:08.07 58.20 percent complete\n",
            "00:50:32.40 58.66 percent complete\n",
            "00:50:56.51 59.12 percent complete\n",
            "00:51:20.65 59.59 percent complete\n",
            "00:51:44.56 60.05 percent complete\n",
            "00:52:08.95 60.51 percent complete\n",
            "00:52:32.77 60.97 percent complete\n",
            "00:52:56.32 61.43 percent complete\n",
            "00:53:20.96 61.89 percent complete\n",
            "00:53:45.01 62.36 percent complete\n",
            "00:54:08.62 62.82 percent complete\n",
            "00:54:32.80 63.28 percent complete\n",
            "00:54:56.52 63.74 percent complete\n",
            "00:55:20.42 64.20 percent complete\n",
            "00:55:44.48 64.67 percent complete\n",
            "00:56:08.38 65.13 percent complete\n",
            "00:56:32.50 65.59 percent complete\n",
            "00:56:56.41 66.05 percent complete\n",
            "00:57:20.00 66.51 percent complete\n",
            "00:57:43.52 66.98 percent complete\n",
            "00:58:07.51 67.44 percent complete\n",
            "00:58:31.43 67.90 percent complete\n",
            "00:58:55.35 68.36 percent complete\n",
            "00:59:19.06 68.82 percent complete\n",
            "00:59:42.85 69.29 percent complete\n",
            "01:00:07.00 69.75 percent complete\n",
            "01:00:30.53 70.21 percent complete\n",
            "01:00:54.45 70.67 percent complete\n",
            "01:01:18.35 71.13 percent complete\n",
            "01:01:42.37 71.59 percent complete\n",
            "01:02:06.05 72.06 percent complete\n",
            "01:02:29.54 72.52 percent complete\n",
            "01:02:53.79 72.98 percent complete\n",
            "01:03:17.95 73.44 percent complete\n",
            "01:03:41.78 73.90 percent complete\n",
            "01:04:05.36 74.37 percent complete\n",
            "01:04:29.49 74.83 percent complete\n",
            "01:04:54.40 75.29 percent complete\n",
            "01:05:18.19 75.75 percent complete\n",
            "01:05:41.97 76.21 percent complete\n",
            "01:06:05.42 76.68 percent complete\n",
            "01:06:29.65 77.14 percent complete\n",
            "01:06:53.24 77.60 percent complete\n",
            "01:07:16.62 78.06 percent complete\n",
            "01:07:40.89 78.52 percent complete\n",
            "01:08:05.22 78.98 percent complete\n",
            "01:08:28.49 79.45 percent complete\n",
            "01:08:52.56 79.91 percent complete\n",
            "01:09:16.44 80.37 percent complete\n",
            "01:09:40.34 80.83 percent complete\n",
            "01:10:04.15 81.29 percent complete\n",
            "01:10:28.28 81.76 percent complete\n",
            "01:10:51.83 82.22 percent complete\n",
            "01:11:15.87 82.68 percent complete\n",
            "01:11:39.95 83.14 percent complete\n",
            "01:12:03.72 83.60 percent complete\n",
            "01:12:26.92 84.07 percent complete\n",
            "01:12:51.37 84.53 percent complete\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '⇩']\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "01:13:15.72 84.99 percent complete\n",
            "01:13:39.67 85.45 percent complete\n",
            "01:14:03.39 85.91 percent complete\n",
            "01:14:27.32 86.38 percent complete\n",
            "01:14:51.76 86.84 percent complete\n",
            "01:15:15.58 87.30 percent complete\n",
            "01:15:39.33 87.76 percent complete\n",
            "01:16:03.85 88.22 percent complete\n",
            "01:16:27.71 88.68 percent complete\n",
            "01:16:51.58 89.15 percent complete\n",
            "01:17:15.41 89.61 percent complete\n",
            "01:17:39.83 90.07 percent complete\n",
            "01:18:04.13 90.53 percent complete\n",
            "01:18:28.67 90.99 percent complete\n",
            "01:18:53.01 91.46 percent complete\n",
            "01:19:16.73 91.92 percent complete\n",
            "01:19:41.87 92.38 percent complete\n",
            "01:20:05.67 92.84 percent complete\n",
            "01:20:29.44 93.30 percent complete\n",
            "01:20:53.86 93.77 percent complete\n",
            "01:21:18.33 94.23 percent complete\n",
            "01:21:42.36 94.69 percent complete\n",
            "01:22:06.26 95.15 percent complete\n",
            "01:22:29.82 95.61 percent complete\n",
            "01:22:53.83 96.08 percent complete\n",
            "01:23:17.51 96.54 percent complete\n",
            "01:23:41.70 97.00 percent complete\n",
            "01:24:05.69 97.46 percent complete\n",
            "01:24:30.08 97.92 percent complete\n",
            "01:24:53.94 98.38 percent complete\n",
            "01:25:17.57 98.85 percent complete\n",
            "01:25:41.43 99.31 percent complete\n",
            "01:26:05.41 99.77 percent complete\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hxxBOCA-xXhy",
        "outputId": "c1d5d941-1524-480d-9371-b2abd5a19d0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        }
      },
      "source": [
        "# This section does the split between train/dev for the parallel corpora then saves them as separate files\n",
        "# We use 1000 dev test and the given test set.\n",
        "import csv\n",
        "\n",
        "# Do the split between dev/train and create parallel corpora\n",
        "num_dev_patterns = 1000\n",
        "\n",
        "# Optional: lower case the corpora - this will make it easier to generalize, but without proper casing.\n",
        "if lc:  # Julia: making lowercasing optional\n",
        "    df_pp[\"source_sentence\"] = df_pp[\"source_sentence\"].str.lower()\n",
        "    df_pp[\"target_sentence\"] = df_pp[\"target_sentence\"].str.lower()\n",
        "\n",
        "# Julia: test sets are already generated\n",
        "dev = df_pp.tail(num_dev_patterns) # Herman: Error in original\n",
        "stripped = df_pp.drop(df_pp.tail(num_dev_patterns).index)\n",
        "\n",
        "with open(\"train.\"+source_language, \"w\") as src_file, open(\"train.\"+target_language, \"w\") as trg_file:\n",
        "  for index, row in stripped.iterrows():\n",
        "    src_file.write(row[\"source_sentence\"]+\"\\n\")\n",
        "    trg_file.write(row[\"target_sentence\"]+\"\\n\")\n",
        "    \n",
        "with open(\"dev.\"+source_language, \"w\") as src_file, open(\"dev.\"+target_language, \"w\") as trg_file:\n",
        "  for index, row in dev.iterrows():\n",
        "    src_file.write(row[\"source_sentence\"]+\"\\n\")\n",
        "    trg_file.write(row[\"target_sentence\"]+\"\\n\")\n",
        "\n",
        "#stripped[[\"source_sentence\"]].to_csv(\"train.\"+source_language, header=False, index=False)  # Herman: Added `header=False` everywhere\n",
        "#stripped[[\"target_sentence\"]].to_csv(\"train.\"+target_language, header=False, index=False)  # Julia: Problematic handling of quotation marks.\n",
        "\n",
        "#dev[[\"source_sentence\"]].to_csv(\"dev.\"+source_language, header=False, index=False)\n",
        "#dev[[\"target_sentence\"]].to_csv(\"dev.\"+target_language, header=False, index=False)\n",
        "\n",
        "# Doublecheck the format below. There should be no extra quotation marks or weird characters.\n",
        "! head train.*\n",
        "! head dev.*"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==> train.en <==\n",
            "Now in his 80 ’ s , John admits that at times he feels despondent .\n",
            "The Bible exhorts us to “ speak consolingly to the depressed souls , support the weak . ”\n",
            "Those words of 17th - century British historian Edward Herbert underscore one reason why we need to be forgiving toward others : Sooner or later , we may need to ask others to forgive us .\n",
            "So why not prove to yourself that what you have been taught from the Bible is indeed the truth ?\n",
            "Father , glorify your name . ’\n",
            "God’s Word foretold this development , saying : “ There will be a period of time when they [ people professing to serve God ] will not put up with the healthful teaching , but , in accord with their own desires , they will accumulate teachers for themselves to have their ears tickled . ”\n",
            "We get water from a well at the police station .\n",
            "Do we courageously identify ourselves as Jehovah’s Witnesses , even though doing so may mean persecution ?\n",
            "Tatiana , a full - time evangelizer in Kamchatka , a Russian peninsula located northeast of Japan , began saving for the trip a year in advance .\n",
            "Since 1939 , the cover of each issue of The Watchtower magazine has displayed the words “ Announcing Jehovah’s Kingdom . ”\n",
            "\n",
            "==> train.iso <==\n",
            "Enẹna Jọn ọ kpako te ikpe udhone gbọ no , ọ ta nọ ẹsejọ ọ be hai wo elọhoma .\n",
            "Ebaibol na e ta udu họ omai awọ nnọ “ wha ta udu họ enọ udu u re bro awọ , wha fiobọhọ kẹ enọ e ko . ”\n",
            "Eme yena nọ ogbiku yena ọ ta anwọ ikpe udhusoi akwa ane ( 400 ) nọ i kpemu na , i dhesẹ epanọ u wuzou te re ma rọ vrẹ amọfa , keme ma te siọ amọfa ba eruthọ ẹdẹjọ họ , nọ o te gwọlọ nọ a rọ vrẹ omai .\n",
            "Kiẹ kẹ oma ra re u mu owhẹ ẹro inọ eware nọ a wuhrẹ owhẹ no Ebaibol ze na ginọ uzẹme .\n",
            "Koyehọ uru jọ u te no eva ehru ze nọ , ‘ Mẹ kẹ riẹ oro uno , mẹ jẹ te wariẹ kẹ e oro . ’\n",
            "A jọ Ebaibol ruẹaro kpahe onana , inọ : “ Oke o be tha nọ ahwo [ enọ i se oma rai eg’Ọghẹnẹ ] a rẹ te rehọ uwuhrẹ nọ o gbunu hu , [ rekọ ] ezọ e rẹ te sae okpọ a ve ti koko iwuhrẹ nọ i re ti wuhrẹ ai onọ a guọlọ . ”\n",
            "Ozae nọ o rrọ ogba iporisi ma re kpohọ jo vo ame .\n",
            "Kọ ma be hae gbaudu dhesẹ oma wọhọ Isẹri Jihova , o tẹ make rọnọ ere oruo o rẹ sae wha ukpokpoma ze ?\n",
            "Tatiana , ọtausiuwoma oke - kpobi nọ o no Kamchatka ze , ẹwho Russia jọ nọ ọ rrọ ofẹ obọze ẹkpẹlobọ ovatha - ọre ọrọ Japan , o muọ ugho họ ekoko họ kẹ erẹ na ukpe soso taure oke na u te ti te .\n",
            "Anwọ ukpe 1939 ze , uzoẹme nọ o rrọ uke emagazini Uwou - Eroro Na họ “ Uwou - Eroro Na Nọ U Bi Whowho Uvie Jihova . ”\n",
            "==> dev.en <==\n",
            "We can even ask God to ‘ create in us a pure heart . ’\n",
            "This was followed by Kingdom News No .\n",
            "In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "Still , words of apology are a strong force toward making peace .\n",
            "Elijah brings the boy down to his mother and says : “ See , your son is alive . ”\n",
            "By means of his ministry , he gave a priceless gift to humankind ​ — a message that revealed the truth about God and His will .\n",
            "Comparably , Christian husbands assign their mates honor and praise them .\n",
            "How do we feel about all those who are making sacrifices for the Kingdom , and what should all of us consider ?\n",
            "Jesus too is a shepherd and a conquering king .\n",
            "These examples clearly establish that those who truly belong to Jehovah must firmly take their stand for righteousness and against wickedness .\n",
            "\n",
            "==> dev.iso <==\n",
            "Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "Elaeja ọ tẹ rehọ ọmọ na se oni riẹ jẹ ta nọ : “ Ri , ọmọ ra ọ zọe ” no .\n",
            "Ọ rehọ ẹkwoma odibọgba riẹ kẹ ahwo - akpọ okẹ jọ nọ o ghare thesiwa — ovuẹ nọ u dhesẹ uzẹme na via kpahe Ọghẹnẹ gbe oreva riẹ .\n",
            "Epọvo na re , ezae Ileleikristi a re tete eyae rai je jiri ai .\n",
            "Ẹvẹ u fo nọ ma re rri inievo nọ i bi si obọ no eware jọ re a sae rọ iruo Uvie na karo , kọ eme u fo nọ mai omomọvo o re ru ?\n",
            "Jesu omariẹ yọ othuru - igodẹ gbe ovie nọ o bi fi kparobọ .\n",
            "Iriruo nana i dhesẹ vevẹ nọ enọ e ginẹ rrọ erọ Jihova a rẹ gbaemu nọ a re ru eware nọ i dhesẹ nọ a kiẹrẹe je mukpahe oware uyoma .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "epeCydmCyS8X"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Installation of JoeyNMT\n",
        "\n",
        "JoeyNMT is a simple, minimalist NMT package which is useful for learning and teaching. Check out the documentation for JoeyNMT [here](https://joeynmt.readthedocs.io)  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iBRMm4kMxZ8L",
        "outputId": "788da3f0-8eba-4575-8ceb-0d8e0b73b08e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Install JoeyNMT\n",
        "! git clone https://github.com/joeynmt/joeynmt.git\n",
        "! cd joeynmt; pip3 install ."
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'joeynmt'...\n",
            "remote: Enumerating objects: 20, done.\u001b[K\n",
            "remote: Counting objects:   5% (1/20)\u001b[K\rremote: Counting objects:  10% (2/20)\u001b[K\rremote: Counting objects:  15% (3/20)\u001b[K\rremote: Counting objects:  20% (4/20)\u001b[K\rremote: Counting objects:  25% (5/20)\u001b[K\rremote: Counting objects:  30% (6/20)\u001b[K\rremote: Counting objects:  35% (7/20)\u001b[K\rremote: Counting objects:  40% (8/20)\u001b[K\rremote: Counting objects:  45% (9/20)\u001b[K\rremote: Counting objects:  50% (10/20)\u001b[K\rremote: Counting objects:  55% (11/20)\u001b[K\rremote: Counting objects:  60% (12/20)\u001b[K\rremote: Counting objects:  65% (13/20)\u001b[K\rremote: Counting objects:  70% (14/20)\u001b[K\rremote: Counting objects:  75% (15/20)\u001b[K\rremote: Counting objects:  80% (16/20)\u001b[K\rremote: Counting objects:  85% (17/20)\u001b[K\rremote: Counting objects:  90% (18/20)\u001b[K\rremote: Counting objects:  95% (19/20)\u001b[K\rremote: Counting objects: 100% (20/20)\u001b[K\rremote: Counting objects: 100% (20/20), done.\u001b[K\n",
            "remote: Compressing objects:   5% (1/17)\u001b[K\rremote: Compressing objects:  11% (2/17)\u001b[K\rremote: Compressing objects:  17% (3/17)\u001b[K\rremote: Compressing objects:  23% (4/17)\u001b[K\rremote: Compressing objects:  29% (5/17)\u001b[K\rremote: Compressing objects:  35% (6/17)\u001b[K\rremote: Compressing objects:  41% (7/17)\u001b[K\rremote: Compressing objects:  47% (8/17)\u001b[K\rremote: Compressing objects:  52% (9/17)\u001b[K\rremote: Compressing objects:  58% (10/17)\u001b[K\rremote: Compressing objects:  64% (11/17)\u001b[K\rremote: Compressing objects:  70% (12/17)\u001b[K\rremote: Compressing objects:  76% (13/17)\u001b[K\rremote: Compressing objects:  82% (14/17)\u001b[K\rremote: Compressing objects:  88% (15/17)\u001b[K\rremote: Compressing objects:  94% (16/17)\u001b[K\rremote: Compressing objects: 100% (17/17)\u001b[K\rremote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "Receiving objects:   0% (1/2204)   \rReceiving objects:   1% (23/2204)   \rReceiving objects:   2% (45/2204)   \rReceiving objects:   3% (67/2204)   \rReceiving objects:   4% (89/2204)   \rReceiving objects:   5% (111/2204)   \rReceiving objects:   6% (133/2204)   \rReceiving objects:   7% (155/2204)   \rReceiving objects:   8% (177/2204)   \rReceiving objects:   9% (199/2204)   \rReceiving objects:  10% (221/2204)   \rReceiving objects:  11% (243/2204)   \rReceiving objects:  12% (265/2204)   \rReceiving objects:  13% (287/2204)   \rReceiving objects:  14% (309/2204)   \rReceiving objects:  15% (331/2204)   \rReceiving objects:  16% (353/2204)   \rReceiving objects:  17% (375/2204)   \rReceiving objects:  18% (397/2204)   \rReceiving objects:  19% (419/2204)   \rReceiving objects:  20% (441/2204)   \rReceiving objects:  21% (463/2204)   \rReceiving objects:  22% (485/2204)   \rReceiving objects:  23% (507/2204)   \rReceiving objects:  24% (529/2204)   \rReceiving objects:  25% (551/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  26% (574/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  27% (596/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  28% (618/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  29% (640/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  30% (662/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  31% (684/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  32% (706/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  33% (728/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  34% (750/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  35% (772/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  36% (794/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  37% (816/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  38% (838/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  39% (860/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  40% (882/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  41% (904/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  42% (926/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  43% (948/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  44% (970/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  45% (992/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  46% (1014/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  47% (1036/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  48% (1058/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  49% (1080/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  50% (1102/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  51% (1125/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  52% (1147/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  53% (1169/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  54% (1191/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  55% (1213/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  56% (1235/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  57% (1257/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  58% (1279/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  59% (1301/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  60% (1323/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  61% (1345/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  62% (1367/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  63% (1389/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  64% (1411/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  65% (1433/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  66% (1455/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  67% (1477/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  68% (1499/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  69% (1521/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  70% (1543/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  71% (1565/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  72% (1587/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  73% (1609/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  74% (1631/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  75% (1653/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  76% (1676/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  77% (1698/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  78% (1720/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  79% (1742/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  80% (1764/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  81% (1786/2204), 380.01 KiB | 707.00 KiB/s   \rremote: Total 2204 (delta 8), reused 5 (delta 3), pack-reused 2184\u001b[K\n",
            "Receiving objects:  82% (1808/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  83% (1830/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  84% (1852/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  85% (1874/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  86% (1896/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  87% (1918/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  88% (1940/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  89% (1962/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  90% (1984/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  91% (2006/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  92% (2028/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  93% (2050/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  94% (2072/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  95% (2094/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  96% (2116/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  97% (2138/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  98% (2160/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects:  99% (2182/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects: 100% (2204/2204), 380.01 KiB | 707.00 KiB/s   \rReceiving objects: 100% (2204/2204), 2.60 MiB | 2.74 MiB/s, done.\n",
            "Resolving deltas: 100% (1529/1529), done.\n",
            "Processing /content/joeynmt\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from joeynmt==0.0.1) (0.16.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from joeynmt==0.0.1) (6.2.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from joeynmt==0.0.1) (1.17.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from joeynmt==0.0.1) (42.0.2)\n",
            "Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.6/dist-packages (from joeynmt==0.0.1) (1.3.1)\n",
            "Requirement already satisfied: tensorflow>=1.14 in /usr/local/lib/python3.6/dist-packages (from joeynmt==0.0.1) (1.15.0)\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.6/dist-packages (from joeynmt==0.0.1) (0.3.1)\n",
            "Collecting sacrebleu>=1.3.6\n",
            "  Downloading https://files.pythonhosted.org/packages/45/31/1a135b964c169984b27fb2f7a50280fa7f8e6d9d404d8a9e596180487fd1/sacrebleu-1.4.3-py3-none-any.whl\n",
            "Collecting subword-nmt\n",
            "  Downloading https://files.pythonhosted.org/packages/74/60/6600a7bc09e7ab38bc53a48a20d8cae49b837f93f5842a41fe513a694912/subword_nmt-0.3.7-py2.py3-none-any.whl\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from joeynmt==0.0.1) (3.1.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (from joeynmt==0.0.1) (0.9.0)\n",
            "Collecting pyyaml>=5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/d9/ea9816aea31beeadccd03f1f8b625ecf8f645bd66744484d162d84803ce5/PyYAML-5.3.tar.gz (268kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 8.0MB/s \n",
            "\u001b[?25hCollecting pylint\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/59/43fc36c5ee316bb9aeb7cf5329cdbdca89e5749c34d5602753827c0aa2dc/pylint-2.4.4-py3-none-any.whl (302kB)\n",
            "\u001b[K     |████████████████████████████████| 307kB 40.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six==1.12 in /usr/local/lib/python3.6/dist-packages (from joeynmt==0.0.1) (1.12.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (0.9.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (0.8.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (0.33.6)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (0.2.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (3.1.0)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (1.15.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (1.11.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (3.10.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (1.0.8)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (0.1.8)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext->joeynmt==0.0.1) (4.28.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext->joeynmt==0.0.1) (2.21.0)\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from sacrebleu>=1.3.6->joeynmt==0.0.1) (3.6.6)\n",
            "Collecting portalocker\n",
            "  Downloading https://files.pythonhosted.org/packages/91/db/7bc703c0760df726839e0699b7f78a4d8217fdc9c7fcb1b51b39c5a22a4e/portalocker-1.5.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->joeynmt==0.0.1) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->joeynmt==0.0.1) (2.6.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->joeynmt==0.0.1) (2.4.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->joeynmt==0.0.1) (0.10.0)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from seaborn->joeynmt==0.0.1) (1.4.1)\n",
            "Requirement already satisfied: pandas>=0.15.2 in /usr/local/lib/python3.6/dist-packages (from seaborn->joeynmt==0.0.1) (0.25.3)\n",
            "Collecting mccabe<0.7,>=0.6\n",
            "  Downloading https://files.pythonhosted.org/packages/87/89/479dc97e18549e21354893e4ee4ef36db1d237534982482c3681ee6e7b57/mccabe-0.6.1-py2.py3-none-any.whl\n",
            "Collecting astroid<2.4,>=2.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/ae/86734823047962e7b8c8529186a1ac4a7ca19aaf1aa0c7713c022ef593fd/astroid-2.3.3-py3-none-any.whl (205kB)\n",
            "\u001b[K     |████████████████████████████████| 215kB 44.2MB/s \n",
            "\u001b[?25hCollecting isort<5,>=4.2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/b0/c121fd1fa3419ea9bfd55c7f9c4fedfec5143208d8c7ad3ce3db6c623c21/isort-4.3.21-py2.py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow>=1.14->joeynmt==0.0.1) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow>=1.14->joeynmt==0.0.1) (0.16.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow>=1.14->joeynmt==0.0.1) (2.8.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext->joeynmt==0.0.1) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext->joeynmt==0.0.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext->joeynmt==0.0.1) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext->joeynmt==0.0.1) (3.0.4)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.15.2->seaborn->joeynmt==0.0.1) (2018.9)\n",
            "Collecting typed-ast<1.5,>=1.4.0; implementation_name == \"cpython\" and python_version < \"3.8\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/ed/5459080d95eb87a02fe860d447197be63b6e2b5e9ff73c2b0a85622994f4/typed_ast-1.4.1-cp36-cp36m-manylinux1_x86_64.whl (737kB)\n",
            "\u001b[K     |████████████████████████████████| 747kB 37.2MB/s \n",
            "\u001b[?25hCollecting lazy-object-proxy==1.4.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0b/dd/b1e3407e9e6913cf178e506cd0dee818e58694d9a5cd1984e3f6a8b9a10f/lazy_object_proxy-1.4.3-cp36-cp36m-manylinux1_x86_64.whl (55kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 8.4MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: joeynmt, pyyaml\n",
            "  Building wheel for joeynmt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for joeynmt: filename=joeynmt-0.0.1-cp36-none-any.whl size=72136 sha256=b62b0d984f8e513cfbda8cd20ee04da8cf7d1ea8d81c0dd964e15c6343f2e6a5\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-cu8n56e2/wheels/db/01/db/751cc9f3e7f6faec127c43644ba250a3ea7ad200594aeda70a\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyyaml: filename=PyYAML-5.3-cp36-cp36m-linux_x86_64.whl size=44229 sha256=df3dc8e7d9b2acae56116833b1d6b5b2eeb9575fa9acf32fb7bc0a1a032097d8\n",
            "  Stored in directory: /root/.cache/pip/wheels/e4/76/4d/a95b8dd7b452b69e8ed4f68b69e1b55e12c9c9624dd962b191\n",
            "Successfully built joeynmt pyyaml\n",
            "Installing collected packages: portalocker, sacrebleu, subword-nmt, pyyaml, mccabe, typed-ast, lazy-object-proxy, astroid, isort, pylint, joeynmt\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed astroid-2.3.3 isort-4.3.21 joeynmt-0.0.1 lazy-object-proxy-1.4.3 mccabe-0.6.1 portalocker-1.5.2 pylint-2.4.4 pyyaml-5.3 sacrebleu-1.4.3 subword-nmt-0.3.7 typed-ast-1.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AaE77Tcppex9"
      },
      "source": [
        "# Preprocessing the Data into Subword BPE Tokens\n",
        "\n",
        "- One of the most powerful improvements for agglutinative languages (a feature of most Bantu languages) is using BPE tokenization [ (Sennrich, 2015) ](https://arxiv.org/abs/1508.07909).\n",
        "\n",
        "- It was also shown that by optimizing the umber of BPE codes we significantly improve results for low-resourced languages [(Sennrich, 2019)](https://www.aclweb.org/anthology/P19-1021) [(Martinus, 2019)](https://arxiv.org/abs/1906.05685)\n",
        "\n",
        "- Below we have the scripts for doing BPE tokenization of our data. We use 4000 tokens as recommended by [(Sennrich, 2019)](https://www.aclweb.org/anthology/P19-1021). You do not need to change anything. Simply running the below will be suitable. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H-TyjtmXB1mL",
        "outputId": "291628f4-f823-4ead-d7ec-3a887e954089",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "# One of the huge boosts in NMT performance was to use a different method of tokenizing. \n",
        "# Usually, NMT would tokenize by words. However, using a method called BPE gave amazing boosts to performance\n",
        "\n",
        "# Do subword NMT\n",
        "from os import path\n",
        "os.environ[\"src\"] = source_language # Sets them in bash as well, since we often use bash scripts\n",
        "os.environ[\"tgt\"] = target_language\n",
        "\n",
        "# Learn BPEs on the training data.\n",
        "os.environ[\"data_path\"] = path.join(\"joeynmt\", \"data\", source_language + target_language) # Herman! \n",
        "! subword-nmt learn-joint-bpe-and-vocab --input train.$src train.$tgt -s 4000 -o bpe.codes.4000 --write-vocabulary vocab.$src vocab.$tgt\n",
        "\n",
        "# Apply BPE splits to the development and test data.\n",
        "! subword-nmt apply-bpe -c bpe.codes.4000 --vocabulary vocab.$src < train.$src > train.bpe.$src\n",
        "! subword-nmt apply-bpe -c bpe.codes.4000 --vocabulary vocab.$tgt < train.$tgt > train.bpe.$tgt\n",
        "\n",
        "! subword-nmt apply-bpe -c bpe.codes.4000 --vocabulary vocab.$src < dev.$src > dev.bpe.$src\n",
        "! subword-nmt apply-bpe -c bpe.codes.4000 --vocabulary vocab.$tgt < dev.$tgt > dev.bpe.$tgt\n",
        "! subword-nmt apply-bpe -c bpe.codes.4000 --vocabulary vocab.$src < test.$src > test.bpe.$src\n",
        "! subword-nmt apply-bpe -c bpe.codes.4000 --vocabulary vocab.$tgt < test.$tgt > test.bpe.$tgt\n",
        "\n",
        "# Create directory, move everyone we care about to the correct location\n",
        "! mkdir -p $data_path\n",
        "! cp train.* $data_path\n",
        "! cp test.* $data_path\n",
        "! cp dev.* $data_path\n",
        "! cp bpe.codes.4000 $data_path\n",
        "! ls $data_path\n",
        "\n",
        "# Also move everything we care about to a mounted location in google drive (relevant if running in colab) at gdrive_path\n",
        "! cp train.* \"$gdrive_path\"\n",
        "! cp test.* \"$gdrive_path\"\n",
        "! cp dev.* \"$gdrive_path\"\n",
        "! cp bpe.codes.4000 \"$gdrive_path\"\n",
        "! ls \"$gdrive_path\"\n",
        "\n",
        "# Create that vocab using build_vocab\n",
        "! sudo chmod 777 joeynmt/scripts/build_vocab.py\n",
        "! joeynmt/scripts/build_vocab.py joeynmt/data/$src$tgt/train.bpe.$src joeynmt/data/$src$tgt/train.bpe.$tgt --output_path joeynmt/data/$src$tgt/vocab.txt\n",
        "\n",
        "# Some output\n",
        "! echo \"BPE Isoko Sentences\"\n",
        "! tail -n 5 test.bpe.$tgt\n",
        "! echo \"Combined BPE Vocab\"\n",
        "! tail -n 10 joeynmt/data/$src$tgt/vocab.txt  # Herman\n",
        "! cp joeynmt/data/$src$tgt/vocab.txt \"$gdrive_path\""
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bpe.codes.4000\tdev.en\t     test.bpe.iso    test.iso\t    train.en\n",
            "dev.bpe.en\tdev.iso      test.en\t     train.bpe.en   train.iso\n",
            "dev.bpe.iso\ttest.bpe.en  test.en-any.en  train.bpe.iso\n",
            "bpe.codes.4000\tdev.en\t     test.bpe.iso    test.iso\t    train.en\n",
            "dev.bpe.en\tdev.iso      test.en\t     train.bpe.en   train.iso\n",
            "dev.bpe.iso\ttest.bpe.en  test.en-any.en  train.bpe.iso\n",
            "BPE Isoko Sentences\n",
            "Fikieme o rọ gwọlọ nọ H@@ us@@ hai o re wo udu re ọ sae tal@@ amu Ọghẹnẹ ?\n",
            "Fikieme o rọ gwọlọ nọ ma wo udu re ma sai yoẹme kẹ Jihova ?\n",
            "Mẹ tẹ lẹ se Ọghẹnẹ re ọ kẹ omẹ udu nọ me re ro ru lele iroro nọ mẹ jẹ na .\n",
            "Enẹna eva mẹ e gbẹ be d@@ hae he , yọ mẹ sai weze bru ai oke kpobi . ” — Se Itẹ 29 : 25 .\n",
            "[ 1 ] ( edhe - ẹme avọ 7 ) Ma nwene edẹ na jọ .\n",
            "Combined BPE Vocab\n",
            "ş\n",
            "⁄\n",
            "=\n",
            "↓\n",
            "rint\n",
            "nwan@@\n",
            "Ó@@\n",
            "especi@@\n",
            "Prover@@\n",
            "ā\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IlMitUHR8Qy-",
        "outputId": "a1f4e86b-e790-4ad3-bd6f-ebcaaa356a7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Also move everything we care about to a mounted location in google drive (relevant if running in colab) at gdrive_path\n",
        "! cp train.* \"$gdrive_path\"\n",
        "! cp test.* \"$gdrive_path\"\n",
        "! cp dev.* \"$gdrive_path\"\n",
        "! cp bpe.codes.4000 \"$gdrive_path\"\n",
        "! ls \"$gdrive_path\""
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bpe.codes.4000\tdev.en\t     test.bpe.iso    test.iso\t    train.en\n",
            "dev.bpe.en\tdev.iso      test.en\t     train.bpe.en   train.iso\n",
            "dev.bpe.iso\ttest.bpe.en  test.en-any.en  train.bpe.iso  vocab.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ixmzi60WsUZ8"
      },
      "source": [
        "# Creating the JoeyNMT Config\n",
        "\n",
        "JoeyNMT requires a yaml config. We provide a template below. We've also set a number of defaults with it, that you may play with!\n",
        "\n",
        "- We used Transformer architecture \n",
        "- We set our dropout to reasonably high: 0.3 (recommended in  [(Sennrich, 2019)](https://www.aclweb.org/anthology/P19-1021))\n",
        "\n",
        "Things worth playing with:\n",
        "- The batch size (also recommended to change for low-resourced languages)\n",
        "- The number of epochs (we've set it at 30 just so it runs in about an hour, for testing purposes)\n",
        "- The decoder options (beam_size, alpha)\n",
        "- Evaluation metrics (BLEU versus Crhf4)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PIs1lY2hxMsl",
        "colab": {}
      },
      "source": [
        "# This creates the config file for our JoeyNMT system. It might seem overwhelming so we've provided a couple of useful parameters you'll need to update\n",
        "# (You can of course play with all the parameters if you'd like!)\n",
        "\n",
        "name = '%s%s' % (source_language, target_language)\n",
        "gdrive_path = os.environ[\"gdrive_path\"]\n",
        "\n",
        "# Create the config\n",
        "config = \"\"\"\n",
        "name: \"{name}_transformer\"\n",
        "\n",
        "data:\n",
        "    src: \"{source_language}\"\n",
        "    trg: \"{target_language}\"\n",
        "    train: \"{gdrive_path}/train.bpe\"\n",
        "    dev:   \"{gdrive_path}/dev.bpe\"\n",
        "    test:  \"{gdrive_path}/test.bpe\"\n",
        "    level: \"bpe\"\n",
        "    lowercase: False\n",
        "    max_sent_length: 100\n",
        "    src_vocab: \"{gdrive_path}/vocab.txt\"\n",
        "    trg_vocab: \"{gdrive_path}/vocab.txt\"\n",
        "\n",
        "testing:\n",
        "    beam_size: 5\n",
        "    alpha: 1.0\n",
        "\n",
        "training:\n",
        "    # load_model: \"{gdrive_path}/models/{name}_transformer/10000.ckpt\" # if uncommented, load a pre-trained model from this checkpoint\n",
        "    random_seed: 42\n",
        "    optimizer: \"adam\"\n",
        "    normalization: \"tokens\"\n",
        "    adam_betas: [0.9, 0.999] \n",
        "    scheduling: \"plateau\"           # TODO: try switching from plateau to Noam scheduling\n",
        "    patience: 5                     # For plateau: decrease learning rate by decrease_factor if validation score has not improved for this many validation rounds.\n",
        "    learning_rate_factor: 0.5       # factor for Noam scheduler (used with Transformer)\n",
        "    learning_rate_warmup: 1000      # warmup steps for Noam scheduler (used with Transformer)\n",
        "    decrease_factor: 0.7\n",
        "    loss: \"crossentropy\"\n",
        "    learning_rate: 0.0003\n",
        "    learning_rate_min: 0.00000001\n",
        "    weight_decay: 0.0\n",
        "    label_smoothing: 0.1\n",
        "    batch_size: 4096\n",
        "    batch_type: \"token\"\n",
        "    eval_batch_size: 3600\n",
        "    eval_batch_type: \"token\"\n",
        "    batch_multiplier: 1\n",
        "    early_stopping_metric: \"ppl\"\n",
        "    epochs: 30                     # TODO: Decrease for when playing around and checking of working. Around 30 is sufficient to check if its working at all\n",
        "    validation_freq: 1000          # TODO: Set to at least once per epoch.\n",
        "    logging_freq: 100\n",
        "    eval_metric: \"bleu\"\n",
        "    model_dir: \"{gdrive_path}/models/{name}_transformer\"\n",
        "    overwrite: True               # TODO: Set to True if you want to overwrite possibly existing models. \n",
        "    shuffle: True\n",
        "    use_cuda: True\n",
        "    max_output_length: 100\n",
        "    print_valid_sents: [0, 1, 2, 3]\n",
        "    keep_last_ckpts: 3\n",
        "\n",
        "model:\n",
        "    initializer: \"xavier\"\n",
        "    bias_initializer: \"zeros\"\n",
        "    init_gain: 1.0\n",
        "    embed_initializer: \"xavier\"\n",
        "    embed_init_gain: 1.0\n",
        "    tied_embeddings: True\n",
        "    tied_softmax: True\n",
        "    encoder:\n",
        "        type: \"transformer\"\n",
        "        num_layers: 6\n",
        "        num_heads: 4             # TODO: Increase to 8 for larger data.\n",
        "        embeddings:\n",
        "            embedding_dim: 256   # TODO: Increase to 512 for larger data.\n",
        "            scale: True\n",
        "            dropout: 0.2\n",
        "        # typically ff_size = 4 x hidden_size\n",
        "        hidden_size: 256         # TODO: Increase to 512 for larger data.\n",
        "        ff_size: 1024            # TODO: Increase to 2048 for larger data.\n",
        "        dropout: 0.3\n",
        "    decoder:\n",
        "        type: \"transformer\"\n",
        "        num_layers: 6\n",
        "        num_heads: 4              # TODO: Increase to 8 for larger data.\n",
        "        embeddings:\n",
        "            embedding_dim: 256    # TODO: Increase to 512 for larger data.\n",
        "            scale: True\n",
        "            dropout: 0.2\n",
        "        # typically ff_size = 4 x hidden_size\n",
        "        hidden_size: 256         # TODO: Increase to 512 for larger data.\n",
        "        ff_size: 1024            # TODO: Increase to 2048 for larger data.\n",
        "        dropout: 0.3\n",
        "\"\"\".format(name=name, gdrive_path=os.environ[\"gdrive_path\"], source_language=source_language, target_language=target_language)\n",
        "with open(\"joeynmt/configs/transformer_{name}.yaml\".format(name=name),'w') as f:\n",
        "    f.write(config)\n",
        "\n",
        "! cp joeynmt/configs/transformer_$src$tgt.yaml \"$gdrive_path\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pIifxE3Qzuvs"
      },
      "source": [
        "# Train the Model\n",
        "\n",
        "This single line of joeynmt runs the training using the config we made above"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6ZBPFwT94WpI",
        "outputId": "8724f4d5-8427-496d-8576-8edda9d48d0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Train the model\n",
        "# You can press Ctrl-C to stop. And then run the next cell to save your checkpoints! \n",
        "# !cd joeynmt; python3 -m joeynmt train configs/transformer_$src$tgt.yaml\n",
        "!python3 -m joeynmt train \"$gdrive_path/transformer_$src$tgt.yaml\""
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-01-17 06:37:10,903 Hello! This is Joey-NMT.\n",
            "2020-01-17 06:37:12,270 Total params: 12149248\n",
            "2020-01-17 06:37:12,271 Trainable parameters: ['decoder.layer_norm.bias', 'decoder.layer_norm.weight', 'decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'decoder.layers.1.dec_layer_norm.bias', 'decoder.layers.1.dec_layer_norm.weight', 'decoder.layers.1.feed_forward.layer_norm.bias', 'decoder.layers.1.feed_forward.layer_norm.weight', 'decoder.layers.1.feed_forward.pwff_layer.0.bias', 'decoder.layers.1.feed_forward.pwff_layer.0.weight', 'decoder.layers.1.feed_forward.pwff_layer.3.bias', 'decoder.layers.1.feed_forward.pwff_layer.3.weight', 'decoder.layers.1.src_trg_att.k_layer.bias', 'decoder.layers.1.src_trg_att.k_layer.weight', 'decoder.layers.1.src_trg_att.output_layer.bias', 'decoder.layers.1.src_trg_att.output_layer.weight', 'decoder.layers.1.src_trg_att.q_layer.bias', 'decoder.layers.1.src_trg_att.q_layer.weight', 'decoder.layers.1.src_trg_att.v_layer.bias', 'decoder.layers.1.src_trg_att.v_layer.weight', 'decoder.layers.1.trg_trg_att.k_layer.bias', 'decoder.layers.1.trg_trg_att.k_layer.weight', 'decoder.layers.1.trg_trg_att.output_layer.bias', 'decoder.layers.1.trg_trg_att.output_layer.weight', 'decoder.layers.1.trg_trg_att.q_layer.bias', 'decoder.layers.1.trg_trg_att.q_layer.weight', 'decoder.layers.1.trg_trg_att.v_layer.bias', 'decoder.layers.1.trg_trg_att.v_layer.weight', 'decoder.layers.1.x_layer_norm.bias', 'decoder.layers.1.x_layer_norm.weight', 'decoder.layers.2.dec_layer_norm.bias', 'decoder.layers.2.dec_layer_norm.weight', 'decoder.layers.2.feed_forward.layer_norm.bias', 'decoder.layers.2.feed_forward.layer_norm.weight', 'decoder.layers.2.feed_forward.pwff_layer.0.bias', 'decoder.layers.2.feed_forward.pwff_layer.0.weight', 'decoder.layers.2.feed_forward.pwff_layer.3.bias', 'decoder.layers.2.feed_forward.pwff_layer.3.weight', 'decoder.layers.2.src_trg_att.k_layer.bias', 'decoder.layers.2.src_trg_att.k_layer.weight', 'decoder.layers.2.src_trg_att.output_layer.bias', 'decoder.layers.2.src_trg_att.output_layer.weight', 'decoder.layers.2.src_trg_att.q_layer.bias', 'decoder.layers.2.src_trg_att.q_layer.weight', 'decoder.layers.2.src_trg_att.v_layer.bias', 'decoder.layers.2.src_trg_att.v_layer.weight', 'decoder.layers.2.trg_trg_att.k_layer.bias', 'decoder.layers.2.trg_trg_att.k_layer.weight', 'decoder.layers.2.trg_trg_att.output_layer.bias', 'decoder.layers.2.trg_trg_att.output_layer.weight', 'decoder.layers.2.trg_trg_att.q_layer.bias', 'decoder.layers.2.trg_trg_att.q_layer.weight', 'decoder.layers.2.trg_trg_att.v_layer.bias', 'decoder.layers.2.trg_trg_att.v_layer.weight', 'decoder.layers.2.x_layer_norm.bias', 'decoder.layers.2.x_layer_norm.weight', 'decoder.layers.3.dec_layer_norm.bias', 'decoder.layers.3.dec_layer_norm.weight', 'decoder.layers.3.feed_forward.layer_norm.bias', 'decoder.layers.3.feed_forward.layer_norm.weight', 'decoder.layers.3.feed_forward.pwff_layer.0.bias', 'decoder.layers.3.feed_forward.pwff_layer.0.weight', 'decoder.layers.3.feed_forward.pwff_layer.3.bias', 'decoder.layers.3.feed_forward.pwff_layer.3.weight', 'decoder.layers.3.src_trg_att.k_layer.bias', 'decoder.layers.3.src_trg_att.k_layer.weight', 'decoder.layers.3.src_trg_att.output_layer.bias', 'decoder.layers.3.src_trg_att.output_layer.weight', 'decoder.layers.3.src_trg_att.q_layer.bias', 'decoder.layers.3.src_trg_att.q_layer.weight', 'decoder.layers.3.src_trg_att.v_layer.bias', 'decoder.layers.3.src_trg_att.v_layer.weight', 'decoder.layers.3.trg_trg_att.k_layer.bias', 'decoder.layers.3.trg_trg_att.k_layer.weight', 'decoder.layers.3.trg_trg_att.output_layer.bias', 'decoder.layers.3.trg_trg_att.output_layer.weight', 'decoder.layers.3.trg_trg_att.q_layer.bias', 'decoder.layers.3.trg_trg_att.q_layer.weight', 'decoder.layers.3.trg_trg_att.v_layer.bias', 'decoder.layers.3.trg_trg_att.v_layer.weight', 'decoder.layers.3.x_layer_norm.bias', 'decoder.layers.3.x_layer_norm.weight', 'decoder.layers.4.dec_layer_norm.bias', 'decoder.layers.4.dec_layer_norm.weight', 'decoder.layers.4.feed_forward.layer_norm.bias', 'decoder.layers.4.feed_forward.layer_norm.weight', 'decoder.layers.4.feed_forward.pwff_layer.0.bias', 'decoder.layers.4.feed_forward.pwff_layer.0.weight', 'decoder.layers.4.feed_forward.pwff_layer.3.bias', 'decoder.layers.4.feed_forward.pwff_layer.3.weight', 'decoder.layers.4.src_trg_att.k_layer.bias', 'decoder.layers.4.src_trg_att.k_layer.weight', 'decoder.layers.4.src_trg_att.output_layer.bias', 'decoder.layers.4.src_trg_att.output_layer.weight', 'decoder.layers.4.src_trg_att.q_layer.bias', 'decoder.layers.4.src_trg_att.q_layer.weight', 'decoder.layers.4.src_trg_att.v_layer.bias', 'decoder.layers.4.src_trg_att.v_layer.weight', 'decoder.layers.4.trg_trg_att.k_layer.bias', 'decoder.layers.4.trg_trg_att.k_layer.weight', 'decoder.layers.4.trg_trg_att.output_layer.bias', 'decoder.layers.4.trg_trg_att.output_layer.weight', 'decoder.layers.4.trg_trg_att.q_layer.bias', 'decoder.layers.4.trg_trg_att.q_layer.weight', 'decoder.layers.4.trg_trg_att.v_layer.bias', 'decoder.layers.4.trg_trg_att.v_layer.weight', 'decoder.layers.4.x_layer_norm.bias', 'decoder.layers.4.x_layer_norm.weight', 'decoder.layers.5.dec_layer_norm.bias', 'decoder.layers.5.dec_layer_norm.weight', 'decoder.layers.5.feed_forward.layer_norm.bias', 'decoder.layers.5.feed_forward.layer_norm.weight', 'decoder.layers.5.feed_forward.pwff_layer.0.bias', 'decoder.layers.5.feed_forward.pwff_layer.0.weight', 'decoder.layers.5.feed_forward.pwff_layer.3.bias', 'decoder.layers.5.feed_forward.pwff_layer.3.weight', 'decoder.layers.5.src_trg_att.k_layer.bias', 'decoder.layers.5.src_trg_att.k_layer.weight', 'decoder.layers.5.src_trg_att.output_layer.bias', 'decoder.layers.5.src_trg_att.output_layer.weight', 'decoder.layers.5.src_trg_att.q_layer.bias', 'decoder.layers.5.src_trg_att.q_layer.weight', 'decoder.layers.5.src_trg_att.v_layer.bias', 'decoder.layers.5.src_trg_att.v_layer.weight', 'decoder.layers.5.trg_trg_att.k_layer.bias', 'decoder.layers.5.trg_trg_att.k_layer.weight', 'decoder.layers.5.trg_trg_att.output_layer.bias', 'decoder.layers.5.trg_trg_att.output_layer.weight', 'decoder.layers.5.trg_trg_att.q_layer.bias', 'decoder.layers.5.trg_trg_att.q_layer.weight', 'decoder.layers.5.trg_trg_att.v_layer.bias', 'decoder.layers.5.trg_trg_att.v_layer.weight', 'decoder.layers.5.x_layer_norm.bias', 'decoder.layers.5.x_layer_norm.weight', 'encoder.layer_norm.bias', 'encoder.layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'encoder.layers.3.feed_forward.layer_norm.bias', 'encoder.layers.3.feed_forward.layer_norm.weight', 'encoder.layers.3.feed_forward.pwff_layer.0.bias', 'encoder.layers.3.feed_forward.pwff_layer.0.weight', 'encoder.layers.3.feed_forward.pwff_layer.3.bias', 'encoder.layers.3.feed_forward.pwff_layer.3.weight', 'encoder.layers.3.layer_norm.bias', 'encoder.layers.3.layer_norm.weight', 'encoder.layers.3.src_src_att.k_layer.bias', 'encoder.layers.3.src_src_att.k_layer.weight', 'encoder.layers.3.src_src_att.output_layer.bias', 'encoder.layers.3.src_src_att.output_layer.weight', 'encoder.layers.3.src_src_att.q_layer.bias', 'encoder.layers.3.src_src_att.q_layer.weight', 'encoder.layers.3.src_src_att.v_layer.bias', 'encoder.layers.3.src_src_att.v_layer.weight', 'encoder.layers.4.feed_forward.layer_norm.bias', 'encoder.layers.4.feed_forward.layer_norm.weight', 'encoder.layers.4.feed_forward.pwff_layer.0.bias', 'encoder.layers.4.feed_forward.pwff_layer.0.weight', 'encoder.layers.4.feed_forward.pwff_layer.3.bias', 'encoder.layers.4.feed_forward.pwff_layer.3.weight', 'encoder.layers.4.layer_norm.bias', 'encoder.layers.4.layer_norm.weight', 'encoder.layers.4.src_src_att.k_layer.bias', 'encoder.layers.4.src_src_att.k_layer.weight', 'encoder.layers.4.src_src_att.output_layer.bias', 'encoder.layers.4.src_src_att.output_layer.weight', 'encoder.layers.4.src_src_att.q_layer.bias', 'encoder.layers.4.src_src_att.q_layer.weight', 'encoder.layers.4.src_src_att.v_layer.bias', 'encoder.layers.4.src_src_att.v_layer.weight', 'encoder.layers.5.feed_forward.layer_norm.bias', 'encoder.layers.5.feed_forward.layer_norm.weight', 'encoder.layers.5.feed_forward.pwff_layer.0.bias', 'encoder.layers.5.feed_forward.pwff_layer.0.weight', 'encoder.layers.5.feed_forward.pwff_layer.3.bias', 'encoder.layers.5.feed_forward.pwff_layer.3.weight', 'encoder.layers.5.layer_norm.bias', 'encoder.layers.5.layer_norm.weight', 'encoder.layers.5.src_src_att.k_layer.bias', 'encoder.layers.5.src_src_att.k_layer.weight', 'encoder.layers.5.src_src_att.output_layer.bias', 'encoder.layers.5.src_src_att.output_layer.weight', 'encoder.layers.5.src_src_att.q_layer.bias', 'encoder.layers.5.src_src_att.q_layer.weight', 'encoder.layers.5.src_src_att.v_layer.bias', 'encoder.layers.5.src_src_att.v_layer.weight', 'src_embed.lut.weight']\n",
            "2020-01-17 06:37:21,570 cfg.name                           : eniso_transformer\n",
            "2020-01-17 06:37:21,571 cfg.data.src                       : en\n",
            "2020-01-17 06:37:21,571 cfg.data.trg                       : iso\n",
            "2020-01-17 06:37:21,571 cfg.data.train                     : /content/drive/My Drive/masakhane/en-iso-baseline/train.bpe\n",
            "2020-01-17 06:37:21,571 cfg.data.dev                       : /content/drive/My Drive/masakhane/en-iso-baseline/dev.bpe\n",
            "2020-01-17 06:37:21,572 cfg.data.test                      : /content/drive/My Drive/masakhane/en-iso-baseline/test.bpe\n",
            "2020-01-17 06:37:21,572 cfg.data.level                     : bpe\n",
            "2020-01-17 06:37:21,572 cfg.data.lowercase                 : False\n",
            "2020-01-17 06:37:21,572 cfg.data.max_sent_length           : 100\n",
            "2020-01-17 06:37:21,572 cfg.data.src_vocab                 : /content/drive/My Drive/masakhane/en-iso-baseline/vocab.txt\n",
            "2020-01-17 06:37:21,573 cfg.data.trg_vocab                 : /content/drive/My Drive/masakhane/en-iso-baseline/vocab.txt\n",
            "2020-01-17 06:37:21,573 cfg.testing.beam_size              : 5\n",
            "2020-01-17 06:37:21,573 cfg.testing.alpha                  : 1.0\n",
            "2020-01-17 06:37:21,574 cfg.training.random_seed           : 42\n",
            "2020-01-17 06:37:21,574 cfg.training.optimizer             : adam\n",
            "2020-01-17 06:37:21,574 cfg.training.normalization         : tokens\n",
            "2020-01-17 06:37:21,574 cfg.training.adam_betas            : [0.9, 0.999]\n",
            "2020-01-17 06:37:21,574 cfg.training.scheduling            : plateau\n",
            "2020-01-17 06:37:21,575 cfg.training.patience              : 5\n",
            "2020-01-17 06:37:21,575 cfg.training.learning_rate_factor  : 0.5\n",
            "2020-01-17 06:37:21,575 cfg.training.learning_rate_warmup  : 1000\n",
            "2020-01-17 06:37:21,575 cfg.training.decrease_factor       : 0.7\n",
            "2020-01-17 06:37:21,576 cfg.training.loss                  : crossentropy\n",
            "2020-01-17 06:37:21,576 cfg.training.learning_rate         : 0.0003\n",
            "2020-01-17 06:37:21,576 cfg.training.learning_rate_min     : 1e-08\n",
            "2020-01-17 06:37:21,576 cfg.training.weight_decay          : 0.0\n",
            "2020-01-17 06:37:21,577 cfg.training.label_smoothing       : 0.1\n",
            "2020-01-17 06:37:21,577 cfg.training.batch_size            : 4096\n",
            "2020-01-17 06:37:21,577 cfg.training.batch_type            : token\n",
            "2020-01-17 06:37:21,577 cfg.training.eval_batch_size       : 3600\n",
            "2020-01-17 06:37:21,578 cfg.training.eval_batch_type       : token\n",
            "2020-01-17 06:37:21,578 cfg.training.batch_multiplier      : 1\n",
            "2020-01-17 06:37:21,578 cfg.training.early_stopping_metric : ppl\n",
            "2020-01-17 06:37:21,578 cfg.training.epochs                : 30\n",
            "2020-01-17 06:37:21,578 cfg.training.validation_freq       : 1000\n",
            "2020-01-17 06:37:21,579 cfg.training.logging_freq          : 100\n",
            "2020-01-17 06:37:21,579 cfg.training.eval_metric           : bleu\n",
            "2020-01-17 06:37:21,579 cfg.training.model_dir             : /content/drive/My Drive/masakhane/en-iso-baseline/models/eniso_transformer\n",
            "2020-01-17 06:37:21,579 cfg.training.overwrite             : True\n",
            "2020-01-17 06:37:21,579 cfg.training.shuffle               : True\n",
            "2020-01-17 06:37:21,580 cfg.training.use_cuda              : True\n",
            "2020-01-17 06:37:21,580 cfg.training.max_output_length     : 100\n",
            "2020-01-17 06:37:21,580 cfg.training.print_valid_sents     : [0, 1, 2, 3]\n",
            "2020-01-17 06:37:21,581 cfg.training.keep_last_ckpts       : 3\n",
            "2020-01-17 06:37:21,581 cfg.model.initializer              : xavier\n",
            "2020-01-17 06:37:21,582 cfg.model.bias_initializer         : zeros\n",
            "2020-01-17 06:37:21,582 cfg.model.init_gain                : 1.0\n",
            "2020-01-17 06:37:21,582 cfg.model.embed_initializer        : xavier\n",
            "2020-01-17 06:37:21,582 cfg.model.embed_init_gain          : 1.0\n",
            "2020-01-17 06:37:21,583 cfg.model.tied_embeddings          : True\n",
            "2020-01-17 06:37:21,583 cfg.model.tied_softmax             : True\n",
            "2020-01-17 06:37:21,583 cfg.model.encoder.type             : transformer\n",
            "2020-01-17 06:37:21,583 cfg.model.encoder.num_layers       : 6\n",
            "2020-01-17 06:37:21,583 cfg.model.encoder.num_heads        : 4\n",
            "2020-01-17 06:37:21,584 cfg.model.encoder.embeddings.embedding_dim : 256\n",
            "2020-01-17 06:37:21,584 cfg.model.encoder.embeddings.scale : True\n",
            "2020-01-17 06:37:21,584 cfg.model.encoder.embeddings.dropout : 0.2\n",
            "2020-01-17 06:37:21,584 cfg.model.encoder.hidden_size      : 256\n",
            "2020-01-17 06:37:21,585 cfg.model.encoder.ff_size          : 1024\n",
            "2020-01-17 06:37:21,585 cfg.model.encoder.dropout          : 0.3\n",
            "2020-01-17 06:37:21,585 cfg.model.decoder.type             : transformer\n",
            "2020-01-17 06:37:21,585 cfg.model.decoder.num_layers       : 6\n",
            "2020-01-17 06:37:21,585 cfg.model.decoder.num_heads        : 4\n",
            "2020-01-17 06:37:21,586 cfg.model.decoder.embeddings.embedding_dim : 256\n",
            "2020-01-17 06:37:21,586 cfg.model.decoder.embeddings.scale : True\n",
            "2020-01-17 06:37:21,586 cfg.model.decoder.embeddings.dropout : 0.2\n",
            "2020-01-17 06:37:21,587 cfg.model.decoder.hidden_size      : 256\n",
            "2020-01-17 06:37:21,587 cfg.model.decoder.ff_size          : 1024\n",
            "2020-01-17 06:37:21,587 cfg.model.decoder.dropout          : 0.3\n",
            "2020-01-17 06:37:21,587 Data set sizes: \n",
            "\ttrain 214464,\n",
            "\tvalid 1000,\n",
            "\ttest 2709\n",
            "2020-01-17 06:37:21,588 First training example:\n",
            "\t[SRC] Now in his 8@@ 0 ’ s , John adm@@ its that at times he feel@@ s des@@ p@@ on@@ d@@ ent .\n",
            "\t[TRG] Enẹna Jọn ọ kpako te ikpe udh@@ one gb@@ ọ no , ọ ta nọ ẹsejọ ọ be hai wo el@@ ọ@@ h@@ oma .\n",
            "2020-01-17 06:37:21,588 First 10 words (src): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) . (5) , (6) nọ (7) a (8) the (9) na\n",
            "2020-01-17 06:37:21,589 First 10 words (trg): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) . (5) , (6) nọ (7) a (8) the (9) na\n",
            "2020-01-17 06:37:21,589 Number of Src words (types): 4254\n",
            "2020-01-17 06:37:21,590 Number of Trg words (types): 4254\n",
            "2020-01-17 06:37:21,590 Model(\n",
            "\tencoder=TransformerEncoder(num_layers=6, num_heads=4),\n",
            "\tdecoder=TransformerDecoder(num_layers=6, num_heads=4),\n",
            "\tsrc_embed=Embeddings(embedding_dim=256, vocab_size=4254),\n",
            "\ttrg_embed=Embeddings(embedding_dim=256, vocab_size=4254))\n",
            "2020-01-17 06:37:21,603 EPOCH 1\n",
            "2020-01-17 06:37:36,157 Epoch   1 Step:      100 Batch Loss:     5.179712 Tokens per Sec:    15145, Lr: 0.000300\n",
            "2020-01-17 06:37:50,343 Epoch   1 Step:      200 Batch Loss:     4.952663 Tokens per Sec:    15920, Lr: 0.000300\n",
            "2020-01-17 06:38:04,564 Epoch   1 Step:      300 Batch Loss:     4.915039 Tokens per Sec:    15622, Lr: 0.000300\n",
            "2020-01-17 06:38:18,795 Epoch   1 Step:      400 Batch Loss:     4.522336 Tokens per Sec:    15998, Lr: 0.000300\n",
            "2020-01-17 06:38:32,977 Epoch   1 Step:      500 Batch Loss:     4.164488 Tokens per Sec:    15755, Lr: 0.000300\n",
            "2020-01-17 06:38:47,182 Epoch   1 Step:      600 Batch Loss:     3.936310 Tokens per Sec:    15719, Lr: 0.000300\n",
            "2020-01-17 06:39:01,482 Epoch   1 Step:      700 Batch Loss:     3.918845 Tokens per Sec:    15900, Lr: 0.000300\n",
            "2020-01-17 06:39:15,752 Epoch   1 Step:      800 Batch Loss:     3.251857 Tokens per Sec:    15760, Lr: 0.000300\n",
            "2020-01-17 06:39:30,020 Epoch   1 Step:      900 Batch Loss:     3.703592 Tokens per Sec:    15680, Lr: 0.000300\n",
            "2020-01-17 06:39:44,240 Epoch   1 Step:     1000 Batch Loss:     3.959886 Tokens per Sec:    15871, Lr: 0.000300\n",
            "2020-01-17 06:40:18,429 Hooray! New best validation result [ppl]!\n",
            "2020-01-17 06:40:18,429 Saving new checkpoint.\n",
            "2020-01-17 06:40:19,897 Example #0\n",
            "2020-01-17 06:40:19,898 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 06:40:19,898 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 06:40:19,899 \tHypothesis: Ma rẹ sai ru nọ ma rẹ rọ “ Ọghẹnẹ ” na .\n",
            "2020-01-17 06:40:19,899 Example #1\n",
            "2020-01-17 06:40:19,899 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 06:40:19,900 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 06:40:19,900 \tHypothesis: A te jọ nọ a re ru nọ a re ru .\n",
            "2020-01-17 06:40:19,900 Example #2\n",
            "2020-01-17 06:40:19,901 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 06:40:19,901 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 06:40:19,901 \tHypothesis: Rekọ , ma rẹ sai ru nọ ma rẹ sai ru nọ ma rẹ rọ rehọ oma , yọ ma rẹ sai ru nọ ma rẹ rọ ta nọ ma rẹ rọ rọ ta kẹ omai nọ ma rẹ rọ kẹ omai . ”\n",
            "2020-01-17 06:40:19,901 Example #3\n",
            "2020-01-17 06:40:19,902 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 06:40:19,902 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 06:40:19,902 \tHypothesis: Rekọ , o rẹ sai ru oware nọ o rẹ sai ru nọ o rẹ rọ kẹ omai .\n",
            "2020-01-17 06:40:19,903 Validation result (greedy) at epoch   1, step     1000: bleu:   2.08, loss: 94234.7969, ppl:  37.8981, duration: 35.6621s\n",
            "2020-01-17 06:40:34,569 Epoch   1 Step:     1100 Batch Loss:     4.026417 Tokens per Sec:    14898, Lr: 0.000300\n",
            "2020-01-17 06:40:48,732 Epoch   1 Step:     1200 Batch Loss:     3.676992 Tokens per Sec:    15328, Lr: 0.000300\n",
            "2020-01-17 06:41:02,951 Epoch   1 Step:     1300 Batch Loss:     3.939560 Tokens per Sec:    15689, Lr: 0.000300\n",
            "2020-01-17 06:41:17,138 Epoch   1 Step:     1400 Batch Loss:     3.377037 Tokens per Sec:    15588, Lr: 0.000300\n",
            "2020-01-17 06:41:31,354 Epoch   1 Step:     1500 Batch Loss:     3.395381 Tokens per Sec:    15617, Lr: 0.000300\n",
            "2020-01-17 06:41:45,656 Epoch   1 Step:     1600 Batch Loss:     3.016439 Tokens per Sec:    15696, Lr: 0.000300\n",
            "2020-01-17 06:41:59,984 Epoch   1 Step:     1700 Batch Loss:     3.396242 Tokens per Sec:    15612, Lr: 0.000300\n",
            "2020-01-17 06:42:14,266 Epoch   1 Step:     1800 Batch Loss:     3.366712 Tokens per Sec:    15514, Lr: 0.000300\n",
            "2020-01-17 06:42:28,581 Epoch   1 Step:     1900 Batch Loss:     3.489265 Tokens per Sec:    15763, Lr: 0.000300\n",
            "2020-01-17 06:42:42,778 Epoch   1 Step:     2000 Batch Loss:     2.676149 Tokens per Sec:    15503, Lr: 0.000300\n",
            "2020-01-17 06:43:17,134 Hooray! New best validation result [ppl]!\n",
            "2020-01-17 06:43:17,134 Saving new checkpoint.\n",
            "2020-01-17 06:43:18,600 Example #0\n",
            "2020-01-17 06:43:18,601 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 06:43:18,601 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 06:43:18,601 \tHypothesis: Ma rẹ sai ru nọ Ọghẹnẹ ọ rẹ sai ro “ ru omai . ”\n",
            "2020-01-17 06:43:18,602 Example #1\n",
            "2020-01-17 06:43:18,602 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 06:43:18,602 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 06:43:18,603 \tHypothesis: Onana o rrọ Ebaibol na .\n",
            "2020-01-17 06:43:18,603 Example #2\n",
            "2020-01-17 06:43:18,603 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 06:43:18,604 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 06:43:18,604 \tHypothesis: Evaọ uzẹme , ma rẹ sae rọ rehọ oma mai ru iruo nọ ma re ro ru iruo nọ ma re ro ru iruo nọ Jesu ọ ta nọ : “ Wha rehọ eva riẹ , gbe Ọmọ riẹ , gbe Ọmọ riẹ , gbe akpọ na . ”\n",
            "2020-01-17 06:43:18,604 Example #3\n",
            "2020-01-17 06:43:18,605 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 06:43:18,605 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 06:43:18,605 \tHypothesis: Ghele na , eme o rẹ sai fi obọ họ kẹ omai wo evawere .\n",
            "2020-01-17 06:43:18,605 Validation result (greedy) at epoch   1, step     2000: bleu:   4.41, loss: 80098.5547, ppl:  21.9689, duration: 35.8269s\n",
            "2020-01-17 06:43:33,516 Epoch   1 Step:     2100 Batch Loss:     2.939961 Tokens per Sec:    14994, Lr: 0.000300\n",
            "2020-01-17 06:43:47,757 Epoch   1 Step:     2200 Batch Loss:     2.946548 Tokens per Sec:    15317, Lr: 0.000300\n",
            "2020-01-17 06:44:02,042 Epoch   1 Step:     2300 Batch Loss:     3.184029 Tokens per Sec:    15765, Lr: 0.000300\n",
            "2020-01-17 06:44:16,360 Epoch   1 Step:     2400 Batch Loss:     3.015883 Tokens per Sec:    15441, Lr: 0.000300\n",
            "2020-01-17 06:44:30,695 Epoch   1 Step:     2500 Batch Loss:     2.956036 Tokens per Sec:    15601, Lr: 0.000300\n",
            "2020-01-17 06:44:33,734 Epoch   1: total training loss 9404.59\n",
            "2020-01-17 06:44:33,734 EPOCH 2\n",
            "2020-01-17 06:44:45,254 Epoch   2 Step:     2600 Batch Loss:     3.031394 Tokens per Sec:    15120, Lr: 0.000300\n",
            "2020-01-17 06:44:59,512 Epoch   2 Step:     2700 Batch Loss:     2.861199 Tokens per Sec:    15450, Lr: 0.000300\n",
            "2020-01-17 06:45:13,726 Epoch   2 Step:     2800 Batch Loss:     2.944969 Tokens per Sec:    15332, Lr: 0.000300\n",
            "2020-01-17 06:45:28,009 Epoch   2 Step:     2900 Batch Loss:     2.701467 Tokens per Sec:    15735, Lr: 0.000300\n",
            "2020-01-17 06:45:42,360 Epoch   2 Step:     3000 Batch Loss:     2.699929 Tokens per Sec:    15632, Lr: 0.000300\n",
            "2020-01-17 06:46:16,583 Hooray! New best validation result [ppl]!\n",
            "2020-01-17 06:46:16,584 Saving new checkpoint.\n",
            "2020-01-17 06:46:18,410 Example #0\n",
            "2020-01-17 06:46:18,420 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 06:46:18,421 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 06:46:18,421 \tHypothesis: Ma rẹ sae ta nọ Ọghẹnẹ ọ rẹ sae “ rehọ omai kpobi kpobi . ”\n",
            "2020-01-17 06:46:18,421 Example #1\n",
            "2020-01-17 06:46:18,422 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 06:46:18,422 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 06:46:18,423 \tHypothesis: Onana u dhesẹ nọ Uvie na o rrọ ukoko na .\n",
            "2020-01-17 06:46:18,423 Example #2\n",
            "2020-01-17 06:46:18,424 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 06:46:18,424 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 06:46:18,424 \tHypothesis: Evaọ uzẹme , ma te jọ oria kpobi nọ ma te rọ rehọ aro kele eware nọ e rẹ rọ kẹ omai , ma te jọ wọhọ epanọ Jesu ọ ta nọ : “ Wha rọ aro kele Kristi , re ọ rehọ eva riẹ kpobi , keme a rọ eva riẹ kpobi kpobi , keme a re ti ru oreva Ọghẹnẹ .\n",
            "2020-01-17 06:46:18,425 Example #3\n",
            "2020-01-17 06:46:18,425 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 06:46:18,426 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 06:46:18,426 \tHypothesis: Ghele na , eme nọ e rrọ udevie ahwo nọ a re ro wo evawere .\n",
            "2020-01-17 06:46:18,426 Validation result (greedy) at epoch   2, step     3000: bleu:   6.14, loss: 71809.6406, ppl:  15.9570, duration: 36.0659s\n",
            "2020-01-17 06:46:33,249 Epoch   2 Step:     3100 Batch Loss:     2.684343 Tokens per Sec:    14674, Lr: 0.000300\n",
            "2020-01-17 06:46:47,579 Epoch   2 Step:     3200 Batch Loss:     3.109228 Tokens per Sec:    15608, Lr: 0.000300\n",
            "2020-01-17 06:47:02,029 Epoch   2 Step:     3300 Batch Loss:     2.700184 Tokens per Sec:    15455, Lr: 0.000300\n",
            "2020-01-17 06:47:16,319 Epoch   2 Step:     3400 Batch Loss:     2.654817 Tokens per Sec:    15307, Lr: 0.000300\n",
            "2020-01-17 06:47:30,642 Epoch   2 Step:     3500 Batch Loss:     2.406144 Tokens per Sec:    15844, Lr: 0.000300\n",
            "2020-01-17 06:47:44,935 Epoch   2 Step:     3600 Batch Loss:     2.465588 Tokens per Sec:    15114, Lr: 0.000300\n",
            "2020-01-17 06:47:59,343 Epoch   2 Step:     3700 Batch Loss:     2.590801 Tokens per Sec:    15672, Lr: 0.000300\n",
            "2020-01-17 06:48:13,711 Epoch   2 Step:     3800 Batch Loss:     2.935358 Tokens per Sec:    15813, Lr: 0.000300\n",
            "2020-01-17 06:48:28,139 Epoch   2 Step:     3900 Batch Loss:     2.669350 Tokens per Sec:    15648, Lr: 0.000300\n",
            "2020-01-17 06:48:42,492 Epoch   2 Step:     4000 Batch Loss:     2.972049 Tokens per Sec:    15600, Lr: 0.000300\n",
            "2020-01-17 06:49:16,849 Hooray! New best validation result [ppl]!\n",
            "2020-01-17 06:49:16,850 Saving new checkpoint.\n",
            "2020-01-17 06:49:18,284 Example #0\n",
            "2020-01-17 06:49:18,285 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 06:49:18,285 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 06:49:18,285 \tHypothesis: Ma rẹ sae nọ Ọghẹnẹ ọ rẹ sae rọ “ eva mai kpobi . ”\n",
            "2020-01-17 06:49:18,286 Example #1\n",
            "2020-01-17 06:49:18,286 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 06:49:18,286 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 06:49:18,287 \tHypothesis: Onana u ru nọ Uvie na o rọ rrọ .\n",
            "2020-01-17 06:49:18,287 Example #2\n",
            "2020-01-17 06:49:18,288 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 06:49:18,288 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 06:49:18,288 \tHypothesis: Fikiere , ma te jọ uzuazọ mai kpobi ruẹ epanọ ma te rọ rehọ ẹkwoma odẹ riẹ mu , ma te rọ ere ru ei wọhọ epanọ a rọ rehọ odẹ riẹ mu , keme Jesu ọ ta nọ : “ Wha rọ eva riẹ kpobi , re a rọ eva riẹ kpobi . ”\n",
            "2020-01-17 06:49:18,288 Example #3\n",
            "2020-01-17 06:49:18,289 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 06:49:18,289 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 06:49:18,289 \tHypothesis: Ghele na , eme nọ a re ro ru iruo na e rẹ wha udhedhẹ ze .\n",
            "2020-01-17 06:49:18,289 Validation result (greedy) at epoch   2, step     4000: bleu:   9.19, loss: 66469.9375, ppl:  12.9868, duration: 35.7972s\n",
            "2020-01-17 06:49:33,262 Epoch   2 Step:     4100 Batch Loss:     2.265986 Tokens per Sec:    14828, Lr: 0.000300\n",
            "2020-01-17 06:49:47,605 Epoch   2 Step:     4200 Batch Loss:     2.567861 Tokens per Sec:    15329, Lr: 0.000300\n",
            "2020-01-17 06:50:01,939 Epoch   2 Step:     4300 Batch Loss:     2.581526 Tokens per Sec:    15713, Lr: 0.000300\n",
            "2020-01-17 06:50:16,276 Epoch   2 Step:     4400 Batch Loss:     2.775108 Tokens per Sec:    15664, Lr: 0.000300\n",
            "2020-01-17 06:50:30,648 Epoch   2 Step:     4500 Batch Loss:     2.864021 Tokens per Sec:    15710, Lr: 0.000300\n",
            "2020-01-17 06:50:44,972 Epoch   2 Step:     4600 Batch Loss:     2.341128 Tokens per Sec:    15478, Lr: 0.000300\n",
            "2020-01-17 06:50:59,257 Epoch   2 Step:     4700 Batch Loss:     2.608732 Tokens per Sec:    14991, Lr: 0.000300\n",
            "2020-01-17 06:51:13,640 Epoch   2 Step:     4800 Batch Loss:     2.422869 Tokens per Sec:    15890, Lr: 0.000300\n",
            "2020-01-17 06:51:27,947 Epoch   2 Step:     4900 Batch Loss:     2.773067 Tokens per Sec:    15402, Lr: 0.000300\n",
            "2020-01-17 06:51:42,328 Epoch   2 Step:     5000 Batch Loss:     2.400848 Tokens per Sec:    15671, Lr: 0.000300\n",
            "2020-01-17 06:52:16,533 Hooray! New best validation result [ppl]!\n",
            "2020-01-17 06:52:16,533 Saving new checkpoint.\n",
            "2020-01-17 06:52:17,975 Example #0\n",
            "2020-01-17 06:52:17,975 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 06:52:17,976 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 06:52:17,976 \tHypothesis: Ma rẹ sae nọ Ọghẹnẹ ọ rẹ sae nọ omai ‘ ma eva eva mai . ’\n",
            "2020-01-17 06:52:17,976 Example #1\n",
            "2020-01-17 06:52:17,977 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 06:52:17,977 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 06:52:17,977 \tHypothesis: Onana u te je ru nọ Uvie na o rọ rrọ .\n",
            "2020-01-17 06:52:17,977 Example #2\n",
            "2020-01-17 06:52:17,978 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 06:52:17,978 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 06:52:17,978 \tHypothesis: Ma te ru ere , ma te jọ oria nọ ma rẹ rọ ta ẹme kẹ ahwo nọ a rẹ rọ odẹ na , onọ u dhesẹ nọ a rẹ rọ odẹ riẹ kẹ ae , inọ : “ Wha rehọ odẹ riẹ kẹ odẹ riẹ , re a rehọ odẹ riẹ mu , re a rehọ odẹ riẹ mu ei họ .\n",
            "2020-01-17 06:52:17,979 Example #3\n",
            "2020-01-17 06:52:17,981 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 06:52:17,981 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 06:52:17,981 \tHypothesis: Ghele na , eme nọ e rrọ otọ na e rẹ wha udhedhẹ ze .\n",
            "2020-01-17 06:52:17,981 Validation result (greedy) at epoch   2, step     5000: bleu:  11.61, loss: 62164.8359, ppl:  10.9997, duration: 35.6526s\n",
            "2020-01-17 06:52:24,786 Epoch   2: total training loss 6915.25\n",
            "2020-01-17 06:52:24,787 EPOCH 3\n",
            "2020-01-17 06:52:33,259 Epoch   3 Step:     5100 Batch Loss:     2.574651 Tokens per Sec:    13903, Lr: 0.000300\n",
            "2020-01-17 06:52:47,553 Epoch   3 Step:     5200 Batch Loss:     3.521019 Tokens per Sec:    15332, Lr: 0.000300\n",
            "2020-01-17 06:53:01,883 Epoch   3 Step:     5300 Batch Loss:     2.774091 Tokens per Sec:    15795, Lr: 0.000300\n",
            "2020-01-17 06:53:16,215 Epoch   3 Step:     5400 Batch Loss:     2.281579 Tokens per Sec:    15611, Lr: 0.000300\n",
            "2020-01-17 06:53:30,593 Epoch   3 Step:     5500 Batch Loss:     2.334015 Tokens per Sec:    15787, Lr: 0.000300\n",
            "2020-01-17 06:53:45,004 Epoch   3 Step:     5600 Batch Loss:     2.129029 Tokens per Sec:    15299, Lr: 0.000300\n",
            "2020-01-17 06:53:59,351 Epoch   3 Step:     5700 Batch Loss:     1.966521 Tokens per Sec:    15857, Lr: 0.000300\n",
            "2020-01-17 06:54:13,678 Epoch   3 Step:     5800 Batch Loss:     2.681578 Tokens per Sec:    15695, Lr: 0.000300\n",
            "2020-01-17 06:54:28,005 Epoch   3 Step:     5900 Batch Loss:     2.520865 Tokens per Sec:    15634, Lr: 0.000300\n",
            "2020-01-17 06:54:42,368 Epoch   3 Step:     6000 Batch Loss:     2.160026 Tokens per Sec:    15653, Lr: 0.000300\n",
            "2020-01-17 06:55:16,733 Hooray! New best validation result [ppl]!\n",
            "2020-01-17 06:55:16,734 Saving new checkpoint.\n",
            "2020-01-17 06:55:18,167 Example #0\n",
            "2020-01-17 06:55:18,172 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 06:55:18,172 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 06:55:18,172 \tHypothesis: Ma rẹ sae nọ Ọghẹnẹ ọ ma omai ‘ ma omai eva eva eva eva mai . ’\n",
            "2020-01-17 06:55:18,172 Example #1\n",
            "2020-01-17 06:55:18,173 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 06:55:18,173 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 06:55:18,173 \tHypothesis: Onana u ru nọ Uvie na o ro muhọ .\n",
            "2020-01-17 06:55:18,174 Example #2\n",
            "2020-01-17 06:55:18,174 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 06:55:18,174 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 06:55:18,175 \tHypothesis: Ma te bi ru ere , ma te rọ evawere ru iruo nana nọ ma re ro wo erọvrẹ gbe ukuoriọ nana : “ Wha rehọ odẹ riẹ kẹ odẹ riẹ , re a rehọ odẹ riẹ kẹ ae , re a rehọ odẹ riẹ kẹ ae , re a ruẹse jọ odẹ riẹ .\n",
            "2020-01-17 06:55:18,175 Example #3\n",
            "2020-01-17 06:55:18,176 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 06:55:18,176 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 06:55:18,176 \tHypothesis: Ghele na , eme nọ e rrọ udu u re ru nọ a re ro wo udhedhẹ .\n",
            "2020-01-17 06:55:18,176 Validation result (greedy) at epoch   3, step     6000: bleu:  13.32, loss: 59310.5195, ppl:   9.8530, duration: 35.8075s\n",
            "2020-01-17 06:55:33,247 Epoch   3 Step:     6100 Batch Loss:     2.232039 Tokens per Sec:    14475, Lr: 0.000300\n",
            "2020-01-17 06:55:47,602 Epoch   3 Step:     6200 Batch Loss:     2.410467 Tokens per Sec:    15572, Lr: 0.000300\n",
            "2020-01-17 06:56:02,033 Epoch   3 Step:     6300 Batch Loss:     2.642549 Tokens per Sec:    15528, Lr: 0.000300\n",
            "2020-01-17 06:56:16,450 Epoch   3 Step:     6400 Batch Loss:     2.679075 Tokens per Sec:    15532, Lr: 0.000300\n",
            "2020-01-17 06:56:30,787 Epoch   3 Step:     6500 Batch Loss:     2.349768 Tokens per Sec:    15493, Lr: 0.000300\n",
            "2020-01-17 06:56:45,284 Epoch   3 Step:     6600 Batch Loss:     1.898112 Tokens per Sec:    15830, Lr: 0.000300\n",
            "2020-01-17 06:56:59,606 Epoch   3 Step:     6700 Batch Loss:     2.459423 Tokens per Sec:    15783, Lr: 0.000300\n",
            "2020-01-17 06:57:13,987 Epoch   3 Step:     6800 Batch Loss:     2.651201 Tokens per Sec:    15347, Lr: 0.000300\n",
            "2020-01-17 06:57:28,345 Epoch   3 Step:     6900 Batch Loss:     1.939225 Tokens per Sec:    15503, Lr: 0.000300\n",
            "2020-01-17 06:57:42,744 Epoch   3 Step:     7000 Batch Loss:     2.648763 Tokens per Sec:    15464, Lr: 0.000300\n",
            "2020-01-17 06:58:17,001 Hooray! New best validation result [ppl]!\n",
            "2020-01-17 06:58:17,001 Saving new checkpoint.\n",
            "2020-01-17 06:58:18,438 Example #0\n",
            "2020-01-17 06:58:18,439 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 06:58:18,439 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 06:58:18,440 \tHypothesis: Ma rẹ sae nọ Ọghẹnẹ ọ rẹ sae nọ omai ‘ ma eva mai . ’\n",
            "2020-01-17 06:58:18,440 Example #1\n",
            "2020-01-17 06:58:18,441 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 06:58:18,441 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 06:58:18,441 \tHypothesis: Onana u ru nọ Uvie na o rọ rrọ Ologbo na .\n",
            "2020-01-17 06:58:18,441 Example #2\n",
            "2020-01-17 06:58:18,442 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 06:58:18,442 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 06:58:18,442 \tHypothesis: Ma te ru ere , ma te rọ evawere ru iruo nọ ma bi ro ru iruo nana gba , jẹ rehọ iẹe mu odẹ riẹ họ : “ Wha ru odẹ riẹ eva were , re wha rọ eva riẹ , wha rọ eva riẹ kẹ Ọnowo na , wha rẹ te rehọ iẹ kẹ ae . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
            "2020-01-17 06:58:18,442 Example #3\n",
            "2020-01-17 06:58:18,443 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 06:58:18,443 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 06:58:18,444 \tHypothesis: Ghele na , eme nọ e rrọ udu u re fi obọ họ kẹ ohwo wo udhedhẹ .\n",
            "2020-01-17 06:58:18,444 Validation result (greedy) at epoch   3, step     7000: bleu:  14.62, loss: 56697.8359, ppl:   8.9084, duration: 35.6988s\n",
            "2020-01-17 06:58:33,416 Epoch   3 Step:     7100 Batch Loss:     2.182554 Tokens per Sec:    14719, Lr: 0.000300\n",
            "2020-01-17 06:58:47,867 Epoch   3 Step:     7200 Batch Loss:     2.185552 Tokens per Sec:    15392, Lr: 0.000300\n",
            "2020-01-17 06:59:02,231 Epoch   3 Step:     7300 Batch Loss:     2.671817 Tokens per Sec:    15512, Lr: 0.000300\n",
            "2020-01-17 06:59:16,526 Epoch   3 Step:     7400 Batch Loss:     2.856697 Tokens per Sec:    15514, Lr: 0.000300\n",
            "2020-01-17 06:59:30,875 Epoch   3 Step:     7500 Batch Loss:     2.211361 Tokens per Sec:    15099, Lr: 0.000300\n",
            "2020-01-17 06:59:40,790 Epoch   3: total training loss 6067.62\n",
            "2020-01-17 06:59:40,791 EPOCH 4\n",
            "2020-01-17 06:59:45,510 Epoch   4 Step:     7600 Batch Loss:     2.495811 Tokens per Sec:    14490, Lr: 0.000300\n",
            "2020-01-17 06:59:59,960 Epoch   4 Step:     7700 Batch Loss:     1.867300 Tokens per Sec:    15717, Lr: 0.000300\n",
            "2020-01-17 07:00:14,365 Epoch   4 Step:     7800 Batch Loss:     2.016244 Tokens per Sec:    15354, Lr: 0.000300\n",
            "2020-01-17 07:00:28,643 Epoch   4 Step:     7900 Batch Loss:     2.309531 Tokens per Sec:    15266, Lr: 0.000300\n",
            "2020-01-17 07:00:42,901 Epoch   4 Step:     8000 Batch Loss:     2.295289 Tokens per Sec:    14978, Lr: 0.000300\n",
            "2020-01-17 07:01:17,304 Hooray! New best validation result [ppl]!\n",
            "2020-01-17 07:01:17,304 Saving new checkpoint.\n",
            "2020-01-17 07:01:19,385 Example #0\n",
            "2020-01-17 07:01:19,386 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 07:01:19,386 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 07:01:19,386 \tHypothesis: Ma rẹ sae nọ Ọghẹnẹ ọ rẹ nọ omai ‘ ma eva udu mai . ’\n",
            "2020-01-17 07:01:19,387 Example #1\n",
            "2020-01-17 07:01:19,387 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 07:01:19,387 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 07:01:19,388 \tHypothesis: Onana o jọ oware nọ Uvie na o jọ Ologbo na .\n",
            "2020-01-17 07:01:19,388 Example #2\n",
            "2020-01-17 07:01:19,388 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 07:01:19,389 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 07:01:19,389 \tHypothesis: Fikiere , ma te ruẹ nọ ma te bi ru iruo mai woma vi epaọ anwẹdẹ , ma te ta nọ : “ Jọ odẹ riẹ o rọ kẹ owhai uye , re a ruẹse jọ eva odẹ riẹ , re a ruẹse jọ eva riẹ kpobi , re a ruẹse jọ eva odẹ riẹ , re a ruẹse jọ eva riẹ kpobi .\n",
            "2020-01-17 07:01:19,389 Example #3\n",
            "2020-01-17 07:01:19,390 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 07:01:19,390 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 07:01:19,390 \tHypothesis: Ghele na , eme nọ e rrọ udu u re ru nọ udhedhẹ o rẹ rọ ga .\n",
            "2020-01-17 07:01:19,390 Validation result (greedy) at epoch   4, step     8000: bleu:  15.46, loss: 55065.7305, ppl:   8.3649, duration: 36.4886s\n",
            "2020-01-17 07:01:34,464 Epoch   4 Step:     8100 Batch Loss:     2.385794 Tokens per Sec:    14991, Lr: 0.000300\n",
            "2020-01-17 07:01:48,802 Epoch   4 Step:     8200 Batch Loss:     2.414126 Tokens per Sec:    15323, Lr: 0.000300\n",
            "2020-01-17 07:02:03,171 Epoch   4 Step:     8300 Batch Loss:     2.232402 Tokens per Sec:    15619, Lr: 0.000300\n",
            "2020-01-17 07:02:17,572 Epoch   4 Step:     8400 Batch Loss:     2.403649 Tokens per Sec:    15264, Lr: 0.000300\n",
            "2020-01-17 07:02:31,932 Epoch   4 Step:     8500 Batch Loss:     1.901917 Tokens per Sec:    15031, Lr: 0.000300\n",
            "2020-01-17 07:02:46,383 Epoch   4 Step:     8600 Batch Loss:     2.041152 Tokens per Sec:    15680, Lr: 0.000300\n",
            "2020-01-17 07:03:00,731 Epoch   4 Step:     8700 Batch Loss:     2.242634 Tokens per Sec:    15419, Lr: 0.000300\n",
            "2020-01-17 07:03:15,047 Epoch   4 Step:     8800 Batch Loss:     2.205776 Tokens per Sec:    15622, Lr: 0.000300\n",
            "2020-01-17 07:03:29,389 Epoch   4 Step:     8900 Batch Loss:     2.067200 Tokens per Sec:    15756, Lr: 0.000300\n",
            "2020-01-17 07:03:43,702 Epoch   4 Step:     9000 Batch Loss:     2.506483 Tokens per Sec:    15458, Lr: 0.000300\n",
            "2020-01-17 07:04:18,087 Hooray! New best validation result [ppl]!\n",
            "2020-01-17 07:04:18,087 Saving new checkpoint.\n",
            "2020-01-17 07:04:19,541 Example #0\n",
            "2020-01-17 07:04:19,541 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 07:04:19,542 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 07:04:19,542 \tHypothesis: Ma rẹ sae nọ Ọghẹnẹ ọ rẹ sae nọ omai ‘ ma eva mai . ’\n",
            "2020-01-17 07:04:19,542 Example #1\n",
            "2020-01-17 07:04:19,543 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 07:04:19,543 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 07:04:19,543 \tHypothesis: Onana o jọ Odibọgba Uvie na .\n",
            "2020-01-17 07:04:19,543 Example #2\n",
            "2020-01-17 07:04:19,544 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 07:04:19,544 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 07:04:19,544 \tHypothesis: ( Olezi 111 : 1 ) Fikiere , mai kpobi ma te bi ru iruo mai kpobi nọ ma te bi ru evaọ abọ nana , ma vẹ te ta nọ : “ Jọ odẹ riẹ o rọ eva Ọnowo na [ Jesu ] ọ rọ eva riẹ , re o ru ei lọhọ , re a rehọ odẹ riẹ kẹ ae , re a rehọ odẹ riẹ kpehru vi ai kpobi .\n",
            "2020-01-17 07:04:19,545 Example #3\n",
            "2020-01-17 07:04:19,545 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 07:04:19,545 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 07:04:19,546 \tHypothesis: Ghele na , eme nọ e rrọ udu - esuo e rẹ ga hrọ re ma wo udhedhẹ .\n",
            "2020-01-17 07:04:19,546 Validation result (greedy) at epoch   4, step     9000: bleu:  17.32, loss: 53112.5273, ppl:   7.7578, duration: 35.8436s\n",
            "2020-01-17 07:04:34,441 Epoch   4 Step:     9100 Batch Loss:     2.414254 Tokens per Sec:    14657, Lr: 0.000300\n",
            "2020-01-17 07:04:48,848 Epoch   4 Step:     9200 Batch Loss:     1.977519 Tokens per Sec:    15485, Lr: 0.000300\n",
            "2020-01-17 07:05:03,116 Epoch   4 Step:     9300 Batch Loss:     2.272821 Tokens per Sec:    15247, Lr: 0.000300\n",
            "2020-01-17 07:05:17,478 Epoch   4 Step:     9400 Batch Loss:     2.231190 Tokens per Sec:    15557, Lr: 0.000300\n",
            "2020-01-17 07:05:31,860 Epoch   4 Step:     9500 Batch Loss:     1.987313 Tokens per Sec:    15517, Lr: 0.000300\n",
            "2020-01-17 07:05:46,261 Epoch   4 Step:     9600 Batch Loss:     2.057482 Tokens per Sec:    15822, Lr: 0.000300\n",
            "2020-01-17 07:06:00,616 Epoch   4 Step:     9700 Batch Loss:     2.172221 Tokens per Sec:    15372, Lr: 0.000300\n",
            "2020-01-17 07:06:14,963 Epoch   4 Step:     9800 Batch Loss:     2.040344 Tokens per Sec:    15176, Lr: 0.000300\n",
            "2020-01-17 07:06:29,332 Epoch   4 Step:     9900 Batch Loss:     2.292722 Tokens per Sec:    15701, Lr: 0.000300\n",
            "2020-01-17 07:06:43,604 Epoch   4 Step:    10000 Batch Loss:     2.236258 Tokens per Sec:    15367, Lr: 0.000300\n",
            "2020-01-17 07:07:17,959 Hooray! New best validation result [ppl]!\n",
            "2020-01-17 07:07:17,960 Saving new checkpoint.\n",
            "2020-01-17 07:07:19,511 Example #0\n",
            "2020-01-17 07:07:19,511 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 07:07:19,512 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 07:07:19,512 \tHypothesis: Ma rẹ sae nọ Ọghẹnẹ nọ ma rẹ sae nọ omai nọ ma ‘ ma ma ma ma omai eva mai . ’\n",
            "2020-01-17 07:07:19,512 Example #1\n",
            "2020-01-17 07:07:19,513 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 07:07:19,513 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 07:07:19,513 \tHypothesis: Onana o jọ oware nọ Uvie na o jọ Nebuka .\n",
            "2020-01-17 07:07:19,513 Example #2\n",
            "2020-01-17 07:07:19,514 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 07:07:19,514 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 07:07:19,514 \tHypothesis: Ma te bi ru ere , ma te rọ evawere ru iruo mai kpobi nọ ma te bi ru lele iei , ma vẹ jẹ ta nọ : “ Wha jọ odẹ riẹ [ Kristi ] ta ẹme kẹ ae , re a rehọ odẹ riẹ kẹ ae , re a ruẹse rehọ iẹe , re a ruẹse rehọ iẹe kẹ ae .\n",
            "2020-01-17 07:07:19,514 Example #3\n",
            "2020-01-17 07:07:19,515 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 07:07:19,515 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 07:07:19,515 \tHypothesis: Ghele na , eme nọ e rẹ kẹ ẹgba nọ ma rẹ rọ jọ udhedhẹ .\n",
            "2020-01-17 07:07:19,516 Validation result (greedy) at epoch   4, step    10000: bleu:  17.20, loss: 51696.4375, ppl:   7.3454, duration: 35.9108s\n",
            "2020-01-17 07:07:34,423 Epoch   4 Step:    10100 Batch Loss:     2.144980 Tokens per Sec:    14839, Lr: 0.000300\n",
            "2020-01-17 07:07:35,167 Epoch   4: total training loss 5601.89\n",
            "2020-01-17 07:07:35,168 EPOCH 5\n",
            "2020-01-17 07:07:49,115 Epoch   5 Step:    10200 Batch Loss:     2.235956 Tokens per Sec:    15173, Lr: 0.000300\n",
            "2020-01-17 07:08:03,424 Epoch   5 Step:    10300 Batch Loss:     1.865800 Tokens per Sec:    15316, Lr: 0.000300\n",
            "2020-01-17 07:08:17,804 Epoch   5 Step:    10400 Batch Loss:     2.025363 Tokens per Sec:    15513, Lr: 0.000300\n",
            "2020-01-17 07:08:32,214 Epoch   5 Step:    10500 Batch Loss:     2.095149 Tokens per Sec:    15765, Lr: 0.000300\n",
            "2020-01-17 07:08:46,527 Epoch   5 Step:    10600 Batch Loss:     1.819680 Tokens per Sec:    15322, Lr: 0.000300\n",
            "2020-01-17 07:09:00,928 Epoch   5 Step:    10700 Batch Loss:     1.743330 Tokens per Sec:    15674, Lr: 0.000300\n",
            "2020-01-17 07:09:15,436 Epoch   5 Step:    10800 Batch Loss:     2.417891 Tokens per Sec:    15462, Lr: 0.000300\n",
            "2020-01-17 07:09:29,796 Epoch   5 Step:    10900 Batch Loss:     2.159352 Tokens per Sec:    15431, Lr: 0.000300\n",
            "2020-01-17 07:09:44,145 Epoch   5 Step:    11000 Batch Loss:     2.303234 Tokens per Sec:    15633, Lr: 0.000300\n",
            "2020-01-17 07:10:18,560 Hooray! New best validation result [ppl]!\n",
            "2020-01-17 07:10:18,560 Saving new checkpoint.\n",
            "2020-01-17 07:10:20,040 Example #0\n",
            "2020-01-17 07:10:20,041 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 07:10:20,041 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 07:10:20,041 \tHypothesis: Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ ma omai eva eva . ’\n",
            "2020-01-17 07:10:20,041 Example #1\n",
            "2020-01-17 07:10:20,042 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 07:10:20,042 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 07:10:20,042 \tHypothesis: Onana u ru nọ Uvie na u ro si kẹle iẹe .\n",
            "2020-01-17 07:10:20,043 Example #2\n",
            "2020-01-17 07:10:20,043 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 07:10:20,043 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 07:10:20,044 \tHypothesis: Fikiere , ma te rọ evawere ta usiuwoma na , ma vẹ te ta kpahe epanọ ma rẹ rọ rehọ iẹe wawo erru nana , jẹ ta nọ : “ Wha jọ odẹ riẹ [ Kristi ] , re a jọ odẹ riẹ , re a ruẹse jọ odẹ riẹ , re a ruẹse jọ odẹ riẹ , re a ruẹse jọ bẹdẹ bẹdẹ bẹdẹ bẹdẹ .\n",
            "2020-01-17 07:10:20,044 Example #3\n",
            "2020-01-17 07:10:20,044 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 07:10:20,045 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 07:10:20,045 \tHypothesis: Ghele na , eme nọ e rẹ kẹ ẹgba nọ a re ro ru udhedhẹ .\n",
            "2020-01-17 07:10:20,045 Validation result (greedy) at epoch   5, step    11000: bleu:  17.98, loss: 50569.5391, ppl:   7.0330, duration: 35.8991s\n",
            "2020-01-17 07:10:35,119 Epoch   5 Step:    11100 Batch Loss:     2.184692 Tokens per Sec:    15155, Lr: 0.000300\n",
            "2020-01-17 07:10:49,418 Epoch   5 Step:    11200 Batch Loss:     1.618714 Tokens per Sec:    15131, Lr: 0.000300\n",
            "2020-01-17 07:11:03,823 Epoch   5 Step:    11300 Batch Loss:     2.142127 Tokens per Sec:    15580, Lr: 0.000300\n",
            "2020-01-17 07:11:18,186 Epoch   5 Step:    11400 Batch Loss:     2.501377 Tokens per Sec:    15607, Lr: 0.000300\n",
            "2020-01-17 07:11:32,524 Epoch   5 Step:    11500 Batch Loss:     2.105314 Tokens per Sec:    15352, Lr: 0.000300\n",
            "2020-01-17 07:11:46,846 Epoch   5 Step:    11600 Batch Loss:     2.504711 Tokens per Sec:    15592, Lr: 0.000300\n",
            "2020-01-17 07:12:01,178 Epoch   5 Step:    11700 Batch Loss:     1.853823 Tokens per Sec:    15249, Lr: 0.000300\n",
            "2020-01-17 07:12:15,484 Epoch   5 Step:    11800 Batch Loss:     2.270781 Tokens per Sec:    15360, Lr: 0.000300\n",
            "2020-01-17 07:12:29,916 Epoch   5 Step:    11900 Batch Loss:     2.234148 Tokens per Sec:    15379, Lr: 0.000300\n",
            "2020-01-17 07:12:44,272 Epoch   5 Step:    12000 Batch Loss:     2.397540 Tokens per Sec:    15407, Lr: 0.000300\n",
            "2020-01-17 07:13:18,649 Hooray! New best validation result [ppl]!\n",
            "2020-01-17 07:13:18,649 Saving new checkpoint.\n",
            "2020-01-17 07:13:20,129 Example #0\n",
            "2020-01-17 07:13:20,130 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 07:13:20,130 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 07:13:20,130 \tHypothesis: Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ ma omai eva mai . ’\n",
            "2020-01-17 07:13:20,131 Example #1\n",
            "2020-01-17 07:13:20,131 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 07:13:20,131 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 07:13:20,132 \tHypothesis: A te lele onana evaọ Ọgwa Uvie na .\n",
            "2020-01-17 07:13:20,132 Example #2\n",
            "2020-01-17 07:13:20,133 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 07:13:20,133 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 07:13:20,133 \tHypothesis: Fikiere , o rẹ sae jọnọ ma be hae ghọghọ ẹsikpobi re ma ru lele iei ta ẹme kpahe epanọ o rrọ oware omosasọ te , inọ : “ Jọ odẹ riẹ o rọ Kristi na o jọ eva riẹ , re a rehọ odẹ riẹ kẹ ahwo erẹwho na , re a ruẹse rehọ odẹ riẹ ru ei eva were iẹe .\n",
            "2020-01-17 07:13:20,133 Example #3\n",
            "2020-01-17 07:13:20,134 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 07:13:20,134 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 07:13:20,134 \tHypothesis: Ghele na , eme nọ e rrọ oria kpobi e rẹ bọ usu okpekpe kugbe Ọghẹnẹ ga .\n",
            "2020-01-17 07:13:20,135 Validation result (greedy) at epoch   5, step    12000: bleu:  18.86, loss: 49303.0195, ppl:   6.6976, duration: 35.8623s\n",
            "2020-01-17 07:13:35,111 Epoch   5 Step:    12100 Batch Loss:     2.034586 Tokens per Sec:    14520, Lr: 0.000300\n",
            "2020-01-17 07:13:49,493 Epoch   5 Step:    12200 Batch Loss:     2.195302 Tokens per Sec:    15706, Lr: 0.000300\n",
            "2020-01-17 07:14:03,837 Epoch   5 Step:    12300 Batch Loss:     2.051769 Tokens per Sec:    15393, Lr: 0.000300\n",
            "2020-01-17 07:14:18,367 Epoch   5 Step:    12400 Batch Loss:     1.927616 Tokens per Sec:    15710, Lr: 0.000300\n",
            "2020-01-17 07:14:32,733 Epoch   5 Step:    12500 Batch Loss:     2.181639 Tokens per Sec:    15076, Lr: 0.000300\n",
            "2020-01-17 07:14:47,154 Epoch   5 Step:    12600 Batch Loss:     2.220402 Tokens per Sec:    15348, Lr: 0.000300\n",
            "2020-01-17 07:14:52,089 Epoch   5: total training loss 5246.25\n",
            "2020-01-17 07:14:52,089 EPOCH 6\n",
            "2020-01-17 07:15:01,836 Epoch   6 Step:    12700 Batch Loss:     1.878070 Tokens per Sec:    14871, Lr: 0.000300\n",
            "2020-01-17 07:15:16,159 Epoch   6 Step:    12800 Batch Loss:     1.902308 Tokens per Sec:    15183, Lr: 0.000300\n",
            "2020-01-17 07:15:30,575 Epoch   6 Step:    12900 Batch Loss:     2.407661 Tokens per Sec:    15673, Lr: 0.000300\n",
            "2020-01-17 07:15:44,935 Epoch   6 Step:    13000 Batch Loss:     1.989928 Tokens per Sec:    15570, Lr: 0.000300\n",
            "2020-01-17 07:16:19,339 Hooray! New best validation result [ppl]!\n",
            "2020-01-17 07:16:19,340 Saving new checkpoint.\n",
            "2020-01-17 07:16:21,187 Example #0\n",
            "2020-01-17 07:16:21,188 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 07:16:21,188 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 07:16:21,190 \tHypothesis: Ma rẹ sae tubẹ nọ Ọghẹnẹ ọ ‘ ma omai eva mai . ’\n",
            "2020-01-17 07:16:21,190 Example #1\n",
            "2020-01-17 07:16:21,190 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 07:16:21,190 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 07:16:21,191 \tHypothesis: Onana o jọ oware nọ Uvie na u je ru nọ Nebuka o ro whu hu .\n",
            "2020-01-17 07:16:21,191 Example #2\n",
            "2020-01-17 07:16:21,191 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 07:16:21,192 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 07:16:21,192 \tHypothesis: Fikiere , mai kpobi ma te ghọghọ kugbe eme nọ e rẹ lẹliẹ omai roro kpahe eware nọ e rẹ kẹ omosasọ gbe omosasọ gbe omosasọ nọ ma tẹ be ta nọ : “ Jọ odẹ riẹ [ Jesu Kristi ] ọ rọ kẹ owhai uvẹ re a rehọ odẹ riẹ kẹ ae , re a rehọ odẹ riẹ kẹ ae , re a jọ bẹdẹ bẹdẹ bẹdẹ ; keme a rẹ te rehọ odẹ riẹ kẹ ae .\n",
            "2020-01-17 07:16:21,192 Example #3\n",
            "2020-01-17 07:16:21,193 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 07:16:21,193 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 07:16:21,193 \tHypothesis: Ghele na , eme nọ e rẹ bọ ohwo ga e rẹ ga viere nọ ma tẹ be daoma ru udhedhẹ .\n",
            "2020-01-17 07:16:21,193 Validation result (greedy) at epoch   6, step    13000: bleu:  19.24, loss: 48429.0547, ppl:   6.4756, duration: 36.2579s\n",
            "2020-01-17 07:16:36,265 Epoch   6 Step:    13100 Batch Loss:     2.207131 Tokens per Sec:    15058, Lr: 0.000300\n",
            "2020-01-17 07:16:50,535 Epoch   6 Step:    13200 Batch Loss:     2.057076 Tokens per Sec:    15779, Lr: 0.000300\n",
            "2020-01-17 07:17:04,897 Epoch   6 Step:    13300 Batch Loss:     1.820203 Tokens per Sec:    15642, Lr: 0.000300\n",
            "2020-01-17 07:17:19,155 Epoch   6 Step:    13400 Batch Loss:     2.090955 Tokens per Sec:    15200, Lr: 0.000300\n",
            "2020-01-17 07:17:33,459 Epoch   6 Step:    13500 Batch Loss:     1.837030 Tokens per Sec:    15549, Lr: 0.000300\n",
            "2020-01-17 07:17:47,861 Epoch   6 Step:    13600 Batch Loss:     1.775589 Tokens per Sec:    15744, Lr: 0.000300\n",
            "2020-01-17 07:18:02,173 Epoch   6 Step:    13700 Batch Loss:     1.801350 Tokens per Sec:    15299, Lr: 0.000300\n",
            "2020-01-17 07:18:16,472 Epoch   6 Step:    13800 Batch Loss:     2.014063 Tokens per Sec:    15314, Lr: 0.000300\n",
            "2020-01-17 07:18:30,884 Epoch   6 Step:    13900 Batch Loss:     1.503794 Tokens per Sec:    15121, Lr: 0.000300\n",
            "2020-01-17 07:18:45,230 Epoch   6 Step:    14000 Batch Loss:     1.918795 Tokens per Sec:    15512, Lr: 0.000300\n",
            "2020-01-17 07:19:19,612 Hooray! New best validation result [ppl]!\n",
            "2020-01-17 07:19:19,612 Saving new checkpoint.\n",
            "2020-01-17 07:19:21,275 Example #0\n",
            "2020-01-17 07:19:21,277 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 07:19:21,277 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 07:19:21,277 \tHypothesis: Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ ma omai eva efuafo . ’\n",
            "2020-01-17 07:19:21,277 Example #1\n",
            "2020-01-17 07:19:21,278 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 07:19:21,278 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 07:19:21,278 \tHypothesis: Onana u lele News News !\n",
            "2020-01-17 07:19:21,278 Example #2\n",
            "2020-01-17 07:19:21,279 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 07:19:21,279 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 07:19:21,280 \tHypothesis: Fikiere , mai kpobi ma te ghọghọ gaga nọ ma tẹ be hai roro kpahe epanọ ma rẹ rọ rehọ eme nana ta kpahe epanọ o rrọ udu gbe omosasọ gbe omosasọ nọ o rrọ obe na : “ Wha jọ odẹ riẹ [ Jesu Kristi ] , re a rehọ odẹ riẹ kẹ ae , re a rehọ odẹ riẹ kẹ ae , re a ruẹse rehọ odẹ riẹ ru ei fo , re a rehọ odẹ riẹ kẹ ae .\n",
            "2020-01-17 07:19:21,280 Example #3\n",
            "2020-01-17 07:19:21,281 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 07:19:21,281 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 07:19:21,281 \tHypothesis: Ghele na , eme nọ e rẹ bọ ohwo ga nọ o tẹ be wha udhedhẹ ze .\n",
            "2020-01-17 07:19:21,281 Validation result (greedy) at epoch   6, step    14000: bleu:  20.30, loss: 47421.2500, ppl:   6.2287, duration: 36.0513s\n",
            "2020-01-17 07:19:36,338 Epoch   6 Step:    14100 Batch Loss:     1.760003 Tokens per Sec:    14600, Lr: 0.000300\n",
            "2020-01-17 07:19:50,741 Epoch   6 Step:    14200 Batch Loss:     2.286329 Tokens per Sec:    15541, Lr: 0.000300\n",
            "2020-01-17 07:20:05,115 Epoch   6 Step:    14300 Batch Loss:     1.696931 Tokens per Sec:    15366, Lr: 0.000300\n",
            "2020-01-17 07:20:19,491 Epoch   6 Step:    14400 Batch Loss:     1.880869 Tokens per Sec:    15399, Lr: 0.000300\n",
            "2020-01-17 07:20:33,906 Epoch   6 Step:    14500 Batch Loss:     2.270412 Tokens per Sec:    15576, Lr: 0.000300\n",
            "2020-01-17 07:20:48,199 Epoch   6 Step:    14600 Batch Loss:     2.246036 Tokens per Sec:    15387, Lr: 0.000300\n",
            "2020-01-17 07:21:02,554 Epoch   6 Step:    14700 Batch Loss:     2.086909 Tokens per Sec:    15299, Lr: 0.000300\n",
            "2020-01-17 07:21:16,936 Epoch   6 Step:    14800 Batch Loss:     1.599768 Tokens per Sec:    15526, Lr: 0.000300\n",
            "2020-01-17 07:21:31,315 Epoch   6 Step:    14900 Batch Loss:     1.678113 Tokens per Sec:    15616, Lr: 0.000300\n",
            "2020-01-17 07:21:45,697 Epoch   6 Step:    15000 Batch Loss:     1.837456 Tokens per Sec:    15380, Lr: 0.000300\n",
            "2020-01-17 07:22:20,172 Hooray! New best validation result [ppl]!\n",
            "2020-01-17 07:22:20,172 Saving new checkpoint.\n",
            "2020-01-17 07:22:21,614 Example #0\n",
            "2020-01-17 07:22:21,615 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 07:22:21,616 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 07:22:21,616 \tHypothesis: Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ ma omai eva efuafo . ’\n",
            "2020-01-17 07:22:21,616 Example #1\n",
            "2020-01-17 07:22:21,617 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 07:22:21,617 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 07:22:21,617 \tHypothesis: A te lele iei kpohọ Ọgwa Uvie na .\n",
            "2020-01-17 07:22:21,618 Example #2\n",
            "2020-01-17 07:22:21,618 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 07:22:21,618 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 07:22:21,619 \tHypothesis: Fikiere , mai kpobi ma te ghọghọ gaga re ma ku ẹme nana họ , jẹ ta nọ : “ Wha jọ odẹ riẹ [ Jesu Kristi ] ọ rọ kẹ ae uvẹ re a rehọ odẹ riẹ kẹ ahwo erẹwho na , re a jọ bẹdẹ ; keme a rehọ odẹ riẹ kẹ ae , re a jọ eva rai kpobi , re a jọ bẹdẹ bẹdẹ bẹdẹ .\n",
            "2020-01-17 07:22:21,619 Example #3\n",
            "2020-01-17 07:22:21,619 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 07:22:21,620 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 07:22:21,620 \tHypothesis: Ghele na , eme nọ e rẹ bọ ohwo ga e rẹ bọ udhedhẹ .\n",
            "2020-01-17 07:22:21,620 Validation result (greedy) at epoch   6, step    15000: bleu:  20.53, loss: 46672.7461, ppl:   6.0515, duration: 35.9222s\n",
            "2020-01-17 07:22:36,738 Epoch   6 Step:    15100 Batch Loss:     1.933868 Tokens per Sec:    14846, Lr: 0.000300\n",
            "2020-01-17 07:22:46,110 Epoch   6: total training loss 4994.36\n",
            "2020-01-17 07:22:46,110 EPOCH 7\n",
            "2020-01-17 07:22:51,493 Epoch   7 Step:    15200 Batch Loss:     1.692306 Tokens per Sec:    14444, Lr: 0.000300\n",
            "2020-01-17 07:23:05,957 Epoch   7 Step:    15300 Batch Loss:     1.995687 Tokens per Sec:    15700, Lr: 0.000300\n",
            "2020-01-17 07:23:20,286 Epoch   7 Step:    15400 Batch Loss:     1.742704 Tokens per Sec:    15381, Lr: 0.000300\n",
            "2020-01-17 07:23:34,687 Epoch   7 Step:    15500 Batch Loss:     2.075455 Tokens per Sec:    15266, Lr: 0.000300\n",
            "2020-01-17 07:23:49,049 Epoch   7 Step:    15600 Batch Loss:     2.289037 Tokens per Sec:    15565, Lr: 0.000300\n",
            "2020-01-17 07:24:03,505 Epoch   7 Step:    15700 Batch Loss:     1.705793 Tokens per Sec:    15459, Lr: 0.000300\n",
            "2020-01-17 07:24:17,910 Epoch   7 Step:    15800 Batch Loss:     2.128529 Tokens per Sec:    15654, Lr: 0.000300\n",
            "2020-01-17 07:24:32,338 Epoch   7 Step:    15900 Batch Loss:     2.168117 Tokens per Sec:    15459, Lr: 0.000300\n",
            "2020-01-17 07:24:46,674 Epoch   7 Step:    16000 Batch Loss:     1.854213 Tokens per Sec:    15193, Lr: 0.000300\n",
            "2020-01-17 07:25:21,092 Hooray! New best validation result [ppl]!\n",
            "2020-01-17 07:25:21,093 Saving new checkpoint.\n",
            "2020-01-17 07:25:22,924 Example #0\n",
            "2020-01-17 07:25:22,925 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 07:25:22,925 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 07:25:22,925 \tHypothesis: Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ ma omai eva efuafo . ’\n",
            "2020-01-17 07:25:22,926 Example #1\n",
            "2020-01-17 07:25:22,926 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 07:25:22,926 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 07:25:22,927 \tHypothesis: A lele onana ẹkwoma Uvie na .\n",
            "2020-01-17 07:25:22,927 Example #2\n",
            "2020-01-17 07:25:22,928 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 07:25:22,928 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 07:25:22,928 \tHypothesis: Fikiere , mai kpobi ma te ghọghọ gaga re ma ku ẹme nana họ , ma vẹ te ta kpahe epanọ o te jọ evaọ etoke oghọghọ gbe omosasọ nana : “ Odẹ [ Jesu Kristi ] ọ vẹ te jọ bẹdẹ ; keme odẹ riẹ u re ti te ai kpobi , re a ruẹse rehọ odẹ riẹ se ai ba ẹtha , re a ruẹse rehọ oruaro riẹ .\n",
            "2020-01-17 07:25:22,928 Example #3\n",
            "2020-01-17 07:25:22,929 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 07:25:22,929 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 07:25:22,929 \tHypothesis: Ghele na , eme nọ e rẹ bọ ohwo ga kpahe udhedhẹ .\n",
            "2020-01-17 07:25:22,930 Validation result (greedy) at epoch   7, step    16000: bleu:  20.92, loss: 46095.4922, ppl:   5.9182, duration: 36.2554s\n",
            "2020-01-17 07:25:37,953 Epoch   7 Step:    16100 Batch Loss:     1.792469 Tokens per Sec:    14768, Lr: 0.000300\n",
            "2020-01-17 07:25:52,239 Epoch   7 Step:    16200 Batch Loss:     1.684748 Tokens per Sec:    15233, Lr: 0.000300\n",
            "2020-01-17 07:26:06,626 Epoch   7 Step:    16300 Batch Loss:     1.698414 Tokens per Sec:    15358, Lr: 0.000300\n",
            "2020-01-17 07:26:21,045 Epoch   7 Step:    16400 Batch Loss:     2.265721 Tokens per Sec:    15773, Lr: 0.000300\n",
            "2020-01-17 07:26:35,410 Epoch   7 Step:    16500 Batch Loss:     1.860672 Tokens per Sec:    15229, Lr: 0.000300\n",
            "2020-01-17 07:26:49,778 Epoch   7 Step:    16600 Batch Loss:     1.854210 Tokens per Sec:    15152, Lr: 0.000300\n",
            "2020-01-17 07:27:04,193 Epoch   7 Step:    16700 Batch Loss:     1.806854 Tokens per Sec:    15433, Lr: 0.000300\n",
            "2020-01-17 07:27:18,623 Epoch   7 Step:    16800 Batch Loss:     1.671356 Tokens per Sec:    15365, Lr: 0.000300\n",
            "2020-01-17 07:27:32,998 Epoch   7 Step:    16900 Batch Loss:     1.769432 Tokens per Sec:    15425, Lr: 0.000300\n",
            "2020-01-17 07:27:47,314 Epoch   7 Step:    17000 Batch Loss:     2.138923 Tokens per Sec:    15317, Lr: 0.000300\n",
            "2020-01-17 07:28:21,640 Hooray! New best validation result [ppl]!\n",
            "2020-01-17 07:28:21,641 Saving new checkpoint.\n",
            "2020-01-17 07:28:23,116 Example #0\n",
            "2020-01-17 07:28:23,117 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 07:28:23,117 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 07:28:23,117 \tHypothesis: Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ ma omai eva efuafo . ’\n",
            "2020-01-17 07:28:23,118 Example #1\n",
            "2020-01-17 07:28:23,118 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 07:28:23,119 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 07:28:23,119 \tHypothesis: A lele onana ẹkwoma Uvie na nọ a re se News Avivẹ na .\n",
            "2020-01-17 07:28:23,119 Example #2\n",
            "2020-01-17 07:28:23,124 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 07:28:23,124 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 07:28:23,124 \tHypothesis: Fikiere , mai kpobi ma te ghọghọ fiki epanọ ma re ro ku ẹme nana họ , jẹ kẹ uyere - okẹ nana : “ Jọ odẹ riẹ [ Jesu Kristi ] o dhesẹ odẹ riẹ via , re ma rehọ odẹ riẹ kẹ ae , re a jọ ahwo erẹwho kpobi a jọ eva riẹ , re a jọ odẹ riẹ se ai ba ẹkẹ ae , re a jọ ahwo erẹwho kpobi a jọ bẹdẹ bẹdẹ bẹdẹ bẹdẹ .\n",
            "2020-01-17 07:28:23,124 Example #3\n",
            "2020-01-17 07:28:23,125 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 07:28:23,125 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 07:28:23,125 \tHypothesis: Ghele na , eme efuafo e rrọ ẹgba nọ a re ro ru udhedhẹ .\n",
            "2020-01-17 07:28:23,126 Validation result (greedy) at epoch   7, step    17000: bleu:  21.97, loss: 45379.9922, ppl:   5.7571, duration: 35.8113s\n",
            "2020-01-17 07:28:38,214 Epoch   7 Step:    17100 Batch Loss:     1.976770 Tokens per Sec:    15137, Lr: 0.000300\n",
            "2020-01-17 07:28:52,585 Epoch   7 Step:    17200 Batch Loss:     1.850822 Tokens per Sec:    15000, Lr: 0.000300\n",
            "2020-01-17 07:29:06,965 Epoch   7 Step:    17300 Batch Loss:     1.964521 Tokens per Sec:    15695, Lr: 0.000300\n",
            "2020-01-17 07:29:21,418 Epoch   7 Step:    17400 Batch Loss:     1.868849 Tokens per Sec:    15180, Lr: 0.000300\n",
            "2020-01-17 07:29:35,829 Epoch   7 Step:    17500 Batch Loss:     1.297507 Tokens per Sec:    15458, Lr: 0.000300\n",
            "2020-01-17 07:29:50,273 Epoch   7 Step:    17600 Batch Loss:     1.859442 Tokens per Sec:    15314, Lr: 0.000300\n",
            "2020-01-17 07:30:04,371 Epoch   7: total training loss 4810.77\n",
            "2020-01-17 07:30:04,372 EPOCH 8\n",
            "2020-01-17 07:30:04,978 Epoch   8 Step:    17700 Batch Loss:     1.870227 Tokens per Sec:     8177, Lr: 0.000300\n",
            "2020-01-17 07:30:19,366 Epoch   8 Step:    17800 Batch Loss:     2.000308 Tokens per Sec:    15302, Lr: 0.000300\n",
            "2020-01-17 07:30:33,713 Epoch   8 Step:    17900 Batch Loss:     2.052570 Tokens per Sec:    15487, Lr: 0.000300\n",
            "2020-01-17 07:30:48,087 Epoch   8 Step:    18000 Batch Loss:     2.316086 Tokens per Sec:    15478, Lr: 0.000300\n",
            "2020-01-17 07:31:22,472 Hooray! New best validation result [ppl]!\n",
            "2020-01-17 07:31:22,472 Saving new checkpoint.\n",
            "2020-01-17 07:31:23,900 Example #0\n",
            "2020-01-17 07:31:23,901 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 07:31:23,901 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 07:31:23,901 \tHypothesis: Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ ma omai eva efuafo . ’\n",
            "2020-01-17 07:31:23,902 Example #1\n",
            "2020-01-17 07:31:23,902 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 07:31:23,902 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 07:31:23,903 \tHypothesis: A te lele onana ẹkwoma Uvie na nọ a re se News .\n",
            "2020-01-17 07:31:23,903 Example #2\n",
            "2020-01-17 07:31:23,904 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 07:31:23,904 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 07:31:23,904 \tHypothesis: Fikiere , mai kpobi ma te ghọghọ avọ oghọghọ nọ ma te roro kpahe ẹme nana gbe omosasọ nọ o rrọ eva mai : “ Jọ odẹ riẹ [ Jesu Kristi ] o dikihẹ kẹ odẹ riẹ , re o jọ bẹdẹ bẹdẹ , re ma ruẹse jọ eva riẹ , jọ eva odẹ riẹ , jọ o jọ eva riẹ kpobi , wha jọ eva riẹ se ai .\n",
            "2020-01-17 07:31:23,904 Example #3\n",
            "2020-01-17 07:31:23,905 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 07:31:23,905 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 07:31:23,905 \tHypothesis: Ghele na , eme nọ e rẹ bọ ohwo ga e rẹ ga viere re ma sae jọ udhedhẹ .\n",
            "2020-01-17 07:31:23,906 Validation result (greedy) at epoch   8, step    18000: bleu:  21.41, loss: 44758.8477, ppl:   5.6208, duration: 35.8179s\n",
            "2020-01-17 07:31:38,932 Epoch   8 Step:    18100 Batch Loss:     1.750051 Tokens per Sec:    14934, Lr: 0.000300\n",
            "2020-01-17 07:31:53,231 Epoch   8 Step:    18200 Batch Loss:     2.009067 Tokens per Sec:    15030, Lr: 0.000300\n",
            "2020-01-17 07:32:07,583 Epoch   8 Step:    18300 Batch Loss:     1.335822 Tokens per Sec:    15298, Lr: 0.000300\n",
            "2020-01-17 07:32:21,932 Epoch   8 Step:    18400 Batch Loss:     1.979069 Tokens per Sec:    15375, Lr: 0.000300\n",
            "2020-01-17 07:32:36,313 Epoch   8 Step:    18500 Batch Loss:     1.864417 Tokens per Sec:    15366, Lr: 0.000300\n",
            "2020-01-17 07:32:50,718 Epoch   8 Step:    18600 Batch Loss:     1.711307 Tokens per Sec:    15654, Lr: 0.000300\n",
            "2020-01-17 07:33:05,072 Epoch   8 Step:    18700 Batch Loss:     1.823726 Tokens per Sec:    15729, Lr: 0.000300\n",
            "2020-01-17 07:33:19,521 Epoch   8 Step:    18800 Batch Loss:     1.739027 Tokens per Sec:    15799, Lr: 0.000300\n",
            "2020-01-17 07:33:33,904 Epoch   8 Step:    18900 Batch Loss:     1.779577 Tokens per Sec:    15610, Lr: 0.000300\n",
            "2020-01-17 07:33:48,331 Epoch   8 Step:    19000 Batch Loss:     1.940897 Tokens per Sec:    15597, Lr: 0.000300\n",
            "2020-01-17 07:34:22,766 Hooray! New best validation result [ppl]!\n",
            "2020-01-17 07:34:22,767 Saving new checkpoint.\n",
            "2020-01-17 07:34:24,606 Example #0\n",
            "2020-01-17 07:34:24,607 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 07:34:24,607 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 07:34:24,608 \tHypothesis: Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ ma omai eva efuafo . ’\n",
            "2020-01-17 07:34:24,608 Example #1\n",
            "2020-01-17 07:34:24,609 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 07:34:24,609 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 07:34:24,609 \tHypothesis: Onana u lele i rie , Usi Uvie na o tẹ te jọ họ .\n",
            "2020-01-17 07:34:24,609 Example #2\n",
            "2020-01-17 07:34:24,610 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 07:34:24,610 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 07:34:24,610 \tHypothesis: Fikiere , mai kpobi ma te ghọghọ te epanọ ma re ro ku ẹme nana họ , je ku ei họ avọ omosasọ nọ o rrọ obe na : “ Jọ odẹ riẹ [ Jesu Kristi ] , re ma jọ bẹdẹ , re ma ruẹse jọ odẹ riẹ , re odẹ riẹ o jọ bẹdẹ bẹdẹ ; re ma ruẹse jọ eva odẹ riẹ , re a ruẹse rehọ odẹ riẹ se ai ba ẹkẹ ae , re a ruẹse se odẹ riẹ ba ẹkẹ ae .\n",
            "2020-01-17 07:34:24,611 Example #3\n",
            "2020-01-17 07:34:24,612 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 07:34:24,612 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 07:34:24,612 \tHypothesis: Ghele na , eme nọ a rẹ rọ ta ẹme na e rẹ bọ ohwo ga evaọ udhedhẹ .\n",
            "2020-01-17 07:34:24,612 Validation result (greedy) at epoch   8, step    19000: bleu:  22.14, loss: 44534.3672, ppl:   5.5723, duration: 36.2811s\n",
            "2020-01-17 07:34:39,697 Epoch   8 Step:    19100 Batch Loss:     2.065755 Tokens per Sec:    14606, Lr: 0.000300\n",
            "2020-01-17 07:34:54,156 Epoch   8 Step:    19200 Batch Loss:     1.925221 Tokens per Sec:    15225, Lr: 0.000300\n",
            "2020-01-17 07:35:08,577 Epoch   8 Step:    19300 Batch Loss:     1.780986 Tokens per Sec:    15871, Lr: 0.000300\n",
            "2020-01-17 07:35:22,897 Epoch   8 Step:    19400 Batch Loss:     1.723542 Tokens per Sec:    15185, Lr: 0.000300\n",
            "2020-01-17 07:35:37,204 Epoch   8 Step:    19500 Batch Loss:     1.935210 Tokens per Sec:    15468, Lr: 0.000300\n",
            "2020-01-17 07:35:51,580 Epoch   8 Step:    19600 Batch Loss:     1.583041 Tokens per Sec:    15303, Lr: 0.000300\n",
            "2020-01-17 07:36:05,863 Epoch   8 Step:    19700 Batch Loss:     1.972107 Tokens per Sec:    15621, Lr: 0.000300\n",
            "2020-01-17 07:36:20,272 Epoch   8 Step:    19800 Batch Loss:     1.536856 Tokens per Sec:    15872, Lr: 0.000300\n",
            "2020-01-17 07:36:34,678 Epoch   8 Step:    19900 Batch Loss:     1.682351 Tokens per Sec:    15660, Lr: 0.000300\n",
            "2020-01-17 07:36:48,950 Epoch   8 Step:    20000 Batch Loss:     1.338513 Tokens per Sec:    15411, Lr: 0.000300\n",
            "2020-01-17 07:37:23,218 Example #0\n",
            "2020-01-17 07:37:23,219 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 07:37:23,219 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 07:37:23,219 \tHypothesis: Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ ma omai eva efuafo . ’\n",
            "2020-01-17 07:37:23,220 Example #1\n",
            "2020-01-17 07:37:23,220 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 07:37:23,221 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 07:37:23,221 \tHypothesis: Onana u lele i rie , Egwa Uvie o gbẹ jọ ere he .\n",
            "2020-01-17 07:37:23,221 Example #2\n",
            "2020-01-17 07:37:23,222 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 07:37:23,222 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 07:37:23,222 \tHypothesis: Fikiere , mai kpobi ma te ghọghọ avọ oghọghọ nọ ma te rọ rehọ eme nana ku ẹme na gbe omosasọ nọ o wo no : “ Jọ odẹ [ Jesu Kristi ] ọ rọ kẹ ae bẹdẹ , re a jọ bẹdẹ bẹdẹ , re a jọ bẹdẹ bẹdẹ evaọ aro riẹ , re a jọ bẹdẹ bẹdẹ bẹdẹ .\n",
            "2020-01-17 07:37:23,222 Example #3\n",
            "2020-01-17 07:37:23,223 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 07:37:23,223 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 07:37:23,223 \tHypothesis: Ghele na , eme ọ ọgbakugbe e rẹ bọ udhedhẹ .\n",
            "2020-01-17 07:37:23,224 Validation result (greedy) at epoch   8, step    20000: bleu:  20.87, loss: 44845.1367, ppl:   5.6395, duration: 34.2734s\n",
            "2020-01-17 07:37:37,672 Epoch   8 Step:    20100 Batch Loss:     1.491475 Tokens per Sec:    15481, Lr: 0.000300\n",
            "2020-01-17 07:37:52,084 Epoch   8 Step:    20200 Batch Loss:     1.854671 Tokens per Sec:    15434, Lr: 0.000300\n",
            "2020-01-17 07:37:55,541 Epoch   8: total training loss 4644.24\n",
            "2020-01-17 07:37:55,541 EPOCH 9\n",
            "2020-01-17 07:38:06,781 Epoch   9 Step:    20300 Batch Loss:     1.564389 Tokens per Sec:    15120, Lr: 0.000300\n",
            "2020-01-17 07:38:21,081 Epoch   9 Step:    20400 Batch Loss:     1.861674 Tokens per Sec:    14981, Lr: 0.000300\n",
            "2020-01-17 07:38:35,510 Epoch   9 Step:    20500 Batch Loss:     1.616742 Tokens per Sec:    15901, Lr: 0.000300\n",
            "2020-01-17 07:38:49,916 Epoch   9 Step:    20600 Batch Loss:     1.927590 Tokens per Sec:    15885, Lr: 0.000300\n",
            "2020-01-17 07:39:04,303 Epoch   9 Step:    20700 Batch Loss:     1.602979 Tokens per Sec:    15278, Lr: 0.000300\n",
            "2020-01-17 07:39:18,583 Epoch   9 Step:    20800 Batch Loss:     1.891675 Tokens per Sec:    15285, Lr: 0.000300\n",
            "2020-01-17 07:39:32,927 Epoch   9 Step:    20900 Batch Loss:     2.102910 Tokens per Sec:    15609, Lr: 0.000300\n",
            "2020-01-17 07:39:47,323 Epoch   9 Step:    21000 Batch Loss:     1.241261 Tokens per Sec:    15266, Lr: 0.000300\n",
            "2020-01-17 07:40:21,758 Hooray! New best validation result [ppl]!\n",
            "2020-01-17 07:40:21,759 Saving new checkpoint.\n",
            "2020-01-17 07:40:23,203 Example #0\n",
            "2020-01-17 07:40:23,204 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 07:40:23,204 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 07:40:23,205 \tHypothesis: Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ ma omai eva efuafo . ’\n",
            "2020-01-17 07:40:23,205 Example #1\n",
            "2020-01-17 07:40:23,205 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 07:40:23,206 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 07:40:23,206 \tHypothesis: A lele onana ẹkwoma Uvie na ha .\n",
            "2020-01-17 07:40:23,206 Example #2\n",
            "2020-01-17 07:40:23,207 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 07:40:23,207 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 07:40:23,207 \tHypothesis: Fikiere , mai kpobi ma te ghọghọ avọ oghọghọ nọ ma te ta ẹme te evaọ ẹme araha nana , onọ o rrọ ukuoriọ gbe omosasọ nọ o rrọ obe na : “ Jọ odẹ riẹ nọ Jesu Kristi Ovie na o dhesẹ kẹ ae , re a ruẹse rehọ odẹ riẹ kẹ ae , re a ruẹse rehọ odẹ riẹ kẹ ae , re a ruẹse riẹ , a wo evawere .\n",
            "2020-01-17 07:40:23,208 Example #3\n",
            "2020-01-17 07:40:23,208 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 07:40:23,209 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 07:40:23,209 \tHypothesis: Ghele na , eme nọ a rẹ ta e rẹ jọ gaga re a wo udhedhẹ .\n",
            "2020-01-17 07:40:23,209 Validation result (greedy) at epoch   9, step    21000: bleu:  23.31, loss: 43438.2578, ppl:   5.3417, duration: 35.8857s\n",
            "2020-01-17 07:40:38,230 Epoch   9 Step:    21100 Batch Loss:     1.790817 Tokens per Sec:    14993, Lr: 0.000300\n",
            "2020-01-17 07:40:52,659 Epoch   9 Step:    21200 Batch Loss:     1.412687 Tokens per Sec:    15776, Lr: 0.000300\n",
            "2020-01-17 07:41:07,036 Epoch   9 Step:    21300 Batch Loss:     2.024498 Tokens per Sec:    15262, Lr: 0.000300\n",
            "2020-01-17 07:41:21,453 Epoch   9 Step:    21400 Batch Loss:     1.706428 Tokens per Sec:    15561, Lr: 0.000300\n",
            "2020-01-17 07:41:35,767 Epoch   9 Step:    21500 Batch Loss:     1.731229 Tokens per Sec:    15016, Lr: 0.000300\n",
            "2020-01-17 07:41:50,103 Epoch   9 Step:    21600 Batch Loss:     1.942572 Tokens per Sec:    15573, Lr: 0.000300\n",
            "2020-01-17 07:42:04,513 Epoch   9 Step:    21700 Batch Loss:     1.692850 Tokens per Sec:    15601, Lr: 0.000300\n",
            "2020-01-17 07:42:18,842 Epoch   9 Step:    21800 Batch Loss:     1.867998 Tokens per Sec:    15716, Lr: 0.000300\n",
            "2020-01-17 07:42:33,153 Epoch   9 Step:    21900 Batch Loss:     1.260193 Tokens per Sec:    15205, Lr: 0.000300\n",
            "2020-01-17 07:42:47,495 Epoch   9 Step:    22000 Batch Loss:     1.764315 Tokens per Sec:    15684, Lr: 0.000300\n",
            "2020-01-17 07:43:21,895 Hooray! New best validation result [ppl]!\n",
            "2020-01-17 07:43:21,895 Saving new checkpoint.\n",
            "2020-01-17 07:43:23,344 Example #0\n",
            "2020-01-17 07:43:23,344 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 07:43:23,345 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 07:43:23,345 \tHypothesis: Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ ma omai eva efuafo . ’\n",
            "2020-01-17 07:43:23,345 Example #1\n",
            "2020-01-17 07:43:23,346 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 07:43:23,346 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 07:43:23,348 \tHypothesis: A te lele onana ẹkwoma News Ogbẹgwae Uwou - Owhuowhu na ha .\n",
            "2020-01-17 07:43:23,351 Example #2\n",
            "2020-01-17 07:43:23,352 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 07:43:23,352 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 07:43:23,353 \tHypothesis: Fikiere , mai kpobi ma te ghọghọ avọ oghọghọ nọ ma te roro kpahe ẹme nana , onọ u ti ru omai wo omosasọ nọ ma te bi ro se odẹ Jesu Kristi na , re ma ruẹse rehọ odẹ riẹ kẹ ae , jọ a ru ai wo evawere , jẹ rọ ere wo evawere .\n",
            "2020-01-17 07:43:23,353 Example #3\n",
            "2020-01-17 07:43:23,353 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 07:43:23,354 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 07:43:23,354 \tHypothesis: Ghele na , eme ọ ọgbahọ e rẹ ga re ohwo ọ sai ru udhedhẹ .\n",
            "2020-01-17 07:43:23,354 Validation result (greedy) at epoch   9, step    22000: bleu:  22.98, loss: 43037.9922, ppl:   5.2598, duration: 35.8585s\n",
            "2020-01-17 07:43:38,464 Epoch   9 Step:    22100 Batch Loss:     1.780499 Tokens per Sec:    15073, Lr: 0.000300\n",
            "2020-01-17 07:43:52,825 Epoch   9 Step:    22200 Batch Loss:     1.737947 Tokens per Sec:    15507, Lr: 0.000300\n",
            "2020-01-17 07:44:07,256 Epoch   9 Step:    22300 Batch Loss:     1.602637 Tokens per Sec:    15406, Lr: 0.000300\n",
            "2020-01-17 07:44:21,554 Epoch   9 Step:    22400 Batch Loss:     1.853768 Tokens per Sec:    15308, Lr: 0.000300\n",
            "2020-01-17 07:44:35,855 Epoch   9 Step:    22500 Batch Loss:     1.911700 Tokens per Sec:    15653, Lr: 0.000300\n",
            "2020-01-17 07:44:50,186 Epoch   9 Step:    22600 Batch Loss:     1.718155 Tokens per Sec:    15331, Lr: 0.000300\n",
            "2020-01-17 07:45:04,522 Epoch   9 Step:    22700 Batch Loss:     1.862265 Tokens per Sec:    15542, Lr: 0.000300\n",
            "2020-01-17 07:45:11,728 Epoch   9: total training loss 4519.45\n",
            "2020-01-17 07:45:11,729 EPOCH 10\n",
            "2020-01-17 07:45:19,200 Epoch  10 Step:    22800 Batch Loss:     1.777820 Tokens per Sec:    14736, Lr: 0.000300\n",
            "2020-01-17 07:45:33,616 Epoch  10 Step:    22900 Batch Loss:     1.609916 Tokens per Sec:    15735, Lr: 0.000300\n",
            "2020-01-17 07:45:47,966 Epoch  10 Step:    23000 Batch Loss:     1.924288 Tokens per Sec:    15518, Lr: 0.000300\n",
            "2020-01-17 07:46:22,357 Hooray! New best validation result [ppl]!\n",
            "2020-01-17 07:46:22,357 Saving new checkpoint.\n",
            "2020-01-17 07:46:24,251 Example #0\n",
            "2020-01-17 07:46:24,252 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 07:46:24,252 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 07:46:24,253 \tHypothesis: Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ ma omai eva efuafo . ’\n",
            "2020-01-17 07:46:24,253 Example #1\n",
            "2020-01-17 07:46:24,253 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 07:46:24,254 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 07:46:24,254 \tHypothesis: A te lele onana ẹkwoma Usi Uvie na .\n",
            "2020-01-17 07:46:24,254 Example #2\n",
            "2020-01-17 07:46:24,255 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 07:46:24,255 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 07:46:24,255 \tHypothesis: Fikiere , mai kpobi ma te ghọghọ avọ evawere nọ ma te ta ẹme te evaọ ẹme nana , onọ o rẹ kẹ omosasọ gbe omosasọ : “ Jọ odẹ riẹ [ Jesu Kristi na ] o dhesẹ nọ oke o rẹ te tha , re a jọ bẹdẹ bẹdẹ , re a ruẹse riẹ odẹ riẹ o jọ eva aro riẹ , wha jọ eva e were ae kpobi , wha rẹ te riẹ , wha rẹ te jọ eva e riẹ , wha oghale se ai kpobi , wha rẹ te riẹ , wha rẹ te riẹ o\n",
            "2020-01-17 07:46:24,255 Example #3\n",
            "2020-01-17 07:46:24,256 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 07:46:24,256 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 07:46:24,256 \tHypothesis: Ghele na , eme egbagba e rẹ bọ ẹgba ga re a ru udhedhẹ .\n",
            "2020-01-17 07:46:24,257 Validation result (greedy) at epoch  10, step    23000: bleu:  23.76, loss: 42851.0586, ppl:   5.2220, duration: 36.2901s\n",
            "2020-01-17 07:46:39,245 Epoch  10 Step:    23100 Batch Loss:     1.940218 Tokens per Sec:    14869, Lr: 0.000300\n",
            "2020-01-17 07:46:53,573 Epoch  10 Step:    23200 Batch Loss:     1.808261 Tokens per Sec:    15195, Lr: 0.000300\n",
            "2020-01-17 07:47:07,968 Epoch  10 Step:    23300 Batch Loss:     1.571756 Tokens per Sec:    15349, Lr: 0.000300\n",
            "2020-01-17 07:47:22,324 Epoch  10 Step:    23400 Batch Loss:     1.853035 Tokens per Sec:    15383, Lr: 0.000300\n",
            "2020-01-17 07:47:36,717 Epoch  10 Step:    23500 Batch Loss:     1.317126 Tokens per Sec:    15386, Lr: 0.000300\n",
            "2020-01-17 07:47:51,078 Epoch  10 Step:    23600 Batch Loss:     1.655016 Tokens per Sec:    15184, Lr: 0.000300\n",
            "2020-01-17 07:48:05,542 Epoch  10 Step:    23700 Batch Loss:     1.784282 Tokens per Sec:    15492, Lr: 0.000300\n",
            "2020-01-17 07:48:19,947 Epoch  10 Step:    23800 Batch Loss:     1.688318 Tokens per Sec:    15539, Lr: 0.000300\n",
            "2020-01-17 07:48:34,306 Epoch  10 Step:    23900 Batch Loss:     1.993060 Tokens per Sec:    15742, Lr: 0.000300\n",
            "2020-01-17 07:48:48,693 Epoch  10 Step:    24000 Batch Loss:     1.706690 Tokens per Sec:    15720, Lr: 0.000300\n",
            "2020-01-17 07:49:23,116 Hooray! New best validation result [ppl]!\n",
            "2020-01-17 07:49:23,116 Saving new checkpoint.\n",
            "2020-01-17 07:49:24,574 Example #0\n",
            "2020-01-17 07:49:24,575 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 07:49:24,575 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 07:49:24,575 \tHypothesis: Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ ma omai eva efuafo . ’\n",
            "2020-01-17 07:49:24,575 Example #1\n",
            "2020-01-17 07:49:24,576 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 07:49:24,576 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 07:49:24,576 \tHypothesis: A lele onana ẹkwoma News News ha .\n",
            "2020-01-17 07:49:24,577 Example #2\n",
            "2020-01-17 07:49:24,578 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 07:49:24,578 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 07:49:24,578 \tHypothesis: Fikiere , mai kpobi ma vẹ te ghọghọ avọ oghọghọ nọ ma te roro kpahe ẹme nana nọ o no rie ze na , onọ o rẹ kẹ omai evawere : “ Jọ odẹ riẹ [ Ovie na ] o jọ bẹdẹ bẹdẹ re o jọ bẹdẹ bẹdẹ ; re ma ruẹse jọ bẹdẹ bẹdẹ bẹdẹ , re a ruẹse rehọ odẹ riẹ kẹ ae , re a jọ eva riẹ ru ai eva were iẹe .\n",
            "2020-01-17 07:49:24,578 Example #3\n",
            "2020-01-17 07:49:24,579 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 07:49:24,579 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 07:49:24,580 \tHypothesis: Ghele na , eme ọ ọgbahọ e rẹ jọ gaga re a ru udhedhẹ .\n",
            "2020-01-17 07:49:24,580 Validation result (greedy) at epoch  10, step    24000: bleu:  23.38, loss: 42324.0977, ppl:   5.1170, duration: 35.8864s\n",
            "2020-01-17 07:49:39,729 Epoch  10 Step:    24100 Batch Loss:     1.979996 Tokens per Sec:    15181, Lr: 0.000300\n",
            "2020-01-17 07:49:54,135 Epoch  10 Step:    24200 Batch Loss:     1.640250 Tokens per Sec:    15341, Lr: 0.000300\n",
            "2020-01-17 07:50:08,518 Epoch  10 Step:    24300 Batch Loss:     1.491750 Tokens per Sec:    15215, Lr: 0.000300\n",
            "2020-01-17 07:50:22,896 Epoch  10 Step:    24400 Batch Loss:     1.789947 Tokens per Sec:    15174, Lr: 0.000300\n",
            "2020-01-17 07:50:37,265 Epoch  10 Step:    24500 Batch Loss:     1.423314 Tokens per Sec:    15176, Lr: 0.000300\n",
            "2020-01-17 07:50:51,667 Epoch  10 Step:    24600 Batch Loss:     1.785535 Tokens per Sec:    15601, Lr: 0.000300\n",
            "2020-01-17 07:51:06,040 Epoch  10 Step:    24700 Batch Loss:     1.955082 Tokens per Sec:    15822, Lr: 0.000300\n",
            "2020-01-17 07:51:20,486 Epoch  10 Step:    24800 Batch Loss:     1.807536 Tokens per Sec:    15471, Lr: 0.000300\n",
            "2020-01-17 07:51:34,892 Epoch  10 Step:    24900 Batch Loss:     1.955148 Tokens per Sec:    15492, Lr: 0.000300\n",
            "2020-01-17 07:51:49,214 Epoch  10 Step:    25000 Batch Loss:     1.673037 Tokens per Sec:    15390, Lr: 0.000300\n",
            "2020-01-17 07:52:23,643 Hooray! New best validation result [ppl]!\n",
            "2020-01-17 07:52:23,643 Saving new checkpoint.\n",
            "2020-01-17 07:52:25,103 Example #0\n",
            "2020-01-17 07:52:25,104 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 07:52:25,104 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 07:52:25,104 \tHypothesis: Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ ma omai eva efuafo . ’\n",
            "2020-01-17 07:52:25,104 Example #1\n",
            "2020-01-17 07:52:25,105 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 07:52:25,105 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 07:52:25,106 \tHypothesis: A te lele onana ẹkwoma Usi Uvie na .\n",
            "2020-01-17 07:52:25,106 Example #2\n",
            "2020-01-17 07:52:25,106 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 07:52:25,107 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 07:52:25,107 \tHypothesis: Fikiere , mai kpobi ma te ghọghọ avọ oghọghọ nọ ma te roro kpahe ẹme nana nọ o no obọ ahwo ze , onọ u re ru omai wo evawere kpahe odẹ riẹ : “ Jọ odẹ [ Jesu Kristi na ] o jọ bẹdẹ bẹdẹ , re ma ruẹse jọ bẹdẹ bẹdẹ , re odẹ riẹ o jọ bẹdẹ bẹdẹ , re o jọ odẹ riẹ o jọ bẹdẹ bẹdẹ , re o jọ odẹ riẹ o jọ eva riẹ , re ti wo oghale kẹ ahwo erẹwho kpobi , re a wo oghale , a wo oghale riẹ\n",
            "2020-01-17 07:52:25,107 Example #3\n",
            "2020-01-17 07:52:25,108 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 07:52:25,108 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 07:52:25,108 \tHypothesis: Ghele na , eme nọ a rẹ rọ ta usiuwoma na e rẹ bọ ohwo ga nọ o te bi ru udhedhẹ .\n",
            "2020-01-17 07:52:25,109 Validation result (greedy) at epoch  10, step    25000: bleu:  24.11, loss: 41840.8594, ppl:   5.0225, duration: 35.8942s\n",
            "2020-01-17 07:52:40,122 Epoch  10 Step:    25100 Batch Loss:     1.830938 Tokens per Sec:    15106, Lr: 0.000300\n",
            "2020-01-17 07:52:54,529 Epoch  10 Step:    25200 Batch Loss:     1.835977 Tokens per Sec:    15432, Lr: 0.000300\n",
            "2020-01-17 07:53:05,574 Epoch  10: total training loss 4405.64\n",
            "2020-01-17 07:53:05,574 EPOCH 11\n",
            "2020-01-17 07:53:09,202 Epoch  11 Step:    25300 Batch Loss:     1.814390 Tokens per Sec:    13081, Lr: 0.000300\n",
            "2020-01-17 07:53:23,593 Epoch  11 Step:    25400 Batch Loss:     1.935710 Tokens per Sec:    15384, Lr: 0.000300\n",
            "2020-01-17 07:53:37,968 Epoch  11 Step:    25500 Batch Loss:     1.333288 Tokens per Sec:    15375, Lr: 0.000300\n",
            "2020-01-17 07:53:52,371 Epoch  11 Step:    25600 Batch Loss:     1.785686 Tokens per Sec:    15626, Lr: 0.000300\n",
            "2020-01-17 07:54:06,725 Epoch  11 Step:    25700 Batch Loss:     1.586648 Tokens per Sec:    15848, Lr: 0.000300\n",
            "2020-01-17 07:54:21,094 Epoch  11 Step:    25800 Batch Loss:     1.581756 Tokens per Sec:    15199, Lr: 0.000300\n",
            "2020-01-17 07:54:35,435 Epoch  11 Step:    25900 Batch Loss:     1.634597 Tokens per Sec:    15184, Lr: 0.000300\n",
            "2020-01-17 07:54:49,773 Epoch  11 Step:    26000 Batch Loss:     1.682464 Tokens per Sec:    15257, Lr: 0.000300\n",
            "2020-01-17 07:55:24,245 Example #0\n",
            "2020-01-17 07:55:24,246 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 07:55:24,247 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 07:55:24,247 \tHypothesis: Ma rẹ sae yare Ọghẹnẹ re ọ ‘ ma omai eva efuafo . ’\n",
            "2020-01-17 07:55:24,247 Example #1\n",
            "2020-01-17 07:55:24,248 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 07:55:24,248 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 07:55:24,248 \tHypothesis: A lele onana lele usi Uvie na ha .\n",
            "2020-01-17 07:55:24,248 Example #2\n",
            "2020-01-17 07:55:24,249 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 07:55:24,249 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 07:55:24,250 \tHypothesis: Fikiere , mai kpobi ma vẹ te ghọghọ avọ oghọghọ nọ ma te roro kpahe ẹme nọ o re ro ku ẹme na họ , je ku ẹme nọ o re no obọ riẹ ze : “ Jọ odẹ riẹ [ Ovie na ] o dhesẹ odẹ riẹ via bẹdẹ bẹdẹ ; re odẹ riẹ o jọ bẹdẹ , re a ruẹse ghale ae ; keme odẹ riẹ o rẹ te jọ eva riẹ .\n",
            "2020-01-17 07:55:24,250 Example #3\n",
            "2020-01-17 07:55:24,251 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 07:55:24,251 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 07:55:24,251 \tHypothesis: Ghele na , eme nọ a rẹ jẹrehọ e rẹ jọ ẹgba ologbo kẹ udhedhẹ .\n",
            "2020-01-17 07:55:24,251 Validation result (greedy) at epoch  11, step    26000: bleu:  24.45, loss: 41932.9258, ppl:   5.0403, duration: 34.4781s\n",
            "2020-01-17 07:55:38,772 Epoch  11 Step:    26100 Batch Loss:     1.839818 Tokens per Sec:    15389, Lr: 0.000300\n",
            "2020-01-17 07:55:53,105 Epoch  11 Step:    26200 Batch Loss:     1.440989 Tokens per Sec:    15189, Lr: 0.000300\n",
            "2020-01-17 07:56:07,450 Epoch  11 Step:    26300 Batch Loss:     2.306305 Tokens per Sec:    15469, Lr: 0.000300\n",
            "2020-01-17 07:56:21,807 Epoch  11 Step:    26400 Batch Loss:     1.606519 Tokens per Sec:    15471, Lr: 0.000300\n",
            "2020-01-17 07:56:36,122 Epoch  11 Step:    26500 Batch Loss:     1.656855 Tokens per Sec:    15013, Lr: 0.000300\n",
            "2020-01-17 07:56:50,479 Epoch  11 Step:    26600 Batch Loss:     1.692122 Tokens per Sec:    15474, Lr: 0.000300\n",
            "2020-01-17 07:57:04,882 Epoch  11 Step:    26700 Batch Loss:     1.777658 Tokens per Sec:    15701, Lr: 0.000300\n",
            "2020-01-17 07:57:19,200 Epoch  11 Step:    26800 Batch Loss:     1.864217 Tokens per Sec:    15675, Lr: 0.000300\n",
            "2020-01-17 07:57:33,509 Epoch  11 Step:    26900 Batch Loss:     1.823481 Tokens per Sec:    15602, Lr: 0.000300\n",
            "2020-01-17 07:57:47,775 Epoch  11 Step:    27000 Batch Loss:     1.798989 Tokens per Sec:    15618, Lr: 0.000300\n",
            "2020-01-17 07:58:22,028 Hooray! New best validation result [ppl]!\n",
            "2020-01-17 07:58:22,029 Saving new checkpoint.\n",
            "2020-01-17 07:58:23,507 Example #0\n",
            "2020-01-17 07:58:23,508 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 07:58:23,508 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 07:58:23,508 \tHypothesis: Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ ma omai eva efuafo . ’\n",
            "2020-01-17 07:58:23,509 Example #1\n",
            "2020-01-17 07:58:23,509 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 07:58:23,509 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 07:58:23,510 \tHypothesis: A lele onana ẹkwoma News News ha .\n",
            "2020-01-17 07:58:23,510 Example #2\n",
            "2020-01-17 07:58:23,511 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 07:58:23,511 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 07:58:23,511 \tHypothesis: Fikiere , mai kpobi ma te ghọghọ avọ oghọghọ nọ ma te roro kpahe ẹme arao nana nọ o wo erru gbe omosasọ nọ o rrọ obe na : “ Jọ odẹ riẹ [ Jesu Kristi ] o jọ bẹdẹ bẹdẹ ; re ma rehọ odẹ riẹ kẹ ae , re a jọ eva riẹ ru odẹ riẹ gbunu , re a ruẹse ghale ae .\n",
            "2020-01-17 07:58:23,511 Example #3\n",
            "2020-01-17 07:58:23,512 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 07:58:23,512 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 07:58:23,512 \tHypothesis: Ghele na , eme nọ e rẹ sae lẹliẹ ohwo wo udhedhẹ .\n",
            "2020-01-17 07:58:23,513 Validation result (greedy) at epoch  11, step    27000: bleu:  24.48, loss: 41288.8203, ppl:   4.9166, duration: 35.7374s\n",
            "2020-01-17 07:58:38,315 Epoch  11 Step:    27100 Batch Loss:     1.561982 Tokens per Sec:    15204, Lr: 0.000300\n",
            "2020-01-17 07:58:52,542 Epoch  11 Step:    27200 Batch Loss:     1.780466 Tokens per Sec:    15773, Lr: 0.000300\n",
            "2020-01-17 07:59:06,671 Epoch  11 Step:    27300 Batch Loss:     2.465067 Tokens per Sec:    15471, Lr: 0.000300\n",
            "2020-01-17 07:59:20,847 Epoch  11 Step:    27400 Batch Loss:     1.643611 Tokens per Sec:    15800, Lr: 0.000300\n",
            "2020-01-17 07:59:34,960 Epoch  11 Step:    27500 Batch Loss:     1.474970 Tokens per Sec:    15790, Lr: 0.000300\n",
            "2020-01-17 07:59:49,205 Epoch  11 Step:    27600 Batch Loss:     1.810301 Tokens per Sec:    15987, Lr: 0.000300\n",
            "2020-01-17 08:00:03,456 Epoch  11 Step:    27700 Batch Loss:     1.841724 Tokens per Sec:    15959, Lr: 0.000300\n",
            "2020-01-17 08:00:17,607 Epoch  11 Step:    27800 Batch Loss:     1.668835 Tokens per Sec:    15413, Lr: 0.000300\n",
            "2020-01-17 08:00:18,764 Epoch  11: total training loss 4325.66\n",
            "2020-01-17 08:00:18,764 EPOCH 12\n",
            "2020-01-17 08:00:32,003 Epoch  12 Step:    27900 Batch Loss:     1.884572 Tokens per Sec:    15246, Lr: 0.000300\n",
            "2020-01-17 08:00:46,203 Epoch  12 Step:    28000 Batch Loss:     1.103669 Tokens per Sec:    15818, Lr: 0.000300\n",
            "2020-01-17 08:01:20,299 Hooray! New best validation result [ppl]!\n",
            "2020-01-17 08:01:20,299 Saving new checkpoint.\n",
            "2020-01-17 08:01:21,738 Example #0\n",
            "2020-01-17 08:01:21,739 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 08:01:21,739 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 08:01:21,740 \tHypothesis: Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ ma omai eva efuafo . ’\n",
            "2020-01-17 08:01:21,740 Example #1\n",
            "2020-01-17 08:01:21,740 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 08:01:21,741 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 08:01:21,741 \tHypothesis: A te lele onana evaọ Egwa Uvie na ha .\n",
            "2020-01-17 08:01:21,741 Example #2\n",
            "2020-01-17 08:01:21,742 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 08:01:21,742 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 08:01:21,742 \tHypothesis: Fikiere , mai kpobi ma te ghọghọ avọ oghọghọ nọ ma te roro kpahe eme nọ e rrọ obe nana nọ e rrọ obe nana , onọ o rrọ omosasọ gbe omosasọ : “ Jọ odẹ [ Jesu Ovie na ] o jọ bẹdẹ bẹdẹ , re ma jọ bẹdẹ bẹdẹ , re ma jọ odẹ riẹ o jọ eva riẹ , re a ghale ae , re a jọ eva riẹ , re a jọ eva rai kpobi , a jọ eva rai kpobi , a jọ eva rai kpobi , a wo evawere .\n",
            "2020-01-17 08:01:21,743 Example #3\n",
            "2020-01-17 08:01:21,743 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 08:01:21,743 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 08:01:21,744 \tHypothesis: Ghele na , eme ọ ọgbahọ e rẹ jọ gaga re ma ru udhedhẹ .\n",
            "2020-01-17 08:01:21,744 Validation result (greedy) at epoch  12, step    28000: bleu:  24.75, loss: 41143.6172, ppl:   4.8892, duration: 35.5403s\n",
            "2020-01-17 08:01:36,552 Epoch  12 Step:    28100 Batch Loss:     1.665430 Tokens per Sec:    15062, Lr: 0.000300\n",
            "2020-01-17 08:01:50,797 Epoch  12 Step:    28200 Batch Loss:     1.590340 Tokens per Sec:    16025, Lr: 0.000300\n",
            "2020-01-17 08:02:05,044 Epoch  12 Step:    28300 Batch Loss:     1.623152 Tokens per Sec:    15667, Lr: 0.000300\n",
            "2020-01-17 08:02:19,242 Epoch  12 Step:    28400 Batch Loss:     1.467562 Tokens per Sec:    15738, Lr: 0.000300\n",
            "2020-01-17 08:02:33,361 Epoch  12 Step:    28500 Batch Loss:     1.531389 Tokens per Sec:    15340, Lr: 0.000300\n",
            "2020-01-17 08:02:47,454 Epoch  12 Step:    28600 Batch Loss:     2.473499 Tokens per Sec:    15721, Lr: 0.000300\n",
            "2020-01-17 08:03:01,659 Epoch  12 Step:    28700 Batch Loss:     1.603284 Tokens per Sec:    15767, Lr: 0.000300\n",
            "2020-01-17 08:03:15,700 Epoch  12 Step:    28800 Batch Loss:     1.345807 Tokens per Sec:    15547, Lr: 0.000300\n",
            "2020-01-17 08:03:29,785 Epoch  12 Step:    28900 Batch Loss:     1.663128 Tokens per Sec:    15634, Lr: 0.000300\n",
            "2020-01-17 08:03:43,833 Epoch  12 Step:    29000 Batch Loss:     1.768353 Tokens per Sec:    15541, Lr: 0.000300\n",
            "2020-01-17 08:04:17,758 Hooray! New best validation result [ppl]!\n",
            "2020-01-17 08:04:17,759 Saving new checkpoint.\n",
            "2020-01-17 08:04:19,218 Example #0\n",
            "2020-01-17 08:04:19,219 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 08:04:19,219 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 08:04:19,219 \tHypothesis: Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ ma omai eva efuafo . ’\n",
            "2020-01-17 08:04:19,220 Example #1\n",
            "2020-01-17 08:04:19,220 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 08:04:19,220 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 08:04:19,221 \tHypothesis: A te ru onana ẹkwoma Usi Uvie na .\n",
            "2020-01-17 08:04:19,221 Example #2\n",
            "2020-01-17 08:04:19,222 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 08:04:19,222 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 08:04:19,222 \tHypothesis: Fikiere , mai kpobi ma te rọ oghọghọ ru iruo mai gba ziezi , ma vẹ te rọ ere ku ẹme na họ avọ omosasọ gbe omosasọ nọ o rrọ obe na họ : “ Jọ odẹ [ Jesu Kristi na ] o dikihẹ bẹdẹ ; re ma ruẹse jọ bẹdẹ bẹdẹ , re odẹ riẹ o jọ bẹdẹ , re a ruẹse jọ odẹ riẹ o jọ bẹdẹ bẹdẹ , re a wo oghale , re a jọ eva riẹ , re a jọ ahwo kpobi a wo oghale .\n",
            "2020-01-17 08:04:19,222 Example #3\n",
            "2020-01-17 08:04:19,223 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 08:04:19,223 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 08:04:19,223 \tHypothesis: Ghele na , eme nọ e rẹ sae wha udhedhẹ ze e rẹ jọ gaga .\n",
            "2020-01-17 08:04:19,224 Validation result (greedy) at epoch  12, step    29000: bleu:  24.62, loss: 40905.4883, ppl:   4.8445, duration: 35.3902s\n",
            "2020-01-17 08:04:34,046 Epoch  12 Step:    29100 Batch Loss:     1.780755 Tokens per Sec:    15257, Lr: 0.000300\n",
            "2020-01-17 08:04:48,160 Epoch  12 Step:    29200 Batch Loss:     1.800091 Tokens per Sec:    15468, Lr: 0.000300\n",
            "2020-01-17 08:05:02,304 Epoch  12 Step:    29300 Batch Loss:     1.830185 Tokens per Sec:    15255, Lr: 0.000300\n",
            "2020-01-17 08:05:16,498 Epoch  12 Step:    29400 Batch Loss:     1.541632 Tokens per Sec:    15748, Lr: 0.000300\n",
            "2020-01-17 08:05:30,617 Epoch  12 Step:    29500 Batch Loss:     1.992168 Tokens per Sec:    15508, Lr: 0.000300\n",
            "2020-01-17 08:05:44,749 Epoch  12 Step:    29600 Batch Loss:     1.492429 Tokens per Sec:    15946, Lr: 0.000300\n",
            "2020-01-17 08:05:58,881 Epoch  12 Step:    29700 Batch Loss:     1.718560 Tokens per Sec:    15571, Lr: 0.000300\n",
            "2020-01-17 08:06:13,075 Epoch  12 Step:    29800 Batch Loss:     1.643764 Tokens per Sec:    16022, Lr: 0.000300\n",
            "2020-01-17 08:06:27,218 Epoch  12 Step:    29900 Batch Loss:     1.782235 Tokens per Sec:    15934, Lr: 0.000300\n",
            "2020-01-17 08:06:41,362 Epoch  12 Step:    30000 Batch Loss:     1.684452 Tokens per Sec:    15814, Lr: 0.000300\n",
            "2020-01-17 08:07:15,398 Hooray! New best validation result [ppl]!\n",
            "2020-01-17 08:07:15,398 Saving new checkpoint.\n",
            "2020-01-17 08:07:16,847 Example #0\n",
            "2020-01-17 08:07:16,848 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 08:07:16,848 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 08:07:16,848 \tHypothesis: Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ ma omai eva efuafo . ’\n",
            "2020-01-17 08:07:16,848 Example #1\n",
            "2020-01-17 08:07:16,849 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 08:07:16,849 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 08:07:16,849 \tHypothesis: A te lele onana ẹkwoma Usi Uvie na ha .\n",
            "2020-01-17 08:07:16,850 Example #2\n",
            "2020-01-17 08:07:16,850 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 08:07:16,850 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 08:07:16,851 \tHypothesis: Fikiere , mai kpobi ma te rọ evawere ta ẹme kpahe ẹme nana nọ o no rie ze , inọ : “ Jọ odẹ riẹ [ Jesu Kristi ] o jọ bẹdẹ bẹdẹ , re ma jọ bẹdẹ bẹdẹ , re odẹ riẹ o jọ bẹdẹ , jọ orọ eva riẹ o jọ ghaghae , jọ orọ eva riẹ , jọ o jọ oghale kẹ ae .\n",
            "2020-01-17 08:07:16,851 Example #3\n",
            "2020-01-17 08:07:16,852 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 08:07:16,852 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 08:07:16,852 \tHypothesis: Ghele na , eme nọ e rẹ sae lẹliẹ ohwo wo udhedhẹ .\n",
            "2020-01-17 08:07:16,852 Validation result (greedy) at epoch  12, step    30000: bleu:  25.66, loss: 40556.3906, ppl:   4.7797, duration: 35.4896s\n",
            "2020-01-17 08:07:31,615 Epoch  12 Step:    30100 Batch Loss:     1.615480 Tokens per Sec:    15188, Lr: 0.000300\n",
            "2020-01-17 08:07:45,841 Epoch  12 Step:    30200 Batch Loss:     1.605576 Tokens per Sec:    15916, Lr: 0.000300\n",
            "2020-01-17 08:07:59,921 Epoch  12 Step:    30300 Batch Loss:     1.525831 Tokens per Sec:    15572, Lr: 0.000300\n",
            "2020-01-17 08:08:05,586 Epoch  12: total training loss 4244.55\n",
            "2020-01-17 08:08:05,586 EPOCH 13\n",
            "2020-01-17 08:08:14,368 Epoch  13 Step:    30400 Batch Loss:     1.626211 Tokens per Sec:    14898, Lr: 0.000300\n",
            "2020-01-17 08:08:28,513 Epoch  13 Step:    30500 Batch Loss:     1.760267 Tokens per Sec:    15630, Lr: 0.000300\n",
            "2020-01-17 08:08:42,641 Epoch  13 Step:    30600 Batch Loss:     1.584840 Tokens per Sec:    15744, Lr: 0.000300\n",
            "2020-01-17 08:08:56,774 Epoch  13 Step:    30700 Batch Loss:     1.501565 Tokens per Sec:    15915, Lr: 0.000300\n",
            "2020-01-17 08:09:10,905 Epoch  13 Step:    30800 Batch Loss:     1.883346 Tokens per Sec:    15578, Lr: 0.000300\n",
            "2020-01-17 08:09:25,032 Epoch  13 Step:    30900 Batch Loss:     1.730416 Tokens per Sec:    15962, Lr: 0.000300\n",
            "2020-01-17 08:09:39,102 Epoch  13 Step:    31000 Batch Loss:     1.777141 Tokens per Sec:    15796, Lr: 0.000300\n",
            "2020-01-17 08:10:13,273 Hooray! New best validation result [ppl]!\n",
            "2020-01-17 08:10:13,273 Saving new checkpoint.\n",
            "2020-01-17 08:10:14,678 Example #0\n",
            "2020-01-17 08:10:14,679 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 08:10:14,679 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 08:10:14,679 \tHypothesis: Ma rẹ sae tubẹ yare Ọghẹnẹ inọ ọ ‘ ma omai eva efuafo . ’\n",
            "2020-01-17 08:10:14,680 Example #1\n",
            "2020-01-17 08:10:14,680 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 08:10:14,681 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 08:10:14,681 \tHypothesis: Onana u lele i rie , Usi Uvie na o tẹ te jọ họ .\n",
            "2020-01-17 08:10:14,681 Example #2\n",
            "2020-01-17 08:10:14,682 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 08:10:14,682 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 08:10:14,682 \tHypothesis: ( Olezi 119 : 139 ) Fikiere , mai kpobi ma ve ti ku ẹme na họ avọ oghọghọ , onọ o rrọ obe nọ o rrọ obe nana nọ o rrọ obe na , onọ o ta nọ : “ Jọ odẹ [ Jesu Kristi Ovie na ] o dikihẹ bẹdẹ bẹdẹ , re odẹ riẹ o jọ bẹdẹ bẹdẹ , re wha jọ odẹ riẹ o jọ ruaro riẹ , re wha jọ ahwo kpobi a wo oghale , re a wo oghale .\n",
            "2020-01-17 08:10:14,682 Example #3\n",
            "2020-01-17 08:10:14,683 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 08:10:14,683 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 08:10:14,683 \tHypothesis: Ghele na , eme ọ ọghoruo e rẹ jọ gaga re ma ru udhedhẹ .\n",
            "2020-01-17 08:10:14,684 Validation result (greedy) at epoch  13, step    31000: bleu:  25.36, loss: 40280.0117, ppl:   4.7290, duration: 35.5814s\n",
            "2020-01-17 08:10:29,340 Epoch  13 Step:    31100 Batch Loss:     1.221219 Tokens per Sec:    14957, Lr: 0.000300\n",
            "2020-01-17 08:10:43,450 Epoch  13 Step:    31200 Batch Loss:     1.447520 Tokens per Sec:    15564, Lr: 0.000300\n",
            "2020-01-17 08:10:57,613 Epoch  13 Step:    31300 Batch Loss:     1.714622 Tokens per Sec:    16058, Lr: 0.000300\n",
            "2020-01-17 08:11:11,730 Epoch  13 Step:    31400 Batch Loss:     1.604917 Tokens per Sec:    15922, Lr: 0.000300\n",
            "2020-01-17 08:11:25,914 Epoch  13 Step:    31500 Batch Loss:     1.728298 Tokens per Sec:    15641, Lr: 0.000300\n",
            "2020-01-17 08:11:40,019 Epoch  13 Step:    31600 Batch Loss:     1.754791 Tokens per Sec:    15773, Lr: 0.000300\n",
            "2020-01-17 08:11:54,197 Epoch  13 Step:    31700 Batch Loss:     1.759848 Tokens per Sec:    15877, Lr: 0.000300\n",
            "2020-01-17 08:12:08,270 Epoch  13 Step:    31800 Batch Loss:     1.975119 Tokens per Sec:    15710, Lr: 0.000300\n",
            "2020-01-17 08:12:22,419 Epoch  13 Step:    31900 Batch Loss:     1.675570 Tokens per Sec:    15925, Lr: 0.000300\n",
            "2020-01-17 08:12:36,416 Epoch  13 Step:    32000 Batch Loss:     1.253652 Tokens per Sec:    15614, Lr: 0.000300\n",
            "2020-01-17 08:13:10,302 Hooray! New best validation result [ppl]!\n",
            "2020-01-17 08:13:10,302 Saving new checkpoint.\n",
            "2020-01-17 08:13:11,730 Example #0\n",
            "2020-01-17 08:13:11,730 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 08:13:11,731 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 08:13:11,731 \tHypothesis: Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ ma omai eva efuafo . ’\n",
            "2020-01-17 08:13:11,731 Example #1\n",
            "2020-01-17 08:13:11,732 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 08:13:11,732 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 08:13:11,732 \tHypothesis: Erere Uvie na o te ti te he .\n",
            "2020-01-17 08:13:11,732 Example #2\n",
            "2020-01-17 08:13:11,733 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 08:13:11,733 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 08:13:11,734 \tHypothesis: O rẹ sai ru omai kpobi riẹ epanọ ma rẹ rọ ghọghọ te , ma ve ti ku ẹme nana họ , je ru ei wo evawere : “ Jọ odẹ riẹ [ Ovie na ] Jesu Kristi na o dhesẹ nọ o re ti ru odẹ riẹ fo , re a rehọ odẹ riẹ ru odẹ riẹ fo , re a ghale ae , re a ruẹse rehọ oruaro kẹ ae .\n",
            "2020-01-17 08:13:11,734 Example #3\n",
            "2020-01-17 08:13:11,735 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 08:13:11,735 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 08:13:11,735 \tHypothesis: Ghele na , eme ọ ọghoruo yọ ẹgba nọ a re ro ru udhedhẹ .\n",
            "2020-01-17 08:13:11,735 Validation result (greedy) at epoch  13, step    32000: bleu:  25.49, loss: 40043.0117, ppl:   4.6860, duration: 35.3193s\n",
            "2020-01-17 08:13:26,473 Epoch  13 Step:    32100 Batch Loss:     1.916762 Tokens per Sec:    15214, Lr: 0.000300\n",
            "2020-01-17 08:13:40,578 Epoch  13 Step:    32200 Batch Loss:     1.660070 Tokens per Sec:    15963, Lr: 0.000300\n",
            "2020-01-17 08:13:54,633 Epoch  13 Step:    32300 Batch Loss:     1.458839 Tokens per Sec:    15922, Lr: 0.000300\n",
            "2020-01-17 08:14:08,648 Epoch  13 Step:    32400 Batch Loss:     1.584791 Tokens per Sec:    15450, Lr: 0.000300\n",
            "2020-01-17 08:14:22,679 Epoch  13 Step:    32500 Batch Loss:     1.878867 Tokens per Sec:    15413, Lr: 0.000300\n",
            "2020-01-17 08:14:36,795 Epoch  13 Step:    32600 Batch Loss:     1.718656 Tokens per Sec:    16073, Lr: 0.000300\n",
            "2020-01-17 08:14:50,962 Epoch  13 Step:    32700 Batch Loss:     1.580394 Tokens per Sec:    15932, Lr: 0.000300\n",
            "2020-01-17 08:15:05,108 Epoch  13 Step:    32800 Batch Loss:     1.868972 Tokens per Sec:    15897, Lr: 0.000300\n",
            "2020-01-17 08:15:14,308 Epoch  13: total training loss 4162.52\n",
            "2020-01-17 08:15:14,309 EPOCH 14\n",
            "2020-01-17 08:15:19,523 Epoch  14 Step:    32900 Batch Loss:     1.759076 Tokens per Sec:    15477, Lr: 0.000300\n",
            "2020-01-17 08:15:33,578 Epoch  14 Step:    33000 Batch Loss:     1.611121 Tokens per Sec:    15658, Lr: 0.000300\n",
            "2020-01-17 08:16:07,641 Hooray! New best validation result [ppl]!\n",
            "2020-01-17 08:16:07,642 Saving new checkpoint.\n",
            "2020-01-17 08:16:09,094 Example #0\n",
            "2020-01-17 08:16:09,095 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 08:16:09,095 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 08:16:09,095 \tHypothesis: Ma rẹ sae tubẹ yare Ọghẹnẹ inọ ọ ‘ ma omai eva efuafo . ’\n",
            "2020-01-17 08:16:09,096 Example #1\n",
            "2020-01-17 08:16:09,096 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 08:16:09,097 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 08:16:09,097 \tHypothesis: A lele onana , News News o te ti ru ere he .\n",
            "2020-01-17 08:16:09,097 Example #2\n",
            "2020-01-17 08:16:09,098 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 08:16:09,098 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 08:16:09,098 \tHypothesis: Fikiere , mai kpobi ma ve ti fiba unu mai kpobi nọ ma te roro kpahe epanọ ma ti ro ku ẹme na họ , je ru odẹ riẹ gbunu , inọ : “ Jọ odẹ riẹ [ Kristi na ] o dhesẹ nọ , re a jọ bẹdẹ bẹdẹ , re odẹ riẹ o jọ bẹdẹ , re wha wo oruaro , re wha wo oghale , re wha wo oghale kẹ ae ; wha wo oghale kẹ ae .\n",
            "2020-01-17 08:16:09,098 Example #3\n",
            "2020-01-17 08:16:09,099 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 08:16:09,099 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 08:16:09,100 \tHypothesis: Ghele na , eme ọ ọghoruo yọ ẹgba nọ a re ro ru udhedhẹ .\n",
            "2020-01-17 08:16:09,100 Validation result (greedy) at epoch  14, step    33000: bleu:  25.54, loss: 39784.0977, ppl:   4.6394, duration: 35.5214s\n",
            "2020-01-17 08:16:23,934 Epoch  14 Step:    33100 Batch Loss:     1.695752 Tokens per Sec:    14495, Lr: 0.000300\n",
            "2020-01-17 08:16:38,164 Epoch  14 Step:    33200 Batch Loss:     1.432000 Tokens per Sec:    15945, Lr: 0.000300\n",
            "2020-01-17 08:16:52,341 Epoch  14 Step:    33300 Batch Loss:     1.656438 Tokens per Sec:    15756, Lr: 0.000300\n",
            "2020-01-17 08:17:06,510 Epoch  14 Step:    33400 Batch Loss:     1.747471 Tokens per Sec:    15738, Lr: 0.000300\n",
            "2020-01-17 08:17:20,574 Epoch  14 Step:    33500 Batch Loss:     1.649618 Tokens per Sec:    15531, Lr: 0.000300\n",
            "2020-01-17 08:17:34,663 Epoch  14 Step:    33600 Batch Loss:     1.534976 Tokens per Sec:    15493, Lr: 0.000300\n",
            "2020-01-17 08:17:48,861 Epoch  14 Step:    33700 Batch Loss:     1.200700 Tokens per Sec:    15955, Lr: 0.000300\n",
            "2020-01-17 08:18:02,886 Epoch  14 Step:    33800 Batch Loss:     1.507306 Tokens per Sec:    15926, Lr: 0.000300\n",
            "2020-01-17 08:18:17,150 Epoch  14 Step:    33900 Batch Loss:     1.518264 Tokens per Sec:    15925, Lr: 0.000300\n",
            "2020-01-17 08:18:31,213 Epoch  14 Step:    34000 Batch Loss:     1.662089 Tokens per Sec:    15735, Lr: 0.000300\n",
            "2020-01-17 08:19:05,228 Hooray! New best validation result [ppl]!\n",
            "2020-01-17 08:19:05,228 Saving new checkpoint.\n",
            "2020-01-17 08:19:06,619 Example #0\n",
            "2020-01-17 08:19:06,620 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 08:19:06,620 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 08:19:06,620 \tHypothesis: Ma rẹ sae yare Ọghẹnẹ re ọ ‘ ma omai eva efuafo . ’\n",
            "2020-01-17 08:19:06,620 Example #1\n",
            "2020-01-17 08:19:06,621 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 08:19:06,621 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 08:19:06,621 \tHypothesis: A te lele onana evaọ obọ News of the Holy Scriptures .\n",
            "2020-01-17 08:19:06,622 Example #2\n",
            "2020-01-17 08:19:06,622 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 08:19:06,622 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 08:19:06,623 \tHypothesis: Fikiere , mai kpobi ma te rọ evawere ru iruo mai gba kẹ ẹme nọ ma ta kpahe epanọ ma re ro ku ẹme nana họ , onọ u re ru omai wo evawere kpahe odẹ riẹ nọ o rrọ obe na , onọ u re ru omai wo evawere evaọ aro riẹ , re ma wo odẹ riẹ , re ma wo oghale , re ahwo kpobi a wo oghale , re a wo oghale eva efuafo riẹ , a wo oghale eva efuafo riẹ .\n",
            "2020-01-17 08:19:06,623 Example #3\n",
            "2020-01-17 08:19:06,624 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 08:19:06,624 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 08:19:06,624 \tHypothesis: Ghele na , eme eghrorotha e rẹ jọ ẹgba gaga re a ru udhedhẹ .\n",
            "2020-01-17 08:19:06,624 Validation result (greedy) at epoch  14, step    34000: bleu:  25.62, loss: 39677.8203, ppl:   4.6204, duration: 35.4103s\n",
            "2020-01-17 08:19:21,413 Epoch  14 Step:    34100 Batch Loss:     1.567922 Tokens per Sec:    14918, Lr: 0.000300\n",
            "2020-01-17 08:19:35,510 Epoch  14 Step:    34200 Batch Loss:     2.069920 Tokens per Sec:    15396, Lr: 0.000300\n",
            "2020-01-17 08:19:49,679 Epoch  14 Step:    34300 Batch Loss:     1.175008 Tokens per Sec:    15912, Lr: 0.000300\n",
            "2020-01-17 08:20:03,812 Epoch  14 Step:    34400 Batch Loss:     1.704481 Tokens per Sec:    15871, Lr: 0.000300\n",
            "2020-01-17 08:20:17,943 Epoch  14 Step:    34500 Batch Loss:     1.524394 Tokens per Sec:    16072, Lr: 0.000300\n",
            "2020-01-17 08:20:32,031 Epoch  14 Step:    34600 Batch Loss:     1.957623 Tokens per Sec:    15934, Lr: 0.000300\n",
            "2020-01-17 08:20:46,095 Epoch  14 Step:    34700 Batch Loss:     1.495033 Tokens per Sec:    15592, Lr: 0.000300\n",
            "2020-01-17 08:21:00,174 Epoch  14 Step:    34800 Batch Loss:     1.735225 Tokens per Sec:    15601, Lr: 0.000300\n",
            "2020-01-17 08:21:14,173 Epoch  14 Step:    34900 Batch Loss:     1.559505 Tokens per Sec:    15647, Lr: 0.000300\n",
            "2020-01-17 08:21:28,253 Epoch  14 Step:    35000 Batch Loss:     1.779963 Tokens per Sec:    15598, Lr: 0.000300\n",
            "2020-01-17 08:22:02,232 Hooray! New best validation result [ppl]!\n",
            "2020-01-17 08:22:02,233 Saving new checkpoint.\n",
            "2020-01-17 08:22:03,660 Example #0\n",
            "2020-01-17 08:22:03,661 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 08:22:03,661 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 08:22:03,661 \tHypothesis: Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ ma omai eva efuafo . ’\n",
            "2020-01-17 08:22:03,662 Example #1\n",
            "2020-01-17 08:22:03,662 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 08:22:03,662 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 08:22:03,663 \tHypothesis: Usi Uvie na u lele i rie .\n",
            "2020-01-17 08:22:03,663 Example #2\n",
            "2020-01-17 08:22:03,664 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 08:22:03,664 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 08:22:03,664 \tHypothesis: Fikiere , mai kpobi ma te rọ oghọghọ fiba eme nọ e rrọ eva mai kpobi nọ i re fi obọ họ kẹ omai ku ẹme nana họ , onọ o rẹ kẹ omosasọ gbe omosasọ : “ Jọ odẹ [ Jesu Kristi Ovie na ] o jọ bẹdẹ bẹdẹ , re odẹ riẹ o jọ fuafo , re o jọ odẹ riẹ o jọ eva rai , re o jọ kẹ ae evawere .\n",
            "2020-01-17 08:22:03,664 Example #3\n",
            "2020-01-17 08:22:03,665 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 08:22:03,665 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 08:22:03,666 \tHypothesis: Ghele na , eme eghrorotha e rrọ ẹgba gaga re a ru udhedhẹ .\n",
            "2020-01-17 08:22:03,666 Validation result (greedy) at epoch  14, step    35000: bleu:  26.49, loss: 39490.3320, ppl:   4.5871, duration: 35.4122s\n",
            "2020-01-17 08:22:18,390 Epoch  14 Step:    35100 Batch Loss:     1.537634 Tokens per Sec:    15202, Lr: 0.000300\n",
            "2020-01-17 08:22:32,510 Epoch  14 Step:    35200 Batch Loss:     1.815333 Tokens per Sec:    15637, Lr: 0.000300\n",
            "2020-01-17 08:22:46,680 Epoch  14 Step:    35300 Batch Loss:     1.734522 Tokens per Sec:    15753, Lr: 0.000300\n",
            "2020-01-17 08:23:00,329 Epoch  14: total training loss 4114.27\n",
            "2020-01-17 08:23:00,329 EPOCH 15\n",
            "2020-01-17 08:23:01,042 Epoch  15 Step:    35400 Batch Loss:     1.690098 Tokens per Sec:     8913, Lr: 0.000300\n",
            "2020-01-17 08:23:15,057 Epoch  15 Step:    35500 Batch Loss:     1.816674 Tokens per Sec:    15738, Lr: 0.000300\n",
            "2020-01-17 08:23:29,153 Epoch  15 Step:    35600 Batch Loss:     1.421490 Tokens per Sec:    15536, Lr: 0.000300\n",
            "2020-01-17 08:23:43,277 Epoch  15 Step:    35700 Batch Loss:     1.507053 Tokens per Sec:    15794, Lr: 0.000300\n",
            "2020-01-17 08:23:57,356 Epoch  15 Step:    35800 Batch Loss:     1.599183 Tokens per Sec:    15607, Lr: 0.000300\n",
            "2020-01-17 08:24:11,433 Epoch  15 Step:    35900 Batch Loss:     1.643387 Tokens per Sec:    15988, Lr: 0.000300\n",
            "2020-01-17 08:24:25,603 Epoch  15 Step:    36000 Batch Loss:     1.512120 Tokens per Sec:    16060, Lr: 0.000300\n",
            "2020-01-17 08:24:59,584 Hooray! New best validation result [ppl]!\n",
            "2020-01-17 08:24:59,584 Saving new checkpoint.\n",
            "2020-01-17 08:25:01,024 Example #0\n",
            "2020-01-17 08:25:01,025 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 08:25:01,025 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 08:25:01,026 \tHypothesis: Ma rẹ sae tubẹ yare Ọghẹnẹ inọ ọ ‘ ma omai eva efuafo . ’\n",
            "2020-01-17 08:25:01,026 Example #1\n",
            "2020-01-17 08:25:01,026 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 08:25:01,027 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 08:25:01,027 \tHypothesis: A te ru onana ẹkwoma News Uvie na ha .\n",
            "2020-01-17 08:25:01,027 Example #2\n",
            "2020-01-17 08:25:01,028 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 08:25:01,028 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 08:25:01,029 \tHypothesis: Fikiere , mai kpobi ma te rehọ oghọghọ fiba unu mai re ma ku ẹme na họ , onọ o rẹ kẹ omai evawere : “ Jọ odẹ [ Jesu Kristi Ovie na ] o jọ bẹdẹ bẹdẹ , re o ru odẹ riẹ gba , re o jọ bẹdẹ bẹdẹ , re o ru odẹ riẹ gba , re o ghale erẹwho kpobi , re a wo oghale eva rai , re a wo oghale eva riẹ .\n",
            "2020-01-17 08:25:01,029 Example #3\n",
            "2020-01-17 08:25:01,029 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 08:25:01,030 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 08:25:01,030 \tHypothesis: Ghele na , eme ọ ọghoruo yọ ẹgba ologbo nọ a re ro ru udhedhẹ .\n",
            "2020-01-17 08:25:01,030 Validation result (greedy) at epoch  15, step    36000: bleu:  25.94, loss: 39363.2031, ppl:   4.5647, duration: 35.4264s\n",
            "2020-01-17 08:25:15,766 Epoch  15 Step:    36100 Batch Loss:     1.361270 Tokens per Sec:    15111, Lr: 0.000300\n",
            "2020-01-17 08:25:29,942 Epoch  15 Step:    36200 Batch Loss:     1.632372 Tokens per Sec:    15930, Lr: 0.000300\n",
            "2020-01-17 08:25:43,985 Epoch  15 Step:    36300 Batch Loss:     1.595752 Tokens per Sec:    15484, Lr: 0.000300\n",
            "2020-01-17 08:25:58,046 Epoch  15 Step:    36400 Batch Loss:     1.398398 Tokens per Sec:    15679, Lr: 0.000300\n",
            "2020-01-17 08:26:12,101 Epoch  15 Step:    36500 Batch Loss:     1.745380 Tokens per Sec:    15473, Lr: 0.000300\n",
            "2020-01-17 08:26:26,173 Epoch  15 Step:    36600 Batch Loss:     1.632430 Tokens per Sec:    15839, Lr: 0.000300\n",
            "2020-01-17 08:26:40,323 Epoch  15 Step:    36700 Batch Loss:     1.886968 Tokens per Sec:    15807, Lr: 0.000300\n",
            "2020-01-17 08:26:54,478 Epoch  15 Step:    36800 Batch Loss:     1.633167 Tokens per Sec:    15807, Lr: 0.000300\n",
            "2020-01-17 08:27:08,568 Epoch  15 Step:    36900 Batch Loss:     1.475528 Tokens per Sec:    16021, Lr: 0.000300\n",
            "2020-01-17 08:27:22,534 Epoch  15 Step:    37000 Batch Loss:     1.710456 Tokens per Sec:    15595, Lr: 0.000300\n",
            "2020-01-17 08:27:56,588 Hooray! New best validation result [ppl]!\n",
            "2020-01-17 08:27:56,589 Saving new checkpoint.\n",
            "2020-01-17 08:27:58,008 Example #0\n",
            "2020-01-17 08:27:58,009 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 08:27:58,009 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 08:27:58,009 \tHypothesis: Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ ma omai eva efuafo . ’\n",
            "2020-01-17 08:27:58,009 Example #1\n",
            "2020-01-17 08:27:58,010 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 08:27:58,010 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 08:27:58,010 \tHypothesis: A te lele onana ẹkwoma Usi Uvie na ha .\n",
            "2020-01-17 08:27:58,011 Example #2\n",
            "2020-01-17 08:27:58,011 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 08:27:58,012 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 08:27:58,012 \tHypothesis: Fikiere , mai kpobi ma te rọ evawere fiba eme nọ ma be ta kpahe na , ma ve ti ku eme iwoma nana họ : “ Jọ odẹ riẹ [ Jesu Ovie na ] o jọ bẹdẹ bẹdẹ bẹdẹ , re o ru odẹ riẹ gba , re o jọ odẹ riẹ o jọ ruaro , re o jọ odẹ riẹ , re o jọ ọnọ o re ru ahwo erẹwho kpobi wo oghale , re a wo oghale riẹ .\n",
            "2020-01-17 08:27:58,012 Example #3\n",
            "2020-01-17 08:27:58,013 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 08:27:58,013 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 08:27:58,013 \tHypothesis: Ghele na , eme ọ ọghoruo yọ ẹgba nọ a re ro ru udhedhẹ .\n",
            "2020-01-17 08:27:58,014 Validation result (greedy) at epoch  15, step    37000: bleu:  26.28, loss: 39259.3945, ppl:   4.5464, duration: 35.4787s\n",
            "2020-01-17 08:28:12,740 Epoch  15 Step:    37100 Batch Loss:     1.615631 Tokens per Sec:    15191, Lr: 0.000300\n",
            "2020-01-17 08:28:26,839 Epoch  15 Step:    37200 Batch Loss:     1.378787 Tokens per Sec:    15294, Lr: 0.000300\n",
            "2020-01-17 08:28:41,025 Epoch  15 Step:    37300 Batch Loss:     1.632762 Tokens per Sec:    16052, Lr: 0.000300\n",
            "2020-01-17 08:28:55,163 Epoch  15 Step:    37400 Batch Loss:     1.656897 Tokens per Sec:    15838, Lr: 0.000300\n",
            "2020-01-17 08:29:09,286 Epoch  15 Step:    37500 Batch Loss:     1.521526 Tokens per Sec:    15732, Lr: 0.000300\n",
            "2020-01-17 08:29:23,394 Epoch  15 Step:    37600 Batch Loss:     1.621662 Tokens per Sec:    15940, Lr: 0.000300\n",
            "2020-01-17 08:29:37,509 Epoch  15 Step:    37700 Batch Loss:     1.713985 Tokens per Sec:    15567, Lr: 0.000300\n",
            "2020-01-17 08:29:51,623 Epoch  15 Step:    37800 Batch Loss:     1.764825 Tokens per Sec:    15623, Lr: 0.000300\n",
            "2020-01-17 08:30:05,861 Epoch  15 Step:    37900 Batch Loss:     1.574651 Tokens per Sec:    16092, Lr: 0.000300\n",
            "2020-01-17 08:30:09,553 Epoch  15: total training loss 4046.35\n",
            "2020-01-17 08:30:09,553 EPOCH 16\n",
            "2020-01-17 08:30:20,207 Epoch  16 Step:    38000 Batch Loss:     1.557202 Tokens per Sec:    14961, Lr: 0.000300\n",
            "2020-01-17 08:30:54,183 Example #0\n",
            "2020-01-17 08:30:54,183 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 08:30:54,184 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 08:30:54,184 \tHypothesis: Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ ma omai eva efuafo . ’\n",
            "2020-01-17 08:30:54,184 Example #1\n",
            "2020-01-17 08:30:54,185 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 08:30:54,185 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 08:30:54,185 \tHypothesis: A te lele onana evaọ Ọgwa Uvie .\n",
            "2020-01-17 08:30:54,185 Example #2\n",
            "2020-01-17 08:30:54,186 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 08:30:54,186 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 08:30:54,186 \tHypothesis: O wọhọ nọ mai kpobi ma te rọ oghọghọ ta ẹme kpahe epanọ ma rẹ rọ rehọ ole nana ku ẹme na họ : “ Jọ odẹ [ Jesu Kristi Ovie na ] ọ jọ bẹdẹ bẹdẹ , re a jọ odẹ riẹ ru odẹ riẹ fo , re o jọ ukuoriọ kẹ ahwo erẹwho na kpobi , re a wo oghale , re a ruẹse ghale ae , a wo oghale .\n",
            "2020-01-17 08:30:54,187 Example #3\n",
            "2020-01-17 08:30:54,187 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 08:30:54,187 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 08:30:54,188 \tHypothesis: Ghele na , eme ọghoruo e rẹ jọ gaga kẹ udhedhẹ .\n",
            "2020-01-17 08:30:54,188 Validation result (greedy) at epoch  16, step    38000: bleu:  25.92, loss: 39367.7617, ppl:   4.5655, duration: 33.9807s\n",
            "2020-01-17 08:31:08,251 Epoch  16 Step:    38100 Batch Loss:     1.799312 Tokens per Sec:    15611, Lr: 0.000300\n",
            "2020-01-17 08:31:22,326 Epoch  16 Step:    38200 Batch Loss:     1.430584 Tokens per Sec:    15843, Lr: 0.000300\n",
            "2020-01-17 08:31:36,408 Epoch  16 Step:    38300 Batch Loss:     1.319170 Tokens per Sec:    15672, Lr: 0.000300\n",
            "2020-01-17 08:31:50,475 Epoch  16 Step:    38400 Batch Loss:     1.578799 Tokens per Sec:    16076, Lr: 0.000300\n",
            "2020-01-17 08:32:04,512 Epoch  16 Step:    38500 Batch Loss:     1.656253 Tokens per Sec:    15335, Lr: 0.000300\n",
            "2020-01-17 08:32:18,604 Epoch  16 Step:    38600 Batch Loss:     1.751851 Tokens per Sec:    15590, Lr: 0.000300\n",
            "2020-01-17 08:32:32,701 Epoch  16 Step:    38700 Batch Loss:     1.549351 Tokens per Sec:    16130, Lr: 0.000300\n",
            "2020-01-17 08:32:46,731 Epoch  16 Step:    38800 Batch Loss:     1.447309 Tokens per Sec:    15273, Lr: 0.000300\n",
            "2020-01-17 08:33:00,800 Epoch  16 Step:    38900 Batch Loss:     1.428879 Tokens per Sec:    15896, Lr: 0.000300\n",
            "2020-01-17 08:33:14,922 Epoch  16 Step:    39000 Batch Loss:     1.401168 Tokens per Sec:    15824, Lr: 0.000300\n",
            "2020-01-17 08:33:48,999 Hooray! New best validation result [ppl]!\n",
            "2020-01-17 08:33:49,000 Saving new checkpoint.\n",
            "2020-01-17 08:33:50,641 Example #0\n",
            "2020-01-17 08:33:50,642 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 08:33:50,643 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 08:33:50,643 \tHypothesis: Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ ma omai eva efuafo . ’\n",
            "2020-01-17 08:33:50,643 Example #1\n",
            "2020-01-17 08:33:50,644 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 08:33:50,644 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 08:33:50,645 \tHypothesis: A ru onana ẹkwoma Usi Uvie na ha .\n",
            "2020-01-17 08:33:50,645 Example #2\n",
            "2020-01-17 08:33:50,646 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 08:33:50,646 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 08:33:50,646 \tHypothesis: Fikiere mai kpobi ma vẹ te ghọghọ avọ oghọghọ nọ ma te roro kpahe epanọ ma rẹ rọ rehọ emamọ ole nana ku ẹme na họ : “ Jọ odẹ riẹ [ Ovie na ] o jọ bẹdẹ bẹdẹ , re odẹ riẹ o jọ bẹdẹ , re a jọ bẹdẹ bẹdẹ , re odẹ riẹ o jọ bẹdẹ , re o jọ odẹ riẹ o jọ eva riẹ , re o jọ ahwo kpobi a wo oghale , re a wo oghale .\n",
            "2020-01-17 08:33:50,647 Example #3\n",
            "2020-01-17 08:33:50,647 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 08:33:50,647 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 08:33:50,648 \tHypothesis: Ghele na , eme ọ ọghoruo yọ ẹgba ọgaga nọ a re ro ru udhedhẹ .\n",
            "2020-01-17 08:33:50,648 Validation result (greedy) at epoch  16, step    39000: bleu:  26.37, loss: 38852.8320, ppl:   4.4757, duration: 35.7258s\n",
            "2020-01-17 08:34:05,455 Epoch  16 Step:    39100 Batch Loss:     1.389143 Tokens per Sec:    15537, Lr: 0.000300\n",
            "2020-01-17 08:34:19,531 Epoch  16 Step:    39200 Batch Loss:     1.872022 Tokens per Sec:    15382, Lr: 0.000300\n",
            "2020-01-17 08:34:33,593 Epoch  16 Step:    39300 Batch Loss:     1.426664 Tokens per Sec:    15674, Lr: 0.000300\n",
            "2020-01-17 08:34:47,719 Epoch  16 Step:    39400 Batch Loss:     1.798960 Tokens per Sec:    15890, Lr: 0.000300\n",
            "2020-01-17 08:35:01,737 Epoch  16 Step:    39500 Batch Loss:     1.509261 Tokens per Sec:    15687, Lr: 0.000300\n",
            "2020-01-17 08:35:15,866 Epoch  16 Step:    39600 Batch Loss:     1.707075 Tokens per Sec:    15814, Lr: 0.000300\n",
            "2020-01-17 08:35:29,960 Epoch  16 Step:    39700 Batch Loss:     1.584672 Tokens per Sec:    15917, Lr: 0.000300\n",
            "2020-01-17 08:35:44,004 Epoch  16 Step:    39800 Batch Loss:     1.252128 Tokens per Sec:    15641, Lr: 0.000300\n",
            "2020-01-17 08:35:58,179 Epoch  16 Step:    39900 Batch Loss:     1.350880 Tokens per Sec:    16379, Lr: 0.000300\n",
            "2020-01-17 08:36:12,167 Epoch  16 Step:    40000 Batch Loss:     1.711463 Tokens per Sec:    15731, Lr: 0.000300\n",
            "2020-01-17 08:36:46,027 Hooray! New best validation result [ppl]!\n",
            "2020-01-17 08:36:46,027 Saving new checkpoint.\n",
            "2020-01-17 08:36:47,488 Example #0\n",
            "2020-01-17 08:36:47,488 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 08:36:47,489 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 08:36:47,489 \tHypothesis: Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ ma omai eva efuafo . ’\n",
            "2020-01-17 08:36:47,489 Example #1\n",
            "2020-01-17 08:36:47,490 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 08:36:47,490 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 08:36:47,490 \tHypothesis: Onana o jọ ere keme News o bi ru ere he .\n",
            "2020-01-17 08:36:47,491 Example #2\n",
            "2020-01-17 08:36:47,491 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 08:36:47,491 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 08:36:47,492 \tHypothesis: Fikiere , mai kpobi ma ve ti fiba unu mai kpobi nọ ma te ku ẹme na họ , onọ u ti ru nọ ma gbe ro ku ole nana họ họ họ họ : “ Jọ odẹ [ Jesu Kristi Ovie na ] o dhesẹ nọ o dikihẹ bẹdẹ bẹdẹ ; re odẹ riẹ o jọ ruaro , re o jọ ahwo kpobi a wo oghale , re a wo oghale eva efuafo eva odẹ riẹ .\n",
            "2020-01-17 08:36:47,493 Example #3\n",
            "2020-01-17 08:36:47,493 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 08:36:47,494 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 08:36:47,494 \tHypothesis: Ghele na , eme ọghoruo e rẹ jọ ẹgba gaga re a ru udhedhẹ .\n",
            "2020-01-17 08:36:47,494 Validation result (greedy) at epoch  16, step    40000: bleu:  27.20, loss: 38837.3750, ppl:   4.4730, duration: 35.3264s\n",
            "2020-01-17 08:37:02,290 Epoch  16 Step:    40100 Batch Loss:     1.473470 Tokens per Sec:    15299, Lr: 0.000300\n",
            "2020-01-17 08:37:16,427 Epoch  16 Step:    40200 Batch Loss:     1.443297 Tokens per Sec:    15721, Lr: 0.000300\n",
            "2020-01-17 08:37:30,522 Epoch  16 Step:    40300 Batch Loss:     1.979164 Tokens per Sec:    16048, Lr: 0.000300\n",
            "2020-01-17 08:37:44,554 Epoch  16 Step:    40400 Batch Loss:     1.801190 Tokens per Sec:    15494, Lr: 0.000300\n",
            "2020-01-17 08:37:52,627 Epoch  16: total training loss 4000.89\n",
            "2020-01-17 08:37:52,627 EPOCH 17\n",
            "2020-01-17 08:37:58,779 Epoch  17 Step:    40500 Batch Loss:     1.763875 Tokens per Sec:    14268, Lr: 0.000300\n",
            "2020-01-17 08:38:12,859 Epoch  17 Step:    40600 Batch Loss:     1.972085 Tokens per Sec:    15723, Lr: 0.000300\n",
            "2020-01-17 08:38:27,020 Epoch  17 Step:    40700 Batch Loss:     1.416193 Tokens per Sec:    16156, Lr: 0.000300\n",
            "2020-01-17 08:38:41,065 Epoch  17 Step:    40800 Batch Loss:     1.492986 Tokens per Sec:    15851, Lr: 0.000300\n",
            "2020-01-17 08:38:55,077 Epoch  17 Step:    40900 Batch Loss:     1.636196 Tokens per Sec:    15709, Lr: 0.000300\n",
            "2020-01-17 08:39:09,168 Epoch  17 Step:    41000 Batch Loss:     1.491983 Tokens per Sec:    15871, Lr: 0.000300\n",
            "2020-01-17 08:39:43,189 Hooray! New best validation result [ppl]!\n",
            "2020-01-17 08:39:43,189 Saving new checkpoint.\n",
            "2020-01-17 08:39:44,599 Example #0\n",
            "2020-01-17 08:39:44,600 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 08:39:44,600 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 08:39:44,601 \tHypothesis: Ma rẹ sae yare Ọghẹnẹ re ọ ‘ ma omai eva efuafo . ’\n",
            "2020-01-17 08:39:44,601 Example #1\n",
            "2020-01-17 08:39:44,602 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 08:39:44,602 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 08:39:44,602 \tHypothesis: A lele onana ẹkwoma Usi Uvie na ha .\n",
            "2020-01-17 08:39:44,602 Example #2\n",
            "2020-01-17 08:39:44,603 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 08:39:44,603 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 08:39:44,604 \tHypothesis: O rẹ wọhọ nọ mai kpobi ma te rehọ oghọghọ fiba eme nọ ma be ta na , onọ o rẹ kẹ evawere gbe omosasọ nọ ma te jiri odẹ riẹ nọ : “ Jọ odẹ riẹ [ Jesu Kristi Ovie na ] o jọ bẹdẹ , re ma ruẹse jọ bẹdẹ , re odẹ riẹ o jọ vevẹ , re wha jọ ahwo kpobi a wo oghale eva riẹ , re a jiri ei .\n",
            "2020-01-17 08:39:44,604 Example #3\n",
            "2020-01-17 08:39:44,605 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 08:39:44,605 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 08:39:44,605 \tHypothesis: Ghele na , eme ọghoruo e rẹ jọ ẹgba gaga re a ru udhedhẹ .\n",
            "2020-01-17 08:39:44,605 Validation result (greedy) at epoch  17, step    41000: bleu:  27.08, loss: 38758.8203, ppl:   4.4595, duration: 35.4368s\n",
            "2020-01-17 08:39:59,408 Epoch  17 Step:    41100 Batch Loss:     1.430078 Tokens per Sec:    15195, Lr: 0.000300\n",
            "2020-01-17 08:40:13,507 Epoch  17 Step:    41200 Batch Loss:     1.667893 Tokens per Sec:    15833, Lr: 0.000300\n",
            "2020-01-17 08:40:27,588 Epoch  17 Step:    41300 Batch Loss:     1.522428 Tokens per Sec:    15745, Lr: 0.000300\n",
            "2020-01-17 08:40:41,641 Epoch  17 Step:    41400 Batch Loss:     1.305554 Tokens per Sec:    15354, Lr: 0.000300\n",
            "2020-01-17 08:40:55,672 Epoch  17 Step:    41500 Batch Loss:     1.615774 Tokens per Sec:    15846, Lr: 0.000300\n",
            "2020-01-17 08:41:09,810 Epoch  17 Step:    41600 Batch Loss:     1.514056 Tokens per Sec:    16323, Lr: 0.000300\n",
            "2020-01-17 08:41:23,847 Epoch  17 Step:    41700 Batch Loss:     1.220489 Tokens per Sec:    15866, Lr: 0.000300\n",
            "2020-01-17 08:41:37,764 Epoch  17 Step:    41800 Batch Loss:     1.548567 Tokens per Sec:    15472, Lr: 0.000300\n",
            "2020-01-17 08:41:51,804 Epoch  17 Step:    41900 Batch Loss:     1.557838 Tokens per Sec:    15764, Lr: 0.000300\n",
            "2020-01-17 08:42:05,864 Epoch  17 Step:    42000 Batch Loss:     1.867422 Tokens per Sec:    15822, Lr: 0.000300\n",
            "2020-01-17 08:42:39,790 Hooray! New best validation result [ppl]!\n",
            "2020-01-17 08:42:39,791 Saving new checkpoint.\n",
            "2020-01-17 08:42:41,241 Example #0\n",
            "2020-01-17 08:42:41,242 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 08:42:41,242 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 08:42:41,242 \tHypothesis: Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ ma omai eva efuafo . ’\n",
            "2020-01-17 08:42:41,243 Example #1\n",
            "2020-01-17 08:42:41,243 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 08:42:41,243 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 08:42:41,244 \tHypothesis: A te lele onana , Usi Uvie na o gbẹ jọ họ .\n",
            "2020-01-17 08:42:41,244 Example #2\n",
            "2020-01-17 08:42:41,245 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 08:42:41,245 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 08:42:41,245 \tHypothesis: Fikiere , mai kpobi ma vẹ te ghọghọ avọ evawere nọ ma te roro kpahe uvitha igbunu nana , onọ o rẹ kẹ evawere : “ Jọ odẹ riẹ [ Jesu Kristi Ovie na ] o jọ bẹdẹ bẹdẹ ; re odẹ riẹ o jọ bẹdẹ bẹdẹ , re o jọ odẹ riẹ , re o jọ odẹ riẹ , re o jọ ahwo kpobi oma riẹ , re a wo evawere .\n",
            "2020-01-17 08:42:41,245 Example #3\n",
            "2020-01-17 08:42:41,246 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 08:42:41,246 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 08:42:41,246 \tHypothesis: Ghele na , eme ọghoruo e rẹ jọ gaga kẹ udhedhẹ .\n",
            "2020-01-17 08:42:41,247 Validation result (greedy) at epoch  17, step    42000: bleu:  26.11, loss: 38634.7539, ppl:   4.4382, duration: 35.3823s\n",
            "2020-01-17 08:42:55,949 Epoch  17 Step:    42100 Batch Loss:     1.368821 Tokens per Sec:    15181, Lr: 0.000300\n",
            "2020-01-17 08:43:10,162 Epoch  17 Step:    42200 Batch Loss:     1.620894 Tokens per Sec:    16026, Lr: 0.000300\n",
            "2020-01-17 08:43:24,239 Epoch  17 Step:    42300 Batch Loss:     1.693849 Tokens per Sec:    15671, Lr: 0.000300\n",
            "2020-01-17 08:43:38,322 Epoch  17 Step:    42400 Batch Loss:     1.558014 Tokens per Sec:    15883, Lr: 0.000300\n",
            "2020-01-17 08:43:52,427 Epoch  17 Step:    42500 Batch Loss:     1.653813 Tokens per Sec:    15597, Lr: 0.000300\n",
            "2020-01-17 08:44:06,532 Epoch  17 Step:    42600 Batch Loss:     1.749477 Tokens per Sec:    15516, Lr: 0.000300\n",
            "2020-01-17 08:44:20,675 Epoch  17 Step:    42700 Batch Loss:     1.680902 Tokens per Sec:    16312, Lr: 0.000300\n",
            "2020-01-17 08:44:34,741 Epoch  17 Step:    42800 Batch Loss:     1.691166 Tokens per Sec:    15789, Lr: 0.000300\n",
            "2020-01-17 08:44:48,829 Epoch  17 Step:    42900 Batch Loss:     1.683352 Tokens per Sec:    15838, Lr: 0.000300\n",
            "2020-01-17 08:45:00,762 Epoch  17: total training loss 3950.78\n",
            "2020-01-17 08:45:00,763 EPOCH 18\n",
            "2020-01-17 08:45:03,296 Epoch  18 Step:    43000 Batch Loss:     1.346610 Tokens per Sec:    13223, Lr: 0.000300\n",
            "2020-01-17 08:45:37,305 Hooray! New best validation result [ppl]!\n",
            "2020-01-17 08:45:37,306 Saving new checkpoint.\n",
            "2020-01-17 08:45:38,770 Example #0\n",
            "2020-01-17 08:45:38,771 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 08:45:38,771 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 08:45:38,772 \tHypothesis: Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ ma omai eva efuafo . ’\n",
            "2020-01-17 08:45:38,772 Example #1\n",
            "2020-01-17 08:45:38,773 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 08:45:38,773 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 08:45:38,773 \tHypothesis: Usi Uvie na u lele i rie he .\n",
            "2020-01-17 08:45:38,773 Example #2\n",
            "2020-01-17 08:45:38,774 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 08:45:38,774 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 08:45:38,775 \tHypothesis: Fikiere , mai kpobi ma vẹ te ghọghọ avọ oghọghọ nọ ma te roro kpahe ẹme nọ ọ rrọ obe nana nọ o rrọ emamọ obe nana , onọ o rẹ kẹ omai evawere : “ Jọ odẹ riẹ [ Jesu Kristi ] o jọ bẹdẹ bẹdẹ , re a jọ bẹdẹ , re a ruẹse rehọ odẹ riẹ jiri ei , re a ghale ae , re a wo oghale eva riẹ .\n",
            "2020-01-17 08:45:38,775 Example #3\n",
            "2020-01-17 08:45:38,776 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 08:45:38,776 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 08:45:38,776 \tHypothesis: Ghele na , eme ọghoruo yọ ẹgba ọgaga nọ a re ro ru udhedhẹ .\n",
            "2020-01-17 08:45:38,776 Validation result (greedy) at epoch  18, step    43000: bleu:  26.85, loss: 38215.0156, ppl:   4.3669, duration: 35.4791s\n",
            "2020-01-17 08:45:53,492 Epoch  18 Step:    43100 Batch Loss:     1.628843 Tokens per Sec:    15422, Lr: 0.000300\n",
            "2020-01-17 08:46:07,596 Epoch  18 Step:    43200 Batch Loss:     1.116013 Tokens per Sec:    15868, Lr: 0.000300\n",
            "2020-01-17 08:46:21,663 Epoch  18 Step:    43300 Batch Loss:     1.427561 Tokens per Sec:    15888, Lr: 0.000300\n",
            "2020-01-17 08:46:35,812 Epoch  18 Step:    43400 Batch Loss:     1.306190 Tokens per Sec:    16043, Lr: 0.000300\n",
            "2020-01-17 08:46:49,882 Epoch  18 Step:    43500 Batch Loss:     1.692668 Tokens per Sec:    15627, Lr: 0.000300\n",
            "2020-01-17 08:47:03,960 Epoch  18 Step:    43600 Batch Loss:     1.362305 Tokens per Sec:    15756, Lr: 0.000300\n",
            "2020-01-17 08:47:17,953 Epoch  18 Step:    43700 Batch Loss:     1.569624 Tokens per Sec:    15436, Lr: 0.000300\n",
            "2020-01-17 08:47:32,077 Epoch  18 Step:    43800 Batch Loss:     1.265225 Tokens per Sec:    15617, Lr: 0.000300\n",
            "2020-01-17 08:47:46,192 Epoch  18 Step:    43900 Batch Loss:     1.547997 Tokens per Sec:    16011, Lr: 0.000300\n",
            "2020-01-17 08:48:00,300 Epoch  18 Step:    44000 Batch Loss:     1.701742 Tokens per Sec:    16185, Lr: 0.000300\n",
            "2020-01-17 08:48:34,245 Hooray! New best validation result [ppl]!\n",
            "2020-01-17 08:48:34,245 Saving new checkpoint.\n",
            "2020-01-17 08:48:35,685 Example #0\n",
            "2020-01-17 08:48:35,686 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 08:48:35,686 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 08:48:35,686 \tHypothesis: Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ ma omai eva efuafo . ’\n",
            "2020-01-17 08:48:35,686 Example #1\n",
            "2020-01-17 08:48:35,687 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 08:48:35,687 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 08:48:35,687 \tHypothesis: Usi Uvie na o jọ họ .\n",
            "2020-01-17 08:48:35,688 Example #2\n",
            "2020-01-17 08:48:35,688 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 08:48:35,689 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 08:48:35,689 \tHypothesis: Fikiere , mai kpobi ma ve ti fiba eme nọ ma ta na avọ oghọghọ nọ ma ti ro ku ẹme nana họ avọ omosasọ : “ Jọ odẹ riẹ [ Jesu Kristi Ovie na ] o jọ bẹdẹ bẹdẹ ; re a ruẹse jọ odẹ riẹ o jọ bẹdẹ , re a ruẹse jọ ahwo kpobi wo oghale eva riẹ , re a ruẹse rehọ odẹ riẹ ru ai wo oghale eva riẹ .\n",
            "2020-01-17 08:48:35,689 Example #3\n",
            "2020-01-17 08:48:35,690 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 08:48:35,690 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 08:48:35,690 \tHypothesis: Ghele na , eme ọghoruo yọ ẹgba ologbo nọ o re ro ru udhedhẹ .\n",
            "2020-01-17 08:48:35,690 Validation result (greedy) at epoch  18, step    44000: bleu:  26.71, loss: 38140.5625, ppl:   4.3544, duration: 35.3894s\n",
            "2020-01-17 08:48:50,331 Epoch  18 Step:    44100 Batch Loss:     1.511414 Tokens per Sec:    14749, Lr: 0.000300\n",
            "2020-01-17 08:49:04,388 Epoch  18 Step:    44200 Batch Loss:     1.315001 Tokens per Sec:    15636, Lr: 0.000300\n",
            "2020-01-17 08:49:18,565 Epoch  18 Step:    44300 Batch Loss:     1.676663 Tokens per Sec:    16079, Lr: 0.000300\n",
            "2020-01-17 08:49:32,555 Epoch  18 Step:    44400 Batch Loss:     1.773087 Tokens per Sec:    15794, Lr: 0.000300\n",
            "2020-01-17 08:49:46,634 Epoch  18 Step:    44500 Batch Loss:     1.591365 Tokens per Sec:    15974, Lr: 0.000300\n",
            "2020-01-17 08:50:00,673 Epoch  18 Step:    44600 Batch Loss:     1.326442 Tokens per Sec:    15653, Lr: 0.000300\n",
            "2020-01-17 08:50:14,751 Epoch  18 Step:    44700 Batch Loss:     1.436747 Tokens per Sec:    15686, Lr: 0.000300\n",
            "2020-01-17 08:50:28,719 Epoch  18 Step:    44800 Batch Loss:     1.463893 Tokens per Sec:    15845, Lr: 0.000300\n",
            "2020-01-17 08:50:42,876 Epoch  18 Step:    44900 Batch Loss:     1.707094 Tokens per Sec:    15825, Lr: 0.000300\n",
            "2020-01-17 08:50:56,918 Epoch  18 Step:    45000 Batch Loss:     1.653723 Tokens per Sec:    16194, Lr: 0.000300\n",
            "2020-01-17 08:51:30,780 Hooray! New best validation result [ppl]!\n",
            "2020-01-17 08:51:30,781 Saving new checkpoint.\n",
            "2020-01-17 08:51:32,183 Example #0\n",
            "2020-01-17 08:51:32,184 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 08:51:32,184 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 08:51:32,184 \tHypothesis: Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ ma omai eva efuafo . ’\n",
            "2020-01-17 08:51:32,184 Example #1\n",
            "2020-01-17 08:51:32,185 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 08:51:32,185 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 08:51:32,186 \tHypothesis: A te lele onana News News News ha .\n",
            "2020-01-17 08:51:32,186 Example #2\n",
            "2020-01-17 08:51:32,187 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 08:51:32,187 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 08:51:32,187 \tHypothesis: Fikiere , mai kpobi ma ve fiba unu mai kpobi kẹ ukuhọ ukuhọ ukuhọ arao nana nọ o wo erru gbe omosasọ nana : “ Jọ odẹ riẹ [ Jesu Kristi Ovie na ] o jọ bẹdẹ ; taure ọre na ọ tẹ te ze , re o te ti jiri odẹ riẹ , re o jọ uvou - uthei .\n",
            "2020-01-17 08:51:32,187 Example #3\n",
            "2020-01-17 08:51:32,188 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 08:51:32,188 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 08:51:32,188 \tHypothesis: Ghele na , eme ọ ọghoruo yọ ẹgba ologbo nọ o re ro ru udhedhẹ .\n",
            "2020-01-17 08:51:32,189 Validation result (greedy) at epoch  18, step    45000: bleu:  26.84, loss: 37830.8789, ppl:   4.3027, duration: 35.2700s\n",
            "2020-01-17 08:51:46,837 Epoch  18 Step:    45100 Batch Loss:     1.495554 Tokens per Sec:    14745, Lr: 0.000300\n",
            "2020-01-17 08:52:00,927 Epoch  18 Step:    45200 Batch Loss:     1.460160 Tokens per Sec:    15809, Lr: 0.000300\n",
            "2020-01-17 08:52:15,015 Epoch  18 Step:    45300 Batch Loss:     1.678577 Tokens per Sec:    16106, Lr: 0.000300\n",
            "2020-01-17 08:52:28,969 Epoch  18 Step:    45400 Batch Loss:     1.573041 Tokens per Sec:    15249, Lr: 0.000300\n",
            "2020-01-17 08:52:43,047 Epoch  18 Step:    45500 Batch Loss:     1.420315 Tokens per Sec:    15850, Lr: 0.000300\n",
            "2020-01-17 08:52:44,995 Epoch  18: total training loss 3910.45\n",
            "2020-01-17 08:52:44,996 EPOCH 19\n",
            "2020-01-17 08:52:57,405 Epoch  19 Step:    45600 Batch Loss:     1.551122 Tokens per Sec:    15483, Lr: 0.000300\n",
            "2020-01-17 08:53:11,470 Epoch  19 Step:    45700 Batch Loss:     1.357349 Tokens per Sec:    15612, Lr: 0.000300\n",
            "2020-01-17 08:53:25,582 Epoch  19 Step:    45800 Batch Loss:     1.622373 Tokens per Sec:    15937, Lr: 0.000300\n",
            "2020-01-17 08:53:39,676 Epoch  19 Step:    45900 Batch Loss:     1.744955 Tokens per Sec:    15367, Lr: 0.000300\n",
            "2020-01-17 08:53:53,826 Epoch  19 Step:    46000 Batch Loss:     1.458784 Tokens per Sec:    16129, Lr: 0.000300\n",
            "2020-01-17 08:54:27,864 Example #0\n",
            "2020-01-17 08:54:27,865 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 08:54:27,865 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 08:54:27,865 \tHypothesis: Ma rẹ sae tubẹ yare Ọghẹnẹ inọ ọ ma omai evaọ udu efuafo .\n",
            "2020-01-17 08:54:27,865 Example #1\n",
            "2020-01-17 08:54:27,866 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 08:54:27,866 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 08:54:27,866 \tHypothesis: A te ru onana ẹkwoma Usi Uvie na ha .\n",
            "2020-01-17 08:54:27,867 Example #2\n",
            "2020-01-17 08:54:27,867 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 08:54:27,867 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 08:54:27,868 \tHypothesis: Fikiere , mai kpobi ma vẹ te rehọ oghọghọ fiba odẹ ole nana nọ o rrọ ole evawere na : “ Jọ odẹ riẹ [ Jesu Kristi Ovie na ] ọ jọ bẹdẹ , re o jọ bẹdẹ , re odẹ riẹ o jọ urirẹ , re o jọ uvou ulogbo , re erẹwho na kpobi a wo evawere ; jọ a jiri ei , re a jọ eva e were iẹe .\n",
            "2020-01-17 08:54:27,868 Example #3\n",
            "2020-01-17 08:54:27,869 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 08:54:27,869 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 08:54:27,869 \tHypothesis: Ghele na , eme ọ ọghoruo yọ ẹgba ologbo nọ a re ro ru udhedhẹ .\n",
            "2020-01-17 08:54:27,869 Validation result (greedy) at epoch  19, step    46000: bleu:  27.22, loss: 37947.8711, ppl:   4.3222, duration: 34.0426s\n",
            "2020-01-17 08:54:41,990 Epoch  19 Step:    46100 Batch Loss:     1.739807 Tokens per Sec:    15927, Lr: 0.000300\n",
            "2020-01-17 08:54:56,135 Epoch  19 Step:    46200 Batch Loss:     1.446327 Tokens per Sec:    16071, Lr: 0.000300\n",
            "2020-01-17 08:55:10,262 Epoch  19 Step:    46300 Batch Loss:     1.656833 Tokens per Sec:    15445, Lr: 0.000300\n",
            "2020-01-17 08:55:24,384 Epoch  19 Step:    46400 Batch Loss:     1.818220 Tokens per Sec:    15626, Lr: 0.000300\n",
            "2020-01-17 08:55:38,424 Epoch  19 Step:    46500 Batch Loss:     1.412834 Tokens per Sec:    15682, Lr: 0.000300\n",
            "2020-01-17 08:55:52,446 Epoch  19 Step:    46600 Batch Loss:     1.442368 Tokens per Sec:    15750, Lr: 0.000300\n",
            "2020-01-17 08:56:06,558 Epoch  19 Step:    46700 Batch Loss:     1.176592 Tokens per Sec:    15662, Lr: 0.000300\n",
            "2020-01-17 08:56:20,636 Epoch  19 Step:    46800 Batch Loss:     1.544705 Tokens per Sec:    15928, Lr: 0.000300\n",
            "2020-01-17 08:56:34,751 Epoch  19 Step:    46900 Batch Loss:     1.553115 Tokens per Sec:    15672, Lr: 0.000300\n",
            "2020-01-17 08:56:48,967 Epoch  19 Step:    47000 Batch Loss:     1.700349 Tokens per Sec:    16138, Lr: 0.000300\n",
            "2020-01-17 08:57:22,903 Example #0\n",
            "2020-01-17 08:57:22,904 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 08:57:22,904 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 08:57:22,904 \tHypothesis: Ma rẹ sae yare Ọghẹnẹ re ọ ‘ ma omai eva efuafo . ’\n",
            "2020-01-17 08:57:22,905 Example #1\n",
            "2020-01-17 08:57:22,905 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 08:57:22,906 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 08:57:22,906 \tHypothesis: A lele onana evaọ obọ News News of the Hows .\n",
            "2020-01-17 08:57:22,906 Example #2\n",
            "2020-01-17 08:57:22,907 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 08:57:22,907 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 08:57:22,908 \tHypothesis: Fikiere , mai kpobi ma vẹ te rehọ oghọghọ fiba eme mai na rite ekuhọ ukuhọ ọrọ ukuhọ ọrọ uvitha igbunu nana : “ Jọ odẹ riẹ [ Jesu Kristi Ovie na ] o jọ bẹdẹ bẹdẹ , re ọre na ọ jọ o ru odẹ riẹ gba , re o jọ odẹ riẹ o jọ orọ eva e were ae ; jọ ahwo kpobi a jiri ei .\n",
            "2020-01-17 08:57:22,908 Example #3\n",
            "2020-01-17 08:57:22,909 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 08:57:22,909 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 08:57:22,909 \tHypothesis: Ghele na , eme ọghoruo yọ ẹgba ọgaga nọ a re ro ru udhedhẹ .\n",
            "2020-01-17 08:57:22,910 Validation result (greedy) at epoch  19, step    47000: bleu:  26.90, loss: 37837.0195, ppl:   4.3037, duration: 33.9417s\n",
            "2020-01-17 08:57:36,970 Epoch  19 Step:    47100 Batch Loss:     1.560465 Tokens per Sec:    15656, Lr: 0.000300\n",
            "2020-01-17 08:57:51,131 Epoch  19 Step:    47200 Batch Loss:     1.575154 Tokens per Sec:    15979, Lr: 0.000300\n",
            "2020-01-17 08:58:05,287 Epoch  19 Step:    47300 Batch Loss:     1.735078 Tokens per Sec:    15986, Lr: 0.000300\n",
            "2020-01-17 08:58:19,376 Epoch  19 Step:    47400 Batch Loss:     1.467570 Tokens per Sec:    15822, Lr: 0.000300\n",
            "2020-01-17 08:58:33,407 Epoch  19 Step:    47500 Batch Loss:     1.578745 Tokens per Sec:    15466, Lr: 0.000300\n",
            "2020-01-17 08:58:47,511 Epoch  19 Step:    47600 Batch Loss:     1.553291 Tokens per Sec:    15639, Lr: 0.000300\n",
            "2020-01-17 08:59:01,572 Epoch  19 Step:    47700 Batch Loss:     1.593474 Tokens per Sec:    15988, Lr: 0.000300\n",
            "2020-01-17 08:59:15,643 Epoch  19 Step:    47800 Batch Loss:     1.466320 Tokens per Sec:    15861, Lr: 0.000300\n",
            "2020-01-17 08:59:29,687 Epoch  19 Step:    47900 Batch Loss:     1.530802 Tokens per Sec:    15631, Lr: 0.000300\n",
            "2020-01-17 08:59:43,824 Epoch  19 Step:    48000 Batch Loss:     1.459426 Tokens per Sec:    16286, Lr: 0.000300\n",
            "2020-01-17 09:00:17,799 Hooray! New best validation result [ppl]!\n",
            "2020-01-17 09:00:17,800 Saving new checkpoint.\n",
            "2020-01-17 09:00:19,241 Example #0\n",
            "2020-01-17 09:00:19,242 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 09:00:19,242 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 09:00:19,242 \tHypothesis: Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ ma omai eva efuafo . ’\n",
            "2020-01-17 09:00:19,242 Example #1\n",
            "2020-01-17 09:00:19,243 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 09:00:19,243 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 09:00:19,243 \tHypothesis: A te lele onana , Usi Uvie na o tẹ te jọ họ .\n",
            "2020-01-17 09:00:19,243 Example #2\n",
            "2020-01-17 09:00:19,244 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 09:00:19,244 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 09:00:19,245 \tHypothesis: Fikiere , mai kpobi ma vẹ te rọ oghọghọ fiba eme nọ ma ta kpahe erru nana nọ i bi ti kuhọ na , onọ o rẹ kẹ omai evawere : “ Jọ odẹ riẹ [ Ovie na ] o jọ bẹdẹ bẹdẹ , re o ruẹse te jọ elo riẹ , re o ru re erẹwho na kpobi a ruẹse rehọ odẹ riẹ kẹ ae , re a ruẹse ghale ae .\n",
            "2020-01-17 09:00:19,245 Example #3\n",
            "2020-01-17 09:00:19,246 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 09:00:19,246 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 09:00:19,246 \tHypothesis: Ghele na , eme ọ ọghoruo yọ ẹgba ologbo nọ a re ro ru udhedhẹ .\n",
            "2020-01-17 09:00:19,246 Validation result (greedy) at epoch  19, step    48000: bleu:  26.77, loss: 37429.3203, ppl:   4.2366, duration: 35.4217s\n",
            "2020-01-17 09:00:24,518 Epoch  19: total training loss 3865.87\n",
            "2020-01-17 09:00:24,518 EPOCH 20\n",
            "2020-01-17 09:00:33,931 Epoch  20 Step:    48100 Batch Loss:     1.551111 Tokens per Sec:    14595, Lr: 0.000300\n",
            "2020-01-17 09:00:48,382 Epoch  20 Step:    48200 Batch Loss:     1.344426 Tokens per Sec:    15736, Lr: 0.000300\n",
            "2020-01-17 09:01:02,403 Epoch  20 Step:    48300 Batch Loss:     1.405853 Tokens per Sec:    15771, Lr: 0.000300\n",
            "2020-01-17 09:01:16,470 Epoch  20 Step:    48400 Batch Loss:     1.700039 Tokens per Sec:    16082, Lr: 0.000300\n",
            "2020-01-17 09:01:30,502 Epoch  20 Step:    48500 Batch Loss:     1.370880 Tokens per Sec:    15738, Lr: 0.000300\n",
            "2020-01-17 09:01:44,613 Epoch  20 Step:    48600 Batch Loss:     1.433949 Tokens per Sec:    16012, Lr: 0.000300\n",
            "2020-01-17 09:01:58,730 Epoch  20 Step:    48700 Batch Loss:     1.590184 Tokens per Sec:    15820, Lr: 0.000300\n",
            "2020-01-17 09:02:12,858 Epoch  20 Step:    48800 Batch Loss:     1.349697 Tokens per Sec:    15736, Lr: 0.000300\n",
            "2020-01-17 09:02:27,001 Epoch  20 Step:    48900 Batch Loss:     1.564948 Tokens per Sec:    15583, Lr: 0.000300\n",
            "2020-01-17 09:02:41,181 Epoch  20 Step:    49000 Batch Loss:     1.418265 Tokens per Sec:    15399, Lr: 0.000300\n",
            "2020-01-17 09:03:15,452 Example #0\n",
            "2020-01-17 09:03:15,454 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 09:03:15,454 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 09:03:15,454 \tHypothesis: Ma rẹ sae tubẹ lẹ se Ọghẹnẹ re ọ ‘ ma omai eva efuafo . ’\n",
            "2020-01-17 09:03:15,455 Example #1\n",
            "2020-01-17 09:03:15,456 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 09:03:15,456 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 09:03:15,457 \tHypothesis: Usi Uvie na o tẹ nya lele iei .\n",
            "2020-01-17 09:03:15,457 Example #2\n",
            "2020-01-17 09:03:15,457 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 09:03:15,458 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 09:03:15,458 \tHypothesis: Fikiere , mai kpobi ma ve ti fiba oghọghọ mai te ekuhọ uyere nana nọ o rrọ ole nọ o rẹ kẹ omosasọ gbe omosasọ na : “ Jọ odẹ riẹ [ Jesu Kristi na ] o jọ bẹdẹ bẹdẹ ; re ọre na o te lo , re o te je jiri odẹ riẹ , re ahwo erẹwho na kpobi a jiri ei .\n",
            "2020-01-17 09:03:15,458 Example #3\n",
            "2020-01-17 09:03:15,459 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 09:03:15,459 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 09:03:15,459 \tHypothesis: Ghele na , eme ọ ọghoruo yọ ẹgba nọ a re ro ru udhedhẹ .\n",
            "2020-01-17 09:03:15,460 Validation result (greedy) at epoch  20, step    49000: bleu:  27.91, loss: 37535.8086, ppl:   4.2540, duration: 34.2783s\n",
            "2020-01-17 09:03:29,653 Epoch  20 Step:    49100 Batch Loss:     1.573217 Tokens per Sec:    15624, Lr: 0.000300\n",
            "2020-01-17 09:03:43,749 Epoch  20 Step:    49200 Batch Loss:     1.435630 Tokens per Sec:    15854, Lr: 0.000300\n",
            "2020-01-17 09:03:57,945 Epoch  20 Step:    49300 Batch Loss:     1.478797 Tokens per Sec:    15747, Lr: 0.000300\n",
            "2020-01-17 09:04:12,156 Epoch  20 Step:    49400 Batch Loss:     1.866373 Tokens per Sec:    15699, Lr: 0.000300\n",
            "2020-01-17 09:04:26,376 Epoch  20 Step:    49500 Batch Loss:     1.599277 Tokens per Sec:    15475, Lr: 0.000300\n",
            "2020-01-17 09:04:40,499 Epoch  20 Step:    49600 Batch Loss:     1.311149 Tokens per Sec:    15583, Lr: 0.000300\n",
            "2020-01-17 09:04:54,603 Epoch  20 Step:    49700 Batch Loss:     1.732741 Tokens per Sec:    15514, Lr: 0.000300\n",
            "2020-01-17 09:05:08,706 Epoch  20 Step:    49800 Batch Loss:     1.475113 Tokens per Sec:    15684, Lr: 0.000300\n",
            "2020-01-17 09:05:22,856 Epoch  20 Step:    49900 Batch Loss:     1.516559 Tokens per Sec:    15848, Lr: 0.000300\n",
            "2020-01-17 09:05:36,982 Epoch  20 Step:    50000 Batch Loss:     1.658719 Tokens per Sec:    16041, Lr: 0.000300\n",
            "2020-01-17 09:06:11,040 Hooray! New best validation result [ppl]!\n",
            "2020-01-17 09:06:11,041 Saving new checkpoint.\n",
            "2020-01-17 09:06:12,465 Example #0\n",
            "2020-01-17 09:06:12,466 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 09:06:12,466 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 09:06:12,466 \tHypothesis: Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ ma omai eva efuafo . ’\n",
            "2020-01-17 09:06:12,467 Example #1\n",
            "2020-01-17 09:06:12,467 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 09:06:12,468 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 09:06:12,468 \tHypothesis: A te lele onana , Usi Uvie na o tẹ te jọ họ .\n",
            "2020-01-17 09:06:12,468 Example #2\n",
            "2020-01-17 09:06:12,469 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 09:06:12,469 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 09:06:12,469 \tHypothesis: Fikiere , mai kpobi ma vẹ te rehọ oghọghọ fiba iroro mai kpobi nọ ma te roro kpahe ekuhọ ole nana nọ o rrọ ole obọdẹ gbe omosasọ nana : “ Jọ odẹ riẹ [ Jesu Kristi Ovie na ] o jọ bẹdẹ bẹdẹ ; re ọre na ọ ruẹse te rehọ odẹ riẹ jiri ei , re o jọ oghale kẹ ae ; re o jọ oghale kẹ ae kpobi .\n",
            "2020-01-17 09:06:12,470 Example #3\n",
            "2020-01-17 09:06:12,470 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 09:06:12,470 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 09:06:12,471 \tHypothesis: Ghele na , eme ọ ọgbahọ yọ ẹgba ologbo nọ a re ro ru udhedhẹ .\n",
            "2020-01-17 09:06:12,471 Validation result (greedy) at epoch  20, step    50000: bleu:  27.39, loss: 37384.2031, ppl:   4.2292, duration: 35.4879s\n",
            "2020-01-17 09:06:27,315 Epoch  20 Step:    50100 Batch Loss:     1.548658 Tokens per Sec:    15071, Lr: 0.000300\n",
            "2020-01-17 09:06:41,447 Epoch  20 Step:    50200 Batch Loss:     1.463249 Tokens per Sec:    15654, Lr: 0.000300\n",
            "2020-01-17 09:06:55,592 Epoch  20 Step:    50300 Batch Loss:     1.271457 Tokens per Sec:    15727, Lr: 0.000300\n",
            "2020-01-17 09:07:09,704 Epoch  20 Step:    50400 Batch Loss:     2.141376 Tokens per Sec:    16017, Lr: 0.000300\n",
            "2020-01-17 09:07:23,831 Epoch  20 Step:    50500 Batch Loss:     1.740636 Tokens per Sec:    15431, Lr: 0.000300\n",
            "2020-01-17 09:07:33,054 Epoch  20: total training loss 3834.30\n",
            "2020-01-17 09:07:33,054 EPOCH 21\n",
            "2020-01-17 09:07:38,274 Epoch  21 Step:    50600 Batch Loss:     1.885052 Tokens per Sec:    15443, Lr: 0.000300\n",
            "2020-01-17 09:07:52,379 Epoch  21 Step:    50700 Batch Loss:     1.583682 Tokens per Sec:    15432, Lr: 0.000300\n",
            "2020-01-17 09:08:06,563 Epoch  21 Step:    50800 Batch Loss:     1.360142 Tokens per Sec:    15719, Lr: 0.000300\n",
            "2020-01-17 09:08:20,815 Epoch  21 Step:    50900 Batch Loss:     1.343652 Tokens per Sec:    15938, Lr: 0.000300\n",
            "2020-01-17 09:08:34,969 Epoch  21 Step:    51000 Batch Loss:     1.599173 Tokens per Sec:    15708, Lr: 0.000300\n",
            "2020-01-17 09:09:09,308 Example #0\n",
            "2020-01-17 09:09:09,309 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 09:09:09,309 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 09:09:09,310 \tHypothesis: Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ ma omai eva efuafo . ’\n",
            "2020-01-17 09:09:09,310 Example #1\n",
            "2020-01-17 09:09:09,310 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 09:09:09,311 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 09:09:09,311 \tHypothesis: Usi Uvie na u lele i rie .\n",
            "2020-01-17 09:09:09,311 Example #2\n",
            "2020-01-17 09:09:09,312 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 09:09:09,312 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 09:09:09,312 \tHypothesis: O tẹ rrọ ere , mai kpobi ma te rehọ oghọghọ fiba unu mai kẹ ekuhọ ole nana nọ o wo erru gaga na : “ Jọ odẹ riẹ [ Jesu Kristi Ovie na ] o dhesẹ nọ a rẹ jọ bẹdẹ bẹdẹ ; re ọre na ọ jọ uvou - uthei , re ti wo oghale eva rai kpobi .\n",
            "2020-01-17 09:09:09,313 Example #3\n",
            "2020-01-17 09:09:09,313 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 09:09:09,314 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 09:09:09,314 \tHypothesis: Ghele na , eme ọ ọghoruo yọ ẹgba ologbo nọ a re ro ru udhedhẹ .\n",
            "2020-01-17 09:09:09,314 Validation result (greedy) at epoch  21, step    51000: bleu:  27.30, loss: 37488.2656, ppl:   4.2462, duration: 34.3442s\n",
            "2020-01-17 09:09:23,542 Epoch  21 Step:    51100 Batch Loss:     1.587577 Tokens per Sec:    15542, Lr: 0.000300\n",
            "2020-01-17 09:09:37,733 Epoch  21 Step:    51200 Batch Loss:     1.202496 Tokens per Sec:    15333, Lr: 0.000300\n",
            "2020-01-17 09:09:51,870 Epoch  21 Step:    51300 Batch Loss:     1.370834 Tokens per Sec:    15680, Lr: 0.000300\n",
            "2020-01-17 09:10:05,998 Epoch  21 Step:    51400 Batch Loss:     1.276645 Tokens per Sec:    15932, Lr: 0.000300\n",
            "2020-01-17 09:10:20,198 Epoch  21 Step:    51500 Batch Loss:     1.620062 Tokens per Sec:    15519, Lr: 0.000300\n",
            "2020-01-17 09:10:34,347 Epoch  21 Step:    51600 Batch Loss:     1.626126 Tokens per Sec:    15842, Lr: 0.000300\n",
            "2020-01-17 09:10:48,609 Epoch  21 Step:    51700 Batch Loss:     1.346101 Tokens per Sec:    16130, Lr: 0.000300\n",
            "2020-01-17 09:11:02,862 Epoch  21 Step:    51800 Batch Loss:     1.454624 Tokens per Sec:    16015, Lr: 0.000300\n",
            "2020-01-17 09:11:17,045 Epoch  21 Step:    51900 Batch Loss:     1.550377 Tokens per Sec:    15765, Lr: 0.000300\n",
            "2020-01-17 09:11:31,190 Epoch  21 Step:    52000 Batch Loss:     1.554651 Tokens per Sec:    15656, Lr: 0.000300\n",
            "2020-01-17 09:12:05,306 Hooray! New best validation result [ppl]!\n",
            "2020-01-17 09:12:05,306 Saving new checkpoint.\n",
            "2020-01-17 09:12:06,726 Example #0\n",
            "2020-01-17 09:12:06,727 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 09:12:06,727 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 09:12:06,730 \tHypothesis: Ma rẹ sae tubẹ yare Ọghẹnẹ inọ ọ ‘ ma omai eva efuafo . ’\n",
            "2020-01-17 09:12:06,731 Example #1\n",
            "2020-01-17 09:12:06,731 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 09:12:06,731 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 09:12:06,732 \tHypothesis: Usi Uvie na u te lele iei .\n",
            "2020-01-17 09:12:06,732 Example #2\n",
            "2020-01-17 09:12:06,733 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 09:12:06,733 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 09:12:06,733 \tHypothesis: Fikiere , mai kpobi ma vẹ te rehọ oghọghọ fiba isẹri mai nọ i bi ti kuhọ evaọ uvitha igbunu nana : “ Jọ odẹ riẹ [ Jesu Kristi Ovie na ] o jọ bẹdẹ bẹdẹ , re ọre na o te lo , re o te wo odẹ riẹ , re o jọ oghale rọ kẹ ae .\n",
            "2020-01-17 09:12:06,733 Example #3\n",
            "2020-01-17 09:12:06,734 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 09:12:06,735 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 09:12:06,735 \tHypothesis: Ghele na , eme ọ ọghoruo yọ ẹgba ologbo nọ a re ro ru udhedhẹ .\n",
            "2020-01-17 09:12:06,735 Validation result (greedy) at epoch  21, step    52000: bleu:  27.74, loss: 37249.1680, ppl:   4.2072, duration: 35.5444s\n",
            "2020-01-17 09:12:21,610 Epoch  21 Step:    52100 Batch Loss:     1.387212 Tokens per Sec:    15110, Lr: 0.000300\n",
            "2020-01-17 09:12:35,774 Epoch  21 Step:    52200 Batch Loss:     1.277768 Tokens per Sec:    15766, Lr: 0.000300\n",
            "2020-01-17 09:12:49,957 Epoch  21 Step:    52300 Batch Loss:     1.395963 Tokens per Sec:    15558, Lr: 0.000300\n",
            "2020-01-17 09:13:04,152 Epoch  21 Step:    52400 Batch Loss:     1.481501 Tokens per Sec:    15420, Lr: 0.000300\n",
            "2020-01-17 09:13:18,322 Epoch  21 Step:    52500 Batch Loss:     1.362384 Tokens per Sec:    15517, Lr: 0.000300\n",
            "2020-01-17 09:13:32,548 Epoch  21 Step:    52600 Batch Loss:     1.674810 Tokens per Sec:    15863, Lr: 0.000300\n",
            "2020-01-17 09:13:46,743 Epoch  21 Step:    52700 Batch Loss:     1.723416 Tokens per Sec:    15816, Lr: 0.000300\n",
            "2020-01-17 09:14:00,892 Epoch  21 Step:    52800 Batch Loss:     1.352111 Tokens per Sec:    15664, Lr: 0.000300\n",
            "2020-01-17 09:14:15,106 Epoch  21 Step:    52900 Batch Loss:     1.396421 Tokens per Sec:    15791, Lr: 0.000300\n",
            "2020-01-17 09:14:29,246 Epoch  21 Step:    53000 Batch Loss:     1.458568 Tokens per Sec:    15567, Lr: 0.000300\n",
            "2020-01-17 09:15:03,440 Hooray! New best validation result [ppl]!\n",
            "2020-01-17 09:15:03,440 Saving new checkpoint.\n",
            "2020-01-17 09:15:04,906 Example #0\n",
            "2020-01-17 09:15:04,907 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 09:15:04,907 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 09:15:04,907 \tHypothesis: Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ ma omai eva efuafo . ’\n",
            "2020-01-17 09:15:04,907 Example #1\n",
            "2020-01-17 09:15:04,908 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 09:15:04,908 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 09:15:04,909 \tHypothesis: A te lele onana , Usi Uvie na o tẹ te jọ họ .\n",
            "2020-01-17 09:15:04,909 Example #2\n",
            "2020-01-17 09:15:04,910 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 09:15:04,910 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 09:15:04,910 \tHypothesis: Fikiere , mai kpobi ma ve ti fiba oghọghọ mai kẹ ekuhọ ukuhọ ole nana nọ o rrọ emamọ ole nana , onọ o rrọ ole nana : “ Jọ odẹ riẹ [ Jesu Kristi Ovie na ] o jọ bẹdẹ , re o jọ elo kẹ odẹ riẹ , re o jọ oruaro kẹ ae , re erẹwho na kpobi a wo oghale .\n",
            "2020-01-17 09:15:04,910 Example #3\n",
            "2020-01-17 09:15:04,911 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 09:15:04,911 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 09:15:04,911 \tHypothesis: Ghele na , eme ọ ọghoruo yọ ẹgba ologbo nọ a re ro ru udhedhẹ .\n",
            "2020-01-17 09:15:04,912 Validation result (greedy) at epoch  21, step    53000: bleu:  27.67, loss: 37049.7148, ppl:   4.1750, duration: 35.6654s\n",
            "2020-01-17 09:15:18,245 Epoch  21: total training loss 3795.52\n",
            "2020-01-17 09:15:18,246 EPOCH 22\n",
            "2020-01-17 09:15:20,085 Epoch  22 Step:    53100 Batch Loss:     1.569618 Tokens per Sec:    13519, Lr: 0.000300\n",
            "2020-01-17 09:15:34,279 Epoch  22 Step:    53200 Batch Loss:     1.568414 Tokens per Sec:    16222, Lr: 0.000300\n",
            "2020-01-17 09:15:48,517 Epoch  22 Step:    53300 Batch Loss:     1.698478 Tokens per Sec:    15857, Lr: 0.000300\n",
            "2020-01-17 09:16:02,679 Epoch  22 Step:    53400 Batch Loss:     1.319281 Tokens per Sec:    15585, Lr: 0.000300\n",
            "2020-01-17 09:16:16,825 Epoch  22 Step:    53500 Batch Loss:     1.251536 Tokens per Sec:    15320, Lr: 0.000300\n",
            "2020-01-17 09:16:30,999 Epoch  22 Step:    53600 Batch Loss:     1.016207 Tokens per Sec:    15745, Lr: 0.000300\n",
            "2020-01-17 09:16:45,174 Epoch  22 Step:    53700 Batch Loss:     1.400910 Tokens per Sec:    15733, Lr: 0.000300\n",
            "2020-01-17 09:16:59,299 Epoch  22 Step:    53800 Batch Loss:     1.665269 Tokens per Sec:    15585, Lr: 0.000300\n",
            "2020-01-17 09:17:13,315 Epoch  22 Step:    53900 Batch Loss:     1.459095 Tokens per Sec:    15590, Lr: 0.000300\n",
            "2020-01-17 09:17:27,442 Epoch  22 Step:    54000 Batch Loss:     1.588928 Tokens per Sec:    15419, Lr: 0.000300\n",
            "2020-01-17 09:18:01,560 Hooray! New best validation result [ppl]!\n",
            "2020-01-17 09:18:01,560 Saving new checkpoint.\n",
            "2020-01-17 09:18:03,426 Example #0\n",
            "2020-01-17 09:18:03,427 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 09:18:03,427 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 09:18:03,428 \tHypothesis: Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ ma omai eva efuafo . ’\n",
            "2020-01-17 09:18:03,428 Example #1\n",
            "2020-01-17 09:18:03,428 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 09:18:03,429 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 09:18:03,429 \tHypothesis: Usi Uvie na o jọ ere he .\n",
            "2020-01-17 09:18:03,429 Example #2\n",
            "2020-01-17 09:18:03,431 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 09:18:03,431 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 09:18:03,431 \tHypothesis: Koyehọ , mai kpobi ma te rehọ oghọghọ fiba iroro mai nọ ma be te ta kpahe oria ikere nana nọ o rrọ obe nana nọ o rrọ emamọ ole na , onọ o rẹ kẹ evawere : “ Jọ odẹ riẹ [ Jesu Kristi Ovie na ] o jọ bẹdẹ bẹdẹ ; re ọre na o te ti vihọ , re o ru odẹ riẹ gbunu , re erẹwho na kpobi a wo oghale .\n",
            "2020-01-17 09:18:03,431 Example #3\n",
            "2020-01-17 09:18:03,432 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 09:18:03,432 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 09:18:03,432 \tHypothesis: Ghele na , eme ọ ọghoruo yọ ẹgba ologbo nọ a re ro ru udhedhẹ .\n",
            "2020-01-17 09:18:03,432 Validation result (greedy) at epoch  22, step    54000: bleu:  28.06, loss: 37027.8867, ppl:   4.1715, duration: 35.9893s\n",
            "2020-01-17 09:18:18,361 Epoch  22 Step:    54100 Batch Loss:     1.405059 Tokens per Sec:    15159, Lr: 0.000300\n",
            "2020-01-17 09:18:32,551 Epoch  22 Step:    54200 Batch Loss:     1.534270 Tokens per Sec:    15545, Lr: 0.000300\n",
            "2020-01-17 09:18:46,752 Epoch  22 Step:    54300 Batch Loss:     1.531478 Tokens per Sec:    15663, Lr: 0.000300\n",
            "2020-01-17 09:19:00,909 Epoch  22 Step:    54400 Batch Loss:     1.476880 Tokens per Sec:    15924, Lr: 0.000300\n",
            "2020-01-17 09:19:15,093 Epoch  22 Step:    54500 Batch Loss:     1.451415 Tokens per Sec:    15618, Lr: 0.000300\n",
            "2020-01-17 09:19:29,241 Epoch  22 Step:    54600 Batch Loss:     1.356946 Tokens per Sec:    15571, Lr: 0.000300\n",
            "2020-01-17 09:19:43,460 Epoch  22 Step:    54700 Batch Loss:     1.430000 Tokens per Sec:    16265, Lr: 0.000300\n",
            "2020-01-17 09:19:57,581 Epoch  22 Step:    54800 Batch Loss:     1.585365 Tokens per Sec:    15904, Lr: 0.000300\n",
            "2020-01-17 09:20:11,624 Epoch  22 Step:    54900 Batch Loss:     1.624910 Tokens per Sec:    15667, Lr: 0.000300\n",
            "2020-01-17 09:20:25,775 Epoch  22 Step:    55000 Batch Loss:     1.231424 Tokens per Sec:    15402, Lr: 0.000300\n",
            "2020-01-17 09:20:59,962 Hooray! New best validation result [ppl]!\n",
            "2020-01-17 09:20:59,963 Saving new checkpoint.\n",
            "2020-01-17 09:21:01,402 Example #0\n",
            "2020-01-17 09:21:01,402 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 09:21:01,403 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 09:21:01,403 \tHypothesis: Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ ma omai eva efuafo . ’\n",
            "2020-01-17 09:21:01,403 Example #1\n",
            "2020-01-17 09:21:01,404 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 09:21:01,404 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 09:21:01,404 \tHypothesis: A te lele onana , News Kingdom ọ tẹ te jọ họ .\n",
            "2020-01-17 09:21:01,404 Example #2\n",
            "2020-01-17 09:21:01,405 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 09:21:01,405 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 09:21:01,406 \tHypothesis: Wọhọ oriruo , mai kpobi ma ve ti fiba unu mai avọ oghọghọ nọ ma te bi kere eme nana nọ e rrọ obe na , onọ o rẹ kẹ omosasọ : “ Jọ odẹ riẹ [ Ovie na ] u dhesẹ nọ a wo odẹ riẹ bẹdẹ bẹdẹ ; re ọre na ọ tẹ te rehọ oruaro riẹ kẹ ae , re a ruẹse ghale ae , re a wo oghale .\n",
            "2020-01-17 09:21:01,406 Example #3\n",
            "2020-01-17 09:21:01,406 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 09:21:01,407 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 09:21:01,407 \tHypothesis: Ghele na , eme ọ ọghoruo yọ ẹgba ologbo nọ a re ro ru udhedhẹ .\n",
            "2020-01-17 09:21:01,407 Validation result (greedy) at epoch  22, step    55000: bleu:  28.32, loss: 36923.1445, ppl:   4.1547, duration: 35.6314s\n",
            "2020-01-17 09:21:16,274 Epoch  22 Step:    55100 Batch Loss:     1.624681 Tokens per Sec:    15073, Lr: 0.000300\n",
            "2020-01-17 09:21:30,455 Epoch  22 Step:    55200 Batch Loss:     1.427062 Tokens per Sec:    15534, Lr: 0.000300\n",
            "2020-01-17 09:21:44,618 Epoch  22 Step:    55300 Batch Loss:     1.160187 Tokens per Sec:    15786, Lr: 0.000300\n",
            "2020-01-17 09:21:58,743 Epoch  22 Step:    55400 Batch Loss:     1.591682 Tokens per Sec:    15591, Lr: 0.000300\n",
            "2020-01-17 09:22:12,819 Epoch  22 Step:    55500 Batch Loss:     1.311318 Tokens per Sec:    15554, Lr: 0.000300\n",
            "2020-01-17 09:22:26,972 Epoch  22 Step:    55600 Batch Loss:     1.130303 Tokens per Sec:    15676, Lr: 0.000300\n",
            "2020-01-17 09:22:29,782 Epoch  22: total training loss 3770.62\n",
            "2020-01-17 09:22:29,783 EPOCH 23\n",
            "2020-01-17 09:22:41,354 Epoch  23 Step:    55700 Batch Loss:     1.259063 Tokens per Sec:    15112, Lr: 0.000300\n",
            "2020-01-17 09:22:55,545 Epoch  23 Step:    55800 Batch Loss:     1.368794 Tokens per Sec:    15739, Lr: 0.000300\n",
            "2020-01-17 09:23:09,811 Epoch  23 Step:    55900 Batch Loss:     1.655498 Tokens per Sec:    15704, Lr: 0.000300\n",
            "2020-01-17 09:23:24,024 Epoch  23 Step:    56000 Batch Loss:     1.409517 Tokens per Sec:    16031, Lr: 0.000300\n",
            "2020-01-17 09:23:58,190 Hooray! New best validation result [ppl]!\n",
            "2020-01-17 09:23:58,191 Saving new checkpoint.\n",
            "2020-01-17 09:23:59,633 Example #0\n",
            "2020-01-17 09:23:59,634 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 09:23:59,634 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 09:23:59,634 \tHypothesis: Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ ma omai evaọ udu efuafo . ’\n",
            "2020-01-17 09:23:59,634 Example #1\n",
            "2020-01-17 09:23:59,635 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 09:23:59,635 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 09:23:59,635 \tHypothesis: A te lele onana ẹkwoma Usi Uvie na .\n",
            "2020-01-17 09:23:59,636 Example #2\n",
            "2020-01-17 09:23:59,636 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 09:23:59,637 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 09:23:59,637 \tHypothesis: O wọhọ nọ mai kpobi ma te rọ evawere fiba isẹri mai nọ i bi ti kuhọ evaọ ekuhọ ole nana , yọ ma te kẹ ae ole obọdẹ nana : “ Jọ odẹ riẹ [ Jesu Kristi Ovie na ] o jọ bẹdẹ , re ọre na ọ ze , re o wo odẹ riẹ , re o jọ efe kẹ ae ; jọ a jiri ei .\n",
            "2020-01-17 09:23:59,637 Example #3\n",
            "2020-01-17 09:23:59,638 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 09:23:59,638 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 09:23:59,638 \tHypothesis: Ghele na , eme ọghoruo yọ ẹgba ologbo nọ a re ro ru udhedhẹ .\n",
            "2020-01-17 09:23:59,638 Validation result (greedy) at epoch  23, step    56000: bleu:  28.39, loss: 36901.8867, ppl:   4.1512, duration: 35.6139s\n",
            "2020-01-17 09:24:14,458 Epoch  23 Step:    56100 Batch Loss:     1.537536 Tokens per Sec:    15446, Lr: 0.000300\n",
            "2020-01-17 09:24:28,565 Epoch  23 Step:    56200 Batch Loss:     1.530656 Tokens per Sec:    15455, Lr: 0.000300\n",
            "2020-01-17 09:24:42,697 Epoch  23 Step:    56300 Batch Loss:     1.597733 Tokens per Sec:    15676, Lr: 0.000300\n",
            "2020-01-17 09:24:56,853 Epoch  23 Step:    56400 Batch Loss:     1.608456 Tokens per Sec:    15313, Lr: 0.000300\n",
            "2020-01-17 09:25:11,001 Epoch  23 Step:    56500 Batch Loss:     1.477592 Tokens per Sec:    15988, Lr: 0.000300\n",
            "2020-01-17 09:25:25,168 Epoch  23 Step:    56600 Batch Loss:     1.906750 Tokens per Sec:    15810, Lr: 0.000300\n",
            "2020-01-17 09:25:39,269 Epoch  23 Step:    56700 Batch Loss:     1.877596 Tokens per Sec:    15555, Lr: 0.000300\n",
            "2020-01-17 09:25:53,386 Epoch  23 Step:    56800 Batch Loss:     1.448105 Tokens per Sec:    15725, Lr: 0.000300\n",
            "2020-01-17 09:26:07,651 Epoch  23 Step:    56900 Batch Loss:     1.490845 Tokens per Sec:    15765, Lr: 0.000300\n",
            "2020-01-17 09:26:21,790 Epoch  23 Step:    57000 Batch Loss:     1.714266 Tokens per Sec:    15629, Lr: 0.000300\n",
            "2020-01-17 09:26:55,809 Hooray! New best validation result [ppl]!\n",
            "2020-01-17 09:26:55,810 Saving new checkpoint.\n",
            "2020-01-17 09:26:57,662 Example #0\n",
            "2020-01-17 09:26:57,663 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 09:26:57,664 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 09:26:57,664 \tHypothesis: Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ ma omai eva efuafo . ’\n",
            "2020-01-17 09:26:57,664 Example #1\n",
            "2020-01-17 09:26:57,665 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 09:26:57,665 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 09:26:57,665 \tHypothesis: A te lele onana ẹkwoma News Kingdom , Ijo .\n",
            "2020-01-17 09:26:57,665 Example #2\n",
            "2020-01-17 09:26:57,666 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 09:26:57,666 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 09:26:57,667 \tHypothesis: O wọhọ nọ mai kpobi ma te rọ oghọghọ nwene iroro mai kpohọ abọ urere ọrọ ukuhọ ọrọ ole nana gbe ole omosasọ : “ Jọ odẹ riẹ [ Jesu Kristi Ovie na ] o jọ bẹdẹ , re ọre na ọ ze , re o wo odẹ riẹ , re o jọ eva e were ae , re erẹwho kpobi e kẹ ae evawere .\n",
            "2020-01-17 09:26:57,667 Example #3\n",
            "2020-01-17 09:26:57,667 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 09:26:57,668 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 09:26:57,668 \tHypothesis: Ghele na , eme ọghoruo yọ ẹgba ologbo nọ a re ro ru udhedhẹ .\n",
            "2020-01-17 09:26:57,668 Validation result (greedy) at epoch  23, step    57000: bleu:  28.00, loss: 36688.3164, ppl:   4.1172, duration: 35.8775s\n",
            "2020-01-17 09:27:12,498 Epoch  23 Step:    57100 Batch Loss:     1.467894 Tokens per Sec:    15136, Lr: 0.000300\n",
            "2020-01-17 09:27:26,818 Epoch  23 Step:    57200 Batch Loss:     1.411452 Tokens per Sec:    15383, Lr: 0.000300\n",
            "2020-01-17 09:27:41,109 Epoch  23 Step:    57300 Batch Loss:     1.397311 Tokens per Sec:    15690, Lr: 0.000300\n",
            "2020-01-17 09:27:55,457 Epoch  23 Step:    57400 Batch Loss:     1.544106 Tokens per Sec:    15360, Lr: 0.000300\n",
            "2020-01-17 09:28:09,775 Epoch  23 Step:    57500 Batch Loss:     1.300090 Tokens per Sec:    15735, Lr: 0.000300\n",
            "2020-01-17 09:28:24,157 Epoch  23 Step:    57600 Batch Loss:     1.833890 Tokens per Sec:    15551, Lr: 0.000300\n",
            "2020-01-17 09:28:38,482 Epoch  23 Step:    57700 Batch Loss:     1.595260 Tokens per Sec:    15330, Lr: 0.000300\n",
            "2020-01-17 09:28:52,897 Epoch  23 Step:    57800 Batch Loss:     0.877827 Tokens per Sec:    15408, Lr: 0.000300\n",
            "2020-01-17 09:29:07,150 Epoch  23 Step:    57900 Batch Loss:     1.488853 Tokens per Sec:    15389, Lr: 0.000300\n",
            "2020-01-17 09:29:21,504 Epoch  23 Step:    58000 Batch Loss:     1.541149 Tokens per Sec:    15747, Lr: 0.000300\n",
            "2020-01-17 09:29:55,665 Hooray! New best validation result [ppl]!\n",
            "2020-01-17 09:29:55,666 Saving new checkpoint.\n",
            "2020-01-17 09:29:57,093 Example #0\n",
            "2020-01-17 09:29:57,094 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 09:29:57,094 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 09:29:57,095 \tHypothesis: Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ ma omai eva efuafo . ’\n",
            "2020-01-17 09:29:57,095 Example #1\n",
            "2020-01-17 09:29:57,095 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 09:29:57,096 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 09:29:57,096 \tHypothesis: Usi Uvie na o tẹ nya .\n",
            "2020-01-17 09:29:57,096 Example #2\n",
            "2020-01-17 09:29:57,097 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 09:29:57,097 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 09:29:57,097 \tHypothesis: Fikiere , mai kpobi ma vẹ te rehọ oghọghọ fiba isẹri mai , re ole nana o jọ ole evawere gbe evawere kẹ ae , re o ru odẹ riẹ gba bẹdẹ , re ọre na ọ ruẹse kẹ ae oruaro , re o ru ai wo oghale , re a ruẹse rehọ odẹ riẹ kẹ e .\n",
            "2020-01-17 09:29:57,098 Example #3\n",
            "2020-01-17 09:29:57,098 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 09:29:57,098 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 09:29:57,099 \tHypothesis: Ghele na , eme ọ ọghoruo yọ ẹgba ologbo nọ a re ro ru udhedhẹ .\n",
            "2020-01-17 09:29:57,099 Validation result (greedy) at epoch  23, step    58000: bleu:  28.00, loss: 36623.3164, ppl:   4.1069, duration: 35.5944s\n",
            "2020-01-17 09:30:12,260 Epoch  23 Step:    58100 Batch Loss:     1.538548 Tokens per Sec:    14933, Lr: 0.000300\n",
            "2020-01-17 09:30:18,895 Epoch  23: total training loss 3732.48\n",
            "2020-01-17 09:30:18,896 EPOCH 24\n",
            "2020-01-17 09:30:27,112 Epoch  24 Step:    58200 Batch Loss:     1.700216 Tokens per Sec:    15151, Lr: 0.000300\n",
            "2020-01-17 09:30:41,501 Epoch  24 Step:    58300 Batch Loss:     1.525077 Tokens per Sec:    14939, Lr: 0.000300\n",
            "2020-01-17 09:30:55,971 Epoch  24 Step:    58400 Batch Loss:     1.565347 Tokens per Sec:    15244, Lr: 0.000300\n",
            "2020-01-17 09:31:10,443 Epoch  24 Step:    58500 Batch Loss:     1.239358 Tokens per Sec:    15427, Lr: 0.000300\n",
            "2020-01-17 09:31:24,918 Epoch  24 Step:    58600 Batch Loss:     1.459348 Tokens per Sec:    15228, Lr: 0.000300\n",
            "2020-01-17 09:31:39,451 Epoch  24 Step:    58700 Batch Loss:     1.437073 Tokens per Sec:    15522, Lr: 0.000300\n",
            "2020-01-17 09:31:53,902 Epoch  24 Step:    58800 Batch Loss:     1.449995 Tokens per Sec:    15160, Lr: 0.000300\n",
            "2020-01-17 09:32:08,451 Epoch  24 Step:    58900 Batch Loss:     1.717248 Tokens per Sec:    15699, Lr: 0.000300\n",
            "2020-01-17 09:32:22,982 Epoch  24 Step:    59000 Batch Loss:     1.538255 Tokens per Sec:    15507, Lr: 0.000300\n",
            "2020-01-17 09:32:57,427 Hooray! New best validation result [ppl]!\n",
            "2020-01-17 09:32:57,428 Saving new checkpoint.\n",
            "2020-01-17 09:32:58,900 Example #0\n",
            "2020-01-17 09:32:58,900 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 09:32:58,901 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 09:32:58,901 \tHypothesis: Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ ma omai eva efuafo . ’\n",
            "2020-01-17 09:32:58,901 Example #1\n",
            "2020-01-17 09:32:58,902 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 09:32:58,902 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 09:32:58,902 \tHypothesis: A te lele onana , News News of the Hows ?\n",
            "2020-01-17 09:32:58,902 Example #2\n",
            "2020-01-17 09:32:58,903 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 09:32:58,903 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 09:32:58,903 \tHypothesis: O wọhọ nọ mai kpobi ma te rọ oghọghọ fiba eme nọ ma ta kpahe evaọ ekuhọ ole nana nọ o wo erru gaga na : “ Jọ odẹ riẹ [ Jesu Kristi Ovie na ] o jọ bẹdẹ bẹdẹ ; re ọre na ọ tẹ te rehọ odẹ riẹ jiri ai , re o jọ oruaro kẹ ae , re o jọ eva e were ae ; re a jiri ei .\n",
            "2020-01-17 09:32:58,904 Example #3\n",
            "2020-01-17 09:32:58,904 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 09:32:58,904 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 09:32:58,905 \tHypothesis: Ghele na , eme ọghoruo yọ ẹgba ọgaga nọ o re ro ru udhedhẹ .\n",
            "2020-01-17 09:32:58,905 Validation result (greedy) at epoch  24, step    59000: bleu:  28.66, loss: 36544.6133, ppl:   4.0944, duration: 35.9220s\n",
            "2020-01-17 09:33:14,040 Epoch  24 Step:    59100 Batch Loss:     1.262099 Tokens per Sec:    14689, Lr: 0.000300\n",
            "2020-01-17 09:33:28,524 Epoch  24 Step:    59200 Batch Loss:     1.409866 Tokens per Sec:    15106, Lr: 0.000300\n",
            "2020-01-17 09:33:43,035 Epoch  24 Step:    59300 Batch Loss:     1.661978 Tokens per Sec:    15245, Lr: 0.000300\n",
            "2020-01-17 09:33:57,601 Epoch  24 Step:    59400 Batch Loss:     1.738786 Tokens per Sec:    15266, Lr: 0.000300\n",
            "2020-01-17 09:34:12,136 Epoch  24 Step:    59500 Batch Loss:     1.564705 Tokens per Sec:    15115, Lr: 0.000300\n",
            "2020-01-17 09:34:26,609 Epoch  24 Step:    59600 Batch Loss:     1.572153 Tokens per Sec:    15440, Lr: 0.000300\n",
            "2020-01-17 09:34:41,109 Epoch  24 Step:    59700 Batch Loss:     1.405909 Tokens per Sec:    15717, Lr: 0.000300\n",
            "2020-01-17 09:34:55,489 Epoch  24 Step:    59800 Batch Loss:     1.597824 Tokens per Sec:    14970, Lr: 0.000300\n",
            "2020-01-17 09:35:10,061 Epoch  24 Step:    59900 Batch Loss:     1.512458 Tokens per Sec:    15650, Lr: 0.000300\n",
            "2020-01-17 09:35:24,599 Epoch  24 Step:    60000 Batch Loss:     1.527928 Tokens per Sec:    15721, Lr: 0.000300\n",
            "2020-01-17 09:35:58,905 Hooray! New best validation result [ppl]!\n",
            "2020-01-17 09:35:58,906 Saving new checkpoint.\n",
            "2020-01-17 09:36:00,768 Example #0\n",
            "2020-01-17 09:36:00,769 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 09:36:00,769 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 09:36:00,769 \tHypothesis: Ma rẹ sae yare Ọghẹnẹ re ọ ‘ ma omai eva efuafo . ’\n",
            "2020-01-17 09:36:00,769 Example #1\n",
            "2020-01-17 09:36:00,770 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 09:36:00,770 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 09:36:00,771 \tHypothesis: Usi Uvie na o tẹ te jọ họ .\n",
            "2020-01-17 09:36:00,771 Example #2\n",
            "2020-01-17 09:36:00,771 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 09:36:00,772 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 09:36:00,772 \tHypothesis: Fikiere , mai kpobi ma te rọ oghọghọ ta ẹme kugbe eme nọ e rrọ obotọ na , inọ : “ Jọ odẹ riẹ [ orọ Ovie na ] o jọ bẹdẹ bẹdẹ ; re ọre na ọ jọ oruaro riẹ , re o ru re ahwo kpobi a wo oghale , re a wo oghale eva efuafo , re a jiri ei .\n",
            "2020-01-17 09:36:00,772 Example #3\n",
            "2020-01-17 09:36:00,773 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 09:36:00,773 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 09:36:00,773 \tHypothesis: Ghele na , eme ọ ọghoruo yọ ẹgba ọgaga nọ a re ro ru udhedhẹ .\n",
            "2020-01-17 09:36:00,774 Validation result (greedy) at epoch  24, step    60000: bleu:  28.05, loss: 36513.1758, ppl:   4.0895, duration: 36.1742s\n",
            "2020-01-17 09:36:15,873 Epoch  24 Step:    60100 Batch Loss:     1.235703 Tokens per Sec:    14497, Lr: 0.000300\n",
            "2020-01-17 09:36:30,339 Epoch  24 Step:    60200 Batch Loss:     1.403766 Tokens per Sec:    15034, Lr: 0.000300\n",
            "2020-01-17 09:36:44,865 Epoch  24 Step:    60300 Batch Loss:     1.330783 Tokens per Sec:    15481, Lr: 0.000300\n",
            "2020-01-17 09:36:59,357 Epoch  24 Step:    60400 Batch Loss:     1.572849 Tokens per Sec:    15264, Lr: 0.000300\n",
            "2020-01-17 09:37:13,883 Epoch  24 Step:    60500 Batch Loss:     1.555555 Tokens per Sec:    15415, Lr: 0.000300\n",
            "2020-01-17 09:37:28,347 Epoch  24 Step:    60600 Batch Loss:     1.613615 Tokens per Sec:    15285, Lr: 0.000300\n",
            "2020-01-17 09:37:38,938 Epoch  24: total training loss 3714.19\n",
            "2020-01-17 09:37:38,939 EPOCH 25\n",
            "2020-01-17 09:37:43,195 Epoch  25 Step:    60700 Batch Loss:     1.023747 Tokens per Sec:    14393, Lr: 0.000300\n",
            "2020-01-17 09:37:57,626 Epoch  25 Step:    60800 Batch Loss:     1.431165 Tokens per Sec:    15191, Lr: 0.000300\n",
            "2020-01-17 09:38:12,127 Epoch  25 Step:    60900 Batch Loss:     1.355587 Tokens per Sec:    15515, Lr: 0.000300\n",
            "2020-01-17 09:38:26,645 Epoch  25 Step:    61000 Batch Loss:     1.531766 Tokens per Sec:    15566, Lr: 0.000300\n",
            "2020-01-17 09:39:00,993 Hooray! New best validation result [ppl]!\n",
            "2020-01-17 09:39:00,994 Saving new checkpoint.\n",
            "2020-01-17 09:39:02,441 Example #0\n",
            "2020-01-17 09:39:02,442 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 09:39:02,442 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 09:39:02,442 \tHypothesis: Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ ma omai eva efuafo . ’\n",
            "2020-01-17 09:39:02,443 Example #1\n",
            "2020-01-17 09:39:02,443 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 09:39:02,443 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 09:39:02,444 \tHypothesis: A te lele onana , Usi Uvie na O gbẹ jọ họ .\n",
            "2020-01-17 09:39:02,444 Example #2\n",
            "2020-01-17 09:39:02,444 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 09:39:02,445 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 09:39:02,445 \tHypothesis: O wọhọ nọ mai kpobi ma te rọ evawere ta ẹme kpahe oria ikere nana nọ o rrọ ole evawere na : “ Jọ odẹ riẹ [ Jesu Kristi Ovie na ] o jọ bẹdẹ bẹdẹ ; re ọre na ọ tẹ te vọ avọ oghọghọ , re o wo odẹ riẹ , re o jọ eva e were ae .\n",
            "2020-01-17 09:39:02,445 Example #3\n",
            "2020-01-17 09:39:02,447 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 09:39:02,447 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 09:39:02,447 \tHypothesis: Ghele na , eme ọ ọghoruo yọ ẹgba ologbo nọ a re ro ru udhedhẹ .\n",
            "2020-01-17 09:39:02,448 Validation result (greedy) at epoch  25, step    61000: bleu:  28.73, loss: 36508.1758, ppl:   4.0887, duration: 35.8022s\n",
            "2020-01-17 09:39:17,604 Epoch  25 Step:    61100 Batch Loss:     1.405450 Tokens per Sec:    14284, Lr: 0.000300\n",
            "2020-01-17 09:39:32,171 Epoch  25 Step:    61200 Batch Loss:     1.413192 Tokens per Sec:    15790, Lr: 0.000300\n",
            "2020-01-17 09:39:46,642 Epoch  25 Step:    61300 Batch Loss:     1.242658 Tokens per Sec:    15368, Lr: 0.000300\n",
            "2020-01-17 09:40:01,067 Epoch  25 Step:    61400 Batch Loss:     1.360199 Tokens per Sec:    15097, Lr: 0.000300\n",
            "2020-01-17 09:40:15,597 Epoch  25 Step:    61500 Batch Loss:     1.760199 Tokens per Sec:    15474, Lr: 0.000300\n",
            "2020-01-17 09:40:30,110 Epoch  25 Step:    61600 Batch Loss:     1.482585 Tokens per Sec:    15171, Lr: 0.000300\n",
            "2020-01-17 09:40:44,658 Epoch  25 Step:    61700 Batch Loss:     1.710018 Tokens per Sec:    15384, Lr: 0.000300\n",
            "2020-01-17 09:40:59,173 Epoch  25 Step:    61800 Batch Loss:     1.202315 Tokens per Sec:    15249, Lr: 0.000300\n",
            "2020-01-17 09:41:13,806 Epoch  25 Step:    61900 Batch Loss:     1.414882 Tokens per Sec:    15247, Lr: 0.000300\n",
            "2020-01-17 09:41:28,311 Epoch  25 Step:    62000 Batch Loss:     1.302450 Tokens per Sec:    15073, Lr: 0.000300\n",
            "2020-01-17 09:42:02,681 Hooray! New best validation result [ppl]!\n",
            "2020-01-17 09:42:02,682 Saving new checkpoint.\n",
            "2020-01-17 09:42:04,146 Example #0\n",
            "2020-01-17 09:42:04,146 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 09:42:04,147 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 09:42:04,147 \tHypothesis: Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ ma omai eva efuafo . ’\n",
            "2020-01-17 09:42:04,147 Example #1\n",
            "2020-01-17 09:42:04,148 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 09:42:04,148 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 09:42:04,148 \tHypothesis: Usi Uvie na u te lele iei .\n",
            "2020-01-17 09:42:04,148 Example #2\n",
            "2020-01-17 09:42:04,149 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 09:42:04,149 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 09:42:04,149 \tHypothesis: Koyehọ mai kpobi ma te rehọ oghọghọ fiba eme nọ e rrọ obotọ na , onọ u ti ru nọ ma te rọ rehọ ole nana nọ o wo erru ziezi na : “ Jọ odẹ [ Jesu Kristi Ovie na ] o jọ bẹdẹ bẹdẹ , re ọre na ọ jọ bẹdẹ bẹdẹ , re o jiri odẹ riẹ , re o jiri ai ; re ahwo Egedhọ kpobi a wo oghale .\n",
            "2020-01-17 09:42:04,150 Example #3\n",
            "2020-01-17 09:42:04,151 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 09:42:04,151 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 09:42:04,151 \tHypothesis: Ghele na , eme ọ ọghoruo yọ ẹgba ologbo nọ a re ro ru udhedhẹ .\n",
            "2020-01-17 09:42:04,151 Validation result (greedy) at epoch  25, step    62000: bleu:  28.57, loss: 36356.1602, ppl:   4.0648, duration: 35.8402s\n",
            "2020-01-17 09:42:19,364 Epoch  25 Step:    62100 Batch Loss:     1.477578 Tokens per Sec:    14949, Lr: 0.000300\n",
            "2020-01-17 09:42:33,918 Epoch  25 Step:    62200 Batch Loss:     1.468283 Tokens per Sec:    15331, Lr: 0.000300\n",
            "2020-01-17 09:42:48,366 Epoch  25 Step:    62300 Batch Loss:     1.628567 Tokens per Sec:    15214, Lr: 0.000300\n",
            "2020-01-17 09:43:02,859 Epoch  25 Step:    62400 Batch Loss:     1.236851 Tokens per Sec:    15340, Lr: 0.000300\n",
            "2020-01-17 09:43:17,360 Epoch  25 Step:    62500 Batch Loss:     1.373015 Tokens per Sec:    15199, Lr: 0.000300\n",
            "2020-01-17 09:43:31,948 Epoch  25 Step:    62600 Batch Loss:     1.627071 Tokens per Sec:    15114, Lr: 0.000300\n",
            "2020-01-17 09:43:46,402 Epoch  25 Step:    62700 Batch Loss:     1.633562 Tokens per Sec:    15048, Lr: 0.000300\n",
            "2020-01-17 09:44:00,994 Epoch  25 Step:    62800 Batch Loss:     1.235380 Tokens per Sec:    15660, Lr: 0.000300\n",
            "2020-01-17 09:44:15,506 Epoch  25 Step:    62900 Batch Loss:     1.415451 Tokens per Sec:    15398, Lr: 0.000300\n",
            "2020-01-17 09:44:30,057 Epoch  25 Step:    63000 Batch Loss:     1.408167 Tokens per Sec:    15391, Lr: 0.000300\n",
            "2020-01-17 09:45:04,385 Hooray! New best validation result [ppl]!\n",
            "2020-01-17 09:45:04,385 Saving new checkpoint.\n",
            "2020-01-17 09:45:06,250 Example #0\n",
            "2020-01-17 09:45:06,251 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 09:45:06,251 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 09:45:06,252 \tHypothesis: Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ ma omai eva efuafo . ’\n",
            "2020-01-17 09:45:06,252 Example #1\n",
            "2020-01-17 09:45:06,253 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 09:45:06,253 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 09:45:06,254 \tHypothesis: A te ru onana ẹkwoma Usi Uvie na o tẹ te jọ họ .\n",
            "2020-01-17 09:45:06,254 Example #2\n",
            "2020-01-17 09:45:06,255 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 09:45:06,255 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 09:45:06,256 \tHypothesis: Koyehọ mai kpobi ma te rọ oghọghọ ta ẹme kpahe ekuhọ ole nana nọ o wo erru gaga na , inọ : “ Jọ odẹ riẹ [ Jesu Kristi Ovie na ] o jọ bẹdẹ bẹdẹ ; re ọre na ọ jọ ọsoso riẹ , re o wo oghale , re erẹwho kpobi e jọ eva riẹ .\n",
            "2020-01-17 09:45:06,256 Example #3\n",
            "2020-01-17 09:45:06,257 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 09:45:06,257 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 09:45:06,257 \tHypothesis: Ghele na , eme ọghoruo yọ ẹgba ologbo nọ a re ro ru udhedhẹ .\n",
            "2020-01-17 09:45:06,258 Validation result (greedy) at epoch  25, step    63000: bleu:  28.21, loss: 36310.9102, ppl:   4.0577, duration: 36.2000s\n",
            "2020-01-17 09:45:21,452 Epoch  25 Step:    63100 Batch Loss:     1.636142 Tokens per Sec:    14590, Lr: 0.000300\n",
            "2020-01-17 09:45:35,973 Epoch  25 Step:    63200 Batch Loss:     1.491931 Tokens per Sec:    15060, Lr: 0.000300\n",
            "2020-01-17 09:45:36,391 Epoch  25: total training loss 3688.60\n",
            "2020-01-17 09:45:36,392 EPOCH 26\n",
            "2020-01-17 09:45:50,819 Epoch  26 Step:    63300 Batch Loss:     1.430568 Tokens per Sec:    15098, Lr: 0.000300\n",
            "2020-01-17 09:46:05,374 Epoch  26 Step:    63400 Batch Loss:     1.488912 Tokens per Sec:    15247, Lr: 0.000300\n",
            "2020-01-17 09:46:19,888 Epoch  26 Step:    63500 Batch Loss:     1.098339 Tokens per Sec:    15266, Lr: 0.000300\n",
            "2020-01-17 09:46:34,391 Epoch  26 Step:    63600 Batch Loss:     1.444413 Tokens per Sec:    15058, Lr: 0.000300\n",
            "2020-01-17 09:46:48,869 Epoch  26 Step:    63700 Batch Loss:     1.419348 Tokens per Sec:    15106, Lr: 0.000300\n",
            "2020-01-17 09:47:03,408 Epoch  26 Step:    63800 Batch Loss:     1.421044 Tokens per Sec:    15505, Lr: 0.000300\n",
            "2020-01-17 09:47:17,931 Epoch  26 Step:    63900 Batch Loss:     1.528703 Tokens per Sec:    15153, Lr: 0.000300\n",
            "2020-01-17 09:47:32,421 Epoch  26 Step:    64000 Batch Loss:     1.483652 Tokens per Sec:    15205, Lr: 0.000300\n",
            "2020-01-17 09:48:06,841 Hooray! New best validation result [ppl]!\n",
            "2020-01-17 09:48:06,841 Saving new checkpoint.\n",
            "2020-01-17 09:48:08,319 Example #0\n",
            "2020-01-17 09:48:08,320 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 09:48:08,320 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 09:48:08,321 \tHypothesis: Ma rẹ sae yare Ọghẹnẹ re ọ ‘ ma omai eva efuafo . ’\n",
            "2020-01-17 09:48:08,321 Example #1\n",
            "2020-01-17 09:48:08,323 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 09:48:08,323 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 09:48:08,323 \tHypothesis: Usi Uvie na o tẹ te jọ ere .\n",
            "2020-01-17 09:48:08,324 Example #2\n",
            "2020-01-17 09:48:08,324 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 09:48:08,325 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 09:48:08,325 \tHypothesis: Fikiere , mai kpobi ma vẹ te rehọ oghọghọ fiba ovuẹ mai na avọ oghọghọ , re ma ku eme nana họ avọ oghọghọ , jẹ kẹ ae evawere : “ Jọ odẹ riẹ [ Jesu Kristi Ovie na ] o jọ bẹdẹ , re ọre na ọ jọ bẹdẹ , re o wo odẹ riẹ , re o jọ eva e were ae , re erẹwho kpobi a wo oghale .\n",
            "2020-01-17 09:48:08,325 Example #3\n",
            "2020-01-17 09:48:08,326 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 09:48:08,326 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 09:48:08,326 \tHypothesis: Ghele na , eme ọghoruo yọ ẹgba ologbo nọ a re ro ru udhedhẹ .\n",
            "2020-01-17 09:48:08,327 Validation result (greedy) at epoch  26, step    64000: bleu:  28.47, loss: 36172.5508, ppl:   4.0361, duration: 35.9052s\n",
            "2020-01-17 09:48:23,546 Epoch  26 Step:    64100 Batch Loss:     1.248526 Tokens per Sec:    14591, Lr: 0.000300\n",
            "2020-01-17 09:48:37,954 Epoch  26 Step:    64200 Batch Loss:     1.288968 Tokens per Sec:    14783, Lr: 0.000300\n",
            "2020-01-17 09:48:52,418 Epoch  26 Step:    64300 Batch Loss:     1.299080 Tokens per Sec:    15302, Lr: 0.000300\n",
            "2020-01-17 09:49:06,905 Epoch  26 Step:    64400 Batch Loss:     1.614222 Tokens per Sec:    15607, Lr: 0.000300\n",
            "2020-01-17 09:49:21,434 Epoch  26 Step:    64500 Batch Loss:     1.598974 Tokens per Sec:    15451, Lr: 0.000300\n",
            "2020-01-17 09:49:35,966 Epoch  26 Step:    64600 Batch Loss:     1.130683 Tokens per Sec:    15791, Lr: 0.000300\n",
            "2020-01-17 09:49:50,470 Epoch  26 Step:    64700 Batch Loss:     1.579050 Tokens per Sec:    15346, Lr: 0.000300\n",
            "2020-01-17 09:50:05,016 Epoch  26 Step:    64800 Batch Loss:     1.209484 Tokens per Sec:    15696, Lr: 0.000300\n",
            "2020-01-17 09:50:19,600 Epoch  26 Step:    64900 Batch Loss:     1.405026 Tokens per Sec:    15472, Lr: 0.000300\n",
            "2020-01-17 09:50:34,115 Epoch  26 Step:    65000 Batch Loss:     1.246977 Tokens per Sec:    15420, Lr: 0.000300\n",
            "2020-01-17 09:51:08,688 Example #0\n",
            "2020-01-17 09:51:08,689 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 09:51:08,690 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 09:51:08,690 \tHypothesis: Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ ma omai eva efuafo . ’\n",
            "2020-01-17 09:51:08,690 Example #1\n",
            "2020-01-17 09:51:08,691 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 09:51:08,691 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 09:51:08,691 \tHypothesis: Usi Uvie na o tẹ nya .\n",
            "2020-01-17 09:51:08,692 Example #2\n",
            "2020-01-17 09:51:08,692 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 09:51:08,693 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 09:51:08,693 \tHypothesis: Koyehọ , mai kpobi ma te rehọ oghọghọ fiba odẹ riẹ nọ o rrọ ekuhọ avọ oghọghọ na , re o jọ odẹ riẹ nọ o rẹ kẹ evawere , re ahwo kpobi a wo evawere .\n",
            "2020-01-17 09:51:08,693 Example #3\n",
            "2020-01-17 09:51:08,694 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 09:51:08,694 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 09:51:08,694 \tHypothesis: Ghele na , eme ọghoruo yọ ẹgba ọgaga nọ o re ro ru udhedhẹ .\n",
            "2020-01-17 09:51:08,694 Validation result (greedy) at epoch  26, step    65000: bleu:  28.36, loss: 36344.3945, ppl:   4.0629, duration: 34.5791s\n",
            "2020-01-17 09:51:23,237 Epoch  26 Step:    65100 Batch Loss:     1.493819 Tokens per Sec:    15122, Lr: 0.000300\n",
            "2020-01-17 09:51:37,824 Epoch  26 Step:    65200 Batch Loss:     1.393988 Tokens per Sec:    15492, Lr: 0.000300\n",
            "2020-01-17 09:51:52,340 Epoch  26 Step:    65300 Batch Loss:     1.482682 Tokens per Sec:    15124, Lr: 0.000300\n",
            "2020-01-17 09:52:06,873 Epoch  26 Step:    65400 Batch Loss:     1.405560 Tokens per Sec:    15301, Lr: 0.000300\n",
            "2020-01-17 09:52:21,378 Epoch  26 Step:    65500 Batch Loss:     1.376675 Tokens per Sec:    15298, Lr: 0.000300\n",
            "2020-01-17 09:52:35,869 Epoch  26 Step:    65600 Batch Loss:     1.419109 Tokens per Sec:    15280, Lr: 0.000300\n",
            "2020-01-17 09:52:50,424 Epoch  26 Step:    65700 Batch Loss:     1.492349 Tokens per Sec:    15122, Lr: 0.000300\n",
            "2020-01-17 09:52:54,815 Epoch  26: total training loss 3655.31\n",
            "2020-01-17 09:52:54,816 EPOCH 27\n",
            "2020-01-17 09:53:05,326 Epoch  27 Step:    65800 Batch Loss:     2.108713 Tokens per Sec:    14625, Lr: 0.000300\n",
            "2020-01-17 09:53:19,860 Epoch  27 Step:    65900 Batch Loss:     1.714597 Tokens per Sec:    15008, Lr: 0.000300\n",
            "2020-01-17 09:53:34,331 Epoch  27 Step:    66000 Batch Loss:     1.452988 Tokens per Sec:    15166, Lr: 0.000300\n",
            "2020-01-17 09:54:08,813 Hooray! New best validation result [ppl]!\n",
            "2020-01-17 09:54:08,814 Saving new checkpoint.\n",
            "2020-01-17 09:54:10,266 Example #0\n",
            "2020-01-17 09:54:10,266 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 09:54:10,267 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 09:54:10,267 \tHypothesis: Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ ma omai eva efuafo . ’\n",
            "2020-01-17 09:54:10,267 Example #1\n",
            "2020-01-17 09:54:10,268 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 09:54:10,269 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 09:54:10,270 \tHypothesis: Usi Uvie na u te lele iei .\n",
            "2020-01-17 09:54:10,270 Example #2\n",
            "2020-01-17 09:54:10,270 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 09:54:10,271 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 09:54:10,271 \tHypothesis: Fikiere , mai kpobi ma te rọ oghọghọ fiba odẹ riẹ nọ o rrọ obe nana nọ o rrọ ole obọdẹ gbe omosasọ nana : “ Jọ odẹ riẹ [ Jesu Kristi Ovie na ] o jọ bẹdẹ bẹdẹ , re ọre na ọ ruẹse gba odẹ riẹ họ , re o jọ efe riẹ , re erẹwho na kpobi a wo oghale , re a ruẹse rehọ iẹe jiri ei .\n",
            "2020-01-17 09:54:10,271 Example #3\n",
            "2020-01-17 09:54:10,272 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 09:54:10,272 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 09:54:10,272 \tHypothesis: Ghele na , eme ọghoruo yọ ẹgba ọgaga nọ a re ro ru udhedhẹ .\n",
            "2020-01-17 09:54:10,273 Validation result (greedy) at epoch  27, step    66000: bleu:  29.03, loss: 36147.2266, ppl:   4.0322, duration: 35.9416s\n",
            "2020-01-17 09:54:25,538 Epoch  27 Step:    66100 Batch Loss:     1.516220 Tokens per Sec:    14533, Lr: 0.000300\n",
            "2020-01-17 09:54:40,073 Epoch  27 Step:    66200 Batch Loss:     1.524409 Tokens per Sec:    15157, Lr: 0.000300\n",
            "2020-01-17 09:54:54,494 Epoch  27 Step:    66300 Batch Loss:     1.384319 Tokens per Sec:    15039, Lr: 0.000300\n",
            "2020-01-17 09:55:09,078 Epoch  27 Step:    66400 Batch Loss:     1.183241 Tokens per Sec:    15484, Lr: 0.000300\n",
            "2020-01-17 09:55:23,550 Epoch  27 Step:    66500 Batch Loss:     1.448812 Tokens per Sec:    15159, Lr: 0.000300\n",
            "2020-01-17 09:55:38,078 Epoch  27 Step:    66600 Batch Loss:     1.495757 Tokens per Sec:    15600, Lr: 0.000300\n",
            "2020-01-17 09:55:52,654 Epoch  27 Step:    66700 Batch Loss:     1.210159 Tokens per Sec:    15409, Lr: 0.000300\n",
            "2020-01-17 09:56:07,096 Epoch  27 Step:    66800 Batch Loss:     1.454973 Tokens per Sec:    15425, Lr: 0.000300\n",
            "2020-01-17 09:56:21,461 Epoch  27 Step:    66900 Batch Loss:     1.565835 Tokens per Sec:    15517, Lr: 0.000300\n",
            "2020-01-17 09:56:35,849 Epoch  27 Step:    67000 Batch Loss:     1.250847 Tokens per Sec:    15444, Lr: 0.000300\n",
            "2020-01-17 09:57:10,255 Hooray! New best validation result [ppl]!\n",
            "2020-01-17 09:57:10,256 Saving new checkpoint.\n",
            "2020-01-17 09:57:11,751 Example #0\n",
            "2020-01-17 09:57:11,751 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 09:57:11,752 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 09:57:11,752 \tHypothesis: Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ ma omai evaọ udu mai . ’\n",
            "2020-01-17 09:57:11,752 Example #1\n",
            "2020-01-17 09:57:11,753 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 09:57:11,753 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 09:57:11,754 \tHypothesis: Usi Uvie na o tẹ nya lele iei , Ijo .\n",
            "2020-01-17 09:57:11,754 Example #2\n",
            "2020-01-17 09:57:11,754 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 09:57:11,755 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 09:57:11,755 \tHypothesis: Fikiere , mai kpobi ma vẹ te ghọghọ fiki oghọghọ nọ ma be rọ ta ẹme kpahe ekuhọ ọrọ ole nana nọ o wo erru gbe omosasọ na : “ Jọ odẹ riẹ [ Jesu Kristi Ovie na ] o jọ bẹdẹ bẹdẹ , re ọre na ọ jọ bẹdẹ , re o wo odẹ riẹ , re o jọ a wo oghale , re a wo oghale , a wo oghale , a wo oghale , a vẹ te je wo oghale .\n",
            "2020-01-17 09:57:11,755 Example #3\n",
            "2020-01-17 09:57:11,756 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 09:57:11,756 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 09:57:11,756 \tHypothesis: Ghele na , eme ọ ọghoruo yọ ẹgba ologbo nọ a re ro ru udhedhẹ .\n",
            "2020-01-17 09:57:11,757 Validation result (greedy) at epoch  27, step    67000: bleu:  28.62, loss: 36021.0742, ppl:   4.0126, duration: 35.9074s\n",
            "2020-01-17 09:57:26,756 Epoch  27 Step:    67100 Batch Loss:     1.808715 Tokens per Sec:    15196, Lr: 0.000300\n",
            "2020-01-17 09:57:41,003 Epoch  27 Step:    67200 Batch Loss:     1.588718 Tokens per Sec:    15422, Lr: 0.000300\n",
            "2020-01-17 09:57:55,322 Epoch  27 Step:    67300 Batch Loss:     1.661831 Tokens per Sec:    15657, Lr: 0.000300\n",
            "2020-01-17 09:58:09,604 Epoch  27 Step:    67400 Batch Loss:     1.370288 Tokens per Sec:    15511, Lr: 0.000300\n",
            "2020-01-17 09:58:23,917 Epoch  27 Step:    67500 Batch Loss:     1.160344 Tokens per Sec:    15732, Lr: 0.000300\n",
            "2020-01-17 09:58:38,179 Epoch  27 Step:    67600 Batch Loss:     1.315686 Tokens per Sec:    15691, Lr: 0.000300\n",
            "2020-01-17 09:58:52,456 Epoch  27 Step:    67700 Batch Loss:     1.638277 Tokens per Sec:    15757, Lr: 0.000300\n",
            "2020-01-17 09:59:06,765 Epoch  27 Step:    67800 Batch Loss:     1.232423 Tokens per Sec:    15512, Lr: 0.000300\n",
            "2020-01-17 09:59:21,071 Epoch  27 Step:    67900 Batch Loss:     1.417491 Tokens per Sec:    15918, Lr: 0.000300\n",
            "2020-01-17 09:59:35,286 Epoch  27 Step:    68000 Batch Loss:     1.263163 Tokens per Sec:    15739, Lr: 0.000300\n",
            "2020-01-17 10:00:09,607 Hooray! New best validation result [ppl]!\n",
            "2020-01-17 10:00:09,607 Saving new checkpoint.\n",
            "2020-01-17 10:00:11,084 Example #0\n",
            "2020-01-17 10:00:11,085 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 10:00:11,085 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 10:00:11,085 \tHypothesis: Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ ma omai evaọ udu efuafo . ’\n",
            "2020-01-17 10:00:11,085 Example #1\n",
            "2020-01-17 10:00:11,086 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 10:00:11,086 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 10:00:11,087 \tHypothesis: Usi Uvie na o tẹ te nya .\n",
            "2020-01-17 10:00:11,087 Example #2\n",
            "2020-01-17 10:00:11,087 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 10:00:11,088 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 10:00:11,088 \tHypothesis: Koyehọ , mai kpobi ma te rọ oghọghọ fiba eme nọ e rrọ obehru na te ekuhọ ole nana nọ o wo erru gbe omosasọ na : “ Jọ odẹ riẹ [ Jesu Kristi Ovie na ] o jọ bẹdẹ bẹdẹ ; re ọre na ọ tẹ te ze , re o wo odẹ riẹ , re o jọ odẹ riẹ , re o jọ eva e were ae , re a jiri ai .\n",
            "2020-01-17 10:00:11,088 Example #3\n",
            "2020-01-17 10:00:11,089 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 10:00:11,089 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 10:00:11,089 \tHypothesis: Ghele na , eme ọghoruo yọ ẹgba ologbo nọ a re ro ru udhedhẹ .\n",
            "2020-01-17 10:00:11,089 Validation result (greedy) at epoch  27, step    68000: bleu:  28.99, loss: 35972.8047, ppl:   4.0051, duration: 35.8029s\n",
            "2020-01-17 10:00:26,161 Epoch  27 Step:    68100 Batch Loss:     1.642510 Tokens per Sec:    14544, Lr: 0.000300\n",
            "2020-01-17 10:00:40,577 Epoch  27 Step:    68200 Batch Loss:     1.504621 Tokens per Sec:    15649, Lr: 0.000300\n",
            "2020-01-17 10:00:48,408 Epoch  27: total training loss 3635.90\n",
            "2020-01-17 10:00:48,408 EPOCH 28\n",
            "2020-01-17 10:00:55,164 Epoch  28 Step:    68300 Batch Loss:     1.245815 Tokens per Sec:    15165, Lr: 0.000300\n",
            "2020-01-17 10:01:09,559 Epoch  28 Step:    68400 Batch Loss:     1.536107 Tokens per Sec:    15506, Lr: 0.000300\n",
            "2020-01-17 10:01:23,830 Epoch  28 Step:    68500 Batch Loss:     1.527602 Tokens per Sec:    15520, Lr: 0.000300\n",
            "2020-01-17 10:01:38,208 Epoch  28 Step:    68600 Batch Loss:     1.536213 Tokens per Sec:    15670, Lr: 0.000300\n",
            "2020-01-17 10:01:52,504 Epoch  28 Step:    68700 Batch Loss:     1.582816 Tokens per Sec:    15517, Lr: 0.000300\n",
            "2020-01-17 10:02:06,833 Epoch  28 Step:    68800 Batch Loss:     1.577846 Tokens per Sec:    15366, Lr: 0.000300\n",
            "2020-01-17 10:02:21,099 Epoch  28 Step:    68900 Batch Loss:     1.656558 Tokens per Sec:    15346, Lr: 0.000300\n",
            "2020-01-17 10:02:35,397 Epoch  28 Step:    69000 Batch Loss:     1.404522 Tokens per Sec:    15447, Lr: 0.000300\n",
            "2020-01-17 10:03:09,789 Example #0\n",
            "2020-01-17 10:03:09,790 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 10:03:09,790 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 10:03:09,791 \tHypothesis: Ma rẹ sae tubẹ lẹ Ọghẹnẹ re ọ ‘ ma omai eva efuafo . ’\n",
            "2020-01-17 10:03:09,791 Example #1\n",
            "2020-01-17 10:03:09,792 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 10:03:09,792 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 10:03:09,792 \tHypothesis: Usi Uvie na o tẹ nya lele iei .\n",
            "2020-01-17 10:03:09,793 Example #2\n",
            "2020-01-17 10:03:09,793 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 10:03:09,793 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 10:03:09,794 \tHypothesis: Koyehọ , mai kpobi ma te rehọ oghọghọ fiba urirẹ nana nọ o rrọ ole nana nọ o wo erru gbe omosasọ na : “ Jọ odẹ riẹ [ Jesu Kristi Ovie na ] o jọ bẹdẹ bẹdẹ ; re ọre na o te lo via , re o wo odẹ riẹ , re erẹwho kpobi a wo oghale , re a ruẹse rehọ iẹe jiri ei .\n",
            "2020-01-17 10:03:09,794 Example #3\n",
            "2020-01-17 10:03:09,795 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 10:03:09,795 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 10:03:09,795 \tHypothesis: Ghele na , eme ọghoruo yọ ẹgba ọgaga nọ a re ro ru udhedhẹ .\n",
            "2020-01-17 10:03:09,795 Validation result (greedy) at epoch  28, step    69000: bleu:  28.51, loss: 36014.3320, ppl:   4.0115, duration: 34.3979s\n",
            "2020-01-17 10:03:24,200 Epoch  28 Step:    69100 Batch Loss:     1.508964 Tokens per Sec:    15950, Lr: 0.000300\n",
            "2020-01-17 10:03:38,513 Epoch  28 Step:    69200 Batch Loss:     1.625322 Tokens per Sec:    15466, Lr: 0.000300\n",
            "2020-01-17 10:03:52,790 Epoch  28 Step:    69300 Batch Loss:     1.500767 Tokens per Sec:    15414, Lr: 0.000300\n",
            "2020-01-17 10:04:07,148 Epoch  28 Step:    69400 Batch Loss:     1.346761 Tokens per Sec:    15210, Lr: 0.000300\n",
            "2020-01-17 10:04:21,687 Epoch  28 Step:    69500 Batch Loss:     1.626137 Tokens per Sec:    15095, Lr: 0.000300\n",
            "2020-01-17 10:04:36,183 Epoch  28 Step:    69600 Batch Loss:     1.620640 Tokens per Sec:    15306, Lr: 0.000300\n",
            "2020-01-17 10:04:50,637 Epoch  28 Step:    69700 Batch Loss:     1.343024 Tokens per Sec:    15667, Lr: 0.000300\n",
            "2020-01-17 10:05:05,309 Epoch  28 Step:    69800 Batch Loss:     1.538549 Tokens per Sec:    15535, Lr: 0.000300\n",
            "2020-01-17 10:05:19,767 Epoch  28 Step:    69900 Batch Loss:     1.317473 Tokens per Sec:    14868, Lr: 0.000300\n",
            "2020-01-17 10:05:34,254 Epoch  28 Step:    70000 Batch Loss:     1.544981 Tokens per Sec:    15379, Lr: 0.000300\n",
            "2020-01-17 10:06:08,902 Hooray! New best validation result [ppl]!\n",
            "2020-01-17 10:06:08,903 Saving new checkpoint.\n",
            "2020-01-17 10:06:10,784 Example #0\n",
            "2020-01-17 10:06:10,785 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 10:06:10,785 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 10:06:10,785 \tHypothesis: Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ ma omai eva efuafo . ’\n",
            "2020-01-17 10:06:10,786 Example #1\n",
            "2020-01-17 10:06:10,787 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 10:06:10,787 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 10:06:10,787 \tHypothesis: Usi Uvie na o tẹ wariẹ zihe ze .\n",
            "2020-01-17 10:06:10,787 Example #2\n",
            "2020-01-17 10:06:10,788 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 10:06:10,788 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 10:06:10,788 \tHypothesis: Koyehọ , mai kpobi ma te rọ oghọghọ fiba orro mai kẹ abọ urere ọrọ ole nana nọ o wo erru gbe omosasọ na : “ Jọ odẹ riẹ [ Jesu Kristi Ovie na ] o jọ bẹdẹ bẹdẹ ; re ọre na o te lo nwranwranwra , re o wo odẹ riẹ , re wha wo oghale , wha rehọ iẹe jiri ahwo Egedhọ kpobi .\n",
            "2020-01-17 10:06:10,789 Example #3\n",
            "2020-01-17 10:06:10,789 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 10:06:10,790 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 10:06:10,790 \tHypothesis: Ghele na , eme ọ ọghoruo yọ ẹgba ologbo nọ a re ro ru udhedhẹ .\n",
            "2020-01-17 10:06:10,790 Validation result (greedy) at epoch  28, step    70000: bleu:  28.83, loss: 35944.4648, ppl:   4.0007, duration: 36.5350s\n",
            "2020-01-17 10:06:25,341 Epoch  28 Step:    70100 Batch Loss:     1.621996 Tokens per Sec:    15803, Lr: 0.000300\n",
            "2020-01-17 10:06:39,823 Epoch  28 Step:    70200 Batch Loss:     1.256841 Tokens per Sec:    15623, Lr: 0.000300\n",
            "2020-01-17 10:06:54,344 Epoch  28 Step:    70300 Batch Loss:     1.295532 Tokens per Sec:    15349, Lr: 0.000300\n",
            "2020-01-17 10:07:08,978 Epoch  28 Step:    70400 Batch Loss:     1.435895 Tokens per Sec:    15445, Lr: 0.000300\n",
            "2020-01-17 10:07:23,479 Epoch  28 Step:    70500 Batch Loss:     1.376234 Tokens per Sec:    15370, Lr: 0.000300\n",
            "2020-01-17 10:07:37,975 Epoch  28 Step:    70600 Batch Loss:     1.507828 Tokens per Sec:    15147, Lr: 0.000300\n",
            "2020-01-17 10:07:52,515 Epoch  28 Step:    70700 Batch Loss:     1.481427 Tokens per Sec:    15501, Lr: 0.000300\n",
            "2020-01-17 10:08:03,617 Epoch  28: total training loss 3606.53\n",
            "2020-01-17 10:08:03,618 EPOCH 29\n",
            "2020-01-17 10:08:07,414 Epoch  29 Step:    70800 Batch Loss:     1.369883 Tokens per Sec:    13729, Lr: 0.000300\n",
            "2020-01-17 10:08:21,863 Epoch  29 Step:    70900 Batch Loss:     0.979228 Tokens per Sec:    15164, Lr: 0.000300\n",
            "2020-01-17 10:08:36,151 Epoch  29 Step:    71000 Batch Loss:     1.691421 Tokens per Sec:    15102, Lr: 0.000300\n",
            "2020-01-17 10:09:10,642 Example #0\n",
            "2020-01-17 10:09:10,643 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 10:09:10,643 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 10:09:10,643 \tHypothesis: Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ ma omai eva efuafo . ’\n",
            "2020-01-17 10:09:10,644 Example #1\n",
            "2020-01-17 10:09:10,644 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 10:09:10,645 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 10:09:10,645 \tHypothesis: Usi Uvie na o tẹ te jọ họ .\n",
            "2020-01-17 10:09:10,645 Example #2\n",
            "2020-01-17 10:09:10,646 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 10:09:10,646 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 10:09:10,646 \tHypothesis: Koyehọ , mai kpobi ma te rọ oghọghọ fiba ẹthẹ mai te ekuhọ ọrọ ole nana nọ o rrọ urirẹ na : “ Jọ odẹ riẹ [ Jesu Kristi Ovie na ] o jọ bẹdẹ , re ọre na o te vihọ , re o wo odẹ riẹ , re o jọ rọ ere , re ahwo kpobi a wo oghale , re a ruẹse jiri ei .\n",
            "2020-01-17 10:09:10,646 Example #3\n",
            "2020-01-17 10:09:10,647 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 10:09:10,647 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 10:09:10,647 \tHypothesis: Ghele na , eme ọ ọghoruo yọ ẹgba ọgaga nọ a re ro ru udhedhẹ .\n",
            "2020-01-17 10:09:10,648 Validation result (greedy) at epoch  29, step    71000: bleu:  28.60, loss: 36056.9688, ppl:   4.0181, duration: 34.4958s\n",
            "2020-01-17 10:09:25,058 Epoch  29 Step:    71100 Batch Loss:     1.544649 Tokens per Sec:    15291, Lr: 0.000300\n",
            "2020-01-17 10:09:39,465 Epoch  29 Step:    71200 Batch Loss:     1.164574 Tokens per Sec:    15233, Lr: 0.000300\n",
            "2020-01-17 10:09:53,910 Epoch  29 Step:    71300 Batch Loss:     1.078914 Tokens per Sec:    15509, Lr: 0.000300\n",
            "2020-01-17 10:10:08,420 Epoch  29 Step:    71400 Batch Loss:     1.432099 Tokens per Sec:    15363, Lr: 0.000300\n",
            "2020-01-17 10:10:22,878 Epoch  29 Step:    71500 Batch Loss:     1.568149 Tokens per Sec:    15403, Lr: 0.000300\n",
            "2020-01-17 10:10:37,355 Epoch  29 Step:    71600 Batch Loss:     1.340935 Tokens per Sec:    15349, Lr: 0.000300\n",
            "2020-01-17 10:10:51,791 Epoch  29 Step:    71700 Batch Loss:     1.490832 Tokens per Sec:    15344, Lr: 0.000300\n",
            "2020-01-17 10:11:06,300 Epoch  29 Step:    71800 Batch Loss:     1.656802 Tokens per Sec:    15537, Lr: 0.000300\n",
            "2020-01-17 10:11:20,684 Epoch  29 Step:    71900 Batch Loss:     1.453384 Tokens per Sec:    15503, Lr: 0.000300\n",
            "2020-01-17 10:11:35,018 Epoch  29 Step:    72000 Batch Loss:     1.683703 Tokens per Sec:    15013, Lr: 0.000300\n",
            "2020-01-17 10:12:09,410 Example #0\n",
            "2020-01-17 10:12:09,411 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 10:12:09,411 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 10:12:09,412 \tHypothesis: Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ ma omai eva efuafo . ’\n",
            "2020-01-17 10:12:09,412 Example #1\n",
            "2020-01-17 10:12:09,412 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 10:12:09,413 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 10:12:09,413 \tHypothesis: Usi Uvie na o tẹ nya lele iei , Ọrọ Avọ 4\n",
            "2020-01-17 10:12:09,413 Example #2\n",
            "2020-01-17 10:12:09,414 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 10:12:09,414 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 10:12:09,414 \tHypothesis: Koyehọ mai kpobi ma te ghọghọ avọ oghọghọ , ma vẹ te rọ oghọghọ ta kpahe oria ile nana nọ e rẹ kẹ evawere na : “ Jọ odẹ riẹ [ Ovie na Jesu Kristi ] ọ jọ bẹdẹ ; re ọre na ọ jọ ribri , re o wo odẹ riẹ , jẹ rehọ ae kẹ ae evawere . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
            "2020-01-17 10:12:09,414 Example #3\n",
            "2020-01-17 10:12:09,415 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 10:12:09,415 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 10:12:09,415 \tHypothesis: Ghele na , eme ọghoruo yọ ẹgba ologbo nọ a re ro ru udhedhẹ .\n",
            "2020-01-17 10:12:09,416 Validation result (greedy) at epoch  29, step    72000: bleu:  28.94, loss: 35998.1484, ppl:   4.0090, duration: 34.3975s\n",
            "2020-01-17 10:12:23,708 Epoch  29 Step:    72100 Batch Loss:     1.433170 Tokens per Sec:    15895, Lr: 0.000300\n",
            "2020-01-17 10:12:38,024 Epoch  29 Step:    72200 Batch Loss:     1.556698 Tokens per Sec:    15571, Lr: 0.000300\n",
            "2020-01-17 10:12:52,216 Epoch  29 Step:    72300 Batch Loss:     1.444868 Tokens per Sec:    15368, Lr: 0.000300\n",
            "2020-01-17 10:13:06,475 Epoch  29 Step:    72400 Batch Loss:     1.163333 Tokens per Sec:    16044, Lr: 0.000300\n",
            "2020-01-17 10:13:20,676 Epoch  29 Step:    72500 Batch Loss:     1.648147 Tokens per Sec:    15718, Lr: 0.000300\n",
            "2020-01-17 10:13:34,906 Epoch  29 Step:    72600 Batch Loss:     1.148950 Tokens per Sec:    15423, Lr: 0.000300\n",
            "2020-01-17 10:13:49,130 Epoch  29 Step:    72700 Batch Loss:     1.633091 Tokens per Sec:    15885, Lr: 0.000300\n",
            "2020-01-17 10:14:03,288 Epoch  29 Step:    72800 Batch Loss:     1.581325 Tokens per Sec:    15367, Lr: 0.000300\n",
            "2020-01-17 10:14:17,607 Epoch  29 Step:    72900 Batch Loss:     1.251930 Tokens per Sec:    15862, Lr: 0.000300\n",
            "2020-01-17 10:14:31,869 Epoch  29 Step:    73000 Batch Loss:     1.538089 Tokens per Sec:    15824, Lr: 0.000300\n",
            "2020-01-17 10:15:06,141 Hooray! New best validation result [ppl]!\n",
            "2020-01-17 10:15:06,141 Saving new checkpoint.\n",
            "2020-01-17 10:15:07,971 Example #0\n",
            "2020-01-17 10:15:07,972 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 10:15:07,972 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 10:15:07,972 \tHypothesis: Ma rẹ sae tubẹ lẹ Ọghẹnẹ re ọ ‘ ma omai eva efuafo . ’\n",
            "2020-01-17 10:15:07,973 Example #1\n",
            "2020-01-17 10:15:07,973 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 10:15:07,973 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 10:15:07,974 \tHypothesis: Usi Uvie na U Kiẹrẹe No\n",
            "2020-01-17 10:15:07,974 Example #2\n",
            "2020-01-17 10:15:07,975 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 10:15:07,975 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 10:15:07,975 \tHypothesis: Koyehọ mai kpobi ma te rọ oghọghọ ru ẹvi mai kẹre te ekuhọ ole nana nọ o wo erru avọ omosasọ na : “ Jọ odẹ riẹ [ Jesu Kristi Ovie na ] o jọ bẹdẹ bẹdẹ ; re ọre na o te vihọ , re o ru re a jiri odẹ riẹ , re erẹwho kpobi a jiri ei ; re a jiri ei . . .\n",
            "2020-01-17 10:15:07,975 Example #3\n",
            "2020-01-17 10:15:07,976 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 10:15:07,976 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 10:15:07,977 \tHypothesis: Ghele na , eme ọ ọghoruo yọ ẹgba ọgaga nọ a re ro ru udhedhẹ .\n",
            "2020-01-17 10:15:07,977 Validation result (greedy) at epoch  29, step    73000: bleu:  28.95, loss: 35760.0000, ppl:   3.9724, duration: 36.1075s\n",
            "2020-01-17 10:15:22,307 Epoch  29 Step:    73100 Batch Loss:     1.569375 Tokens per Sec:    15500, Lr: 0.000300\n",
            "2020-01-17 10:15:36,557 Epoch  29 Step:    73200 Batch Loss:     1.411819 Tokens per Sec:    15437, Lr: 0.000300\n",
            "2020-01-17 10:15:50,871 Epoch  29 Step:    73300 Batch Loss:     1.498750 Tokens per Sec:    15901, Lr: 0.000300\n",
            "2020-01-17 10:15:51,748 Epoch  29: total training loss 3596.98\n",
            "2020-01-17 10:15:51,749 EPOCH 30\n",
            "2020-01-17 10:16:05,403 Epoch  30 Step:    73400 Batch Loss:     1.506340 Tokens per Sec:    15248, Lr: 0.000300\n",
            "2020-01-17 10:16:19,630 Epoch  30 Step:    73500 Batch Loss:     1.182586 Tokens per Sec:    15793, Lr: 0.000300\n",
            "2020-01-17 10:16:33,869 Epoch  30 Step:    73600 Batch Loss:     1.413265 Tokens per Sec:    15639, Lr: 0.000300\n",
            "2020-01-17 10:16:48,150 Epoch  30 Step:    73700 Batch Loss:     1.585362 Tokens per Sec:    15704, Lr: 0.000300\n",
            "2020-01-17 10:17:02,331 Epoch  30 Step:    73800 Batch Loss:     1.620204 Tokens per Sec:    15554, Lr: 0.000300\n",
            "2020-01-17 10:17:16,795 Epoch  30 Step:    73900 Batch Loss:     1.755797 Tokens per Sec:    15124, Lr: 0.000300\n",
            "2020-01-17 10:17:31,081 Epoch  30 Step:    74000 Batch Loss:     1.655536 Tokens per Sec:    15374, Lr: 0.000300\n",
            "2020-01-17 10:18:05,324 Hooray! New best validation result [ppl]!\n",
            "2020-01-17 10:18:05,325 Saving new checkpoint.\n",
            "2020-01-17 10:18:07,523 Example #0\n",
            "2020-01-17 10:18:07,524 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 10:18:07,524 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 10:18:07,524 \tHypothesis: Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ ma omai eva efuafo . ’\n",
            "2020-01-17 10:18:07,525 Example #1\n",
            "2020-01-17 10:18:07,525 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 10:18:07,526 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 10:18:07,526 \tHypothesis: Usi Uvie na o tẹ nya lele iei .\n",
            "2020-01-17 10:18:07,526 Example #2\n",
            "2020-01-17 10:18:07,527 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 10:18:07,527 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 10:18:07,528 \tHypothesis: Koyehọ , mai kpobi ma te rọ oghọghọ fiba eme nọ e rrọ obehru na rite ekuhọ ole nana nọ o wo erru gbe omosasọ na : “ Jọ odẹ riẹ [ Jesu Kristi Ovie na ] o jọ bẹdẹ bẹdẹ ; re ọre na o te ru re a jiri odẹ riẹ , re ahwo Egedhọ kpobi a wo oghale .\n",
            "2020-01-17 10:18:07,528 Example #3\n",
            "2020-01-17 10:18:07,529 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 10:18:07,529 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 10:18:07,529 \tHypothesis: Ghele na , eme ọ ọghoruo yọ ẹgba ọgaga nọ a re ro ru udhedhẹ .\n",
            "2020-01-17 10:18:07,530 Validation result (greedy) at epoch  30, step    74000: bleu:  28.99, loss: 35690.3125, ppl:   3.9617, duration: 36.4480s\n",
            "2020-01-17 10:18:21,858 Epoch  30 Step:    74100 Batch Loss:     1.387833 Tokens per Sec:    15565, Lr: 0.000300\n",
            "2020-01-17 10:18:36,158 Epoch  30 Step:    74200 Batch Loss:     1.292288 Tokens per Sec:    15480, Lr: 0.000300\n",
            "2020-01-17 10:18:50,574 Epoch  30 Step:    74300 Batch Loss:     1.152574 Tokens per Sec:    15611, Lr: 0.000300\n",
            "2020-01-17 10:19:04,850 Epoch  30 Step:    74400 Batch Loss:     1.296541 Tokens per Sec:    15969, Lr: 0.000300\n",
            "2020-01-17 10:19:19,219 Epoch  30 Step:    74500 Batch Loss:     1.350672 Tokens per Sec:    15489, Lr: 0.000300\n",
            "2020-01-17 10:19:33,546 Epoch  30 Step:    74600 Batch Loss:     1.006137 Tokens per Sec:    15892, Lr: 0.000300\n",
            "2020-01-17 10:19:47,919 Epoch  30 Step:    74700 Batch Loss:     1.574475 Tokens per Sec:    15403, Lr: 0.000300\n",
            "2020-01-17 10:20:02,246 Epoch  30 Step:    74800 Batch Loss:     1.516726 Tokens per Sec:    15867, Lr: 0.000300\n",
            "2020-01-17 10:20:16,516 Epoch  30 Step:    74900 Batch Loss:     1.308184 Tokens per Sec:    15407, Lr: 0.000300\n",
            "2020-01-17 10:20:30,783 Epoch  30 Step:    75000 Batch Loss:     1.207790 Tokens per Sec:    15383, Lr: 0.000300\n",
            "2020-01-17 10:21:05,104 Hooray! New best validation result [ppl]!\n",
            "2020-01-17 10:21:05,105 Saving new checkpoint.\n",
            "2020-01-17 10:21:06,574 Example #0\n",
            "2020-01-17 10:21:06,575 \tSource:     We can even ask God to ‘ create in us a pure heart . ’\n",
            "2020-01-17 10:21:06,575 \tReference:  Ma rẹ sae tubẹ yare Ọghẹnẹ re ọ ‘ kẹ omai eva efuafo . ’\n",
            "2020-01-17 10:21:06,575 \tHypothesis: Ma rẹ sae tubẹ lẹ se Ọghẹnẹ re ọ ‘ ma omai evaọ udu efuafo . ’\n",
            "2020-01-17 10:21:06,575 Example #1\n",
            "2020-01-17 10:21:06,576 \tSource:     This was followed by Kingdom News No .\n",
            "2020-01-17 10:21:06,576 \tReference:  U no ere no , a te siobọno obe usi ofa , Kingdom News No .\n",
            "2020-01-17 10:21:06,577 \tHypothesis: Usi Uvie na o tẹ te jọ kugbe omẹ .\n",
            "2020-01-17 10:21:06,577 Example #2\n",
            "2020-01-17 10:21:06,578 \tSource:     In effect , all of us will then joyfully add our voices to the concluding portion of this beautiful and heartwarming song : “ Let his name [ that of the King Jesus Christ ] prove to be to time indefinite ; before the sun let his name have increase , and by means of him let them bless themselves ; let all nations pronounce him happy .\n",
            "2020-01-17 10:21:06,578 \tReference:  Mai kpobi ma te rọ oghọghọ ku irru mai gbe so abọ urere ọrọ ole omosasọ nana : “ Jọ odẹ riẹ [ ọrọ Jesu Kristi Ovie na ] o te jọ bẹdẹ bẹdẹ , re usi riẹ u ti do bẹse nọ akpọ ọ bẹoviẹ !\n",
            "2020-01-17 10:21:06,578 \tHypothesis: Koyehọ , mai kpobi ma te rọ oghọghọ fiba orro mai kẹ ekuhọ ọrọ ole nana nọ o rẹ kẹ omosasọ gbe omosasọ na : “ Jọ odẹ riẹ [ Jesu Kristi Ovie na ] o jọ bẹdẹ bẹdẹ ; re ọre na o te wo odẹ riẹ , re o jọ efe riẹ , re o jọ kẹ ae evawere , re a ruẹ e .\n",
            "2020-01-17 10:21:06,579 Example #3\n",
            "2020-01-17 10:21:06,579 \tSource:     Still , words of apology are a strong force toward making peace .\n",
            "2020-01-17 10:21:06,580 \tReference:  Ghele na , eme unu - uwou u re fi obọ họ gaga evaọ eruo udhedhẹ .\n",
            "2020-01-17 10:21:06,580 \tHypothesis: Ghele na , eme ọghoruo yọ ẹgba ọgaga nọ a re ro ru udhedhẹ .\n",
            "2020-01-17 10:21:06,580 Validation result (greedy) at epoch  30, step    75000: bleu:  29.38, loss: 35568.8438, ppl:   3.9432, duration: 35.7965s\n",
            "2020-01-17 10:21:21,158 Epoch  30 Step:    75100 Batch Loss:     1.374722 Tokens per Sec:    14785, Lr: 0.000300\n",
            "2020-01-17 10:21:35,663 Epoch  30 Step:    75200 Batch Loss:     1.583418 Tokens per Sec:    15348, Lr: 0.000300\n",
            "2020-01-17 10:21:50,198 Epoch  30 Step:    75300 Batch Loss:     1.489844 Tokens per Sec:    14958, Lr: 0.000300\n",
            "2020-01-17 10:22:04,577 Epoch  30 Step:    75400 Batch Loss:     1.560337 Tokens per Sec:    15536, Lr: 0.000300\n",
            "2020-01-17 10:22:18,841 Epoch  30 Step:    75500 Batch Loss:     1.213528 Tokens per Sec:    15392, Lr: 0.000300\n",
            "2020-01-17 10:22:33,166 Epoch  30 Step:    75600 Batch Loss:     1.268090 Tokens per Sec:    15960, Lr: 0.000300\n",
            "2020-01-17 10:22:47,767 Epoch  30 Step:    75700 Batch Loss:     1.252957 Tokens per Sec:    15426, Lr: 0.000300\n",
            "2020-01-17 10:23:02,049 Epoch  30 Step:    75800 Batch Loss:     1.419122 Tokens per Sec:    15473, Lr: 0.000300\n",
            "2020-01-17 10:23:06,883 Epoch  30: total training loss 3576.43\n",
            "2020-01-17 10:23:06,884 Training ended after  30 epochs.\n",
            "2020-01-17 10:23:06,884 Best validation result (greedy) at step    75000:   3.94 ppl.\n",
            "2020-01-17 10:23:34,463  dev bleu:  30.32 [Beam search decoding with beam size = 5 and alpha = 1.0]\n",
            "2020-01-17 10:23:34,470 Translations saved to: /content/drive/My Drive/masakhane/en-iso-baseline/models/eniso_transformer/00075000.hyps.dev\n",
            "2020-01-17 10:24:20,930 test bleu:  36.53 [Beam search decoding with beam size = 5 and alpha = 1.0]\n",
            "2020-01-17 10:24:20,941 Translations saved to: /content/drive/My Drive/masakhane/en-iso-baseline/models/eniso_transformer/00075000.hyps.test\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MBoDS09JM807",
        "colab": {}
      },
      "source": [
        "# Copy the created models from the notebook storage to google drive for persistant storage \n",
        "# !cp -r joeynmt/models/${src}${tgt}_transformer/* \"$gdrive_path/models/${src}${tgt}_transformer/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n94wlrCjVc17",
        "outputId": "280ab882-55a7-40b6-fb19-3087275ac87b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Output our validation accuracy\n",
        "! cat \"$gdrive_path/models/${src}${tgt}_transformer/validations.txt\""
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Steps: 1000\tLoss: 94234.79688\tPPL: 37.89809\tbleu: 2.08377\tLR: 0.00030000\t*\n",
            "Steps: 2000\tLoss: 80098.55469\tPPL: 21.96886\tbleu: 4.41429\tLR: 0.00030000\t*\n",
            "Steps: 3000\tLoss: 71809.64062\tPPL: 15.95703\tbleu: 6.13988\tLR: 0.00030000\t*\n",
            "Steps: 4000\tLoss: 66469.93750\tPPL: 12.98678\tbleu: 9.18670\tLR: 0.00030000\t*\n",
            "Steps: 5000\tLoss: 62164.83594\tPPL: 10.99975\tbleu: 11.60847\tLR: 0.00030000\t*\n",
            "Steps: 6000\tLoss: 59310.51953\tPPL: 9.85297\tbleu: 13.32222\tLR: 0.00030000\t*\n",
            "Steps: 7000\tLoss: 56697.83594\tPPL: 8.90840\tbleu: 14.61969\tLR: 0.00030000\t*\n",
            "Steps: 8000\tLoss: 55065.73047\tPPL: 8.36486\tbleu: 15.46040\tLR: 0.00030000\t*\n",
            "Steps: 9000\tLoss: 53112.52734\tPPL: 7.75780\tbleu: 17.31818\tLR: 0.00030000\t*\n",
            "Steps: 10000\tLoss: 51696.43750\tPPL: 7.34542\tbleu: 17.20387\tLR: 0.00030000\t*\n",
            "Steps: 11000\tLoss: 50569.53906\tPPL: 7.03297\tbleu: 17.98495\tLR: 0.00030000\t*\n",
            "Steps: 12000\tLoss: 49303.01953\tPPL: 6.69764\tbleu: 18.85888\tLR: 0.00030000\t*\n",
            "Steps: 13000\tLoss: 48429.05469\tPPL: 6.47562\tbleu: 19.24016\tLR: 0.00030000\t*\n",
            "Steps: 14000\tLoss: 47421.25000\tPPL: 6.22872\tbleu: 20.29620\tLR: 0.00030000\t*\n",
            "Steps: 15000\tLoss: 46672.74609\tPPL: 6.05145\tbleu: 20.52968\tLR: 0.00030000\t*\n",
            "Steps: 16000\tLoss: 46095.49219\tPPL: 5.91820\tbleu: 20.91999\tLR: 0.00030000\t*\n",
            "Steps: 17000\tLoss: 45379.99219\tPPL: 5.75710\tbleu: 21.96850\tLR: 0.00030000\t*\n",
            "Steps: 18000\tLoss: 44758.84766\tPPL: 5.62080\tbleu: 21.40537\tLR: 0.00030000\t*\n",
            "Steps: 19000\tLoss: 44534.36719\tPPL: 5.57234\tbleu: 22.14367\tLR: 0.00030000\t*\n",
            "Steps: 20000\tLoss: 44845.13672\tPPL: 5.63954\tbleu: 20.87363\tLR: 0.00030000\t\n",
            "Steps: 21000\tLoss: 43438.25781\tPPL: 5.34165\tbleu: 23.31405\tLR: 0.00030000\t*\n",
            "Steps: 22000\tLoss: 43037.99219\tPPL: 5.25982\tbleu: 22.98467\tLR: 0.00030000\t*\n",
            "Steps: 23000\tLoss: 42851.05859\tPPL: 5.22203\tbleu: 23.75610\tLR: 0.00030000\t*\n",
            "Steps: 24000\tLoss: 42324.09766\tPPL: 5.11695\tbleu: 23.37798\tLR: 0.00030000\t*\n",
            "Steps: 25000\tLoss: 41840.85938\tPPL: 5.02246\tbleu: 24.11398\tLR: 0.00030000\t*\n",
            "Steps: 26000\tLoss: 41932.92578\tPPL: 5.04033\tbleu: 24.44848\tLR: 0.00030000\t\n",
            "Steps: 27000\tLoss: 41288.82031\tPPL: 4.91664\tbleu: 24.48488\tLR: 0.00030000\t*\n",
            "Steps: 28000\tLoss: 41143.61719\tPPL: 4.88918\tbleu: 24.75412\tLR: 0.00030000\t*\n",
            "Steps: 29000\tLoss: 40905.48828\tPPL: 4.84448\tbleu: 24.61773\tLR: 0.00030000\t*\n",
            "Steps: 30000\tLoss: 40556.39062\tPPL: 4.77968\tbleu: 25.65801\tLR: 0.00030000\t*\n",
            "Steps: 31000\tLoss: 40280.01172\tPPL: 4.72900\tbleu: 25.36187\tLR: 0.00030000\t*\n",
            "Steps: 32000\tLoss: 40043.01172\tPPL: 4.68596\tbleu: 25.48974\tLR: 0.00030000\t*\n",
            "Steps: 33000\tLoss: 39784.09766\tPPL: 4.63940\tbleu: 25.54002\tLR: 0.00030000\t*\n",
            "Steps: 34000\tLoss: 39677.82031\tPPL: 4.62042\tbleu: 25.62489\tLR: 0.00030000\t*\n",
            "Steps: 35000\tLoss: 39490.33203\tPPL: 4.58712\tbleu: 26.49471\tLR: 0.00030000\t*\n",
            "Steps: 36000\tLoss: 39363.20312\tPPL: 4.56468\tbleu: 25.94072\tLR: 0.00030000\t*\n",
            "Steps: 37000\tLoss: 39259.39453\tPPL: 4.54644\tbleu: 26.27984\tLR: 0.00030000\t*\n",
            "Steps: 38000\tLoss: 39367.76172\tPPL: 4.56549\tbleu: 25.91601\tLR: 0.00030000\t\n",
            "Steps: 39000\tLoss: 38852.83203\tPPL: 4.47570\tbleu: 26.36728\tLR: 0.00030000\t*\n",
            "Steps: 40000\tLoss: 38837.37500\tPPL: 4.47303\tbleu: 27.19716\tLR: 0.00030000\t*\n",
            "Steps: 41000\tLoss: 38758.82031\tPPL: 4.45950\tbleu: 27.08113\tLR: 0.00030000\t*\n",
            "Steps: 42000\tLoss: 38634.75391\tPPL: 4.43821\tbleu: 26.10681\tLR: 0.00030000\t*\n",
            "Steps: 43000\tLoss: 38215.01562\tPPL: 4.36693\tbleu: 26.85208\tLR: 0.00030000\t*\n",
            "Steps: 44000\tLoss: 38140.56250\tPPL: 4.35441\tbleu: 26.70836\tLR: 0.00030000\t*\n",
            "Steps: 45000\tLoss: 37830.87891\tPPL: 4.30270\tbleu: 26.83892\tLR: 0.00030000\t*\n",
            "Steps: 46000\tLoss: 37947.87109\tPPL: 4.32216\tbleu: 27.22322\tLR: 0.00030000\t\n",
            "Steps: 47000\tLoss: 37837.01953\tPPL: 4.30372\tbleu: 26.90088\tLR: 0.00030000\t\n",
            "Steps: 48000\tLoss: 37429.32031\tPPL: 4.23657\tbleu: 26.76920\tLR: 0.00030000\t*\n",
            "Steps: 49000\tLoss: 37535.80859\tPPL: 4.25401\tbleu: 27.91024\tLR: 0.00030000\t\n",
            "Steps: 50000\tLoss: 37384.20312\tPPL: 4.22920\tbleu: 27.38686\tLR: 0.00030000\t*\n",
            "Steps: 51000\tLoss: 37488.26562\tPPL: 4.24621\tbleu: 27.30332\tLR: 0.00030000\t\n",
            "Steps: 52000\tLoss: 37249.16797\tPPL: 4.20723\tbleu: 27.73932\tLR: 0.00030000\t*\n",
            "Steps: 53000\tLoss: 37049.71484\tPPL: 4.17499\tbleu: 27.67015\tLR: 0.00030000\t*\n",
            "Steps: 54000\tLoss: 37027.88672\tPPL: 4.17147\tbleu: 28.06041\tLR: 0.00030000\t*\n",
            "Steps: 55000\tLoss: 36923.14453\tPPL: 4.15465\tbleu: 28.32371\tLR: 0.00030000\t*\n",
            "Steps: 56000\tLoss: 36901.88672\tPPL: 4.15125\tbleu: 28.38773\tLR: 0.00030000\t*\n",
            "Steps: 57000\tLoss: 36688.31641\tPPL: 4.11719\tbleu: 27.99866\tLR: 0.00030000\t*\n",
            "Steps: 58000\tLoss: 36623.31641\tPPL: 4.10688\tbleu: 28.00368\tLR: 0.00030000\t*\n",
            "Steps: 59000\tLoss: 36544.61328\tPPL: 4.09443\tbleu: 28.65796\tLR: 0.00030000\t*\n",
            "Steps: 60000\tLoss: 36513.17578\tPPL: 4.08947\tbleu: 28.05014\tLR: 0.00030000\t*\n",
            "Steps: 61000\tLoss: 36508.17578\tPPL: 4.08868\tbleu: 28.72723\tLR: 0.00030000\t*\n",
            "Steps: 62000\tLoss: 36356.16016\tPPL: 4.06478\tbleu: 28.56549\tLR: 0.00030000\t*\n",
            "Steps: 63000\tLoss: 36310.91016\tPPL: 4.05769\tbleu: 28.21350\tLR: 0.00030000\t*\n",
            "Steps: 64000\tLoss: 36172.55078\tPPL: 4.03609\tbleu: 28.46607\tLR: 0.00030000\t*\n",
            "Steps: 65000\tLoss: 36344.39453\tPPL: 4.06293\tbleu: 28.36017\tLR: 0.00030000\t\n",
            "Steps: 66000\tLoss: 36147.22656\tPPL: 4.03215\tbleu: 29.02760\tLR: 0.00030000\t*\n",
            "Steps: 67000\tLoss: 36021.07422\tPPL: 4.01258\tbleu: 28.62494\tLR: 0.00030000\t*\n",
            "Steps: 68000\tLoss: 35972.80469\tPPL: 4.00511\tbleu: 28.98547\tLR: 0.00030000\t*\n",
            "Steps: 69000\tLoss: 36014.33203\tPPL: 4.01153\tbleu: 28.50999\tLR: 0.00030000\t\n",
            "Steps: 70000\tLoss: 35944.46484\tPPL: 4.00074\tbleu: 28.83174\tLR: 0.00030000\t*\n",
            "Steps: 71000\tLoss: 36056.96875\tPPL: 4.01814\tbleu: 28.60269\tLR: 0.00030000\t\n",
            "Steps: 72000\tLoss: 35998.14844\tPPL: 4.00903\tbleu: 28.93575\tLR: 0.00030000\t\n",
            "Steps: 73000\tLoss: 35760.00000\tPPL: 3.97237\tbleu: 28.95383\tLR: 0.00030000\t*\n",
            "Steps: 74000\tLoss: 35690.31250\tPPL: 3.96171\tbleu: 28.99425\tLR: 0.00030000\t*\n",
            "Steps: 75000\tLoss: 35568.84375\tPPL: 3.94319\tbleu: 29.37997\tLR: 0.00030000\t*\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "66WhRE9lIhoD",
        "outputId": "c520050b-445e-45cb-ff57-24ce2a56b426",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Test our model\n",
        "! cd joeynmt; python3 -m joeynmt test \"$gdrive_path/models/${src}${tgt}_transformer/config.yaml\""
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-01-17 10:24:48,714 Hello! This is Joey-NMT.\n",
            "2020-01-17 10:25:19,377  dev bleu:  30.32 [Beam search decoding with beam size = 5 and alpha = 1.0]\n",
            "2020-01-17 10:26:04,573 test bleu:  36.53 [Beam search decoding with beam size = 5 and alpha = 1.0]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}