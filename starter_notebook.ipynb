{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Igc5itf-xMGj"
   },
   "source": [
    "# Masakhane - Machine Translation for African Languages (Using JoeyNMT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x4fXCKCf36IK"
   },
   "source": [
    "## Note before beginning:\n",
    "### - The idea is that you should be able to make minimal changes to this in order to get SOME result for your own translation corpus. \n",
    "\n",
    "### - The tl;dr: Go to the **\"TODO\"** comments which will tell you what to update to get up and running\n",
    "\n",
    "### - If you actually want to have a clue what you're doing, read the text and peek at the links\n",
    "\n",
    "### - With 100 epochs, it should take around 7 hours to run in Google Colab\n",
    "\n",
    "### - Once you've gotten a result for your language, please attach and email your notebook that generated it to masakhanetranslation@gmail.com\n",
    "\n",
    "### - If you care enough and get a chance, doing a brief background on your language would be amazing. See examples in  [(Martinus, 2019)](https://arxiv.org/abs/1906.05685)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l929HimrxS0a"
   },
   "source": [
    "## Retrieve your data & make a parallel corpus\n",
    "\n",
    "So the easiest way to get your data is to use some unix tools such as `wget` to fetch it from a url, and then `gunzip` to extract it if it's zipped. \n",
    "\n",
    "Parallel corpuses come in many formats. The ideal corpus comes with 2 files: `file.source` and `file.target` where `\"source\"` is your source language, such as `en` and `\"target\"` is your target language, such as `xh` (Xhosa)\n",
    "\n",
    "Sometimes they come in a **.tmx** file a.k.a a **translation memory file**. This is an xml structure which will include the sentences in your target language and your source language in a single file. Thankfully, Jade wrote a silly `tmx2dataframe` package which converts your tmx file to a pandas dataframe. #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cn3tgQLzUxwn"
   },
   "outputs": [],
   "source": [
    "# TODO: Set your source and target languages. Keep in mind, these traditionally use language codes as found here:\n",
    "# These will also become the suffix's of all vocab and corpus files used throughout\n",
    "import os\n",
    "source_language = \"en\"\n",
    "target_language = \"xh\"\n",
    "os.environ[\"src\"] = source_language # Sets them in bash as well, since we often use bash scripts\n",
    "os.environ[\"tgt\"] = target_language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 663
    },
    "colab_type": "code",
    "id": "3CNdwLBCfSIl",
    "outputId": "02bd0856-5806-4026-f761-1b879178fa8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-08-11 12:25:42--  http://opus.nlpl.eu/download.php?f=XhosaNavy/v1/tmx/en-xh.tmx.gz\n",
      "Resolving opus.nlpl.eu (opus.nlpl.eu)... 193.166.25.9\n",
      "Connecting to opus.nlpl.eu (opus.nlpl.eu)|193.166.25.9|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://object.pouta.csc.fi/OPUS-XhosaNavy/v1/tmx/en-xh.tmx.gz [following]\n",
      "--2019-08-11 12:25:42--  https://object.pouta.csc.fi/OPUS-XhosaNavy/v1/tmx/en-xh.tmx.gz\n",
      "Resolving object.pouta.csc.fi (object.pouta.csc.fi)... 86.50.254.0, 86.50.254.1\n",
      "Connecting to object.pouta.csc.fi (object.pouta.csc.fi)|86.50.254.0|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3526058 (3.4M) [application/gzip]\n",
      "Saving to: ‘en-xh.tmx.gz’\n",
      "\n",
      "en-xh.tmx.gz        100%[===================>]   3.36M  3.12MB/s    in 1.1s    \n",
      "\n",
      "2019-08-11 12:25:44 (3.12 MB/s) - ‘en-xh.tmx.gz’ saved [3526058/3526058]\n",
      "\n",
      "gzip: en-xh.tmx already exists; do you wish to overwrite (y or n)? y\n",
      "total 39M\n",
      "-rw-r--r--  1 root root  34K Aug 11 10:01 bpe.codes.4000\n",
      "-rw-r--r--  1 root root 131K Aug 11 10:02 dev.bpe.en\n",
      "-rw-r--r--  1 root root 163K Aug 11 10:02 dev.bpe.xh\n",
      "-rw-r--r--  1 root root 103K Aug 11 10:00 dev.en\n",
      "-rw-r--r--  1 root root 114K Aug 11 10:00 dev.xh\n",
      "-rw-r--r--  1 root root  14M Nov 17  2018 en-xh.tmx\n",
      "-rw-r--r--  1 root root 3.4M Nov 17  2018 en-xh.tmx.gz\n",
      "drwxr-xr-x 11 root root 4.0K Aug 11 10:09 joeynmt\n",
      "drwxr-xr-x  1 root root 4.0K Aug  2 16:06 sample_data\n",
      "-rw-r--r--  1 root root 156K Aug 11 10:02 test.bpe.en\n",
      "-rw-r--r--  1 root root 183K Aug 11 10:02 test.bpe.xh\n",
      "-rw-r--r--  1 root root 122K Aug 11 10:00 test.en\n",
      "-rw-r--r--  1 root root 128K Aug 11 10:00 test.xh\n",
      "-rw-r--r--  1 root root 5.2M Aug 11 10:01 train.bpe.en\n",
      "-rw-r--r--  1 root root 6.6M Aug 11 10:02 train.bpe.xh\n",
      "-rw-r--r--  1 root root 4.0M Aug 11 10:00 train.en\n",
      "-rw-r--r--  1 root root 4.6M Aug 11 10:00 train.xh\n",
      "-rw-r--r--  1 root root  25K Aug 11 10:01 vocab.en\n",
      "-rw-r--r--  1 root root  33K Aug 11 10:01 vocab.xh\n",
      "Requirement already satisfied: tmx2dataframe in /usr/local/lib/python3.6/dist-packages (0.2)\n"
     ]
    }
   ],
   "source": [
    "# Downloading and unzipping our xhosa corpus\n",
    "# TODO: You'll need to download & extract your own corpus here! \n",
    "! wget \"http://opus.nlpl.eu/download.php?f=XhosaNavy/v1/tmx/en-xh.tmx.gz\" -O en-xh.tmx.gz\n",
    "! gunzip -k  en-xh.tmx.gz\n",
    "! ls -lh\n",
    "\n",
    "# This is useful if you end up having to use a tmx file,\n",
    "! pip install tmx2dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Zwi3M-RwtFd"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tmx2dataframe import tmx2dataframe\n",
    "\n",
    "# TODO:\n",
    "# If your source is a translation memory file (tmx file), then the one file contains both your target and source language. If so, set tmx_file = \"your file here\"\n",
    "# Comment if you have 2 files, instead of the tmx file\n",
    "tmx_file = \"en-xh.tmx\"\n",
    "source_file = None\n",
    "target_file = None \n",
    "\n",
    "# Uncomment if you have 2 files and set source_file and target_file to the path of your parallel corpus files\n",
    "# tmx_file = None\n",
    "# source_file = 'file.src'\n",
    "# target_file = 'file.tgt'\n",
    "\n",
    "# Read in the files so we have an appropriate python dataframe\n",
    "if tmx_file is not None:\n",
    "    # tmx files\n",
    "    metadata, df = tmx2dataframe.read(tmx_file)\n",
    "else:\n",
    "    # For 2 parallel files\n",
    "    df_src = pd.read(\"file.src\", header=None, names=[\"source_sentence\"])\n",
    "    df_tgt = pd.read(\"file.tgt\", header=None, names=[\"target_sentence\"])\n",
    "    df = pd.concat([df_src, df_tgt], axis=1)\n",
    "    df[\"source_language\"] = source_language\n",
    "    df[\"target_language\"] = target_language\n",
    "\n",
    "# Have a peak at the data\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hxxBOCA-xXhy"
   },
   "outputs": [],
   "source": [
    "# This section does the split between train/test/dev for the parallel corpora then saves them as separate files\n",
    "# We use 1000 dev test and 1000 test set. In practice, it's useful to use an external test set\n",
    "\n",
    "\n",
    "# Do the split between dev/test/train and create parallel corpora\n",
    "num_dev_patterns = 1000\n",
    "num_test_patterns = 1000\n",
    "\n",
    "# Lower case the corpora\n",
    "df[\"source_sentence\"] = df[\"source_sentence\"].str.lower()\n",
    "df[\"target_sentence\"] = df[\"target_sentence\"].str.lower()\n",
    "\n",
    "\n",
    "devtest = df.tail(num_dev_patterns + num_test_patterns)\n",
    "test = devtest.tail(num_test_patterns) # Herman\n",
    "dev = devtest.head(num_dev_patterns)  # Herman: Error in original\n",
    "stripped = df.drop(df.tail(num_dev_patterns + num_test_patterns).index)\n",
    "\n",
    "stripped[[\"source_sentence\"]].to_csv(\"train.en\", index=False)\n",
    "stripped[[\"target_sentence\"]].to_csv(\"train.xh\", index=False)\n",
    "\n",
    "dev[[\"source_sentence\"]].to_csv(\"dev.en\", index=False)\n",
    "dev[[\"target_sentence\"]].to_csv(\"dev.xh\", index=False)\n",
    "\n",
    "test[[\"source_sentence\"]].to_csv(\"test.en\", index=False)\n",
    "test[[\"target_sentence\"]].to_csv(\"test.xh\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "epeCydmCyS8X"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Installation of JoeyNMT\n",
    "\n",
    "JoeyNMT is a simple, minimalist NMT package which is useful for learning and teaching. Check out the documentation for JoeyNMT [here](https://joeynmt.readthedocs.io)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "iBRMm4kMxZ8L",
    "outputId": "6d7bc978-1816-4c56-c1ab-67b99ff867ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'joeynmt' already exists and is not an empty directory.\n",
      "Processing /content/joeynmt\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from joeynmt==0.0.1) (0.16.0)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from joeynmt==0.0.1) (4.3.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from joeynmt==0.0.1) (1.16.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from joeynmt==0.0.1) (41.0.1)\n",
      "Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.6/dist-packages (from joeynmt==0.0.1) (1.1.0)\n",
      "Requirement already satisfied: tensorflow>=1.14 in /usr/local/lib/python3.6/dist-packages (from joeynmt==0.0.1) (1.14.0)\n",
      "Requirement already satisfied: torchtext in /usr/local/lib/python3.6/dist-packages (from joeynmt==0.0.1) (0.3.1)\n",
      "Requirement already satisfied: sacrebleu>=1.3.6 in /usr/local/lib/python3.6/dist-packages (from joeynmt==0.0.1) (1.3.7)\n",
      "Requirement already satisfied: subword-nmt in /usr/local/lib/python3.6/dist-packages (from joeynmt==0.0.1) (0.3.6)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from joeynmt==0.0.1) (3.0.3)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (from joeynmt==0.0.1) (0.9.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.6/dist-packages (from joeynmt==0.0.1) (5.1.2)\n",
      "Requirement already satisfied: pylint in /usr/local/lib/python3.6/dist-packages (from joeynmt==0.0.1) (2.3.1)\n",
      "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->joeynmt==0.0.1) (0.46)\n",
      "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (1.14.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (0.1.7)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (3.7.1)\n",
      "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (0.2.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (1.1.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (1.15.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (1.1.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (1.12.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (0.33.4)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (0.8.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (0.7.1)\n",
      "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (1.14.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (1.0.8)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt==0.0.1) (1.11.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext->joeynmt==0.0.1) (4.28.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext->joeynmt==0.0.1) (2.21.0)\n",
      "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from sacrebleu>=1.3.6->joeynmt==0.0.1) (3.7.4)\n",
      "Requirement already satisfied: portalocker in /usr/local/lib/python3.6/dist-packages (from sacrebleu>=1.3.6->joeynmt==0.0.1) (1.5.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->joeynmt==0.0.1) (2.4.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->joeynmt==0.0.1) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->joeynmt==0.0.1) (2.5.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->joeynmt==0.0.1) (0.10.0)\n",
      "Requirement already satisfied: pandas>=0.15.2 in /usr/local/lib/python3.6/dist-packages (from seaborn->joeynmt==0.0.1) (0.24.2)\n",
      "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from seaborn->joeynmt==0.0.1) (1.3.0)\n",
      "Requirement already satisfied: isort<5,>=4.2.5 in /usr/local/lib/python3.6/dist-packages (from pylint->joeynmt==0.0.1) (4.3.21)\n",
      "Requirement already satisfied: mccabe<0.7,>=0.6 in /usr/local/lib/python3.6/dist-packages (from pylint->joeynmt==0.0.1) (0.6.1)\n",
      "Requirement already satisfied: astroid<3,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from pylint->joeynmt==0.0.1) (2.2.5)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow>=1.14->joeynmt==0.0.1) (3.1.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow>=1.14->joeynmt==0.0.1) (0.15.5)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow>=1.14->joeynmt==0.0.1) (2.8.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext->joeynmt==0.0.1) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext->joeynmt==0.0.1) (1.24.3)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext->joeynmt==0.0.1) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext->joeynmt==0.0.1) (2019.6.16)\n",
      "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.15.2->seaborn->joeynmt==0.0.1) (2018.9)\n",
      "Requirement already satisfied: lazy-object-proxy in /usr/local/lib/python3.6/dist-packages (from astroid<3,>=2.2.0->pylint->joeynmt==0.0.1) (1.4.1)\n",
      "Requirement already satisfied: typed-ast>=1.3.0; implementation_name == \"cpython\" in /usr/local/lib/python3.6/dist-packages (from astroid<3,>=2.2.0->pylint->joeynmt==0.0.1) (1.4.0)\n",
      "Building wheels for collected packages: joeynmt\n",
      "  Building wheel for joeynmt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for joeynmt: filename=joeynmt-0.0.1-cp36-none-any.whl size=69350 sha256=2d7f527068a659fa9eb13672d62544cc8b5404053ce4c5ade54abb43114e9d09\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-im26xdyk/wheels/db/01/db/751cc9f3e7f6faec127c43644ba250a3ea7ad200594aeda70a\n",
      "Successfully built joeynmt\n",
      "Installing collected packages: joeynmt\n",
      "  Found existing installation: joeynmt 0.0.1\n",
      "    Uninstalling joeynmt-0.0.1:\n",
      "      Successfully uninstalled joeynmt-0.0.1\n",
      "Successfully installed joeynmt-0.0.1\n"
     ]
    }
   ],
   "source": [
    "# Install JoeyNMT\n",
    "! git clone https://github.com/joeynmt/joeynmt.git\n",
    "! cd joeynmt; pip3 install ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AaE77Tcppex9"
   },
   "source": [
    "# Preprocessing the Data into Subword BPE Tokens\n",
    "\n",
    "- One of the most powerful improvements for agglutinative languages (a feature of most Bantu languages) is using BPE tokenization [ (Sennrich, 2015) ](https://arxiv.org/abs/1508.07909).\n",
    "\n",
    "- It was also shown that by optimizing the umber of BPE codes we significantly improve results for low-resourced languages [(Sennrich, 2019)](https://www.aclweb.org/anthology/P19-1021) [(Martinus, 2019)](https://arxiv.org/abs/1906.05685)\n",
    "\n",
    "- Below we have the scripts for doing BPE tokenization of our data. We use 4000 tokens as recommended by [(Sennrich, 2019)](https://www.aclweb.org/anthology/P19-1021). You do not need to change anything. Simply running the below will be suitable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "colab_type": "code",
    "id": "H-TyjtmXB1mL",
    "outputId": "1e3cc750-37e0-4d61-dac1-a6d314b54ec8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: missing operand\n",
      "Try 'mkdir --help' for more information.\n",
      "cp: target 'train.xh' is not a directory\n",
      "cp: target 'test.xh' is not a directory\n",
      "cp: target 'dev.xh' is not a directory\n",
      "cp: missing destination file operand after 'bpe.codes.4000'\n",
      "Try 'cp --help' for more information.\n",
      "bpe.codes.4000\tdev.xh\t      sample_data  test.xh\t train.xh\n",
      "dev.bpe.en\ten-xh.tmx     test.bpe.en  train.bpe.en  vocab.en\n",
      "dev.bpe.xh\ten-xh.tmx.gz  test.bpe.xh  train.bpe.xh  vocab.xh\n",
      "dev.en\t\tjoeynmt       test.en\t   train.en\n",
      "BPE Xhosa Sentences\n",
      "is@@ enzo soku@@ jika inqanawa kwelinye icala kwindawo yayo yokum@@ isa (@@ uku@@ jika kwisiphelo ukuya kwes@@ inye isiph@@ el@@ o@@ ).\n",
      "\"um@@ linganiselo w@@ enyawo ezint@@ andathu uling@@ ana ne ft ezint@@ and@@ athu. umlinganiselo w@@ enyawo ezint@@ andathu ing@@ um@@ v@@ o jikelele wom@@ linganiselo w@@ entamb@@ o, intambo y@@ entsimb@@ i, ubun@@ zulu b@@ amanzi kunye nes@@ and@@ i.\"\n",
      "\"xa ints@@ on@@ el@@ e@@ o yokubophelela inqanawa iling@@ ana nem@@ ay@@ ile ezil@@ ishumi (@@ im@@ ay@@ ile zas@@ elw@@ and@@ le@@ ) kwaye ilinganis@@ elwe ne@@ 6@@ 8@@ 0@@ f@@ t, okanye nje kwi@@ 20@@ 0 y@@ d. ngum@@ v@@ o woku@@ linganis@@ elela im@@ igama om@@ f@@ utsh@@ ane. (@@ ubude be ankile y@@ ents@@ ontela yokubophelela inqanawa kuqala bab@@ ukh@@ e bay@@ i@@ 10@@ 1 y@@ enyawo ezint@@ andathu (@@ 60@@ 6 f@@ t@@ ), ubude be@@ ankile y@@ ents@@ ontela yoku@@ b@@ ph@@ elela inqanawa yez@@ inqanawa zikh@@ ona iy@@ ash@@ iy@@ an ngok@@ obung@@ akan@@ an@@ a@@ i benqanawa kwaye ayin@@ akun@@ yam@@ ez@@ ela un@@ xulum@@ ano kum@@ linganiselo w@@ ents@@ ont@@ elo.\"\n",
      "\"im@@ ay@@ ile enye y@@ olwandle iling@@ ana kunye ne 6@@ ,@@ 0@@ 8@@ 0 f@@ t, okanye nje 2@@ ,@@ 00@@ 00 y@@ d. ing@@ umlinganiselo wom@@ gama om@@ de@@ .\"\n",
      "\"is@@ at@@ ya senqanawa ngum@@ v@@ o ol@@ ing@@ ana m@@ em@@ ay@@ ile yas@@ elwandle ng@@ ey@@ ure. umzekelo inqanawa ing@@ abal@@ eka ngesantya es@@ ik@@ u 15@@ . (@@ xa isantya esib@@ onisa ng@@ ey@@ ure s@@ iph@@ os@@ isa kufuneka sing@@ aph@@ inde sis@@ ety@@ en@@ n@@ z@@ iswe uku@@ ch@@ aza is@@ anty@@ a@@ .@@ ) el@@ igama ling@@ undoqo lis@@ us@@ el@@ akw@@ indlela es@@ etyenzisw@@ ayo yoku@@ linganisa isantya ng@@ ents@@ uku soku@@ hamba ng@@ enqanawa, xa iqh@@ ek@@ eza lo m@@ thi li@@ the l@@ ach@@ amath@@ ela kumgca l@@ iph@@ os@@ wa emanzin@@ i, un@@ inzi lwes@@ antya senqanawa olun@@ eth@@ uba ol@@ uling@@ anayo kumgca o@@ gq@@ itha kum@@ va wenqanawa kwixesha elim@@ isiweyo in@@ ika isantya n@@ qanaw@@ a.\"\n",
      "Combined BPE Vocab\n",
      "uld\n",
      "\n",
      "ü@@\n",
      "…@@\n",
      ">\n",
      "strum@@\n",
      "…\n",
      "}\n",
      "`\n",
      "@@\n"
     ]
    }
   ],
   "source": [
    "# One of the huge boosts in NMT performance was to use a different method of tokenizing. \n",
    "# Usually, NMT would tokenize by words. However, using a method called BPE gave amazing boosts to performance\n",
    "\n",
    "# Do subword NMT\n",
    "from os import pathos.environ[\"data_path\"] = path.join(\"joeynmt\", \"data\", source_language + target_language) # Herman! subword-nmt learn-joint-bpe-and-vocab --input train.$src train.$tgt -s 4000 -o bpe.codes.4000 --write-vocabulary vocab.$src vocab.$tgt\n",
    "\n",
    "! subword-nmt apply-bpe -c bpe.codes.4000 --vocabulary vocab.$src < train.$src > train.bpe.$src\n",
    "! subword-nmt apply-bpe -c bpe.codes.4000 --vocabulary vocab.$tgt < train.$tgt > train.bpe.$tgt\n",
    "\n",
    "! subword-nmt apply-bpe -c bpe.codes.4000 --vocabulary vocab.$src < dev.$src > dev.bpe.$src\n",
    "! subword-nmt apply-bpe -c bpe.codes.4000 --vocabulary vocab.$tgt < dev.$tgt > dev.bpe.$tgt\n",
    "! subword-nmt apply-bpe -c bpe.codes.4000 --vocabulary vocab.$src < test.$src > test.bpe.$src\n",
    "! subword-nmt apply-bpe -c bpe.codes.4000 --vocabulary vocab.$tgt < test.$tgt > test.bpe.$tgt\n",
    "\n",
    "# Create directory, move everyone we care about to the correct location\n",
    "! mkdir -p $data_path\n",
    "! cp train.* $data_path\n",
    "! cp test.* $data_path\n",
    "! cp dev.* $data_path\n",
    "! cp bpe.codes.4000 $data_path\n",
    "! ls $data_path\n",
    "\n",
    "# Create that vocab using build_vocab\n",
    "! sudo chmod 777 joeynmt/scripts/build_vocab.py\n",
    "! joeynmt/scripts/build_vocab.py joeynmt/data/$src$tgt/train.bpe.$src joeynmt/data/$src$tgt/train.bpe.$tgt --output_path joeynmt/data/$src$tgt/vocab.txt\n",
    "\n",
    "# Some output\n",
    "! echo \"BPE Xhosa Sentences\"\n",
    "! tail -n 5 test.bpe.$tgt\n",
    "! echo \"Combined BPE Vocab\"\n",
    "! tail -n 10 joeynmt/data/enxh/vocab.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ixmzi60WsUZ8"
   },
   "source": [
    "# Creating the JoeyNMT Config\n",
    "\n",
    "JoeyNMT requires a yaml config. We provide a template below. We've also set a number of defaults with it, that you may play with!\n",
    "\n",
    "- We used Transformer architecture \n",
    "- We set our dropout to reasonably high: 0.3 (recommended in  [(Sennrich, 2019)](https://www.aclweb.org/anthology/P19-1021))\n",
    "\n",
    "Things worth playing with:\n",
    "- The batch size (also recommended to change for low-resourced languages)\n",
    "- The number of epochs (we've set it at 30 just so it runs in about an hour, for testing purposes)\n",
    "- The decoder options (beam_size, alpha)\n",
    "- Evaluation metrics (BLEU versus Crhf4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "PIs1lY2hxMsl",
    "outputId": "ac86984b-5a7b-484a-8cfe-e9c87d14caee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "name: \"enxh_transformer\"\n",
      "\n",
      "data:\n",
      "    src: \"en\"\n",
      "    trg: \"xh\"\n",
      "    train: \"data/enxh/train.bpe\"\n",
      "    dev:   \"data/enxh/dev.bpe\"\n",
      "    test:  \"data/enxh/test.bpe\"\n",
      "    level: \"bpe\"\n",
      "    lowercase: False\n",
      "    max_sent_length: 100\n",
      "    src_vocab: \"data/enxh/vocab.txt\"\n",
      "    trg_vocab: \"data/enxh/vocab.txt\"\n",
      "\n",
      "testing:\n",
      "    beam_size: 5\n",
      "    alpha: 1.0\n",
      "\n",
      "training:\n",
      "    #load_model: \"models/enxh_transformer/12000.ckpt\" # if given, load a pre-trained model from this checkpoint\n",
      "    random_seed: 42\n",
      "    optimizer: \"adam\"\n",
      "    normalization: \"tokens\"\n",
      "    adam_betas: [0.9, 0.999] \n",
      "    scheduling: \"noam\"            # Try switching from plateau to Noam scheduling\n",
      "    learning_rate_factor: 0.5       # factor for Noam scheduler (used with Transformer)\n",
      "    learning_rate_warmup: 1000      # warmup steps for Noam scheduler (used with Transformer)\n",
      "    patience: 8\n",
      "    decrease_factor: 0.7\n",
      "    loss: \"crossentropy\"\n",
      "    learning_rate: 0.0002\n",
      "    learning_rate_min: 0.00000001\n",
      "    weight_decay: 0.0\n",
      "    label_smoothing: 0.1\n",
      "    batch_size: 4096\n",
      "    batch_type: \"token\"\n",
      "    eval_batch_size: 3600\n",
      "    eval_batch_type: \"token\"\n",
      "    batch_multiplier: 1\n",
      "    early_stopping_metric: \"ppl\"\n",
      "    epochs: 30 # Decreased for testing\n",
      "    validation_freq: 4000 # Decrease this for testing\n",
      "    logging_freq: 100\n",
      "    eval_metric: \"bleu\"\n",
      "    model_dir: \"models/enxh_transformer\"\n",
      "    overwrite: True\n",
      "    shuffle: True\n",
      "    use_cuda: True\n",
      "    max_output_length: 100\n",
      "    print_valid_sents: [0, 1, 2, 3]\n",
      "    keep_last_ckpts: 3\n",
      "\n",
      "model:\n",
      "    initializer: \"xavier\"\n",
      "    bias_initializer: \"zeros\"\n",
      "    init_gain: 1.0\n",
      "    embed_initializer: \"xavier\"\n",
      "    embed_init_gain: 1.0\n",
      "    tied_embeddings: True\n",
      "    tied_softmax: True\n",
      "    encoder:\n",
      "        type: \"transformer\"\n",
      "        num_layers: 6\n",
      "        num_heads: 8\n",
      "        embeddings:\n",
      "            embedding_dim: 512\n",
      "            scale: True\n",
      "            dropout: 0.\n",
      "        # typically ff_size = 4 x hidden_size\n",
      "        hidden_size: 512\n",
      "        ff_size: 2048\n",
      "        dropout: 0.3\n",
      "    decoder:\n",
      "        type: \"transformer\"\n",
      "        num_layers: 6\n",
      "        num_heads: 8\n",
      "        embeddings:\n",
      "            embedding_dim: 512\n",
      "            scale: True\n",
      "            dropout: 0.\n",
      "        # typically ff_size = 4 x hidden_size\n",
      "        hidden_size: 512\n",
      "        ff_size: 2048\n",
      "        dropout: 0.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# This creates the config file for our JoeyNMT system. It might seem overwhelming so we've provided a couple of useful parameters you'll need to update\n",
    "# (You can of course play with all the parameters if you'd like!)\n",
    "name = '%s%s' % (source_language, target_language)\n",
    "\n",
    "config = \"\"\"\n",
    "name: \"{name}_transformer\"\n",
    "\n",
    "data:\n",
    "    src: \"{source_language}\"\n",
    "    trg: \"{target_language}\"\n",
    "    train: \"data/{name}/train.bpe\"\n",
    "    dev:   \"data/{name}/dev.bpe\"\n",
    "    test:  \"data/{name}/test.bpe\"\n",
    "    level: \"bpe\"\n",
    "    lowercase: False\n",
    "    max_sent_length: 100\n",
    "    src_vocab: \"data/{name}/vocab.txt\"\n",
    "    trg_vocab: \"data/{name}/vocab.txt\"\n",
    "\n",
    "testing:\n",
    "    beam_size: 5\n",
    "    alpha: 1.0\n",
    "\n",
    "training:\n",
    "    #load_model: \"models/{name}_transformer/12000.ckpt\" # if given, load a pre-trained model from this checkpoint\n",
    "    random_seed: 42\n",
    "    optimizer: \"adam\"\n",
    "    normalization: \"tokens\"\n",
    "    adam_betas: [0.9, 0.999] \n",
    "    scheduling: \"noam\"            # Try switching from plateau to Noam scheduling\n",
    "    learning_rate_factor: 0.5       # factor for Noam scheduler (used with Transformer)\n",
    "    learning_rate_warmup: 1000      # warmup steps for Noam scheduler (used with Transformer)\n",
    "    patience: 8\n",
    "    decrease_factor: 0.7\n",
    "    loss: \"crossentropy\"\n",
    "    learning_rate: 0.0002\n",
    "    learning_rate_min: 0.00000001\n",
    "    weight_decay: 0.0\n",
    "    label_smoothing: 0.1\n",
    "    batch_size: 4096\n",
    "    batch_type: \"token\"\n",
    "    eval_batch_size: 3600\n",
    "    eval_batch_type: \"token\"\n",
    "    batch_multiplier: 1\n",
    "    early_stopping_metric: \"ppl\"\n",
    "    epochs: 100 # TODO: Decrease for when playing around and checking of working. Around 30 is sufficient to check if its working at all\n",
    "    validation_freq: 4000 # Decrease this for testing\n",
    "    logging_freq: 100\n",
    "    eval_metric: \"bleu\"\n",
    "    model_dir: \"models/{name}_transformer\"\n",
    "    overwrite: True\n",
    "    shuffle: True\n",
    "    use_cuda: True\n",
    "    max_output_length: 100\n",
    "    print_valid_sents: [0, 1, 2, 3]\n",
    "    keep_last_ckpts: 3\n",
    "\n",
    "model:\n",
    "    initializer: \"xavier\"\n",
    "    bias_initializer: \"zeros\"\n",
    "    init_gain: 1.0\n",
    "    embed_initializer: \"xavier\"\n",
    "    embed_init_gain: 1.0\n",
    "    tied_embeddings: True\n",
    "    tied_softmax: True\n",
    "    encoder:\n",
    "        type: \"transformer\"\n",
    "        num_layers: 6\n",
    "        num_heads: 8\n",
    "        embeddings:\n",
    "            embedding_dim: 512\n",
    "            scale: True\n",
    "            dropout: 0.\n",
    "        # typically ff_size = 4 x hidden_size\n",
    "        hidden_size: 512\n",
    "        ff_size: 2048\n",
    "        dropout: 0.3\n",
    "    decoder:\n",
    "        type: \"transformer\"\n",
    "        num_layers: 6\n",
    "        num_heads: 8\n",
    "        embeddings:\n",
    "            embedding_dim: 512\n",
    "            scale: True\n",
    "            dropout: 0.\n",
    "        # typically ff_size = 4 x hidden_size\n",
    "        hidden_size: 512\n",
    "        ff_size: 2048\n",
    "        dropout: 0.3\n",
    "\"\"\".format(name=name, source_language=source_language, target_language=target_language)\n",
    "with open(\"joeynmt/configs/transformer_{name}.yaml\".format(name=name),'w') as f:\n",
    "    f.write(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pIifxE3Qzuvs"
   },
   "source": [
    "# Train the Model\n",
    "\n",
    "This single line of joeynmt runs the training using the config we made above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "6ZBPFwT94WpI",
    "outputId": "c870c696-97dd-4a64-cba7-51099fe828e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-11 13:02:03,892 Hello! This is Joey-NMT.\n",
      "2019-08-11 13:02:03,898 Total params: 46273024\n",
      "2019-08-11 13:02:03,899 Trainable parameters: ['decoder.layer_norm.bias', 'decoder.layer_norm.weight', 'decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'decoder.layers.1.dec_layer_norm.bias', 'decoder.layers.1.dec_layer_norm.weight', 'decoder.layers.1.feed_forward.layer_norm.bias', 'decoder.layers.1.feed_forward.layer_norm.weight', 'decoder.layers.1.feed_forward.pwff_layer.0.bias', 'decoder.layers.1.feed_forward.pwff_layer.0.weight', 'decoder.layers.1.feed_forward.pwff_layer.3.bias', 'decoder.layers.1.feed_forward.pwff_layer.3.weight', 'decoder.layers.1.src_trg_att.k_layer.bias', 'decoder.layers.1.src_trg_att.k_layer.weight', 'decoder.layers.1.src_trg_att.output_layer.bias', 'decoder.layers.1.src_trg_att.output_layer.weight', 'decoder.layers.1.src_trg_att.q_layer.bias', 'decoder.layers.1.src_trg_att.q_layer.weight', 'decoder.layers.1.src_trg_att.v_layer.bias', 'decoder.layers.1.src_trg_att.v_layer.weight', 'decoder.layers.1.trg_trg_att.k_layer.bias', 'decoder.layers.1.trg_trg_att.k_layer.weight', 'decoder.layers.1.trg_trg_att.output_layer.bias', 'decoder.layers.1.trg_trg_att.output_layer.weight', 'decoder.layers.1.trg_trg_att.q_layer.bias', 'decoder.layers.1.trg_trg_att.q_layer.weight', 'decoder.layers.1.trg_trg_att.v_layer.bias', 'decoder.layers.1.trg_trg_att.v_layer.weight', 'decoder.layers.1.x_layer_norm.bias', 'decoder.layers.1.x_layer_norm.weight', 'decoder.layers.2.dec_layer_norm.bias', 'decoder.layers.2.dec_layer_norm.weight', 'decoder.layers.2.feed_forward.layer_norm.bias', 'decoder.layers.2.feed_forward.layer_norm.weight', 'decoder.layers.2.feed_forward.pwff_layer.0.bias', 'decoder.layers.2.feed_forward.pwff_layer.0.weight', 'decoder.layers.2.feed_forward.pwff_layer.3.bias', 'decoder.layers.2.feed_forward.pwff_layer.3.weight', 'decoder.layers.2.src_trg_att.k_layer.bias', 'decoder.layers.2.src_trg_att.k_layer.weight', 'decoder.layers.2.src_trg_att.output_layer.bias', 'decoder.layers.2.src_trg_att.output_layer.weight', 'decoder.layers.2.src_trg_att.q_layer.bias', 'decoder.layers.2.src_trg_att.q_layer.weight', 'decoder.layers.2.src_trg_att.v_layer.bias', 'decoder.layers.2.src_trg_att.v_layer.weight', 'decoder.layers.2.trg_trg_att.k_layer.bias', 'decoder.layers.2.trg_trg_att.k_layer.weight', 'decoder.layers.2.trg_trg_att.output_layer.bias', 'decoder.layers.2.trg_trg_att.output_layer.weight', 'decoder.layers.2.trg_trg_att.q_layer.bias', 'decoder.layers.2.trg_trg_att.q_layer.weight', 'decoder.layers.2.trg_trg_att.v_layer.bias', 'decoder.layers.2.trg_trg_att.v_layer.weight', 'decoder.layers.2.x_layer_norm.bias', 'decoder.layers.2.x_layer_norm.weight', 'decoder.layers.3.dec_layer_norm.bias', 'decoder.layers.3.dec_layer_norm.weight', 'decoder.layers.3.feed_forward.layer_norm.bias', 'decoder.layers.3.feed_forward.layer_norm.weight', 'decoder.layers.3.feed_forward.pwff_layer.0.bias', 'decoder.layers.3.feed_forward.pwff_layer.0.weight', 'decoder.layers.3.feed_forward.pwff_layer.3.bias', 'decoder.layers.3.feed_forward.pwff_layer.3.weight', 'decoder.layers.3.src_trg_att.k_layer.bias', 'decoder.layers.3.src_trg_att.k_layer.weight', 'decoder.layers.3.src_trg_att.output_layer.bias', 'decoder.layers.3.src_trg_att.output_layer.weight', 'decoder.layers.3.src_trg_att.q_layer.bias', 'decoder.layers.3.src_trg_att.q_layer.weight', 'decoder.layers.3.src_trg_att.v_layer.bias', 'decoder.layers.3.src_trg_att.v_layer.weight', 'decoder.layers.3.trg_trg_att.k_layer.bias', 'decoder.layers.3.trg_trg_att.k_layer.weight', 'decoder.layers.3.trg_trg_att.output_layer.bias', 'decoder.layers.3.trg_trg_att.output_layer.weight', 'decoder.layers.3.trg_trg_att.q_layer.bias', 'decoder.layers.3.trg_trg_att.q_layer.weight', 'decoder.layers.3.trg_trg_att.v_layer.bias', 'decoder.layers.3.trg_trg_att.v_layer.weight', 'decoder.layers.3.x_layer_norm.bias', 'decoder.layers.3.x_layer_norm.weight', 'decoder.layers.4.dec_layer_norm.bias', 'decoder.layers.4.dec_layer_norm.weight', 'decoder.layers.4.feed_forward.layer_norm.bias', 'decoder.layers.4.feed_forward.layer_norm.weight', 'decoder.layers.4.feed_forward.pwff_layer.0.bias', 'decoder.layers.4.feed_forward.pwff_layer.0.weight', 'decoder.layers.4.feed_forward.pwff_layer.3.bias', 'decoder.layers.4.feed_forward.pwff_layer.3.weight', 'decoder.layers.4.src_trg_att.k_layer.bias', 'decoder.layers.4.src_trg_att.k_layer.weight', 'decoder.layers.4.src_trg_att.output_layer.bias', 'decoder.layers.4.src_trg_att.output_layer.weight', 'decoder.layers.4.src_trg_att.q_layer.bias', 'decoder.layers.4.src_trg_att.q_layer.weight', 'decoder.layers.4.src_trg_att.v_layer.bias', 'decoder.layers.4.src_trg_att.v_layer.weight', 'decoder.layers.4.trg_trg_att.k_layer.bias', 'decoder.layers.4.trg_trg_att.k_layer.weight', 'decoder.layers.4.trg_trg_att.output_layer.bias', 'decoder.layers.4.trg_trg_att.output_layer.weight', 'decoder.layers.4.trg_trg_att.q_layer.bias', 'decoder.layers.4.trg_trg_att.q_layer.weight', 'decoder.layers.4.trg_trg_att.v_layer.bias', 'decoder.layers.4.trg_trg_att.v_layer.weight', 'decoder.layers.4.x_layer_norm.bias', 'decoder.layers.4.x_layer_norm.weight', 'decoder.layers.5.dec_layer_norm.bias', 'decoder.layers.5.dec_layer_norm.weight', 'decoder.layers.5.feed_forward.layer_norm.bias', 'decoder.layers.5.feed_forward.layer_norm.weight', 'decoder.layers.5.feed_forward.pwff_layer.0.bias', 'decoder.layers.5.feed_forward.pwff_layer.0.weight', 'decoder.layers.5.feed_forward.pwff_layer.3.bias', 'decoder.layers.5.feed_forward.pwff_layer.3.weight', 'decoder.layers.5.src_trg_att.k_layer.bias', 'decoder.layers.5.src_trg_att.k_layer.weight', 'decoder.layers.5.src_trg_att.output_layer.bias', 'decoder.layers.5.src_trg_att.output_layer.weight', 'decoder.layers.5.src_trg_att.q_layer.bias', 'decoder.layers.5.src_trg_att.q_layer.weight', 'decoder.layers.5.src_trg_att.v_layer.bias', 'decoder.layers.5.src_trg_att.v_layer.weight', 'decoder.layers.5.trg_trg_att.k_layer.bias', 'decoder.layers.5.trg_trg_att.k_layer.weight', 'decoder.layers.5.trg_trg_att.output_layer.bias', 'decoder.layers.5.trg_trg_att.output_layer.weight', 'decoder.layers.5.trg_trg_att.q_layer.bias', 'decoder.layers.5.trg_trg_att.q_layer.weight', 'decoder.layers.5.trg_trg_att.v_layer.bias', 'decoder.layers.5.trg_trg_att.v_layer.weight', 'decoder.layers.5.x_layer_norm.bias', 'decoder.layers.5.x_layer_norm.weight', 'encoder.layer_norm.bias', 'encoder.layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'encoder.layers.3.feed_forward.layer_norm.bias', 'encoder.layers.3.feed_forward.layer_norm.weight', 'encoder.layers.3.feed_forward.pwff_layer.0.bias', 'encoder.layers.3.feed_forward.pwff_layer.0.weight', 'encoder.layers.3.feed_forward.pwff_layer.3.bias', 'encoder.layers.3.feed_forward.pwff_layer.3.weight', 'encoder.layers.3.layer_norm.bias', 'encoder.layers.3.layer_norm.weight', 'encoder.layers.3.src_src_att.k_layer.bias', 'encoder.layers.3.src_src_att.k_layer.weight', 'encoder.layers.3.src_src_att.output_layer.bias', 'encoder.layers.3.src_src_att.output_layer.weight', 'encoder.layers.3.src_src_att.q_layer.bias', 'encoder.layers.3.src_src_att.q_layer.weight', 'encoder.layers.3.src_src_att.v_layer.bias', 'encoder.layers.3.src_src_att.v_layer.weight', 'encoder.layers.4.feed_forward.layer_norm.bias', 'encoder.layers.4.feed_forward.layer_norm.weight', 'encoder.layers.4.feed_forward.pwff_layer.0.bias', 'encoder.layers.4.feed_forward.pwff_layer.0.weight', 'encoder.layers.4.feed_forward.pwff_layer.3.bias', 'encoder.layers.4.feed_forward.pwff_layer.3.weight', 'encoder.layers.4.layer_norm.bias', 'encoder.layers.4.layer_norm.weight', 'encoder.layers.4.src_src_att.k_layer.bias', 'encoder.layers.4.src_src_att.k_layer.weight', 'encoder.layers.4.src_src_att.output_layer.bias', 'encoder.layers.4.src_src_att.output_layer.weight', 'encoder.layers.4.src_src_att.q_layer.bias', 'encoder.layers.4.src_src_att.q_layer.weight', 'encoder.layers.4.src_src_att.v_layer.bias', 'encoder.layers.4.src_src_att.v_layer.weight', 'encoder.layers.5.feed_forward.layer_norm.bias', 'encoder.layers.5.feed_forward.layer_norm.weight', 'encoder.layers.5.feed_forward.pwff_layer.0.bias', 'encoder.layers.5.feed_forward.pwff_layer.0.weight', 'encoder.layers.5.feed_forward.pwff_layer.3.bias', 'encoder.layers.5.feed_forward.pwff_layer.3.weight', 'encoder.layers.5.layer_norm.bias', 'encoder.layers.5.layer_norm.weight', 'encoder.layers.5.src_src_att.k_layer.bias', 'encoder.layers.5.src_src_att.k_layer.weight', 'encoder.layers.5.src_src_att.output_layer.bias', 'encoder.layers.5.src_src_att.output_layer.weight', 'encoder.layers.5.src_src_att.q_layer.bias', 'encoder.layers.5.src_src_att.q_layer.weight', 'encoder.layers.5.src_src_att.v_layer.bias', 'encoder.layers.5.src_src_att.v_layer.weight', 'src_embed.lut.weight']\n",
      "2019-08-11 13:02:07,993 cfg.name                           : enxh_transformer\n",
      "2019-08-11 13:02:07,993 cfg.data.src                       : en\n",
      "2019-08-11 13:02:07,993 cfg.data.trg                       : xh\n",
      "2019-08-11 13:02:07,993 cfg.data.train                     : data/enxh/train.bpe\n",
      "2019-08-11 13:02:07,993 cfg.data.dev                       : data/enxh/dev.bpe\n",
      "2019-08-11 13:02:07,993 cfg.data.test                      : data/enxh/test.bpe\n",
      "2019-08-11 13:02:07,993 cfg.data.level                     : bpe\n",
      "2019-08-11 13:02:07,993 cfg.data.lowercase                 : False\n",
      "2019-08-11 13:02:07,993 cfg.data.max_sent_length           : 100\n",
      "2019-08-11 13:02:07,993 cfg.data.src_vocab                 : data/enxh/vocab.txt\n",
      "2019-08-11 13:02:07,993 cfg.data.trg_vocab                 : data/enxh/vocab.txt\n",
      "2019-08-11 13:02:07,993 cfg.testing.beam_size              : 5\n",
      "2019-08-11 13:02:07,994 cfg.testing.alpha                  : 1.0\n",
      "2019-08-11 13:02:07,994 cfg.training.random_seed           : 42\n",
      "2019-08-11 13:02:07,994 cfg.training.optimizer             : adam\n",
      "2019-08-11 13:02:07,994 cfg.training.normalization         : tokens\n",
      "2019-08-11 13:02:07,994 cfg.training.adam_betas            : [0.9, 0.999]\n",
      "2019-08-11 13:02:07,994 cfg.training.scheduling            : noam\n",
      "2019-08-11 13:02:07,994 cfg.training.learning_rate_factor  : 0.5\n",
      "2019-08-11 13:02:07,994 cfg.training.learning_rate_warmup  : 1000\n",
      "2019-08-11 13:02:07,994 cfg.training.patience              : 8\n",
      "2019-08-11 13:02:07,994 cfg.training.decrease_factor       : 0.7\n",
      "2019-08-11 13:02:07,994 cfg.training.loss                  : crossentropy\n",
      "2019-08-11 13:02:07,994 cfg.training.learning_rate         : 0.0002\n",
      "2019-08-11 13:02:07,994 cfg.training.learning_rate_min     : 1e-08\n",
      "2019-08-11 13:02:07,994 cfg.training.weight_decay          : 0.0\n",
      "2019-08-11 13:02:07,994 cfg.training.label_smoothing       : 0.1\n",
      "2019-08-11 13:02:07,994 cfg.training.batch_size            : 4096\n",
      "2019-08-11 13:02:07,994 cfg.training.batch_type            : token\n",
      "2019-08-11 13:02:07,994 cfg.training.eval_batch_size       : 3600\n",
      "2019-08-11 13:02:07,995 cfg.training.eval_batch_type       : token\n",
      "2019-08-11 13:02:07,995 cfg.training.batch_multiplier      : 1\n",
      "2019-08-11 13:02:07,995 cfg.training.early_stopping_metric : ppl\n",
      "2019-08-11 13:02:07,995 cfg.training.epochs                : 30\n",
      "2019-08-11 13:02:07,995 cfg.training.validation_freq       : 4000\n",
      "2019-08-11 13:02:07,995 cfg.training.logging_freq          : 100\n",
      "2019-08-11 13:02:07,995 cfg.training.eval_metric           : bleu\n",
      "2019-08-11 13:02:07,995 cfg.training.model_dir             : models/enxh_transformer\n",
      "2019-08-11 13:02:07,995 cfg.training.overwrite             : True\n",
      "2019-08-11 13:02:07,995 cfg.training.shuffle               : True\n",
      "2019-08-11 13:02:07,995 cfg.training.use_cuda              : True\n",
      "2019-08-11 13:02:07,995 cfg.training.max_output_length     : 100\n",
      "2019-08-11 13:02:07,995 cfg.training.print_valid_sents     : [0, 1, 2, 3]\n",
      "2019-08-11 13:02:07,995 cfg.training.keep_last_ckpts       : 3\n",
      "2019-08-11 13:02:07,995 cfg.model.initializer              : xavier\n",
      "2019-08-11 13:02:07,995 cfg.model.bias_initializer         : zeros\n",
      "2019-08-11 13:02:07,995 cfg.model.init_gain                : 1.0\n",
      "2019-08-11 13:02:07,995 cfg.model.embed_initializer        : xavier\n",
      "2019-08-11 13:02:07,996 cfg.model.embed_init_gain          : 1.0\n",
      "2019-08-11 13:02:07,996 cfg.model.tied_embeddings          : True\n",
      "2019-08-11 13:02:07,996 cfg.model.tied_softmax             : True\n",
      "2019-08-11 13:02:07,996 cfg.model.encoder.type             : transformer\n",
      "2019-08-11 13:02:07,996 cfg.model.encoder.num_layers       : 6\n",
      "2019-08-11 13:02:07,996 cfg.model.encoder.num_heads        : 8\n",
      "2019-08-11 13:02:07,996 cfg.model.encoder.embeddings.embedding_dim : 512\n",
      "2019-08-11 13:02:07,996 cfg.model.encoder.embeddings.scale : True\n",
      "2019-08-11 13:02:07,996 cfg.model.encoder.embeddings.dropout : 0.0\n",
      "2019-08-11 13:02:07,996 cfg.model.encoder.hidden_size      : 512\n",
      "2019-08-11 13:02:07,996 cfg.model.encoder.ff_size          : 2048\n",
      "2019-08-11 13:02:07,996 cfg.model.encoder.dropout          : 0.3\n",
      "2019-08-11 13:02:07,996 cfg.model.decoder.type             : transformer\n",
      "2019-08-11 13:02:07,996 cfg.model.decoder.num_layers       : 6\n",
      "2019-08-11 13:02:07,996 cfg.model.decoder.num_heads        : 8\n",
      "2019-08-11 13:02:07,996 cfg.model.decoder.embeddings.embedding_dim : 512\n",
      "2019-08-11 13:02:07,997 cfg.model.decoder.embeddings.scale : True\n",
      "2019-08-11 13:02:07,997 cfg.model.decoder.embeddings.dropout : 0.0\n",
      "2019-08-11 13:02:07,997 cfg.model.decoder.hidden_size      : 512\n",
      "2019-08-11 13:02:07,997 cfg.model.decoder.ff_size          : 2048\n",
      "2019-08-11 13:02:07,997 cfg.model.decoder.dropout          : 0.3\n",
      "2019-08-11 13:02:07,997 Data set sizes: \n",
      "\ttrain 47489,\n",
      "\tvalid 1001,\n",
      "\ttest 1001\n",
      "2019-08-11 13:02:07,997 First training example:\n",
      "\t[SRC] so@@ ur@@ c@@ e@@ _@@ s@@ ent@@ ence\n",
      "\t[TRG] t@@ arg@@ et@@ _@@ s@@ ent@@ ence\n",
      "2019-08-11 13:02:07,997 First 10 words (src): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) the (5) of (6) a (7) to (8) and (9) \"@@\n",
      "2019-08-11 13:02:07,997 First 10 words (trg): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) the (5) of (6) a (7) to (8) and (9) \"@@\n",
      "2019-08-11 13:02:07,997 Number of Src words (types): 4165\n",
      "2019-08-11 13:02:07,998 Number of Trg words (types): 4165\n",
      "2019-08-11 13:02:07,998 Model(\n",
      "\tencoder=TransformerEncoder(num_layers=6, num_heads=8),\n",
      "\tdecoder=TransformerDecoder(num_layers=6, num_heads=8),\n",
      "\tsrc_embed=Embeddings(embedding_dim=512, vocab_size=4165),\n",
      "\ttrg_embed=Embeddings(embedding_dim=512, vocab_size=4165))\n",
      "2019-08-11 13:02:08,002 EPOCH 1\n",
      "2019-08-11 13:02:40,198 Epoch   1 Step:      100 Batch Loss:     6.183726 Tokens per Sec:     6869, Lr: 0.000070\n",
      "2019-08-11 13:03:12,692 Epoch   1 Step:      200 Batch Loss:     6.111157 Tokens per Sec:    13470, Lr: 0.000140\n",
      "2019-08-11 13:03:46,136 Epoch   1 Step:      300 Batch Loss:     6.077042 Tokens per Sec:    19656, Lr: 0.000210\n",
      "2019-08-11 13:04:20,516 Epoch   1 Step:      400 Batch Loss:     5.935090 Tokens per Sec:    25520, Lr: 0.000280\n",
      "2019-08-11 13:04:55,087 Epoch   1 Step:      500 Batch Loss:     5.636033 Tokens per Sec:    31682, Lr: 0.000349\n",
      "2019-08-11 13:05:18,180 Epoch   1: total training loss 3376.25\n",
      "2019-08-11 13:05:18,181 EPOCH 2\n",
      "2019-08-11 13:05:31,188 Epoch   2 Step:      600 Batch Loss:     5.401138 Tokens per Sec:     6272, Lr: 0.000419\n",
      "2019-08-11 13:06:07,056 Epoch   2 Step:      700 Batch Loss:     5.354033 Tokens per Sec:     8460, Lr: 0.000489\n",
      "2019-08-11 13:06:43,140 Epoch   2 Step:      800 Batch Loss:     5.276667 Tokens per Sec:    14511, Lr: 0.000559\n",
      "2019-08-11 13:07:19,440 Epoch   2 Step:      900 Batch Loss:     4.685168 Tokens per Sec:    20638, Lr: 0.000629\n",
      "2019-08-11 13:07:55,030 Epoch   2 Step:     1000 Batch Loss:     4.974727 Tokens per Sec:    27152, Lr: 0.000699\n",
      "2019-08-11 13:08:30,952 Epoch   2 Step:     1100 Batch Loss:     4.634137 Tokens per Sec:    33003, Lr: 0.000666\n",
      "2019-08-11 13:08:40,319 Epoch   2: total training loss 2874.79\n",
      "2019-08-11 13:08:40,319 EPOCH 3\n",
      "2019-08-11 13:09:06,841 Epoch   3 Step:     1200 Batch Loss:     4.544964 Tokens per Sec:     6142, Lr: 0.000638\n",
      "2019-08-11 13:09:43,023 Epoch   3 Step:     1300 Batch Loss:     4.127499 Tokens per Sec:    10636, Lr: 0.000613\n",
      "2019-08-11 13:10:18,993 Epoch   3 Step:     1400 Batch Loss:     4.238897 Tokens per Sec:    16824, Lr: 0.000591\n",
      "2019-08-11 13:10:55,122 Epoch   3 Step:     1500 Batch Loss:     4.244452 Tokens per Sec:    22962, Lr: 0.000571\n",
      "2019-08-11 13:11:31,318 Epoch   3 Step:     1600 Batch Loss:     4.344046 Tokens per Sec:    29041, Lr: 0.000552\n",
      "2019-08-11 13:12:02,258 Epoch   3: total training loss 2392.49\n",
      "2019-08-11 13:12:02,259 EPOCH 4\n",
      "2019-08-11 13:12:07,465 Epoch   4 Step:     1700 Batch Loss:     3.557467 Tokens per Sec:     6037, Lr: 0.000536\n",
      "2019-08-11 13:12:43,386 Epoch   4 Step:     1800 Batch Loss:     3.613854 Tokens per Sec:     7071, Lr: 0.000521\n",
      "2019-08-11 13:13:19,548 Epoch   4 Step:     1900 Batch Loss:     3.981313 Tokens per Sec:    13078, Lr: 0.000507\n",
      "2019-08-11 13:13:55,292 Epoch   4 Step:     2000 Batch Loss:     3.956080 Tokens per Sec:    19384, Lr: 0.000494\n",
      "2019-08-11 13:14:30,922 Epoch   4 Step:     2100 Batch Loss:     3.786195 Tokens per Sec:    25536, Lr: 0.000482\n",
      "2019-08-11 13:15:07,009 Epoch   4 Step:     2200 Batch Loss:     3.820885 Tokens per Sec:    31456, Lr: 0.000471\n",
      "2019-08-11 13:15:24,269 Epoch   4: total training loss 2175.57\n",
      "2019-08-11 13:15:24,270 EPOCH 5\n",
      "2019-08-11 13:15:42,879 Epoch   5 Step:     2300 Batch Loss:     3.627681 Tokens per Sec:     6013, Lr: 0.000461\n",
      "2019-08-11 13:16:18,609 Epoch   5 Step:     2400 Batch Loss:     2.980991 Tokens per Sec:     9300, Lr: 0.000451\n",
      "2019-08-11 13:16:54,657 Epoch   5 Step:     2500 Batch Loss:     3.634264 Tokens per Sec:    15397, Lr: 0.000442\n",
      "2019-08-11 13:17:30,267 Epoch   5 Step:     2600 Batch Loss:     3.346801 Tokens per Sec:    21676, Lr: 0.000433\n",
      "2019-08-11 13:18:05,966 Epoch   5 Step:     2700 Batch Loss:     3.512352 Tokens per Sec:    27764, Lr: 0.000425\n",
      "2019-08-11 13:18:42,597 Epoch   5 Step:     2800 Batch Loss:     3.537556 Tokens per Sec:    33267, Lr: 0.000418\n",
      "2019-08-11 13:18:46,426 Epoch   5: total training loss 2032.47\n",
      "2019-08-11 13:18:46,426 EPOCH 6\n",
      "2019-08-11 13:19:17,862 Epoch   6 Step:     2900 Batch Loss:     3.391896 Tokens per Sec:     6001, Lr: 0.000410\n",
      "2019-08-11 13:19:53,677 Epoch   6 Step:     3000 Batch Loss:     3.056508 Tokens per Sec:    11363, Lr: 0.000403\n",
      "2019-08-11 13:20:29,490 Epoch   6 Step:     3100 Batch Loss:     3.558915 Tokens per Sec:    17565, Lr: 0.000397\n",
      "2019-08-11 13:21:05,586 Epoch   6 Step:     3200 Batch Loss:     2.619599 Tokens per Sec:    23585, Lr: 0.000391\n",
      "2019-08-11 13:21:41,579 Epoch   6 Step:     3300 Batch Loss:     3.543409 Tokens per Sec:    29809, Lr: 0.000385\n",
      "2019-08-11 13:22:09,234 Epoch   6: total training loss 1927.90\n",
      "2019-08-11 13:22:09,234 EPOCH 7\n",
      "2019-08-11 13:22:17,438 Epoch   7 Step:     3400 Batch Loss:     3.350644 Tokens per Sec:     6091, Lr: 0.000379\n",
      "2019-08-11 13:22:53,357 Epoch   7 Step:     3500 Batch Loss:     3.630020 Tokens per Sec:     7503, Lr: 0.000374\n",
      "2019-08-11 13:23:29,362 Epoch   7 Step:     3600 Batch Loss:     3.109764 Tokens per Sec:    13624, Lr: 0.000368\n",
      "2019-08-11 13:24:04,705 Epoch   7 Step:     3700 Batch Loss:     2.887273 Tokens per Sec:    19985, Lr: 0.000363\n",
      "2019-08-11 13:24:41,058 Epoch   7 Step:     3800 Batch Loss:     3.399018 Tokens per Sec:    25642, Lr: 0.000358\n",
      "2019-08-11 13:25:17,134 Epoch   7 Step:     3900 Batch Loss:     3.182283 Tokens per Sec:    31944, Lr: 0.000354\n",
      "2019-08-11 13:25:31,603 Epoch   7: total training loss 1816.32\n",
      "2019-08-11 13:25:31,603 EPOCH 8\n",
      "2019-08-11 13:25:53,474 Epoch   8 Step:     4000 Batch Loss:     2.323789 Tokens per Sec:     6007, Lr: 0.000349\n",
      "2019-08-11 13:28:18,607 Hooray! New best validation result [ppl]!\n",
      "2019-08-11 13:28:18,607 Saving new checkpoint.\n",
      "2019-08-11 13:28:20,131 Example #0\n",
      "2019-08-11 13:28:20,131 \tSource:     source_sentence\n",
      "2019-08-11 13:28:20,131 \tReference:  target_sentence\n",
      "2019-08-11 13:28:20,131 \tHypothesis: i-arhente yokwenene\n",
      "2019-08-11 13:28:20,131 Example #1\n",
      "2019-08-11 13:28:20,132 \tSource:     rope and its usage\n",
      "2019-08-11 13:28:20,132 \tReference:  intambo nomsebenzi ewenzayo.\n",
      "2019-08-11 13:28:20,132 \tHypothesis: intambo kunye nentsinga\n",
      "2019-08-11 13:28:20,132 Example #2\n",
      "2019-08-11 13:28:20,132 \tSource:     \"in this chapter are described the various types of rope with which a seaman works, and the manner in which he uses them.\"\n",
      "2019-08-11 13:28:20,132 \tReference:  \"kwesi sahluko sixelelwa ngendindi zeentambo athi amadoda aselwandle azisebenzise, nangendlela azisebenzisa ngayo.\"\n",
      "2019-08-11 13:28:20,132 \tHypothesis: \"kule meko zenziwe ngeemeko zentsinga zentambo zocingo zentsimbi, iingcingo kunye neentlobo zabo zonke.\"\n",
      "2019-08-11 13:28:20,132 Example #3\n",
      "2019-08-11 13:28:20,132 \tSource:     \"the chapter has been divided into seven sections, headed as follows:\"\n",
      "2019-08-11 13:28:20,132 \tReference:  \"esi sahluko sahlulwa - hlulwe kasixhenxe, zicalulwe ngokulandelayo.\"\n",
      "2019-08-11 13:28:20,132 \tHypothesis: \"amangesi ayesele ayesele ukuchaza, ngoluhlobo olulandelayo.\"\n",
      "2019-08-11 13:28:20,133 Validation result at epoch   8, step     4000: bleu:   0.54, loss: 94582.9297, ppl:  22.4176, duration: 146.6579s\n",
      "2019-08-11 13:28:55,945 Epoch   8 Step:     4100 Batch Loss:     3.050960 Tokens per Sec:     9769, Lr: 0.000345\n",
      "2019-08-11 13:29:32,433 Epoch   8 Step:     4200 Batch Loss:     3.086605 Tokens per Sec:    15757, Lr: 0.000341\n",
      "2019-08-11 13:30:08,537 Epoch   8 Step:     4300 Batch Loss:     3.405017 Tokens per Sec:    22164, Lr: 0.000337\n",
      "2019-08-11 13:30:44,266 Epoch   8 Step:     4400 Batch Loss:     3.291511 Tokens per Sec:    28466, Lr: 0.000333\n",
      "2019-08-11 13:31:20,190 Epoch   8 Step:     4500 Batch Loss:     2.516833 Tokens per Sec:    34420, Lr: 0.000329\n",
      "2019-08-11 13:31:20,974 Epoch   8: total training loss 1717.94\n",
      "2019-08-11 13:31:20,974 EPOCH 9\n",
      "2019-08-11 13:31:56,250 Epoch   9 Step:     4600 Batch Loss:     3.091045 Tokens per Sec:     6129, Lr: 0.000326\n",
      "2019-08-11 13:32:31,841 Epoch   9 Step:     4700 Batch Loss:     3.165661 Tokens per Sec:    12160, Lr: 0.000322\n",
      "2019-08-11 13:33:07,995 Epoch   9 Step:     4800 Batch Loss:     2.763155 Tokens per Sec:    18145, Lr: 0.000319\n",
      "2019-08-11 13:33:43,865 Epoch   9 Step:     4900 Batch Loss:     2.883564 Tokens per Sec:    24383, Lr: 0.000316\n",
      "2019-08-11 13:34:20,045 Epoch   9 Step:     5000 Batch Loss:     2.828076 Tokens per Sec:    30363, Lr: 0.000313\n",
      "2019-08-11 13:34:43,138 Epoch   9: total training loss 1640.43\n",
      "2019-08-11 13:34:43,139 EPOCH 10\n",
      "2019-08-11 13:34:56,308 Epoch  10 Step:     5100 Batch Loss:     3.067256 Tokens per Sec:     6144, Lr: 0.000309\n",
      "2019-08-11 13:35:32,768 Epoch  10 Step:     5200 Batch Loss:     2.917032 Tokens per Sec:     8378, Lr: 0.000306\n",
      "2019-08-11 13:36:08,670 Epoch  10 Step:     5300 Batch Loss:     2.153826 Tokens per Sec:    14598, Lr: 0.000304\n",
      "2019-08-11 13:36:44,555 Epoch  10 Step:     5400 Batch Loss:     2.719361 Tokens per Sec:    20785, Lr: 0.000301\n",
      "2019-08-11 13:37:20,290 Epoch  10 Step:     5500 Batch Loss:     3.109466 Tokens per Sec:    26980, Lr: 0.000298\n",
      "2019-08-11 13:37:56,587 Epoch  10 Step:     5600 Batch Loss:     3.074280 Tokens per Sec:    32762, Lr: 0.000295\n",
      "2019-08-11 13:38:05,287 Epoch  10: total training loss 1566.17\n",
      "2019-08-11 13:38:05,287 EPOCH 11\n",
      "2019-08-11 13:38:32,484 Epoch  11 Step:     5700 Batch Loss:     2.117684 Tokens per Sec:     6120, Lr: 0.000293\n",
      "2019-08-11 13:39:08,350 Epoch  11 Step:     5800 Batch Loss:     2.699680 Tokens per Sec:    10811, Lr: 0.000290\n",
      "2019-08-11 13:39:44,200 Epoch  11 Step:     5900 Batch Loss:     2.896962 Tokens per Sec:    16910, Lr: 0.000288\n",
      "2019-08-11 13:40:19,784 Epoch  11 Step:     6000 Batch Loss:     2.302808 Tokens per Sec:    23285, Lr: 0.000285\n",
      "2019-08-11 13:40:56,315 Epoch  11 Step:     6100 Batch Loss:     2.125336 Tokens per Sec:    28920, Lr: 0.000283\n",
      "2019-08-11 13:41:26,449 Epoch  11: total training loss 1506.96\n",
      "2019-08-11 13:41:26,449 EPOCH 12\n",
      "2019-08-11 13:41:32,266 Epoch  12 Step:     6200 Batch Loss:     2.737737 Tokens per Sec:     6010, Lr: 0.000281\n",
      "2019-08-11 13:42:07,784 Epoch  12 Step:     6300 Batch Loss:     2.436197 Tokens per Sec:     7127, Lr: 0.000278\n",
      "2019-08-11 13:42:43,644 Epoch  12 Step:     6400 Batch Loss:     2.464159 Tokens per Sec:    13220, Lr: 0.000276\n",
      "2019-08-11 13:43:20,595 Epoch  12 Step:     6500 Batch Loss:     2.567278 Tokens per Sec:    19126, Lr: 0.000274\n",
      "2019-08-11 13:43:55,943 Epoch  12 Step:     6600 Batch Loss:     3.096385 Tokens per Sec:    26069, Lr: 0.000272\n",
      "2019-08-11 13:44:31,686 Epoch  12 Step:     6700 Batch Loss:     2.988177 Tokens per Sec:    31892, Lr: 0.000270\n",
      "2019-08-11 13:44:48,436 Epoch  12: total training loss 1460.01\n",
      "2019-08-11 13:44:48,436 EPOCH 13\n",
      "2019-08-11 13:45:08,196 Epoch  13 Step:     6800 Batch Loss:     2.065612 Tokens per Sec:     6281, Lr: 0.000268\n",
      "2019-08-11 13:45:43,792 Epoch  13 Step:     6900 Batch Loss:     2.138862 Tokens per Sec:     9643, Lr: 0.000266\n",
      "2019-08-11 13:46:19,856 Epoch  13 Step:     7000 Batch Loss:     1.701815 Tokens per Sec:    15685, Lr: 0.000264\n",
      "2019-08-11 13:46:55,351 Epoch  13 Step:     7100 Batch Loss:     2.352584 Tokens per Sec:    22071, Lr: 0.000262\n",
      "2019-08-11 13:47:31,203 Epoch  13 Step:     7200 Batch Loss:     2.225352 Tokens per Sec:    28048, Lr: 0.000260\n",
      "2019-08-11 13:48:06,787 Epoch  13 Step:     7300 Batch Loss:     2.929675 Tokens per Sec:    34331, Lr: 0.000259\n",
      "2019-08-11 13:48:10,047 Epoch  13: total training loss 1412.27\n",
      "2019-08-11 13:48:10,047 EPOCH 14\n",
      "2019-08-11 13:48:42,823 Epoch  14 Step:     7400 Batch Loss:     2.357532 Tokens per Sec:     6145, Lr: 0.000257\n",
      "2019-08-11 13:49:18,862 Epoch  14 Step:     7500 Batch Loss:     2.352286 Tokens per Sec:    11768, Lr: 0.000255\n"
     ]
    }
   ],
   "source": [
    "!cd joeynmt; python3 -m joeynmt train configs/transformer_$src$tgt.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "n94wlrCjVc17",
    "outputId": "be2ed53e-4a28-4791-f05e-c4a57e4d0431"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00016000.hyps.dev   16000.ckpt\t8000.hyps      tensorboard\n",
      "00016000.hyps.test  16000.hyps\tbest.ckpt      train.log\n",
      "12000.ckpt\t    4000.hyps\tconfig.yaml    trg_vocab.txt\n",
      "12000.hyps\t    8000.ckpt\tsrc_vocab.txt  validations.txt\n",
      "Steps: 4000\tLoss: 97521.18750\tPPL: 24.69145\tbleu: 0.53349\tLR: 0.00020000\t*\n",
      "Steps: 8000\tLoss: 72234.91406\tPPL: 10.75160\tbleu: 1.73058\tLR: 0.00020000\t*\n",
      "Steps: 12000\tLoss: 56225.00781\tPPL: 6.35127\tbleu: 3.27729\tLR: 0.00020000\t*\n",
      "Steps: 16000\tLoss: 44070.66797\tPPL: 4.25896\tbleu: 6.30347\tLR: 0.00020000\t*\n"
     ]
    }
   ],
   "source": [
    "! cat joeynmt/models/$src$tgt_transformer/validations.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "66WhRE9lIhoD",
    "outputId": "b6eec75f-a9a1-46eb-dd96-d614caca9148"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-11 12:22:49,070 -  dev bleu:   7.18 [Beam search decoding with beam size = 5 and alpha = 1.0]\n",
      "2019-08-11 12:25:02,652 - test bleu:   1.74 [Beam search decoding with beam size = 5 and alpha = 1.0]\n"
     ]
    }
   ],
   "source": [
    "! cd joeynmt; python3 -m joeynmt test models/$src$tgt_transformer/config.yaml\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Masakhane - MT for African Languages",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
